{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c766fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://www.youtube.com/watch?v=fklHBWow8vE&list=RDCMUCW8Ews7tdKKkBT6GdtQaXvQ&start_radio=1&t=256s&ab_channel=StrataScratch\n",
    "#https://github.com/pawanyaddanapudi/python-for-engineering-and-analytics/tree/master/Track%204%20%7C%20Python%20Data%20Engineering%20%7C%20Real-time%20data%20%7C%20Extract%20%26%20Transform\n",
    "#https://www.geeksforgeeks.org/how-to-track-iss-international-space-station-using-python/\n",
    "#https://github.com/Strata-Scratch/api-youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579100e1",
   "metadata": {},
   "source": [
    "Organizations host their APIs on web servers. When someone types www.google.com in their browser's \n",
    "address bar, the computer is asking the www.google.com server for a web page; the server returns the page to the user's browser.\n",
    "\n",
    "APIs work the same way, except instead of the web browser asking for a web page, \n",
    "the user's program asks for a particular set of data. The API usually returns this data in JavaScript Object Notation (JSON) format (like a key:value pair format). \n",
    "\n",
    "When an API request is made to the web server about a particular data the user wants, the server then replies and sends the data to the user. In Python, the requests library is used to make the call the server (as the name suggests, requesting for the data to the web server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393f4d3",
   "metadata": {},
   "source": [
    "The main goal is to access Internation Space Station data from OpenNotify API. \n",
    "Open Notify is an open source project to provide the programming interface for some of NASA’s \n",
    "brilliant data. \n",
    "\n",
    "http://open-notify.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b157e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a get request to get the latest position of the ISS from the OpenNotify API.\n",
    "response = requests.get(\"http://api.open-notify.org/iss-now.json\")\n",
    "status_code = response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f591ffb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4eea83",
   "metadata": {},
   "source": [
    "The list of Status Codes explained below.\n",
    "\n",
    "The request we made returned a status code of 200. Web servers return status codes every time they receive an API request. A status code reports what happened with a request. \n",
    "\n",
    "Here are some codes that are relevant to GET requests:\n",
    "\n",
    "200 — Everything went okay, and the server returned a result (if any).\n",
    "\n",
    "301 — The server is redirecting the user to a different endpoint. This can happen when a company \n",
    "switches domain names, or when an endpoint's name has changed.\n",
    "\n",
    "401 — The server thinks you're not authenticated. This happens when the user doesn't send the \n",
    "right credentials to access an API.\n",
    "\n",
    "400 — The server thinks that the user has made a bad request. This can happen when the user doesn't send the information that the API requires to process the user's request (among other things).\n",
    "\n",
    "403 — The resource user is trying to access is forbidden, and the user doesn't have the right permission(s) to see it.\n",
    "\n",
    "404 — The server didn't find the resource the user is trying to access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414cd20",
   "metadata": {},
   "source": [
    "There are many type of requests among which the most common is a GET request, \n",
    "which is used to retrieve data here. OpenNotify has several API endpoints. \n",
    "\n",
    "An endpoint is a server route for retrieving specific data from an API.\n",
    "\n",
    "In the first endpoint, the iss-now.json is explored as we see above. \n",
    "\n",
    "This endpoint gets the timestamp, and the current latitude and longitude position of the ISS. \n",
    "T\n",
    "he International Space Station moves at 28000 Kph, thus the location changes every second.\n",
    "http://open-notify.org/Open-Notify-API/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c68e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a get request to get the latest position of the ISS from the OpenNotify API.\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass\")\n",
    "status_code = response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59718d",
   "metadata": {},
   "source": [
    "iss-pass wasn't a valid endpoint (since .json was missing in the end), so the API's server \n",
    "sent us a 404 status code in response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f66e04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\r\\n<head><title>404 Not Found</title></head>\\r\\n<body bgcolor=\"white\">\\r\\n<center><h1>404 Not Found</h1></center>\\r\\n<hr><center>nginx/1.10.3</center>\\r\\n</body>\\r\\n</html>\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameters we want to pass to the API.\n",
    "# This is the latitude and longitude of San Francisco City.\n",
    "parameters = {\"lat\": 37.78, \"lon\": -122.41}\n",
    "\n",
    "# Make a get request with the parameters.\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "\n",
    "# Print the content of the response (the data the server returned)\n",
    "print(response.content)\n",
    "\n",
    "content = response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed057c4",
   "metadata": {},
   "source": [
    "In the above code, we are assigning latitude and longitude values in the form of key and value pairs \n",
    "to the parameters dictionary. This way we can get the ISS (International Space Station) end point \n",
    "for a particular location on earth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3aff74",
   "metadata": {},
   "source": [
    "The above operation can also be done with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d5a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\r\\n<head><title>404 Not Found</title></head>\\r\\n<body bgcolor=\"white\">\\r\\n<center><h1>404 Not Found</h1></center>\\r\\n<hr><center>nginx/1.10.3</center>\\r\\n</body>\\r\\n</html>\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "# This gets the same data as the command above\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json?lat=37.78&lon=-122.41\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2852485",
   "metadata": {},
   "source": [
    "Handling JSON Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7913fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Import the JSON library.\n",
    "import json\n",
    "\n",
    "# Make a list of fast food chains.\n",
    "best_food_chains = [\"Taco Bell\", \"Shake Shack\", \"Chipotle\"]\n",
    "print(type(best_food_chains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "269c3d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(str(best_food_chains)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff88e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Use json.dumps to convert best_food_chains to a string.\n",
    "best_food_chains_string = json.dumps(best_food_chains)\n",
    "print(type(best_food_chains_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab84c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Convert best_food_chains_string back to a list.\n",
    "print(type(json.loads(best_food_chains_string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f030299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Taco Bell\", \"Shake Shack\", \"Chipotle\"]\n"
     ]
    }
   ],
   "source": [
    "print(best_food_chains_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1774e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Taco Bell', 'Shake Shack', 'Chipotle']\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(best_food_chains_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb22092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cdf18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Make a dictionary\n",
    "fast_food_franchise = {\n",
    "    \"Subway\": 24722,\n",
    "    \"McDonalds\": 14098,\n",
    "    \"Starbucks\": 10821,\n",
    "    \"Pizza Hut\": 7600\n",
    "}\n",
    "\n",
    "# We can also dump a dictionary to a string and load it.\n",
    "fast_food_franchise_string = json.dumps(fast_food_franchise)\n",
    "print(type(fast_food_franchise_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "554d666c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "fast_food_franchise_2 = json.loads(fast_food_franchise_string)\n",
    "print(type(fast_food_franchise_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e67b3d",
   "metadata": {},
   "source": [
    "You may have noticed that the API response we received earlier was a string. Strings are how the information is passed back and forth through APIs, but it's not easy to get the information \n",
    "we want out of them. How do we know how to decode the string we receive and work with it in Python?\n",
    "\n",
    "So JSON format comes to the rescue. This format encodes data structures like lists and dictionaries as strings to ensure that machines can read them easily. JSON is the main format for sending and receiving data through APIs.\n",
    "\n",
    "Python offers great support for JSON through the json library. We can convert lists and dictionaries \n",
    "to JSON, and vice versa. In the ISS Pass data, for example, is a dictionary encoded as a string in JSON format.\n",
    "\n",
    "The JSON library has two main methods:\n",
    "\n",
    "dumps — takes in a Python object and converts it to a string\n",
    "\n",
    "loads — takes in a JSON string and converts it to a Python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0e12060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iss_position': {'longitude': '-82.0139', 'latitude': '32.3410'}, 'message': 'success', 'timestamp': 1669095447}\n",
      "{'longitude': '-82.0139', 'latitude': '32.3410'}\n"
     ]
    }
   ],
   "source": [
    "# Make the same request we did two screens ago.\n",
    "#parameters = {\"lat\": 37.78, \"lon\": -122.41}\n",
    "#We can change the lat and long values in the link below (lat=, lon=)\n",
    "response = requests.get(\"http://api.open-notify.org/iss-now.json\")\n",
    "\n",
    "    \n",
    "# Get the response data as a Python object.  Verify that it's a dictionary.\n",
    "\n",
    "json_data = response.json()\n",
    "        \n",
    "#print(type(json_data))\n",
    "print(json_data)\n",
    "\n",
    "first_pass_duration = json_data[\"iss_position\"]\n",
    "print(first_pass_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9781460d",
   "metadata": {},
   "source": [
    "Get the duration value of the ISS's first pass over San Francisco and assign the value to \n",
    "first_pass_duration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef52587",
   "metadata": {},
   "source": [
    "#https://app.dataquest.io/c/18/m/52/working-with-apis/9/content-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4f831fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\r\n",
      "<head><title>404 Not Found</title></head>\r\n",
      "<body bgcolor=\"white\">\r\n",
      "<center><h1>404 Not Found</h1></center>\r\n",
      "<hr><center>nginx/1.10.3</center>\r\n",
      "</body>\r\n",
      "</html>\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9da4a728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"iss_position\": {\"longitude\": \"-82.0139\", \"latitude\": \"32.3410\"}, \"message\": \"success\", \"timestamp\": 1669095447}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a4b758b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Server': 'nginx/1.10.3', 'Date': 'Tue, 22 Nov 2022 05:37:28 GMT', 'Content-Type': 'application/json', 'Content-Length': '113', 'Connection': 'keep-alive', 'access-control-allow-origin': '*'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe0b13",
   "metadata": {},
   "source": [
    "Access worldwide Earthquake data from this API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f68eddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def earthquake(f):\n",
    "    paramss = {\"format\": \"geojson\", \"starttime\": \"2010-01-01\", \"endtime\": \"2021-12-31\", \"alertlevel\": \"orange\"}\n",
    "    data = requests.get(f, params = paramss)\n",
    "    data = json.loads(data.text)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0860f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1621620253565 Southern Qinghai, China 9.1 0\n",
      "1621604917193 25 km NW of Dali, China 7.9 0\n",
      "1613225269797 73 km ENE of Namie, Japan 9.1 1\n",
      "1609240794762 2 km WSW of Petrinja, Croatia 9.1 0\n",
      "1604058687348 13 km NNE of Néon Karlovásion, Greece 7.6 0\n",
      "1592926144350 9 km SE of Santa María Xadani, Mexico 7.7 1\n",
      "1588417998680 6 km S of Tallaboa, Puerto Rico 7.4 0\n",
      "1579888514147 13 km N of Do?anyol, Turkey 7.9 0\n",
      "1579440476630 104 km ENE of Kashgar, China 7.4 0\n",
      "1578385465262 13 km SSE of Maria Antonia, Puerto Rico 8.2 1\n",
      "1574736852872 15 km WSW of Mamurras, Albania 9.1 0\n",
      "1573166827041 59 km NE of Hashtr?d, Iran 7.9 0\n",
      "1569322914990 8 km SSE of New Mirpur, Pakistan 6.6 0\n",
      "1561213796148 11 km SE of Xunchang, China 5.8 0\n",
      "1558856475073 78 km NE of Navarro, Peru 8.9 1\n",
      "1547947972480 10 km SSW of Coquimbo, Chile 7.6 1\n",
      "1543598969330 1 km SE of Point MacKenzie, Alaska 7.9 1\n",
      "1536170879150 27 km ESE of Chitose, Japan 8.1 1\n",
      "1533469598630 36 km NW of Labuan Lombok, Indonesia 8.9 0\n",
      "1484734450980 5 km ESE of Cittareale, Italy 6 0\n",
      "1479034976340 53 km NNE of Amberley, New Zealand 9.1 1\n",
      "1477501837210 2 km SSE of Preci, Italy 6.7 0\n",
      "1477026442990 6 km S of Kurayoshi, Japan 7.5 1\n",
      "1460851116980 27 km SSE of Muisne, Ecuador 8.6 1\n",
      "1455408824040 12 km ENE of Christchurch, New Zealand 6.9 0\n",
      "1451862322270 29 km W of Imph?l, India 7.6 0\n",
      "1447744207300 19 km SSW of Lefkáda, Greece 7.2 0\n",
      "1445850582560 Hindu Kush region, Afghanistan 7.9 0\n",
      "1442444072860 48 km W of Illapel, Chile 9 1\n",
      "1431414319730 Nepal 7.7 0\n",
      "1412689779720 125 km SW of Jianshui, China 3.8 0\n",
      "1404732234780 4 km W of Puerto Madero, Mexico 7.7 1\n",
      "1390744542210 1 km ENE of Lixoúri, Greece 8.3 0\n",
      "1385646694000 10 km ENE of Bor?zj?n, Iran 5 0\n",
      "1381795952050 4 km SE of Sagbayan, Philippines 9.1 1\n",
      "1380353646450 129 km WSW of Khuzdar, Pakistan 7 0\n",
      "1377088709700 5 km ESE of Barrio Nuevo de los Muertos, Mexico 8.3 0\n",
      "1374450356660 60 km W of Mawu, China 6.8 0\n",
      "1365508369920 95 km SE of Bushehr, Iran 4.5 0\n",
      "1337479432000 4 km NNE of Massa Finalese, Italy 7.7 0\n"
     ]
    }
   ],
   "source": [
    "f = r\"https://earthquake.usgs.gov/fdsnws/event/1/query?\"\n",
    "a = earthquake(f)\n",
    "\n",
    "for i in (a[\"features\"]):\n",
    "    print(i[\"properties\"][\"time\"], i[\"properties\"][\"place\"], \n",
    "          i[\"properties\"][\"cdi\"], i[\"properties\"][\"tsunami\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82dab3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a['features'][0]['properties'][\"tsunami\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "019c6ffa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m (a[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproperties\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramFiles\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:756\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# For data is scalar\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 756\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame constructor not properly called!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;66;03m# Argument 1 to \"ensure_index\" has incompatible type \"Collection[Any]\";\u001b[39;00m\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;66;03m# expected \"Union[Union[Union[ExtensionArray, ndarray],\u001b[39;00m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;66;03m# Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[0;32m    761\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "for i in (a[\"features\"]):\n",
    "    pd.DataFrame(i[\"properties\"][\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb613247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://holypython.com/api-6-earthquake-data/\n",
    "#https://www.springboard.com/blog/data-science/top-apis-for-data-scientists/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620eb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://sedl.org/afterschool/toolkits/science/pdf/ast_sci_data_tables_sample.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e131c52e",
   "metadata": {},
   "source": [
    "# Extract table from pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b33b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabula-py\n",
      "  Downloading tabula_py-2.6.0-py3-none-any.whl (12.0 MB)\n",
      "Requirement already satisfied: numpy in d:\\programfiles\\anaconda3\\lib\\site-packages (from tabula-py) (1.21.5)\n",
      "Requirement already satisfied: pandas>=0.25.3 in d:\\programfiles\\anaconda3\\lib\\site-packages (from tabula-py) (1.4.2)\n",
      "Collecting distro\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pandas>=0.25.3->tabula-py) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programfiles\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.25.3->tabula-py) (1.16.0)\n",
      "Installing collected packages: distro, tabula-py\n",
      "Successfully installed distro-1.8.0 tabula-py-2.6.0\n",
      "Requirement already satisfied: tabulate in d:\\programfiles\\anaconda3\\lib\\site-packages (0.8.9)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tabula-py\n",
    "!pip3 install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b4e643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tk in d:\\programfiles\\anaconda3\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: ghostscript in d:\\programfiles\\anaconda3\\lib\\site-packages (0.7)\n",
      "Requirement already satisfied: setuptools>=38.6.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from ghostscript) (60.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tk\n",
    "!pip3 install ghostscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27ae99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - java\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac25950",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install tabula-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56da8b",
   "metadata": {},
   "source": [
    "The tabula-py is a simple Python wrapper of tabula-java, which can read tables in a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023e642a",
   "metadata": {},
   "outputs": [
    {
     "ename": "JavaNotFoundError",
     "evalue": "`java` command is not found from this Python process.Please ensure Java is installed and PATH is set for `java`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mD:\\ProgramFiles\\anaconda3\\lib\\site-packages\\tabula\\io.py:87\u001b[0m, in \u001b[0;36m_run\u001b[1;34m(java_options, options, path, encoding)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVNULL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstderr:\n",
      "File \u001b[1;32mD:\\ProgramFiles\\anaconda3\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\ProgramFiles\\anaconda3\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ProgramFiles\\anaconda3\\lib\\subprocess.py:1420\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1420\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1422\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1433\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJavaNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtabulate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tabulate\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#reads table from pdf file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mread_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMLBOOK.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mguess\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#address of pdf file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(tabulate(df))\n",
      "File \u001b[1;32mD:\\ProgramFiles\\anaconda3\\lib\\site-packages\\tabula\\io.py:426\u001b[0m, in \u001b[0;36mread_pdf\u001b[1;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, user_agent, use_raw_url, pages, guess, area, relative_area, lattice, stream, password, silent, columns, relative_columns, format, batch, output_path, options)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is empty. Check the file, or download it manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path)\n\u001b[0;32m    423\u001b[0m     )\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 426\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjava_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtabula_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m temporary:\n",
      "File \u001b[1;32mD:\\ProgramFiles\\anaconda3\\lib\\site-packages\\tabula\\io.py:98\u001b[0m, in \u001b[0;36m_run\u001b[1;34m(java_options, options, path, encoding)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JavaNotFoundError(JAVA_NOT_FOUND_ERROR)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    100\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError from tabula-java:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode(encoding)))\n",
      "\u001b[1;31mJavaNotFoundError\u001b[0m: `java` command is not found from this Python process.Please ensure Java is installed and PATH is set for `java`"
     ]
    }
   ],
   "source": [
    "from tabula import read_pdf\n",
    "from tabulate import tabulate\n",
    " \n",
    "#reads table from pdf file\n",
    "df = read_pdf(\"MLBOOK.pdf\",encoding = 'latin1', pages ='all', \n",
    "              guess = False) #address of pdf file\n",
    "print(tabulate(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "811f2ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: camelot-py[cv] in d:\\programfiles\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: tabula-py in d:\\programfiles\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (1.21.5)\n",
      "Requirement already satisfied: pdfminer.six>=20200726 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (20220524)\n",
      "Requirement already satisfied: openpyxl>=2.5.8 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (3.0.9)\n",
      "Requirement already satisfied: PyPDF2>=1.26.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (2.11.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (0.8.9)\n",
      "Requirement already satisfied: click>=6.7 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (8.0.4)\n",
      "Requirement already satisfied: chardet>=3.0.4 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (4.0.0)\n",
      "Requirement already satisfied: opencv-python>=3.4.2.17 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (4.6.0.66)\n",
      "Collecting pdftopng>=0.2.3\n",
      "  Downloading pdftopng-0.2.3-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: ghostscript>=0.7 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (0.7)\n",
      "Requirement already satisfied: distro in d:\\programfiles\\anaconda3\\lib\\site-packages (from tabula-py) (1.8.0)\n",
      "Requirement already satisfied: colorama in d:\\programfiles\\anaconda3\\lib\\site-packages (from click>=6.7->camelot-py[cv]) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=38.6.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from ghostscript>=0.7->camelot-py[cv]) (60.10.0)\n",
      "Requirement already satisfied: et-xmlfile in d:\\programfiles\\anaconda3\\lib\\site-packages (from openpyxl>=2.5.8->camelot-py[cv]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->camelot-py[cv]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->camelot-py[cv]) (2021.3)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pdfminer.six>=20200726->camelot-py[cv]) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pdfminer.six>=20200726->camelot-py[cv]) (38.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\programfiles\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[cv]) (1.15.0)\n",
      "Requirement already satisfied: pycparser in d:\\programfiles\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[cv]) (2.21)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from PyPDF2>=1.26.0->camelot-py[cv]) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programfiles\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.23.4->camelot-py[cv]) (1.16.0)\n",
      "Installing collected packages: pdftopng\n",
      "Successfully installed pdftopng-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install camelot-py[cv] tabula-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda73808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: camelot-py in d:\\programfiles\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: openpyxl>=2.5.8 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py) (1.21.5)\n",
      "Requirement already satisfied: pandas>=0.23.4 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py) (1.4.2)\n",
      "Requirement already satisfied: pdfminer.six>=20200726 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py) (20220524)\n",
      "Requirement already satisfied: chardet>=3.0.4 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py) (4.0.0)\n",
      "Requirement already satisfied: click>=6.7 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py) (8.0.4)\n",
      "Requirement already satisfied: PyPDF2>=1.26.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py) (2.11.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in d:\\programfiles\\anaconda3\\lib\\site-packages (from camelot-py) (0.8.9)\n",
      "Requirement already satisfied: colorama in d:\\programfiles\\anaconda3\\lib\\site-packages (from click>=6.7->camelot-py) (0.4.4)\n",
      "Requirement already satisfied: et-xmlfile in d:\\programfiles\\anaconda3\\lib\\site-packages (from openpyxl>=2.5.8->camelot-py) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->camelot-py) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->camelot-py) (2021.3)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pdfminer.six>=20200726->camelot-py) (38.0.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pdfminer.six>=20200726->camelot-py) (2.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\programfiles\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py) (1.15.0)\n",
      "Requirement already satisfied: pycparser in d:\\programfiles\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py) (2.21)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from PyPDF2>=1.26.0->camelot-py) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programfiles\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.23.4->camelot-py) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install camelot-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffb294d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer.six in d:\\programfiles\\anaconda3\\lib\\site-packages (20220524)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pdfminer.six) (38.0.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\programfiles\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.0)\n",
      "Requirement already satisfied: pycparser in d:\\programfiles\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3bfa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 uninstall pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9944ffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables extracted: 12\n"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "tables = camelot.read_pdf(\"MLBOOK.pdf\",pages = 'all')\n",
    "print(\"Total tables extracted:\", tables.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7300027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  1  2  3  4  5  6                  7  8  9  10\n",
      "0                                                 \n",
      "1                                                 \n",
      "2                         training errors         \n",
      "3                       validation errors         \n",
      "4                                                 \n",
      "5                                                 \n",
      "6                                                 \n"
     ]
    }
   ],
   "source": [
    "print(tables[5].df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51812dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 100.0, 'whitespace': 25.71, 'order': 1, 'page': 2}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[1].parsing_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46a08f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>training errors</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>validation errors</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0  1  2  3  4  5  6                  7  8  9  10\n",
       "0                                                 \n",
       "1                                                 \n",
       "2                         training errors         \n",
       "3                       validation errors         \n",
       "4                                                 \n",
       "5                                                 \n",
       "6                                                 "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[5].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/44324464/python-tabula-py-wont-read-pdf\n",
    "#https://tabula-py.readthedocs.io/en/latest/getting_started.html\n",
    "#https://www.analyticsvidhya.com/blog/2020/08/how-to-extract-tabular-data-from-pdf-document-using-camelot-in-python/#h2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6108726",
   "metadata": {},
   "source": [
    "Camelot vs other pdf extraction libraries\n",
    "\n",
    "https://camelot-py.readthedocs.io/en/master/#why-camelot\n",
    "\n",
    "https://github.com/camelot-dev/camelot/wiki/Comparison-with-other-PDF-Table-Extraction-libraries-and-tools    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b21060",
   "metadata": {},
   "source": [
    "# Extract text from pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "794d1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in d:\\programfiles\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from PyPDF2) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6949c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd95ab82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xref table not zero-indexed. ID numbers for objects will be corrected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/ModDate': \"D:20060706163857-04'00'\", '/CreationDate': 'D:20051108152002Z', '/Producer': 'Adobe PDF Library 5.0', '/Title': 'Sample Data for Data Tables', '/Creator': 'Adobe InDesign 2.0.2', '/Trapped': '/False'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_path=\"FOO.pdf\"\n",
    "with open(pdf_path, 'rb') as f:\n",
    "        pdf = PdfFileReader(f)\n",
    "        information = pdf.getDocumentInfo()\n",
    "        number_of_pages = pdf.getNumPages()\n",
    "        print(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc523458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea5f0c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xref table not zero-indexed. ID numbers for objects will be corrected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutoring to Enhance Science Skills\n",
      "Tutoring Two:  Learning to Make Data Tables..............................................................................................\n",
      "Sample Data for Data Tables��������������������������NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\n",
      "www.sedl.org/afterschool/toolkits\n",
      "Use these data to create data tables following the Guidelines for Making a Data Table and \n",
      "Checklist for a Data Table.\n",
      "Example 1: Pet Survey (GR 2–3)\n",
      "Ms. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary \n",
      "School. Students were asked to select their favorite pet from a list of eight animals. Here \n",
      "are the results. \n",
      "Lizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75, \n",
      "Ferret 10 \n",
      "Example 2: Electromagnets—Increasing Coils (GR 3–5)\n",
      "The following data were collected using an electromagnet with a 1.5 volt battery, a switch, \n",
      "a piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in \n",
      "repeating this experiment include using safety goggles or safety spectacles and avoiding \n",
      "short circuits.  \n",
      "  Number of Coils         Number of Paperclips\n",
      " 5 3, 5, 4\n",
      " 10        7, 8, 6\n",
      " 15  11, 10, 12\n",
      " 20  15, 13, 14\n",
      "    \n",
      "Example 3: pH of Substances (GR 5–10)\n",
      "The following are pH values of common household substances taken by three different \n",
      "teams using pH probes. Safety precautions in repeating this experiment include hooded \n",
      "ventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach, \n",
      "ammonia, or strong acids with children.\n",
      "Lemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7; \n",
      "Orange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5; \n",
      "Tomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3, \n",
      "10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach \n",
      "12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\n",
      "Lye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1, \n",
      "10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and \n",
      "Cola 3.0, 2.5, 3.2\n",
      "Teaching tip:  The pH scale is from 0 to 14. Have students make two data tables, one \n",
      "with the data as given and one with the pH scale 0 to 14 with the substances’ average \n",
      "pH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at \n",
      "the upper end) or create a pH graphic organizer .\n",
      "1© 2006 WGBH Educational Foundation. All rights reserved.Example 4: Automobile Land Speed Records (GR 5-10)\n",
      "In the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of \n",
      "Paris, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour \n",
      "(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across \n",
      "frozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American \n",
      "Eagle is trying to break a land speed record of 800 mph. The Federation International de \n",
      "L’Automobile (FIA), the world’s governing body for motor sport and land speed records, \n",
      "recorded the following land speed records. (Retrieved on February 5, 2006, from \n",
      "http://www.landspeed.com/lsrinfo.asp .)\n",
      "Speed (mph)\n",
      "407.447\n",
      "413.199\n",
      "434.22\n",
      "468.719\n",
      "526.277\n",
      "536.712\n",
      "555.127\n",
      "576.553\n",
      "600.601\n",
      "622.407\n",
      "633.468\n",
      "763.035Driver\n",
      "Craig Breedlove\n",
      "Tom Green \n",
      "Art Arfons\n",
      "Craig Breedlove\n",
      "Craig Breedlove\n",
      "Art Arfons\n",
      "Craig Breedlove\n",
      "Art Arfons\n",
      "Craig Breedlove\n",
      "Gary Gabelich\n",
      "Richard Noble \n",
      "Andy GreenCar\n",
      "Spirit of America \n",
      "Wingfoot Express \n",
      "Green Monster \n",
      "Spirit of America\n",
      "Spirit of America\n",
      "Green Monster \n",
      "Spirit of America, Sonic 1 \n",
      "Green Monster \n",
      "Spirit of America, Sonic 1\n",
      "Blue Flame \n",
      "Thrust 2 \n",
      "Thrust SSCEngine\n",
      "GE J47\n",
      "WE J46  \n",
      "GE J79 \n",
      "GE J79 \n",
      "GE J79 \n",
      "GE J79  \n",
      "GE J79 \n",
      "GE J79 \n",
      "GE J79 \n",
      "Rocket \n",
      "RR RG 146 \n",
      "RR SpeyDate\n",
      "8/5/63\n",
      "10/2/64\n",
      "10/5/64\n",
      "10/13/64\n",
      "10/15/65\n",
      "10/27/65\n",
      "11/2/65 \n",
      "11/7/65 \n",
      "11/15/65 \n",
      "10/23/70  \n",
      "10/4/83  \n",
      "10/15/97\n",
      "Example 5: Distance and Time (GR 8-10)\n",
      "The following data were collected using a car with a water clock set to release a drop in \n",
      "a unit of time and a meter stick. The car rolled down an inclined plane. Three trials were \n",
      "run. Create a data table with an average distance column and an average velocity column, \n",
      "create an average distance-time graph, and draw the best-fit line or curve. Estimate the \n",
      "car’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is \n",
      "it going at a constant speed, accelerating, or decelerating? How do you know?\n",
      "   Time (drops of water)           Distance (cm)\n",
      " 1  10,11,9\n",
      " 2  29, 31, 30\n",
      " 3  59, 58, 61\n",
      " 4  102, 100, 98\n",
      " 5  122, 125, 127    \n",
      "     \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# creating a pdf file object\n",
    "pdfFileObject = open(pdf_path, 'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "text=''\n",
    "for i in range(0,pdfReader.numPages):\n",
    "    # creating a page object\n",
    "    pageObj = pdfReader.getPage(i)\n",
    "    # extracting text from page\n",
    "    text=text+pageObj.extractText()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e876c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"MLBOOK.pdf\")\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text() + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4df9b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTRODUCTION\n",
      "TO\n",
      "MACHINE LEARNING\n",
      "AN EARLY DRAFT OF A PROPOSED\n",
      "TEXTBOOK\n",
      "Nils J. Nilsson\n",
      "Robotics Laboratory\n",
      "Department of Computer Science\n",
      "Stanford University\n",
      "Stanford, CA 94305\n",
      "e-mail: nilsson@cs.stanford.edu\n",
      "November 3, 1998\n",
      "Copyright c\r",
      "2005 Nils J. Nilsson\n",
      "This material may not be copied, reproduced, or distributed without the\n",
      "written permission of the copyright holder.\n",
      "ii\n",
      "Contents\n",
      "1 Preliminaries 1\n",
      "1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n",
      "1.1.1 What is Machine Learning? . . . . . . . . . . . . . . . . . 1\n",
      "1.1.2 Wellsprings of Machine Learning . . . . . . . . . . . . . . 3\n",
      "1.1.3 Varieties of Machine Learning . . . . . . . . . . . . . . . . 4\n",
      "1.2 Learning Input-Output Functions . . . . . . . . . . . . . . . . . . 5\n",
      "1.2.1 Types of Learning . . . . . . . . . . . . . . . . . . . . . . 5\n",
      "1.2.2 Input Vectors . . . . . . . . . . . . . . . . . . . . . . . . . 7\n",
      "1.2.3 Outputs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n",
      "1.2.4 Training Regimes . . . . . . . . . . . . . . . . . . . . . . . 8\n",
      "1.2.5 Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n",
      "1.2.6 Performance Evaluation . . . . . . . . . . . . . . . . . . . 9\n",
      "1.3 Learning Requires Bias . . . . . . . . . . . . . . . . . . . . . . . . 9\n",
      "1.4 Sample Applications . . . . . . . . . . . . . . . . . . . . . . . . . 11\n",
      "1.5 Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n",
      "1.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 13\n",
      "2 Boolean Functions 15\n",
      "2.1 Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n",
      "2.1.1 Boolean Algebra . . . . . . . . . . . . . . . . . . . . . . . 15\n",
      "2.1.2 Diagrammatic Representations . . . . . . . . . . . . . . . 16\n",
      "2.2 Classes of Boolean Functions . . . . . . . . . . . . . . . . . . . . 17\n",
      "2.2.1 Terms and Clauses . . . . . . . . . . . . . . . . . . . . . . 17\n",
      "2.2.2 DNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 18\n",
      "2.2.3 CNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 21\n",
      "2.2.4 Decision Lists . . . . . . . . . . . . . . . . . . . . . . . . . 22\n",
      "2.2.5 Symmetric and Voting Functions . . . . . . . . . . . . . . 23\n",
      "2.2.6 Linearly Separable Functions . . . . . . . . . . . . . . . . 23\n",
      "2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n",
      "2.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 25\n",
      "iii\n",
      "3 Using Version Spaces for Learning 27\n",
      "3.1 Version Spaces and Mistake Bounds . . . . . . . . . . . . . . . . 27\n",
      "3.2 Version Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n",
      "3.3 Learning as Search of a Version Space . . . . . . . . . . . . . . . 32\n",
      "3.4 The Candidate Elimination Method . . . . . . . . . . . . . . . . 32\n",
      "3.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 34\n",
      "4 Neural Networks 35\n",
      "4.1 Threshold Logic Units . . . . . . . . . . . . . . . . . . . . . . . . 35\n",
      "4.1.1 De\f",
      "nitions and Geometry . . . . . . . . . . . . . . . . . . 35\n",
      "4.1.2 Special Cases of Linearly Separable Functions . . . . . . . 37\n",
      "4.1.3 Error-Correction Training of a TLU . . . . . . . . . . . . 38\n",
      "4.1.4 Weight Space . . . . . . . . . . . . . . . . . . . . . . . . . 40\n",
      "4.1.5 The Widrow-Ho\u000b",
      " Procedure . . . . . . . . . . . . . . . . . 42\n",
      "4.1.6 Training a TLU on Non-Linearly-Separable Training Sets 44\n",
      "4.2 Linear Machines . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n",
      "4.3 Networks of TLUs . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n",
      "4.3.1 Motivation and Examples . . . . . . . . . . . . . . . . . . 46\n",
      "4.3.2 Madalines . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n",
      "4.3.3 Piecewise Linear Machines . . . . . . . . . . . . . . . . . . 50\n",
      "4.3.4 Cascade Networks . . . . . . . . . . . . . . . . . . . . . . 51\n",
      "4.4 Training Feedforward Networks by Backpropagation . . . . . . . 52\n",
      "4.4.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n",
      "4.4.2 The Backpropagation Method . . . . . . . . . . . . . . . . 53\n",
      "4.4.3 Computing Weight Changes in the Final Layer . . . . . . 56\n",
      "4.4.4 Computing Changes to the Weights in Intermediate Layers 58\n",
      "4.4.5 Variations on Backprop . . . . . . . . . . . . . . . . . . . 59\n",
      "4.4.6 An Application: Steering a Van . . . . . . . . . . . . . . . 60\n",
      "4.5 Synergies Between Neural Network and Knowledge-Based Methods 61\n",
      "4.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 61\n",
      "5 Statistical Learning 63\n",
      "5.1 Using Statistical Decision Theory . . . . . . . . . . . . . . . . . . 63\n",
      "5.1.1 Background and General Method . . . . . . . . . . . . . . 63\n",
      "5.1.2 Gaussian (or Normal) Distributions . . . . . . . . . . . . 65\n",
      "5.1.3 Conditionally Independent Binary Components . . . . . . 68\n",
      "5.2 Learning Belief Networks . . . . . . . . . . . . . . . . . . . . . . 70\n",
      "5.3 Nearest-Neighbor Methods . . . . . . . . . . . . . . . . . . . . . . 70\n",
      "5.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 72\n",
      "iv\n",
      "6 Decision Trees 73\n",
      "6.1 De\f",
      "nitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n",
      "6.2 Supervised Learning of Univariate Decision Trees . . . . . . . . . 74\n",
      "6.2.1 Selecting the Type of Test . . . . . . . . . . . . . . . . . . 75\n",
      "6.2.2 Using Uncertainty Reduction to Select Tests . . . . . . . 75\n",
      "6.2.3 Non-Binary Attributes . . . . . . . . . . . . . . . . . . . . 79\n",
      "6.3 Networks Equivalent to Decision Trees . . . . . . . . . . . . . . . 79\n",
      "6.4 Over\f",
      "tting and Evaluation . . . . . . . . . . . . . . . . . . . . . 80\n",
      "6.4.1 Over\f",
      "tting . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n",
      "6.4.2 Validation Methods . . . . . . . . . . . . . . . . . . . . . 81\n",
      "6.4.3 Avoiding Over\f",
      "tting in Decision Trees . . . . . . . . . . . 82\n",
      "6.4.4 Minimum-Description Length Methods . . . . . . . . . . . 83\n",
      "6.4.5 Noise in Data . . . . . . . . . . . . . . . . . . . . . . . . . 84\n",
      "6.5 The Problem of Replicated Subtrees . . . . . . . . . . . . . . . . 84\n",
      "6.6 The Problem of Missing Attributes . . . . . . . . . . . . . . . . . 86\n",
      "6.7 Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n",
      "6.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 87\n",
      "7 Inductive Logic Programming 89\n",
      "7.1 Notation and De\f",
      "nitions . . . . . . . . . . . . . . . . . . . . . . . 90\n",
      "7.2 A Generic ILP Algorithm . . . . . . . . . . . . . . . . . . . . . . 91\n",
      "7.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n",
      "7.4 Inducing Recursive Programs . . . . . . . . . . . . . . . . . . . . 98\n",
      "7.5 Choosing Literals to Add . . . . . . . . . . . . . . . . . . . . . . 100\n",
      "7.6 Relationships Between ILP and Decision Tree Induction . . . . . 101\n",
      "7.7 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 104\n",
      "8 Computational Learning Theory 107\n",
      "8.1 Notation and Assumptions for PAC Learning Theory . . . . . . . 107\n",
      "8.2 PAC Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n",
      "8.2.1 The Fundamental Theorem . . . . . . . . . . . . . . . . . 109\n",
      "8.2.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n",
      "8.2.3 Some Properly PAC-Learnable Classes . . . . . . . . . . . 112\n",
      "8.3 The Vapnik-Chervonenkis Dimension . . . . . . . . . . . . . . . . 113\n",
      "8.3.1 Linear Dichotomies . . . . . . . . . . . . . . . . . . . . . . 113\n",
      "8.3.2 Capacity . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n",
      "8.3.3 A More General Capacity Result . . . . . . . . . . . . . . 116\n",
      "8.3.4 Some Facts and Speculations About the VC Dimension . 117\n",
      "8.4 VC Dimension and PAC Learning . . . . . . . . . . . . . . . . . 118\n",
      "8.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 118\n",
      "v\n",
      "9 Unsupervised Learning 119\n",
      "9.1 What is Unsupervised Learning? . . . . . . . . . . . . . . . . . . 119\n",
      "9.2 Clustering Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n",
      "9.2.1 A Method Based on Euclidean Distance . . . . . . . . . . 120\n",
      "9.2.2 A Method Based on Probabilities . . . . . . . . . . . . . . 124\n",
      "9.3 Hierarchical Clustering Methods . . . . . . . . . . . . . . . . . . 125\n",
      "9.3.1 A Method Based on Euclidean Distance . . . . . . . . . . 125\n",
      "9.3.2 A Method Based on Probabilities . . . . . . . . . . . . . . 126\n",
      "9.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 130\n",
      "10 Temporal-Di\u000b",
      "erence Learning 131\n",
      "10.1 Temporal Patterns and Prediction Problems . . . . . . . . . . . . 131\n",
      "10.2 Supervised and Temporal-Di\u000b",
      "erence Methods . . . . . . . . . . . 131\n",
      "10.3 Incremental Computation of the (\u0001 W)i. . . . . . . . . . . . . . 134\n",
      "10.4 An Experiment with TD Methods . . . . . . . . . . . . . . . . . 135\n",
      "10.5 Theoretical Results . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n",
      "10.6 Intra-Sequence Weight Updating . . . . . . . . . . . . . . . . . . 138\n",
      "10.7 An Example Application: TD-gammon . . . . . . . . . . . . . . . 140\n",
      "10.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 141\n",
      "11 Delayed-Reinforcement Learning 143\n",
      "11.1 The General Problem . . . . . . . . . . . . . . . . . . . . . . . . 143\n",
      "11.2 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n",
      "11.3 Temporal Discounting and Optimal Policies . . . . . . . . . . . . 145\n",
      "11.4Q-Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n",
      "11.5 Discussion, Limitations, and Extensions of Q-Learning . . . . . . 150\n",
      "11.5.1 An Illustrative Example . . . . . . . . . . . . . . . . . . . 150\n",
      "11.5.2 Using Random Actions . . . . . . . . . . . . . . . . . . . 152\n",
      "11.5.3 Generalizing Over Inputs . . . . . . . . . . . . . . . . . . 153\n",
      "11.5.4 Partially Observable States . . . . . . . . . . . . . . . . . 154\n",
      "11.5.5 Scaling Problems . . . . . . . . . . . . . . . . . . . . . . . 154\n",
      "11.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 155\n",
      "vi\n",
      "12 Explanation-Based Learning 157\n",
      "12.1 Deductive Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 157\n",
      "12.2 Domain Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n",
      "12.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n",
      "12.4 Evaluable Predicates . . . . . . . . . . . . . . . . . . . . . . . . . 162\n",
      "12.5 More General Proofs . . . . . . . . . . . . . . . . . . . . . . . . . 164\n",
      "12.6 Utility of EBL . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n",
      "12.7 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n",
      "12.7.1 Macro-Operators in Planning . . . . . . . . . . . . . . . . 164\n",
      "12.7.2 Learning Search Control Knowledge . . . . . . . . . . . . 167\n",
      "12.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 168\n",
      "vii\n",
      "viii\n",
      "Preface\n",
      "These notes are in the process of becoming a textbook. The process is quite\n",
      "un\f",
      "nished, and the author solicits corrections, criticisms, and suggestions from\n",
      "students and other readers. Although I have tried to eliminate errors, some un-\n",
      "doubtedly remain| caveat lector . Many typographical infelicities will no doubt\n",
      "persist until the \f",
      "nal version. More material has yet to be added. Please let Some of my plans for additions and\n",
      "other reminders are mentioned in\n",
      "marginal notes.me have your suggestions about topics that are too important to be left out.\n",
      "I hope that future versions will cover Hop\f",
      "eld nets, Elman nets and other re-\n",
      "current nets, radial basis functions, grammar and automata learning, genetic\n",
      "algorithms, and Bayes networks :::. I am also collecting exercises and project\n",
      "suggestions which will appear in future versions.\n",
      "My intention is to pursue a middle ground between a theoretical textbook\n",
      "and one that focusses on applications. The book concentrates on the important\n",
      "ideas in machine learning. I do not give proofs of many of the theorems that I\n",
      "state, but I do give plausibility arguments and citations to formal proofs. And, I\n",
      "do not treat many matters that would be of practical importance in applications;\n",
      "the book is not a handbook of machine learning practice. Instead, my goal is\n",
      "to give the reader su\u000ecient preparation to make the extensive literature on\n",
      "machine learning accessible.\n",
      "Students in my Stanford courses on machine learning have already made\n",
      "several useful suggestions, as have my colleague, Pat Langley, and my teaching\n",
      "assistants, Ron Kohavi, Karl P\r",
      "eger, Robert Allen, and Lise Getoor.\n",
      "ix\n",
      "Chapter 1\n",
      "Preliminaries\n",
      "1.1 Introduction\n",
      "1.1.1 What is Machine Learning?\n",
      "Learning , like intelligence, covers such a broad range of processes that it is dif-\n",
      "\f",
      "cult to de\f",
      "ne precisely. A dictionary de\f",
      "nition includes phrases such as \\to\n",
      "gain knowledge, or understanding of, or skill in, by study, instruction, or expe-\n",
      "rience,\" and \\modi\f",
      "cation of a behavioral tendency by experience.\" Zoologists\n",
      "and psychologists study learning in animals and humans. In this book we fo-\n",
      "cus on learning in machines. There are several parallels between animal and\n",
      "machine learning. Certainly, many techniques in machine learning derive from\n",
      "the e\u000b",
      "orts of psychologists to make more precise their theories of animal and\n",
      "human learning through computational models. It seems likely also that the\n",
      "concepts and techniques being explored by researchers in machine learning may\n",
      "illuminate certain aspects of biological learning.\n",
      "As regards machines, we might say, very broadly, that a machine learns\n",
      "whenever it changes its structure, program, or data (based on its inputs or in\n",
      "response to external information) in such a manner that its expected future\n",
      "performance improves. Some of these changes, such as the addition of a record\n",
      "to a data base, fall comfortably within the province of other disciplines and are\n",
      "not necessarily better understood for being called learning. But, for example,\n",
      "when the performance of a speech-recognition machine improves after hearing\n",
      "several samples of a person's speech, we feel quite justi\f",
      "ed in that case to say\n",
      "that the machine has learned.\n",
      "Machine learning usually refers to the changes in systems that perform tasks\n",
      "associated with arti\f",
      "cial intelligence (AI) . Such tasks involve recognition, diag-\n",
      "nosis, planning, robot control, prediction, etc. The \\changes\" might be either\n",
      "enhancements to already performing systems or ab initio synthesis of new sys-\n",
      "tems. To be slightly more speci\f",
      "c, we show the architecture of a typical AI\n",
      "1\n",
      "2 CHAPTER 1. PRELIMINARIES\n",
      "\\agent\" in Fig. 1.1. This agent perceives and models its environment and com-\n",
      "putes appropriate actions, perhaps by anticipating their e\u000b",
      "ects. Changes made\n",
      "to any of the components shown in the \f",
      "gure might count as learning. Di\u000b",
      "erent\n",
      "learning mechanisms might be employed depending on which subsystem is being\n",
      "changed. We will study several di\u000b",
      "erent learning methods in this book.\n",
      "Sensory signals\n",
      "Perception\n",
      "ActionsAction\n",
      "ComputationModel\n",
      "Planning and\n",
      "ReasoningGoals\n",
      "Figure 1.1: An AI System\n",
      "One might ask \\Why should machines have to learn? Why not design ma-\n",
      "chines to perform as desired in the \f",
      "rst place?\" There are several reasons why\n",
      "machine learning is important. Of course, we have already mentioned that the\n",
      "achievement of learning in machines might help us understand how animals and\n",
      "humans learn. But there are important engineering reasons as well. Some of\n",
      "these are:\n",
      "\u000fSome tasks cannot be de\f",
      "ned well except by example; that is, we might be\n",
      "able to specify input/output pairs but not a concise relationship between\n",
      "inputs and desired outputs. We would like machines to be able to adjust\n",
      "their internal structure to produce correct outputs for a large number of\n",
      "sample inputs and thus suitably constrain their input/output function to\n",
      "approximate the relationship implicit in the examples.\n",
      "\u000fIt is possible that hidden among large piles of data are important rela-\n",
      "tionships and correlations. Machine learning methods can often be used\n",
      "to extract these relationships ( data mining ).\n",
      "1.1. INTRODUCTION 3\n",
      "\u000fHuman designers often produce machines that do not work as well as\n",
      "desired in the environments in which they are used. In fact, certain char-\n",
      "acteristics of the working environment might not be completely known\n",
      "at design time. Machine learning methods can be used for on-the-job\n",
      "improvement of existing machine designs.\n",
      "\u000fThe amount of knowledge available about certain tasks might be too large\n",
      "for explicit encoding by humans. Machines that learn this knowledge\n",
      "gradually might be able to capture more of it than humans would want to\n",
      "write down.\n",
      "\u000fEnvironments change over time. Machines that can adapt to a changing\n",
      "environment would reduce the need for constant redesign.\n",
      "\u000fNew knowledge about tasks is constantly being discovered by humans.\n",
      "Vocabulary changes. There is a constant stream of new events in the\n",
      "world. Continuing redesign of AI systems to conform to new knowledge is\n",
      "impractical, but machine learning methods might be able to track much\n",
      "of it.\n",
      "1.1.2 Wellsprings of Machine Learning\n",
      "Work in machine learning is now converging from several sources. These dif-\n",
      "ferent traditions each bring di\u000b",
      "erent methods and di\u000b",
      "erent vocabulary which\n",
      "are now being assimilated into a more uni\f",
      "ed discipline. Here is a brief listing\n",
      "of some of the separate disciplines that have contributed to machine learning;\n",
      "more details will follow in the the appropriate chapters:\n",
      "\u000fStatistics: A long-standing problem in statistics is how best to use sam-\n",
      "ples drawn from unknown probability distributions to help decide from\n",
      "which distribution some new sample is drawn. A related problem is how\n",
      "to estimate the value of an unknown function at a new point given the\n",
      "values of this function at a set of sample points. Statistical methods\n",
      "for dealing with these problems can be considered instances of machine\n",
      "learning because the decision and estimation rules depend on a corpus of\n",
      "samples drawn from the problem environment. We will explore some of\n",
      "the statistical methods later in the book. Details about the statistical the-\n",
      "ory underlying these methods can be found in statistical textbooks such\n",
      "as [Anderson, 1958].\n",
      "\u000fBrain Models: Non-linear elements with weighted inputs\n",
      "have been suggested as simple models of biological neu-\n",
      "rons. Networks of these elements have been studied by sev-\n",
      "eral researchers including [McCulloch & Pitts, 1943, Hebb, 1949,\n",
      "Rosenblatt, 1958] and, more recently by [Gluck & Rumelhart, 1989,\n",
      "Sejnowski, Koch, & Churchland, 1988]. Brain modelers are interested\n",
      "in how closely these networks approximate the learning phenomena of\n",
      "4 CHAPTER 1. PRELIMINARIES\n",
      "living brains. We shall see that several important machine learning\n",
      "techniques are based on networks of nonlinear elements|often called\n",
      "neural networks . Work inspired by this school is sometimes called\n",
      "connectionism ,brain-style computation , orsub-symbolic processing .\n",
      "\u000fAdaptive Control Theory: Control theorists study the problem of con-\n",
      "trolling a process having unknown parameters which must be estimated\n",
      "during operation. Often, the parameters change during operation, and the\n",
      "control process must track these changes. Some aspects of controlling a\n",
      "robot based on sensory inputs represent instances of this sort of problem.\n",
      "For an introduction see [Bollinger & Du\u000ee, 1988].\n",
      "\u000fPsychological Models: Psychologists have studied the performance of\n",
      "humans in various learning tasks. An early example is the EPAM net-\n",
      "work for storing and retrieving one member of a pair of words when\n",
      "given another [Feigenbaum, 1961]. Related work led to a number of\n",
      "early decision tree [Hunt, Marin, & Stone, 1966] and semantic network\n",
      "[Anderson & Bower, 1973] methods. More recent work of this sort has\n",
      "been in\r",
      "uenced by activities in arti\f",
      "cial intelligence which we will be pre-\n",
      "senting.\n",
      "Some of the work in reinforcement learning can be traced to e\u000b",
      "orts to\n",
      "model how reward stimuli in\r",
      "uence the learning of goal-seeking behavior in\n",
      "animals [Sutton & Barto, 1987]. Reinforcement learning is an important\n",
      "theme in machine learning research.\n",
      "\u000fArti\f",
      "cial Intelligence: From the beginning, AI research has been con-\n",
      "cerned with machine learning. Samuel developed a prominent early pro-\n",
      "gram that learned parameters of a function for evaluating board posi-\n",
      "tions in the game of checkers [Samuel, 1959]. AI researchers have also\n",
      "explored the role of analogies in learning [Carbonell, 1983] and how fu-\n",
      "ture actions and decisions can be based on previous exemplary cases\n",
      "[Kolodner, 1993]. Recent work has been directed at discovering rules\n",
      "for expert systems using decision-tree methods [Quinlan, 1990] and in-\n",
      "ductive logic programming [Muggleton, 1991, Lavra\u0014 c & D\u0014 zeroski, 1994].\n",
      "Another theme has been saving and generalizing the results of prob-\n",
      "lem solving using explanation-based learning [DeJong & Mooney, 1986,\n",
      "Laird, et al. , 1986, Minton, 1988, Etzioni, 1993].\n",
      "\u000fEvolutionary Models:\n",
      "In nature, not only do individual animals learn to perform better, but\n",
      "species evolve to be better \f",
      "t in their individual niches. Since the distinc-\n",
      "tion between evolving and learning can be blurred in computer systems,\n",
      "techniques that model certain aspects of biological evolution have been\n",
      "proposed as learning methods to improve the performance of computer\n",
      "programs. Genetic algorithms [Holland, 1975] and genetic programming\n",
      "[Koza, 1992, Koza, 1994] are the most prominent computational tech-\n",
      "niques for evolution.\n",
      "1.2. LEARNING INPUT-OUTPUT FUNCTIONS 5\n",
      "1.1.3 Varieties of Machine Learning\n",
      "Orthogonal to the question of the historical source of any learning technique is\n",
      "the more important question of what is to be learned. In this book, we take it\n",
      "that the thing to be learned is a computational structure of some sort. We will\n",
      "consider a variety of di\u000b",
      "erent computational structures:\n",
      "\u000fFunctions\n",
      "\u000fLogic programs and rule sets\n",
      "\u000fFinite-state machines\n",
      "\u000fGrammars\n",
      "\u000fProblem solving systems\n",
      "We will present methods both for the synthesis of these structures from examples\n",
      "and for changing existing structures. In the latter case, the change to the\n",
      "existing structure might be simply to make it more computationally e\u000ecient\n",
      "rather than to increase the coverage of the situations it can handle. Much of\n",
      "the terminology that we shall be using throughout the book is best introduced\n",
      "by discussing the problem of learning functions, and we turn to that matter\n",
      "\f",
      "rst.\n",
      "1.2 Learning Input-Output Functions\n",
      "We use Fig. 1.2 to help de\f",
      "ne some of the terminology used in describing the\n",
      "problem of learning a function. Imagine that there is a function, f, and the task\n",
      "of the learner is to guess what it is. Our hypothesis about the function to be\n",
      "learned is denoted by h. Bothfandhare functions of a vector-valued input\n",
      "X= (x1;x2;:::;xi;:::;xn) which has ncomponents. We think of has being\n",
      "implemented by a device that has Xas input and h(X) as output. Both fand\n",
      "hthemselves may be vector-valued. We assume a priori that the hypothesized\n",
      "function,h, is selected from a class of functions H. Sometimes we know that\n",
      "falso belongs to this class or to a subset of this class. We select hbased on a\n",
      "training set , \u0004, ofminput vector examples. Many important details depend on\n",
      "the nature of the assumptions made about all of these entities.\n",
      "1.2.1 Types of Learning\n",
      "There are two major settings in which we wish to learn a function. In one,\n",
      "called supervised learning , we know (sometimes only approximately) the values\n",
      "offfor themsamples in the training set, \u0004. We assume that if we can \f",
      "nd\n",
      "a hypothesis, h, that closely agrees with ffor the members of \u0004, then this\n",
      "hypothesis will be a good guess for f|especially if \u0004 is large.\n",
      "6 CHAPTER 1. PRELIMINARIES\n",
      "h(X)\n",
      "hU = {X1, X2, . . . Xi, . . ., Xm}Training Set:\n",
      "X =x1\n",
      ".\n",
      ".\n",
      ".\n",
      "xi\n",
      ".\n",
      ".\n",
      ".\n",
      "xnh D H\n",
      "Figure 1.2: An Input-Output Function\n",
      "Curve-\f",
      "tting is a simple example of supervised learning of a function. Sup-\n",
      "pose we are given the values of a two-dimensional function, f, at the four sample\n",
      "points shown by the solid circles in Fig. 1.3. We want to \f",
      "t these four points\n",
      "with a function, h, drawn from the set, H, of second-degree functions. We show\n",
      "there a two-dimensional parabolic surface above the x1,x2plane that \f",
      "ts the\n",
      "points. This parabolic function, h, is our hypothesis about the function, f, that\n",
      "produced the four samples. In this case, h=fat the four samples, but we need\n",
      "not have required exact matches.\n",
      "In the other setting, termed unsupervised learning , we simply have a train-\n",
      "ing set of vectors without function values for them. The problem in this case,\n",
      "typically, is to partition the training set into subsets, \u0004 1, . . . , \u0004R, in some ap-\n",
      "propriate way. (We can still regard the problem as one of learning a function;\n",
      "the value of the function is the name of the subset to which an input vector be-\n",
      "longs.) Unsupervised learning methods have application in taxonomic problems\n",
      "in which it is desired to invent ways to classify data into meaningful categories.\n",
      "We shall also describe methods that are intermediate between supervised\n",
      "and unsupervised learning.\n",
      "We might either be trying to \f",
      "nd a new function, h, or to modify an existing\n",
      "one. An interesting special case is that of changing an existing function into an\n",
      "equivalent one that is computationally more e\u000ecient. This type of learning is\n",
      "sometimes called speed-up learning. A very simple example of speed-up learning\n",
      "involves deduction processes. From the formulas A\u001bBandB\u001bC, we can\n",
      "deduceCif we are given A. From this deductive process, we can create the\n",
      "formulaA\u001bC|a new formula but one that does not sanction any more con-\n",
      "1.2. LEARNING INPUT-OUTPUT FUNCTIONS 7\n",
      "-10\n",
      "-5\n",
      "0\n",
      "5\n",
      "10-10-50510\n",
      "050010001500-10\n",
      "-5\n",
      "0\n",
      "5\n",
      "10-10-50510\n",
      "000000\n",
      "x1x2hsample f-value\n",
      "Figure 1.3: A Surface that Fits Four Points\n",
      "clusions than those that could be derived from the formulas that we previously\n",
      "had. But with this new formula we can derive Cmore quickly, given A, than\n",
      "we could have done before. We can contrast speed-up learning with methods\n",
      "that create genuinely new functions|ones that might give di\u000b",
      "erent results after\n",
      "learning than they did before. We say that the latter methods involve inductive\n",
      "learning. As opposed to deduction, there are no correct inductions|only useful\n",
      "ones.\n",
      "1.2.2 Input Vectors\n",
      "Because machine learning methods derive from so many di\u000b",
      "erent traditions, its\n",
      "terminology is rife with synonyms, and we will be using most of them in this\n",
      "book. For example, the input vector is called by a variety of names. Some\n",
      "of these are: input vector ,pattern vector ,feature vector ,sample ,example , and\n",
      "instance . The components, xi, of the input vector are variously called features ,\n",
      "attributes ,input variables , and components .\n",
      "The values of the components can be of three main types. They might\n",
      "be real-valued numbers, discrete-valued numbers, or categorical values . As an\n",
      "example illustrating categorical values, information about a student might be\n",
      "represented by the values of the attributes class, major, sex, adviser . A par-\n",
      "ticular student would then be represented by a vector such as: (sophomore,\n",
      "history, male, higgins). Additionally, categorical values may be ordered (as in\n",
      "fsmall, medium, large g) orunordered (as in the example just given). Of course,\n",
      "mixtures of all these types of values are possible.\n",
      "In all cases, it is possible to represent the input in unordered form by listing\n",
      "the names of the attributes together with their values. The vector form assumes\n",
      "that the attributes are ordered and given implicitly by a form. As an example\n",
      "of an attribute-value representation, we might have: (major: history, sex: male,\n",
      "8 CHAPTER 1. PRELIMINARIES\n",
      "class: sophomore, adviser: higgins, age: 19). We will be using the vector form\n",
      "exclusively.\n",
      "An important specialization uses Boolean values, which can be regarded as\n",
      "a special case of either discrete numbers (1,0) or of categorical variables ( True,\n",
      "False ).\n",
      "1.2.3 Outputs\n",
      "The output may be a real number, in which case the process embodying the\n",
      "function,h, is called a function estimator , and the output is called an output\n",
      "value orestimate .\n",
      "Alternatively, the output may be a categorical value, in which case the pro-\n",
      "cess embodying his variously called a classi\f",
      "er , arecognizer , or a categorizer ,\n",
      "and the output itself is called a label, aclass, acategory , or a decision . Classi-\n",
      "\f",
      "ers have application in a number of recognition problems, for example in the\n",
      "recognition of hand-printed characters. The input in that case is some suitable\n",
      "representation of the printed character, and the classi\f",
      "er maps this input into\n",
      "one of, say, 64 categories.\n",
      "Vector-valued outputs are also possible with components being real numbers\n",
      "or categorical values.\n",
      "An important special case is that of Boolean output values. In that case,\n",
      "a training pattern having value 1 is called a positive instance , and a training\n",
      "sample having value 0 is called a negative instance . When the input is also\n",
      "Boolean, the classi\f",
      "er implements a Boolean function . We study the Boolean\n",
      "case in some detail because it allows us to make important general points in\n",
      "a simpli\f",
      "ed setting. Learning a Boolean function is sometimes called concept\n",
      "learning , and the function is called a concept .\n",
      "1.2.4 Training Regimes\n",
      "There are several ways in which the training set, \u0004, can be used to produce a\n",
      "hypothesized function. In the batch method, the entire training set is available\n",
      "and used all at once to compute the function, h. A variation of this method\n",
      "uses the entire training set to modify a current hypothesis iteratively until an\n",
      "acceptable hypothesis is obtained. By contrast, in the incremental method, we\n",
      "select one member at a time from the training set and use this instance alone\n",
      "to modify a current hypothesis. Then another member of the training set is\n",
      "selected, and so on. The selection method can be random (with replacement)\n",
      "or it can cycle through the training set iteratively. If the entire training set\n",
      "becomes available one member at a time, then we might also use an incremental\n",
      "method|selecting and using training set members as they arrive. (Alterna-\n",
      "tively, at any stage all training set members so far available could be used in a\n",
      "\\batch\" process.) Using the training set members as they become available is\n",
      "called an online method. Online methods might be used, for example, when the\n",
      "1.3. LEARNING REQUIRES BIAS 9\n",
      "next training instance is some function of the current hypothesis and the previ-\n",
      "ous instance|as it would be when a classi\f",
      "er is used to decide on a robot's next\n",
      "action given its current set of sensory inputs. The next set of sensory inputs\n",
      "will depend on which action was selected.\n",
      "1.2.5 Noise\n",
      "Sometimes the vectors in the training set are corrupted by noise. There are two\n",
      "kinds of noise. Class noise randomly alters the value of the function; attribute\n",
      "noise randomly alters the values of the components of the input vector. In either\n",
      "case, it would be inappropriate to insist that the hypothesized function agree\n",
      "precisely with the values of the samples in the training set.\n",
      "1.2.6 Performance Evaluation\n",
      "Even though there is no correct answer in inductive learning, it is important\n",
      "to have methods to evaluate the result of learning. We will discuss this matter\n",
      "in more detail later, but, brie\r",
      "y, in supervised learning the induced function is\n",
      "usually evaluated on a separate set of inputs and function values for them called\n",
      "thetesting set . A hypothesized function is said to generalize when it guesses\n",
      "well on the testing set. Both mean-squared-error and the total number of errors\n",
      "are common measures.\n",
      "1.3 Learning Requires Bias\n",
      "Long before now the reader has undoubtedly asked why is learning a function\n",
      "possible at all? Certainly, for example, there are an uncountable number of\n",
      "di\u000b",
      "erent functions having values that agree with the four samples shown in Fig.\n",
      "1.3. Why would a learning procedure happen to select the quadratic one shown\n",
      "in that \f",
      "gure? In order to make that selection we had at least to limit a priori\n",
      "the set of hypotheses to quadratic functions and then to insist that the one we\n",
      "chose passed through all four sample points. This kind of a priori information\n",
      "is called bias, and useful learning without bias is impossible.\n",
      "We can gain more insight into the role of bias by considering the special case\n",
      "of learning a Boolean function of ndimensions. There are 2ndi\u000b",
      "erent Boolean\n",
      "inputs possible. Suppose we had no bias; that is His the set of all22nBoolean\n",
      "functions, and we have no preference among those that \f",
      "t the samples in the\n",
      "training set. In this case, after being presented with one member of the training\n",
      "set and its value we can rule out precisely one-half of the members of H|those\n",
      "Boolean functions that would misclassify this labeled sample. The remaining\n",
      "functions constitute what is called a \\version space;\" we'll explore that concept\n",
      "in more detail later. As we present more members of the training set, the graph\n",
      "of the number of hypotheses not yet ruled out as a function of the number of\n",
      "di\u000b",
      "erent patterns presented is as shown in Fig. 1.4. At any stage of the process,\n",
      "10 CHAPTER 1. PRELIMINARIES\n",
      "half of the remaining Boolean functions have value 1 and half have value 0 for\n",
      "anytraining pattern not yet seen. No generalization is possible in this case\n",
      "because the training patterns give no clue about the value of a pattern not yet\n",
      "seen. Only memorization is possible here, which is a trivial sort of learning.\n",
      "log2|Hv|\n",
      "2n\n",
      "2n\n",
      "j = no. of labeled\n",
      "patterns already seen0\n",
      "02n < j\n",
      "(generalization is not possible)|Hv| = no. of functions not ruled out\n",
      "Figure 1.4: Hypotheses Remaining as a Function of Labeled Patterns Presented\n",
      "But suppose we limited Hto some subset,Hc, of all Boolean functions.\n",
      "Depending on the subset and on the order of presentation of training patterns,\n",
      "a curve of hypotheses not yet ruled out might look something like the one\n",
      "shown in Fig. 1.5. In this case it is even possible that after seeing fewer than\n",
      "all 2nlabeled samples, there might be only one hypothesis that agrees with\n",
      "the training set. Certainly, even if there is more than one hypothesis remaining,\n",
      "most of them may have the same value for most of the patterns not yet seen! The\n",
      "theory of Probably Approximately Correct (PAC) learning makes this intuitive\n",
      "idea precise. We'll examine that theory later.\n",
      "Let's look at a speci\f",
      "c example of how bias aids learning. A Boolean function\n",
      "can be represented by a hypercube each of whose vertices represents a di\u000b",
      "erent\n",
      "input pattern. We show a 3-dimensional version in Fig. 1.6. There, we show a\n",
      "training set of six sample patterns and have marked those having a value of 1 by\n",
      "a small square and those having a value of 0 by a small circle. If the hypothesis\n",
      "set consists of just the linearly separable functions|those for which the positive\n",
      "and negative instances can be separated by a linear surface, then there is only\n",
      "one function remaining in this hypothsis set that is consistent with the training\n",
      "set. So, in this case, even though the training set does not contain all possible\n",
      "patterns, we can already pin down what the function must be|given the bias.\n",
      "1.4. SAMPLE APPLICATIONS 11\n",
      "log2|Hv|\n",
      "2n\n",
      "2n\n",
      "j = no. of labeled\n",
      "patterns already seen0\n",
      "0|Hv| = no. of functions not ruled out\n",
      "depends on order\n",
      "of presentation\n",
      "log2|Hc|\n",
      "Figure 1.5: Hypotheses Remaining From a Restricted Subset\n",
      "Machine learning researchers have identi\f",
      "ed two main varieties of bias, ab-\n",
      "solute and preference. In absolute bias (also called restricted hypothesis-space\n",
      "bias), one restrictsHto a de\f",
      "nite subset of functions. In our example of Fig. 1.6,\n",
      "the restriction was to linearly separable Boolean functions. In preference bias ,\n",
      "one selects that hypothesis that is minimal according to some ordering scheme\n",
      "over all hypotheses. For example, if we had some way of measuring the complex-\n",
      "ityof a hypothesis, we might select the one that was simplest among those that\n",
      "performed satisfactorily on the training set. The principle of Occam's razor ,\n",
      "used in science to prefer simple explanations to more complex ones, is a type\n",
      "of preference bias. (William of Occam, 1285-?1349, was an English philosopher\n",
      "who said: \\ non sunt multiplicanda entia praeter necessitatem ,\" which means\n",
      "\\entities should not be multiplied unnecessarily.\")\n",
      "1.4 Sample Applications\n",
      "Our main emphasis in this book is on the concepts of machine learning|not\n",
      "on its applications. Nevertheless, if these concepts were irrelevant to real-world\n",
      "problems they would probably not be of much interest. As motivation, we give\n",
      "a short summary of some areas in which machine learning techniques have been\n",
      "successfully applied. [Langley, 1992] cites some of the following applications and\n",
      "others:\n",
      "a. Rule discovery using a variant of ID3 for a printing industry problem\n",
      "12 CHAPTER 1. PRELIMINARIES\n",
      "x1x2x3\n",
      "Figure 1.6: A Training Set That Completely Determines a Linearly Separable\n",
      "Function\n",
      "[Evans & Fisher, 1992].\n",
      "b. Electric power load forecasting using a k-nearest-neighbor rule system\n",
      "[Jabbour, K., et al. , 1987].\n",
      "c. Automatic \\help desk\" assistant using a nearest-neighbor system\n",
      "[Acorn & Walden, 1992].\n",
      "d. Planning and scheduling for a steel mill using ExpertEase, a marketed\n",
      "(ID3-like) system [Michie, 1992].\n",
      "e. Classi\f",
      "cation of stars and galaxies [Fayyad, et al. , 1993].\n",
      "Many application-oriented papers are presented at the annual conferences\n",
      "on Neural Information Processing Systems. Among these are papers on: speech\n",
      "recognition, dolphin echo recognition, image processing, bio-engineering, diag-\n",
      "nosis, commodity trading, face recognition, music composition, optical character\n",
      "recognition, and various control applications [Various Editors, 1989-1994].\n",
      "As additional examples, [Hammerstrom, 1993] mentions:\n",
      "a. Sharp's Japanese kanji character recognition system processes 200 char-\n",
      "acters per second with 99+% accuracy. It recognizes 3000+ characters.\n",
      "b. NeuroForecasting Centre's (London Business School and University Col-\n",
      "lege London) trading strategy selection network earned an average annual\n",
      "pro\f",
      "t of 18% against a conventional system's 12.3%.\n",
      "1.5. SOURCES 13\n",
      "c. Fujitsu's (plus a partner's) neural network for monitoring a continuous\n",
      "steel casting operation has been in successful operation since early 1990.\n",
      "In summary, it is rather easy nowadays to \f",
      "nd applications of machine learn-\n",
      "ing techniques. This fact should come as no surprise inasmuch as many machine\n",
      "learning techniques can be viewed as extensions of well known statistical meth-\n",
      "ods which have been successfully applied for many years.\n",
      "1.5 Sources\n",
      "Besides the rich literature in machine learning (a small part of\n",
      "which is referenced in the Bibliography), there are several text-\n",
      "books that are worth mentioning [Hertz, Krogh, & Palmer, 1991,\n",
      "Weiss & Kulikowski, 1991, Natarjan, 1991, Fu, 1994, Langley, 1996].\n",
      "[Shavlik & Dietterich, 1990, Buchanan & Wilkins, 1993] are edited vol-\n",
      "umes containing some of the most important papers. A survey paper by\n",
      "[Dietterich, 1990] gives a good overview of many important topics. There are\n",
      "also well established conferences and publications where papers are given and\n",
      "appear including:\n",
      "\u000fThe Annual Conferences on Advances in Neural Information Processing\n",
      "Systems\n",
      "\u000fThe Annual Workshops on Computational Learning Theory\n",
      "\u000fThe Annual International Workshops on Machine Learning\n",
      "\u000fThe Annual International Conferences on Genetic Algorithms\n",
      "(The Proceedings of the above-listed four conferences are published by\n",
      "Morgan Kaufmann.)\n",
      "\u000fThe journal Machine Learning (published by Kluwer Academic Publish-\n",
      "ers).\n",
      "There is also much information, as well as programs and datasets, available over\n",
      "the Internet through the World Wide Web.\n",
      "1.6 Bibliographical and Historical Remarks\n",
      "To be added. Every chapter will\n",
      "contain a brief survey of the history\n",
      "of the material covered in that\n",
      "chapter.\n",
      "14 CHAPTER 1. PRELIMINARIES\n",
      "Chapter 2\n",
      "Boolean Functions\n",
      "2.1 Representation\n",
      "2.1.1 Boolean Algebra\n",
      "Many important ideas about learning of functions are most easily presented\n",
      "using the special case of Boolean functions. There are several important sub-\n",
      "classes of Boolean functions that are used as hypothesis classes for function\n",
      "learning. Therefore, we digress in this chapter to present a review of Boolean\n",
      "functions and their properties. (For a more thorough treatment see, for example,\n",
      "[Unger, 1989].)\n",
      "A Boolean function, f(x1;x2;:::;xn) maps an n-tuple of (0,1) values to\n",
      "f0;1g.Boolean algebra is a convenient notation for representing Boolean func-\n",
      "tions. Boolean algebra uses the connectives \u0001, +, and . For example, the and\n",
      "function of two variables is written x1\u0001x2. By convention, the connective, \\ \u0001\"\n",
      "is usually suppressed, and the andfunction is written x1x2.x1x2has value 1 if\n",
      "and only if bothx1andx2have value 1; if either x1orx2has value 0, x1x2has\n",
      "value 0. The (inclusive) orfunction of two variables is written x1+x2.x1+x2\n",
      "has value 1 if and only if either or both of x1orx2has value 1; if both x1and\n",
      "x2have value 0, x1+x2has value 0. The complement ornegation of a variable,\n",
      "x, is written x.xhas value 1 if and only if xhas value 0; if xhas value 1, xhas\n",
      "value 0.\n",
      "These de\f",
      "nitions are compactly given by the following rules for Boolean\n",
      "algebra:\n",
      "1 + 1 = 1, 1 + 0 = 1, 0 + 0 = 0,\n",
      "1\u00011 = 1, 1\u00010 = 0, 0\u00010 = 0, and\n",
      "1 = 0, 0 = 1.\n",
      "Sometimes the arguments and values of Boolean functions are expressed in\n",
      "terms of the constants T(True) andF(False ) instead of 1 and 0, respectively.\n",
      "15\n",
      "16 CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "The connectives\u0001and + are each commutative and associative. Thus, for\n",
      "example,x1(x2x3) = (x1x2)x3, and both can be written simply as x1x2x3.\n",
      "Similarly for +.\n",
      "A Boolean formula consisting of a single variable, such as x1is called an\n",
      "atom . One consisting of either a single variable or its complement, such as x1,\n",
      "is called a literal .\n",
      "The operators\u0001and + do not commute between themselves. Instead, we\n",
      "have DeMorgan's laws (which can be veri\f",
      "ed by using the above de\f",
      "nitions):\n",
      "x1x2=x1+x2, and\n",
      "x1+x2=x1x2.\n",
      "2.1.2 Diagrammatic Representations\n",
      "We saw in the last chapter that a Boolean function could be represented by\n",
      "labeling the vertices of a cube. For a function of nvariables, we would need\n",
      "ann-dimensional hypercube . In Fig. 2.1 we show some 2- and 3-dimensional\n",
      "examples. Vertices having value 1 are labeled with a small square, and vertices\n",
      "having value 0 are labeled with a small circle.\n",
      "x1x2\n",
      "x1x2\n",
      "x1x2and or\n",
      "xor (exclusive or)x1x2 x1 + x2\n",
      "x1x2  +  x1x2\n",
      "even parity functionx1x2x3\n",
      "x1x2x3  +  x1x2x3\n",
      "+ x1x2x3 + x1x2x3\n",
      "Figure 2.1: Representing Boolean Functions on Cubes\n",
      "Using the hypercube representations, it is easy to see how many Boolean\n",
      "functions of ndimensions there are. A 3-dimensional cube has 23= 8 vertices,\n",
      "and each may be labeled in two di\u000b",
      "erent ways; thus there are 2(23)= 256\n",
      "2.2. CLASSES OF BOOLEAN FUNCTIONS 17\n",
      "di\u000b",
      "erent Boolean functions of 3 variables. In general, there are 22nBoolean\n",
      "functions of nvariables.\n",
      "We will be using 2- and 3-dimensional cubes later to provide some intuition\n",
      "about the properties of certain Boolean functions. Of course, we cannot visualize\n",
      "hypercubes (for n > 3), and there are many surprising properties of higher\n",
      "dimensional spaces, so we must be careful in using intuitions gained in low\n",
      "dimensions. One diagrammatic technique for dimensions slightly higher than\n",
      "3 is the Karnaugh map . A Karnaugh map is an array of values of a Boolean\n",
      "function in which the horizontal rows are indexed by the values of some of\n",
      "the variables and the vertical columns are indexed by the rest. The rows and\n",
      "columns are arranged in such a way that entries that are adjacent in the map\n",
      "correspond to vertices that are adjacent in the hypercube representation. We\n",
      "show an example of the 4-dimensional even parity function in Fig. 2.2. (An\n",
      "even parity function is a Boolean function that has value 1 if there are an even\n",
      "number of its arguments that have value 1; otherwise it has value 0.) Note\n",
      "that all adjacent cells in the table correspond to inputs di\u000b",
      "ering in only one\n",
      "component. Also describe general logic\n",
      "diagrams , [Wnek, et al. , 1990].\n",
      "00 01 1011\n",
      "00\n",
      "01\n",
      "101111\n",
      "11\n",
      "1 111 000\n",
      "0\n",
      "000\n",
      "0x1,x2x3,x4\n",
      "Figure 2.2: A Karnaugh Map\n",
      "2.2 Classes of Boolean Functions\n",
      "2.2.1 Terms and Clauses\n",
      "To use absolute bias in machine learning, we limit the class of hypotheses. In\n",
      "learning Boolean functions, we frequently use some of the common sub-classes of\n",
      "those functions. Therefore, it will be important to know about these subclasses.\n",
      "One basic subclass is called terms . A term is any function written in the\n",
      "forml1l2\u0001\u0001\u0001lk, where the liare literals. Such a form is called a conjunction of\n",
      "literals. Some example terms are x1x7andx1x2x4. The sizeof a term is the\n",
      "number of literals it contains. The examples are of sizes 2 and 3, respectively.\n",
      "(Strictly speaking, the class of conjunctions of literals is called the monomials ,\n",
      "18 CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "and a conjunction of literals itself is called a term. This distinction is a \f",
      "ne one\n",
      "which we elect to blur here.)\n",
      "It is easy to show that there are exactly 3npossible terms of nvariables.\n",
      "The number of terms of size kor less is bounded from above byPk\n",
      "i=0C(2n;i) =\n",
      "O(nk), whereC(i;j) =i!\n",
      "(i\u0000j)!j!is the binomial coe\u000ecient. Probably I'll put in a simple\n",
      "term-learning algorithm here|so\n",
      "we can get started on learning!\n",
      "Also for DNF functions and\n",
      "decision lists|as they are de\f",
      "ned\n",
      "in the next few pages.Aclause is any function written in the form l1+l2+\u0001\u0001\u0001+lk, where the liare\n",
      "literals. Such a form is called a disjunction of literals. Some example clauses\n",
      "arex3+x5+x6andx1+x4. The sizeof a clause is the number of literals it\n",
      "contains. There are 3npossible clauses and fewer thanPk\n",
      "i=0C(2n;i) clauses of\n",
      "sizekor less. Iffis a term, then (by De Morgan's laws) fis a clause, and vice\n",
      "versa. Thus, terms and clauses are duals of each other.\n",
      "In psychological experiments, conjunctions of literals seem easier for humans\n",
      "to learn than disjunctions of literals.\n",
      "2.2.2 DNF Functions\n",
      "A Boolean function is said to be in disjunctive normal form (DNF) if it can be\n",
      "written as a disjunction of terms. Some examples in DNF are: f=x1x2+x2x3x4\n",
      "andf=x1x3+x2x3+x1x2x3. A DNF expression is called a k-term DNF\n",
      "expression if it is a disjunction of kterms; it is in the class k-DNF if the size of\n",
      "its largest term is k. The examples above are 2-term and 3-term expressions,\n",
      "respectively. Both expressions are in the class 3-DNF.\n",
      "Each term in a DNF expression for a function is called an implicant because\n",
      "it \\implies\" the function (if the term has value 1, so does the function). In\n",
      "general, a term, t, is an implicant of a function, f, iffhas value 1 whenever\n",
      "tdoes. A term, t, is a prime implicant offif the term, t0, formed by taking\n",
      "any literal out of an implicant tis no longer an implicant of f. (The implicant\n",
      "cannot be \\divided\" by any term and remain an implicant.)\n",
      "Thus, both x2x3andx1x3are prime implicants of f=x2x3+x1x3+x2x1x3,\n",
      "butx2x1x3is not.\n",
      "The relationship between implicants and prime implicants can be geometri-\n",
      "cally illustrated using the cube representation for Boolean functions. Consider,\n",
      "for example, the function f=x2x3+x1x3+x2x1x3. We illustrate it in Fig.\n",
      "2.3. Note that each of the three planes in the \f",
      "gure \\cuts o\u000b",
      "\" a group of\n",
      "vertices having value 1, but none cuts o\u000b",
      " any vertices having value 0. These\n",
      "planes are pictorial devices used to isolate certain lower dimensional subfaces\n",
      "of the cube. Two of them isolate one-dimensional edges , and the third isolates\n",
      "a zero-dimensional vertex . Each group of vertices on a subface corresponds to\n",
      "one of the implicants of the function, f, and thus each implicant corresponds\n",
      "to a subface of some dimension. A k-dimensional subface corresponds to an\n",
      "(n\u0000k)-size implicant term. The function is written as the disjunction of the\n",
      "implicants|corresponding to the union of all the vertices cut o\u000b",
      " by all of the\n",
      "planes. Geometrically, an implicant is prime if and only if its corresponding\n",
      "subface is the largest dimensional subface that includes all of its vertices and\n",
      "2.2. CLASSES OF BOOLEAN FUNCTIONS 19\n",
      "no other vertices having value 0. Note that the term x2x1x3is not a prime\n",
      "implicant of f. (In this case, we don't even have to include this term in the\n",
      "function because the vertex cut o\u000b",
      " by the plane corresponding to x2x1x3is\n",
      "already cut o\u000b",
      " by the plane corresponding to x2x3.) The other two implicants\n",
      "are prime because their corresponding subfaces cannot be expanded without\n",
      "including vertices having value 0.\n",
      "x2\n",
      "x1x3\n",
      "1, 0, 01, 0, 1\n",
      "1, 1, 10, 0, 1\n",
      "f = x2x3 + x1x3 + x2x1x3\n",
      "   = x2x3 + x1x3\n",
      "x2x3 and  x1x3 are prime implicants\n",
      "Figure 2.3: A Function and its Implicants\n",
      "Note that all Boolean functions can be represented in DNF|trivially by\n",
      "disjunctions of terms of size nwhere each term corresponds to one of the vertices\n",
      "whose value is 1. Whereas there are 22nfunctions of ndimensions in DNF (since\n",
      "any Boolean function can be written in DNF), there are just 2O(nk)functions\n",
      "ink-DNF.\n",
      "All Boolean functions can also be represented in DNF in which each term is\n",
      "a prime implicant, but that representation is not unique, as shown in Fig. 2.4.\n",
      "If we can express a function in DNF form, we can use the consensus method\n",
      "to \f",
      "nd an expression for the function in which each term is a prime implicant.\n",
      "The consensus method relies on two results: We may replace this section with\n",
      "one describing the\n",
      "Quine-McCluskey method instead.\u000fConsensus:\n",
      "20 CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "x2\n",
      "x1x3\n",
      "1, 0, 01, 0, 1\n",
      "1, 1, 10, 0, 1\n",
      "f = x2x3 + x1x3 + x1x2\n",
      "   = x1x2 + x1x3\n",
      "All of the terms are prime implicants, but there\n",
      "is not a unique representation\n",
      "Figure 2.4: Non-Uniqueness of Representation by Prime Implicants\n",
      "xi\u0001f1+xi\u0001f2=xi\u0001f1+xi\u0001f2+f1\u0001f2\n",
      "wheref1andf2are terms such that no literal appearing in f1appears\n",
      "complemented in f2.f1\u0001f2is called the consensus ofxi\u0001f1andxi\u0001\n",
      "f2. Readers familiar with the resolution rule of inference will note that\n",
      "consensus is the dual of resolution.\n",
      "Examples: x1is the consensus of x1x2andx1x2. The terms x1x2andx1x2\n",
      "have no consensus since each term has more than one literal appearing\n",
      "complemented in the other.\n",
      "\u000fSubsumption:\n",
      "xi\u0001f1+f1=f1\n",
      "wheref1is a term. We say that f1subsumesxi\u0001f1.\n",
      "Example:x1x4x5subsumesx1x4x2x5\n",
      "2.2. CLASSES OF BOOLEAN FUNCTIONS 21\n",
      "The consensus method for \f",
      "nding a set of prime implicants for a function,\n",
      "f, iterates the following operations on the terms of a DNF expression for funtil\n",
      "no more such operations can be applied:\n",
      "a. initialize the process with the set, T, of terms in the DNF expression of\n",
      "f,\n",
      "b. compute the consensus of a pair of terms in Tand add the result to T,\n",
      "c. eliminate any terms in Tthat are subsumed by other terms in T.\n",
      "When this process halts, the terms remaining in Tare all prime implicants of\n",
      "f.\n",
      "Example: Let f=x1x2+x1x2x3+x1x2x3x4x5. We show a derivation of\n",
      "a set of prime implicants in the consensus tree of Fig. 2.5. The circled numbers\n",
      "adjoining the terms indicate the order in which the consensus and subsumption\n",
      "operations were performed. Shaded boxes surrounding a term indicate that it\n",
      "was subsumed. The \f",
      "nal form of the function in which all terms are prime\n",
      "implicants is: f=x1x2+x1x3+x1x4x5. Its terms are all of the non-subsumed\n",
      "terms in the consensus tree.\n",
      " x1x2x1x2x3x1x2x3x4x5\n",
      " x1x3\n",
      "x1x2x4x5\n",
      "x1x4x5f = x1x2+ +  x1x3x1x4x512\n",
      "64\n",
      "53\n",
      "Figure 2.5: A Consensus Tree\n",
      "2.2.3 CNF Functions\n",
      "Disjunctive normal form has a dual: conjunctive normal form (CNF) . A Boolean\n",
      "function is said to be in CNF if it can be written as a conjunction of clauses.\n",
      "22 CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "An example in CNF is: f= (x1+x2)(x2+x3+x4). A CNF expression is called\n",
      "ak-clause CNF expression if it is a conjunction of kclauses; it is in the class\n",
      "k-CNF if the size of its largest clause is k. The example is a 2-clause expression\n",
      "in 3-CNF. If fis written in DNF, an application of De Morgan's law renders f\n",
      "in CNF, and vice versa. Because CNF and DNF are duals, there are also 2O(nk)\n",
      "functions in k-CNF.\n",
      "2.2.4 Decision Lists\n",
      "Rivest has proposed a class of Boolean functions called decision lists [Rivest, 1987].\n",
      "A decision list is written as an ordered list of pairs:\n",
      "(tq;vq)\n",
      "(tq\u00001;vq\u00001)\n",
      "\u0001\u0001\u0001\n",
      "(ti;vi)\n",
      "\u0001\u0001\u0001\n",
      "(t2;v2)\n",
      "(T;v1)\n",
      "where theviare either 0 or 1, the tiare terms in ( x1;:::;xn), andTis a term\n",
      "whose value is 1 (regardless of the values of the xi). The value of a decision list\n",
      "is the value of vifor the \f",
      "rst tiin the list that has value 1. (At least one tiwill\n",
      "have value 1, because the last one does; v1can be regarded as a default value of\n",
      "the decision list.) The decision list is of sizek, if the size of the largest term in\n",
      "it isk. The class of decision lists of size kor less is called k-DL.\n",
      "An example decision list is:\n",
      "f=\n",
      "(x1x2;1)\n",
      "(x1x2x3;0)\n",
      "x2x3;1)\n",
      "(1;0)\n",
      "fhas value 0 for x1= 0,x2= 0, andx3= 1. It has value 1 for x1= 1,x2= 0,\n",
      "andx3= 1. This function is in 3-DL.\n",
      "It has been shown that the class k-DL is a strict superset of the union of\n",
      "k-DNF andk-CNF. There are 2O[nkklog(n)]functions in k-DL [Rivest, 1987].\n",
      "Interesting generalizations of decision lists use other Boolean functions in\n",
      "place of the terms, ti. For example we might use linearly separable functions in\n",
      "place of the ti(see below and [Marchand & Golea, 1993]).\n",
      "2.2. CLASSES OF BOOLEAN FUNCTIONS 23\n",
      "2.2.5 Symmetric and Voting Functions\n",
      "A Boolean function is called symmetric if it is invariant under permutations\n",
      "of the input variables. For example, any function that is dependent only on\n",
      "the number of input variables whose values are 1 is a symmetric function. The\n",
      "parity functions, which have value 1 depending on whether or not the number\n",
      "of input variables with value 1 is even or odd is a symmetric function. (The\n",
      "exclusive or function, illustrated in Fig. 2.1, is an odd-parity function of two\n",
      "dimensions. The orand andfunctions of two dimensions are also symmetric.)\n",
      "An important subclass of the symmetric functions is the class of voting func-\n",
      "tions (also called m-of-nfunctions). A k-voting function has value 1 if and only\n",
      "ifkor more of its ninputs has value 1. If k= 1, a voting function is the same\n",
      "as ann-sized clause; if k=n, a voting function is the same as an n-sized term;\n",
      "ifk= (n+ 1)=2 fornodd ork= 1 +n=2 forneven, we have the majority\n",
      "function.\n",
      "2.2.6 Linearly Separable Functions\n",
      "The linearly separable functions are those that can be expressed as follows:\n",
      "f= thresh(nX\n",
      "i=1wixi;\u0012)\n",
      "wherewi,i= 1;:::;n , are real-valued numbers called weights ,\u0012is a real-valued\n",
      "number called the threshold , and thresh( \u001b;\u0012) is 1 if\u001b\u0015\u0012and 0 otherwise.\n",
      "(Note that the concept of linearly separable functions can be extended to non-\n",
      "Boolean inputs.) The k-voting functions are all members of the class of linearly\n",
      "separable functions in which the weights all have unit value and the threshold\n",
      "depends on k. Thus, terms and clauses are special cases of linearly separable\n",
      "functions.\n",
      "A convenient way to write linearly separable functions uses vector notation:\n",
      "f= thresh( X\u0001W;\u0012)\n",
      "where X= (x1;:::;xn) is ann-dimensional vector of input variables, W=\n",
      "(w1;:::;wn) is ann-dimensional vector of weight values, and X\u0001Wis the dot\n",
      "(orinner ) product of the two vectors. Input vectors for which fhas value 1 lie\n",
      "in a half-space on one side of (and on) a hyperplane whose orientation is normal\n",
      "toWand whose position (with respect to the origin) is determined by \u0012. We\n",
      "saw an example of such a separating plane in Fig. 1.6. With this idea in mind,\n",
      "it is easy to see that two of the functions in Fig. 2.1 are linearly separable, while\n",
      "two are not. Also note that the terms in Figs. 2.3 and 2.4 are linearly separable\n",
      "functions as evidenced by the separating planes shown.\n",
      "There is no closed-form expression for the number of linearly separable func-\n",
      "tions ofndimensions, but the following table gives the numbers for nup to 6.\n",
      "24 CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "n Boolean Linearly Separable\n",
      "Functions Functions\n",
      "1 4 4\n",
      "2 16 14\n",
      "3 256 104\n",
      "4 65,536 1,882\n",
      "5\u00194:3\u000210994,572\n",
      "6\u00191:8\u0002101915,028,134\n",
      "[Muroga, 1971] has shown that (for n>1) there are no more than 2n2linearly\n",
      "separable functions of ndimensions. (See also [Winder, 1961, Winder, 1962].)\n",
      "2.3 Summary\n",
      "The diagram in Fig. 2.6 shows some of the set inclusions of the classes of Boolean\n",
      "functions that we have considered. We will be confronting these classes again\n",
      "in later chapters.\n",
      "DNF\n",
      "(All)k-DL k-DNFk-size-\n",
      "terms\n",
      "terms\n",
      "lin sep\n",
      "Figure 2.6: Classes of Boolean Functions\n",
      "The sizes of the various classes are given in the following table (adapted from\n",
      "[Dietterich, 1990, page 262]):\n",
      "2.4. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 25\n",
      "Class Size of Class\n",
      "terms 3n\n",
      "clauses 3n\n",
      "k-term DNF 2O(kn)\n",
      "k-clause CNF 2O(kn)\n",
      "k-DNF 2O(nk)\n",
      "k-CNF 2O(nk)\n",
      "k-DL 2O[nkklog(n)]\n",
      "lin sep 2O(n2)\n",
      "DNF 22n\n",
      "2.4 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "26 CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "Chapter 3\n",
      "Using Version Spaces for\n",
      "Learning\n",
      "3.1 Version Spaces and Mistake Bounds\n",
      "The \f",
      "rst learning methods we present are based on the concepts of version\n",
      "spaces and version graphs . These ideas are most clearly explained for the case\n",
      "of Boolean function learning. Given an initial hypothesis set H(a subset of\n",
      "all Boolean functions) and the values of f(X) for each Xin a training set, \u0004,\n",
      "the version space is that subset of hypotheses, Hv, that is consistent with these\n",
      "values. A hypothesis, h, isconsistent with the values of Xin \u0004 if and only if\n",
      "h(X) =f(X) for all Xin \u0004. We say that the hypotheses in Hthat are not\n",
      "consistent with the values in the training set are ruled out by the training set.\n",
      "We could imagine (conceptually only!) that we have devices for implement-\n",
      "ing every function in H. An incremental training procedure could then be\n",
      "de\f",
      "ned which presented each pattern in \u0004 to each of these functions and then\n",
      "eliminated those functions whose values for that pattern did not agree with its\n",
      "given value. At any stage of the process we would then have left some subset\n",
      "of functions that are consistent with the patterns presented so far; this subset\n",
      "is the version space for the patterns already presented. This idea is illustrated\n",
      "in Fig. 3.1.\n",
      "Consider the following procedure for classifying an arbitrary input pattern,\n",
      "X: the pattern is put in the same class (0 or 1) as are the majority of the\n",
      "outputs of the functions in the version space. During the learning procedure,\n",
      "if this majority is not equal to the value of the pattern presented, we say a\n",
      "mistake is made, and we revise the version space accordingly|eliminating all\n",
      "those (majority of the) functions voting incorrectly. Thus, whenever a mistake\n",
      "is made, we rule out at least half of the functions remaining in the version space.\n",
      "How many mistakes can such a procedure make? Obviously, we can make\n",
      "no more than log2(jHj) mistakes, where jHjis the number of hypotheses in the\n",
      "27\n",
      "28 CHAPTER 3. USING VERSION SPACES FOR LEARNING\n",
      "h1\n",
      "h2\n",
      "hi\n",
      "hKXA Subset, H,  of all\n",
      "Boolean Functions\n",
      "Rule out hypotheses not\n",
      "consistent with training patterns\n",
      "hj\n",
      "Hypotheses not ruled out\n",
      "constitute the version space\n",
      "K = |H|1 or 0\n",
      "Figure 3.1: Implementing the Version Space\n",
      "original hypothesis set, H. (Note, though, that the number of training patterns\n",
      "seen before this maximum number of mistakes is made might be much greater.)\n",
      "This theoretical (and very impractical!) result (due to [Littlestone, 1988]) is an\n",
      "example of a mistake bound |an important concept in machine learning theory.\n",
      "It shows that there must exist a learning procedure that makes no more mistakes\n",
      "than this upper bound. Later, we'll derive other mistake bounds.\n",
      "As a special case, if our bias was to limit Hto terms, we would make no\n",
      "more than log2(3n) =nlog2(3) = 1:585nmistakes before exhausting the version\n",
      "space. This result means that if fwere a term, we would make no more than\n",
      "1:585nmistakes before learning f, and otherwise we would make no more than\n",
      "that number of mistakes before being able to decide that fis not a term.\n",
      "Even if we do not have su\u000ecient training patterns to reduce the version\n",
      "space to a single function, it may be that there are enough training patterns\n",
      "to reduce the version space to a set of functions such that most of them assign\n",
      "the same values to most of the patterns we will see henceforth. We could select\n",
      "one of the remaining functions at random and be reasonably assured that it\n",
      "will generalize satisfactorily. We next discuss a computationally more feasible\n",
      "method for representing the version space.\n",
      "3.2. VERSION GRAPHS 29\n",
      "3.2 Version Graphs\n",
      "Boolean functions can be ordered by generality . A Boolean function, f1, ismore\n",
      "general than a function, f2, (andf2ismore speci\f",
      "c thanf1), iff1has value 1\n",
      "for all of the arguments for which f2has value 1, and f16=f2. For example, x3\n",
      "is more general than x2x3but is not more general than x3+x2.\n",
      "We can form a graph with the hypotheses, fhig, in the version space as\n",
      "nodes. A node in the graph, hi, has an arc directed to node, hj, if and only if\n",
      "hjis more general than hi. We call such a graph a version graph . In Fig. 3.2,\n",
      "we show an example of a version graph over a 3-dimensional input space for\n",
      "hypotheses restricted to terms (with none of them yet ruled out).\n",
      "0x1x2x3 x2 x31\n",
      "x1x2x3x1x2x1Version Graph for Terms\n",
      "x1x2x3\n",
      "(for simplicity, only some arcs in the graph are shown)(none yet ruled out)\n",
      "(k = 1)\n",
      "(k = 2)\n",
      "(k = 3)x1x3\n",
      "Figure 3.2: A Version Graph for Terms\n",
      "That function, denoted here by \\1,\" which has value 1 for all inputs, corre-\n",
      "sponds to the node at the top of the graph. (It is more general than any other\n",
      "term.) Similarly, the function \\0\" is at the bottom of the graph. Just below\n",
      "\\1\" is a row of nodes corresponding to all terms having just one literal, and just\n",
      "below them is a row of nodes corresponding to terms having two literals, and\n",
      "30 CHAPTER 3. USING VERSION SPACES FOR LEARNING\n",
      "so on. There are 33= 27 functions altogether (the function \\0,\" included in\n",
      "the graph, is technically not a term). To make our portrayal of the graph less\n",
      "cluttered only some of the arcs are shown; each node in the actual graph has an\n",
      "arc directed to all of the nodes above it that are more general.\n",
      "We use this same example to show how the version graph changes as we\n",
      "consider a set of labeled samples in a training set, \u0004. Suppose we \f",
      "rst consider\n",
      "the training pattern (1, 0, 1) with value 0. Some of the functions in the version\n",
      "graph of Fig. 3.2 are inconsistent with this training pattern. These ruled out\n",
      "nodes are no longer in the version graph and are shown shaded in Fig. 3.3. We\n",
      "also show there the three-dimensional cube representation in which the vertex\n",
      "(1, 0, 1) has value 0.\n",
      "0x1x2 x3 x2 x31\n",
      "x1x2x3x1x2x1New Version Graph1, 0, 1 has\n",
      "value 0\n",
      "x1x3x1x2x2x3\n",
      "x1x2x3x1x2x3\n",
      "x1x3\n",
      "(only some arcs in the graph are shown)ruled out nodes\n",
      "Figure 3.3: The Version Graph Upon Seeing (1, 0, 1)\n",
      "In a version graph, there are always a set of hypotheses that are maximally\n",
      "general and a set of hypotheses that are maximally speci\f",
      "c. These are called\n",
      "thegeneral boundary set (gbs) and the speci\f",
      "c boundary set (sbs) , respectively.\n",
      "In Fig. 3.4, we have the version graph as it exists after learning that (1,0,1) has\n",
      "value 0 and (1, 0, 0) has value 1. The gbs and sbs are shown.\n",
      "3.2. VERSION GRAPHS 31\n",
      "0x1x2x3\n",
      "x2 x31\n",
      "x1x2x3x1\n",
      "x2x3 x1x3general boundary set\n",
      "(gbs)\n",
      "specific boundary set (sbs)x1x2more specific than gbs,\n",
      "more general than sbs1, 0, 1 has\n",
      "value 0\n",
      "x1x2x3\n",
      "1, 0, 0 has\n",
      "value 1\n",
      "Figure 3.4: The Version Graph Upon Seeing (1, 0, 1) and (1, 0, 0)\n",
      "Boundary sets are important because they provide an alternative to repre-\n",
      "senting the entire version space explicitly, which would be impractical. Given\n",
      "only the boundary sets, it is possible to determine whether or not any hypoth-\n",
      "esis (in the prescribed class of Boolean functions we are using) is a member or\n",
      "not of the version space. This determination is possible because of the fact that\n",
      "any member of the version space (that is not a member of one of the boundary\n",
      "sets) is more speci\f",
      "c than some member of the general boundary set and is more\n",
      "general than some member of the speci\f",
      "c boundary set.\n",
      "If we limit our Boolean functions that can be in the version space to terms,\n",
      "it is a simple matter to determine maximally general and maximally speci\f",
      "c\n",
      "functions (assuming that there is some term that is in the version space). A\n",
      "maximally speci\f",
      "c one corresponds to a subface of minimal dimension that\n",
      "contains all the members of the training set labelled by a 1 and no members\n",
      "labelled by a 0. A maximally general one corresponds to a subface of maximal\n",
      "dimension that contains all the members of the training set labelled by a 1 and\n",
      "no members labelled by a 0. Looking at Fig. 3.4, we see that the subface of\n",
      "minimal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is just\n",
      "the vertex (1, 0, 0) itself|corresponding to the function x1x2x3. The subface\n",
      "32 CHAPTER 3. USING VERSION SPACES FOR LEARNING\n",
      "of maximal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is\n",
      "the bottom face of the cube|corresponding to the function x3. In Figs. 3.2\n",
      "through 3.4 the sbs is always singular. Version spaces for terms always have\n",
      "singular speci\f",
      "c boundary sets. As seen in Fig. 3.3, however, the gbs of a\n",
      "version space for terms need not be singular.\n",
      "3.3 Learning as Search of a Version Space\n",
      "[To be written. Relate to term learning algorithm presented in Chapter\n",
      "Two. Also discuss best-\f",
      "rst search methods. See Pat Langley's example us-\n",
      "ing \\pseudo-cells\" of how to generate and eliminate hypotheses.]\n",
      "Selecting a hypothesis from the version space can be thought of as a search\n",
      "problem. One can start with a very general function and specialize it through\n",
      "various specialization operators until one \f",
      "nds a function that is consistent (or\n",
      "adequately so) with a set of training patterns. Such procedures are usually\n",
      "called top-down methods. Or, one can start with a very special function and\n",
      "generalize it|resulting in bottom-up methods. We shall see instances of both\n",
      "styles of learning in this book. Compare this view of top-down\n",
      "versus bottom-up with the\n",
      "divide-and-conquer and the\n",
      "covering (or AQ) methods of\n",
      "decision-tree induction. 3.4 The Candidate Elimination Method\n",
      "The candidate elimination method , is an incremental method for computing the\n",
      "boundary sets. Quoting from [Hirsh, 1994, page 6]:\n",
      "\\The candidate-elimination algorithm manipulates the boundary-set\n",
      "representation of a version space to create boundary sets that rep-\n",
      "resent a new version space consistent with all the previous instances\n",
      "plus the new one. For a positive exmple the algorithm generalizes\n",
      "the elements of the [sbs] as little as possible so that they cover the\n",
      "new instance yet remain consistent with past data, and removes\n",
      "those elements of the [gbs] that do not cover the new instance. For\n",
      "a negative instance the algorithm specializes elements of the [gbs]\n",
      "so that they no longer cover the new instance yet remain consis-\n",
      "tent with past data, and removes from the [sbs] those elements that\n",
      "mistakenly cover the new, negative instance.\"\n",
      "The method uses the following de\f",
      "nitions (adapted from\n",
      "[Genesereth & Nilsson, 1987]):\n",
      "\u000fa hypothesis is called su\u000ecient if and only if it has value 1 for all training\n",
      "samples labeled by a 1,\n",
      "\u000fa hypothesis is called necessary if and only if it has value 0 for all training\n",
      "samples labeled by a 0.\n",
      "3.4. THE CANDIDATE ELIMINATION METHOD 33\n",
      "Here is how to think about these de\f",
      "nitions: A hypothesis implements a su\u000e-\n",
      "cient condition that a training sample has value 1 if the hypothesis has value 1\n",
      "for all of the positive instances; a hypothesis implements a necessary condition\n",
      "that a training sample has value 1 if the hypothesis has value 0 for all of the\n",
      "negative instances. A hypothesis is consistent with the training set (and thus is\n",
      "in the version space) if and only if it is both su\u000ecient and necessary.\n",
      "We start (before receiving any members of the training set) with the function\n",
      "\\0\" as the singleton element of the speci\f",
      "c boundary set and with the function\n",
      "\\1\" as the singleton element of the general boundary set. Upon receiving a new\n",
      "labeled input vector, the boundary sets are changed as follows:\n",
      "a. If the new vector is labelled with a 1:\n",
      "The new general boundary set is obtained from the previous one by ex-\n",
      "cluding any elements in it that are not su\u000ecient. (That is, we exclude any\n",
      "elements that have value 0 for the new vector.)\n",
      "The new speci\f",
      "c boundary set is obtained from the previous one by re-\n",
      "placing each element, hi, in it by all of its least generalizations .\n",
      "The hypothesis hgis a least generalization ofhif and only if: a) his\n",
      "more speci\f",
      "c than hg, b)hgis su\u000ecient, c) no function (including h) that\n",
      "is more speci\f",
      "c than hgis su\u000ecient, and d) hgis more speci\f",
      "c than some\n",
      "member of the new general boundary set. It might be that hg=h. Also,\n",
      "least generalizations of two di\u000b",
      "erent functions in the speci\f",
      "c boundary set\n",
      "may be identical.\n",
      "b. If the new vector is labelled with a 0:\n",
      "The new speci\f",
      "c boundary set is obtained from the previous one by ex-\n",
      "cluding any elements in it that are not necessary. (That is, we exclude\n",
      "any elements that have value 1 for the new vector.)\n",
      "The new general boundary set is obtained from the previous one by re-\n",
      "placing each element, hi, in it by all of its least specializations .\n",
      "The hypothesis hsis aleast specialization ofhif and only if: a) his more\n",
      "general than hs, b)hsis necessary, c) no function (including h) that is\n",
      "more general than hsis necessary, and d) hsis more general than some\n",
      "member of the new speci\f",
      "c boundary set. Again, it might be that hs=h,\n",
      "and least specializations of two di\u000b",
      "erent functions in the general boundary\n",
      "set may be identical.\n",
      "As an example, suppose we present the vectors in the following order:\n",
      "vector label\n",
      "(1, 0, 1) 0\n",
      "(1, 0, 0) 1\n",
      "(1, 1, 1) 0\n",
      "(0, 0, 1) 0\n",
      "34 CHAPTER 3. USING VERSION SPACES FOR LEARNING\n",
      "We start with general boundary set, \\1\", and speci\f",
      "c boundary set, \\0.\"\n",
      "After seeing the \f",
      "rst sample, (1, 0, 1), labeled with a 0, the speci\f",
      "c boundary\n",
      "set stays at \\0\" (it is necessary), and we change the general boundary set to\n",
      "fx1;x2;x3g. Each of the functions, x1,x2, andx3, are least specializations of\n",
      "\\1\" (they are necessary, \\1\" is not, they are more general than \\0\", and there\n",
      "are no functions that are more general than they and also necessary).\n",
      "Then, after seeing (1, 0, 0), labeled with a 1, the general boundary set\n",
      "changes tofx3g(becausex1andx2are not su\u000ecient), and the speci\f",
      "c boundary\n",
      "set is changed to fx1x2x3g. This single function is a least generalization of \\0\"\n",
      "(it is su\u000ecient, \\0\" is more speci\f",
      "c than it, no function (including \\0\") that is\n",
      "more speci\f",
      "c than it is su\u000ecient, and it is more speci\f",
      "c than some member of\n",
      "the general boundary set.\n",
      "When we see (1, 1, 1), labeled with a 0, we do not change the speci\f",
      "c\n",
      "boundary set because its function is still necessary. We do not change the\n",
      "general boundary set either because x3is still necessary.\n",
      "Finally, when we see (0, 0, 1), labeled with a 0, we do not change the speci\f",
      "c\n",
      "boundary set because its function is still necessary. We do not change the general\n",
      "boundary set either because x3is still necessary. Maybe I'll put in an example of a\n",
      "version graph for non-Boolean\n",
      "functions.\n",
      "3.5 Bibliographical and Historical Remarks\n",
      "The concept of version spaces and their role in learning was \f",
      "rst investigated\n",
      "by Tom Mitchell [Mitchell, 1982]. Although these ideas are not used in prac-\n",
      "tical machine learning procedures, they do provide insight into the nature of\n",
      "hypothesis selection. In order to accomodate noisy data, version spaces have\n",
      "been generalized by [Hirsh, 1994] to allow hypotheses that are not necessarily\n",
      "consistent with the training set. More to be added.\n",
      "Chapter 4\n",
      "Neural Networks\n",
      "In chapter two we de\f",
      "ned several important subsets of Boolean functions. Sup-\n",
      "pose we decide to use one of these subsets as a hypothesis set for supervised\n",
      "function learning. We next have the question of how best to implement the\n",
      "function as a device that gives the outputs prescribed by the function for arbi-\n",
      "trary inputs. In this chapter we describe how networks of non-linear elements\n",
      "can be used to implement various input-output functions and how they can be\n",
      "trained using supervised learning methods.\n",
      "Networks of non-linear elements, interconnected through adjustable weights,\n",
      "play a prominent role in machine learning. They are called neural networks be-\n",
      "cause the non-linear elements have as their inputs a weighted sum of the outputs\n",
      "of other elements|much like networks of biological neurons do. These networks\n",
      "commonly use the threshold element which we encountered in chapter two in\n",
      "our study of linearly separable Boolean functions. We begin our treatment of\n",
      "neural nets by studying this threshold element and how it can be used in the\n",
      "simplest of all networks, namely ones composed of a single threshold element.\n",
      "4.1 Threshold Logic Units\n",
      "4.1.1 De\f",
      "nitions and Geometry\n",
      "Linearly separable (threshold) functions are implemented in a straightforward\n",
      "way by summing the weighted inputs and comparing this sum to a threshold\n",
      "value as shown in Fig. 4.1. This structure we call a threshold logic unit (TLU) .\n",
      "Its output is 1 or 0 depending on whether or not the weighted sum of its inputs is\n",
      "greater than or equal to a threshold value, \u0012. It has also been called an Adaline\n",
      "(for ada ptive lin ear e lement) [Widrow, 1962, Widrow & Lehr, 1990], an LTU\n",
      "(linear threshold unit), a perceptron , and a neuron . (Although the word \\per-\n",
      "ceptron\" is often used nowadays to refer to a single TLU, Rosenblatt originally\n",
      "de\f",
      "ned it as a class of networks of threshold elements [Rosenblatt, 1958].)\n",
      "35\n",
      "36 CHAPTER 4. NEURAL NETWORKS\n",
      "!x1\n",
      "x2\n",
      "xn+1 = 1xiw1\n",
      "w2\n",
      "wn+1wi\n",
      "wnX\n",
      "threshold weightxnW threshold  \"  = 0\n",
      "f\n",
      "f = thresh ( ! wi xi,  0)\n",
      "i = 1n+1\n",
      "Figure 4.1: A Threshold Logic Unit (TLU)\n",
      "Then-dimensional feature or input vector is denoted by X= (x1;:::;xn).\n",
      "When we want to distinguish among di\u000b",
      "erent feature vectors, we will attach\n",
      "subscripts, such as Xi. The components of Xcan be any real-valued numbers,\n",
      "but we often specialize to the binary numbers 0 and 1. The weights of a TLU\n",
      "are represented by an n-dimensional weight vector ,W= (w1;:::;wn). Its\n",
      "components are real-valued numbers (but we sometimes specialize to integers).\n",
      "The TLU has output 1 ifPn\n",
      "i=1xiwi\u0015\u0012; otherwise it has output 0. The\n",
      "weighted sum that is calculated by the TLU can be simply represented as a\n",
      "vector dot product, X\u000fW. (If the pattern and weight vectors are thought of as\n",
      "\\column\" vectors, this dot product is then sometimes written as XtW, where\n",
      "the \\row\" vector Xtis the transpose of X.) Often, the threshold, \u0012, of the TLU\n",
      "is \f",
      "xed at 0; in that case, arbitrary thresholds are achieved by using ( n+ 1)-\n",
      "dimensional \\augmented\" vectors, Y, and V, whose \f",
      "rst ncomponents are the\n",
      "same as those of XandW, respectively. The ( n+ 1)-st component, xn+1, of\n",
      "the augmented feature vector, Y, always has value 1; the ( n+ 1)-st component,\n",
      "wn+1, of the augmented weight vector, V, is set equal to the negative of the\n",
      "desired threshold value. (When we want to emphasize the use of augmented\n",
      "vectors, we'll use the Y,Vnotation; however when the context of the discussion\n",
      "makes it clear about what sort of vectors we are talking about, we'll lapse back\n",
      "into the more familiar X,Wnotation.) In the Y,Vnotation, the TLU has an\n",
      "output of 1 if Y\u000fV\u00150. Otherwise, the output is 0.\n",
      "We can give an intuitively useful geometric description of a TLU. A TLU\n",
      "divides the input space by a hyperplane as sketched in Fig. 4.2. The hyperplane\n",
      "is the boundary between patterns for which X\u000fW+wn+1>0 and patterns\n",
      "for which X\u000fW+wn+1<0. Thus, the equation of the hyperplane itself is\n",
      "X\u000fW+wn+1= 0. The unit vector that is normal to the hyperplane is n=W\n",
      "jWj,\n",
      "wherejWj=p\n",
      "(w2\n",
      "1+:::+w2n) is the length of the vector W. (The normal\n",
      "4.1. THRESHOLD LOGIC UNITS 37\n",
      "form of the hyperplane equation is X\u000fn+W\n",
      "jWj= 0.) The distance from the\n",
      "hyperplane to the origin iswn+1\n",
      "jWj, and the distance from an arbitrary point, X,\n",
      "to the hyperplane isX\u000fW+wn+1\n",
      "jWj. When the distance from the hyperplane to the\n",
      "origin is negative (that is, when wn+1<0), then the origin is on the negative\n",
      "side of the hyperplane (that is, the side for which X\u000fW+wn+1<0).\n",
      "X.W + wn+1 > 0\n",
      "on this side\n",
      "WX\n",
      "W\n",
      "n =W\n",
      "|W|Origin\n",
      "Unit vector normal\n",
      "to hyperplaneW + wn+1 = 0 X\n",
      "n +           = 0 XEquations of hyperplane:\n",
      "wn+1\n",
      "|W|\n",
      "wn+1 W + wn+1X\n",
      "X.W + wn+1 < 0\n",
      "on this side\n",
      "Figure 4.2: TLU Geometry\n",
      "Adjusting the weight vector, W, changes the orientation of the hyperplane;\n",
      "adjustingwn+1changes the position of the hyperplane (relative to the origin).\n",
      "Thus, training of a TLU can be achieved by adjusting the values of the weights.\n",
      "In this way the hyperplane can be moved so that the TLU implements di\u000b",
      "erent\n",
      "(linearly separable) functions of the input.\n",
      "4.1.2 Special Cases of Linearly Separable Functions\n",
      "Terms\n",
      "Any term of size kcan be implemented by a TLU with a weight from each of\n",
      "those inputs corresponding to variables occurring in the term. A weight of +1 is\n",
      "used from an input corresponding to a positive literal, and a weight of \u00001 is used\n",
      "from an input corresponding to a negative literal. (Literals not mentioned in\n",
      "the term have weights of zero|that is, no connection at all|from their inputs.)\n",
      "The threshold, \u0012, is set equal to kp\u00001=2, wherekpis the number of positive\n",
      "literals in the term. Such a TLU implements a hyperplane boundary that is\n",
      "38 CHAPTER 4. NEURAL NETWORKS\n",
      "parallel to a subface of dimension ( n\u0000k) of the unit hypercube. We show a\n",
      "three-dimensional example in Fig. 4.3. Thus, linearly separable functions are a\n",
      "superset of terms.\n",
      "(1,1,1)\n",
      "(1,1,0)x2\n",
      "x1x3f = x1x2\n",
      "x1 + x2 - 3/2 = 0Equation of plane is:\n",
      "Figure 4.3: Implementing a Term\n",
      "Clauses\n",
      "The negation of a clause is a term. For example, the negation of the clause\n",
      "f=x1+x2+x3is the term f=x1x2x3. A hyperplane can be used to\n",
      "implement this term. If we \\invert\" the hyperplane, it will implement the\n",
      "clause instead. Inverting a hyperplane is done by multiplying all of the TLU\n",
      "weights|even wn+1|by\u00001. This process simply changes the orientation of the\n",
      "hyperplane|\r",
      "ipping it around by 180 degrees and thus changing its \\positive\n",
      "side.\" Therefore, linearly separable functions are also a superset of clauses. We\n",
      "show an example in Fig. 4.4.\n",
      "4.1.3 Error-Correction Training of a TLU\n",
      "There are several procedures that have been proposed for adjusting the weights\n",
      "of a TLU. We present next a family of incremental training procedures with\n",
      "parameterc. These methods make adjustments to the weight vector only when\n",
      "the TLU being trained makes an error on a training pattern; they are called\n",
      "error-correction procedures. We use augmented feature and weight vectors in\n",
      "describing them.\n",
      "a. We start with a \f",
      "nite training set, \u0004, of vectors, Yi, and their binary\n",
      "labels.\n",
      "4.1. THRESHOLD LOGIC UNITS 39\n",
      "f = x1 + x2 + x3\n",
      "x1\n",
      "x1 + x2 + x3 < 1/2 = 0f = x1x2x3\n",
      "Equation of plane is:x2x3\n",
      "Figure 4.4: Implementing a Clause\n",
      "b. Compose an in\f",
      "nite training sequence, \u0006, of vectors from \u0004 and their\n",
      "labels such that each member of \u0004 occurs in\f",
      "nitely often in \u0006. Set the\n",
      "initial weight values of an TLU to arbitrary values.\n",
      "c. Repeat forever:\n",
      "Present the next vector, Yi, in \u0006 to the TLU and note its response.\n",
      "(a) If the TLU responds correctly, make no change in the weight vector.\n",
      "(b) If Yiis supposed to produce an output of 0 and produces an output\n",
      "of 1 instead, modify the weight vector as follows:\n",
      "V \u0000V\u0000ciYi\n",
      "whereciis a positive real number called the learning rate parame-\n",
      "ter(whose value is di\u000b",
      "ererent in di\u000b",
      "erent instances of this family of\n",
      "procedures and may depend on i).\n",
      "Note that after this adjustment the new dot product will be ( V\u0000\n",
      "ciYi)\u000fYi=V\u000fYi\u0000ciYi\u000fYi, which is smaller than it was before the\n",
      "weight adjustment.\n",
      "(c) If Yiis supposed to produce an output of 1 and produces an output\n",
      "of 0 instead, modify the weight vector as follows:\n",
      "V \u0000V+ciYi\n",
      "In this case, the new dot product will be ( V+ciYi)\u000fYi=V\u000fYi+\n",
      "ciYi\u000fYi, which is larger than it was before the weight adjustment.\n",
      "Note that all three of these cases can be combined in the following rule:\n",
      "40 CHAPTER 4. NEURAL NETWORKS\n",
      "V \u0000V+ci(di\u0000fi)Yi\n",
      "wherediis the desired response (1 or 0) for Yi, andfiis the actual\n",
      "response (1 or 0) for Yi.]\n",
      "Note also that because the weight vector Vnow includes the wn+1thresh-\n",
      "old component, the threshold of the TLU is also changed by these adjust-\n",
      "ments.\n",
      "We identify two versions of this procedure:\n",
      "1) In the \f",
      "xed-increment procedure , the learning rate parameter, ci, is the\n",
      "same \f",
      "xed, positive constant for all i. Depending on the value of this constant,\n",
      "the weight adjustment may or may not correct the response to an erroneously\n",
      "classi\f",
      "ed feature vector.\n",
      "2) In the fractional-correction procedure , the parameter ciis set to\u0015Yi\u000fV\n",
      "Yi\u000fYi,\n",
      "where Vis the weight vector before it is changed. Note that if \u0015= 0, no\n",
      "correction takes place at all. If \u0015= 1, the correction is just su\u000ecient to make\n",
      "Yi\u000fV= 0. If\u0015>1, the error will be corrected.\n",
      "It can be proved that if there is some weight vector, V, that produces a\n",
      "correct output for all of the feature vectors in \u0004, then after a \f",
      "nite number\n",
      "of feature vector presentations, the \f",
      "xed-increment procedure will \f",
      "nd such a\n",
      "weight vector and thus make no more weight changes. The same result holds\n",
      "for the fractional-correction procedure if 1 <\u0015\u00142.\n",
      "For additional background, proofs, and examples of error-correction proce-\n",
      "dures, see [Nilsson, 1990]. See [Maass & Tur\u0013 an, 1994] for a\n",
      "hyperplane-\f",
      "nding procedure that\n",
      "makes no more than O(n2logn)\n",
      "mistakes.4.1.4 Weight Space\n",
      "We can give an intuitive idea about how these procedures work by considering\n",
      "what happens to the augmented weight vector in \\weight space\" as corrections\n",
      "are made. We use augmented vectors in our discussion here so that the threshold\n",
      "function compares the dot product, Yi\u000fV, against a threshold of 0. A particular\n",
      "weight vector, V, then corresponds to a point in ( n+ 1)-dimensional weight\n",
      "space. Now, for any pattern vector, Yi, consider the locus of all points in\n",
      "weight space corresponding to weight vectors yielding Yi\u000fV= 0. This locus is\n",
      "a hyperplane passing through the origin of the ( n+ 1)-dimensional space. Each\n",
      "pattern vector will have such a hyperplane corresponding to it. Weight points\n",
      "in one of the half-spaces de\f",
      "ned by this hyperplane will cause the corresponding\n",
      "pattern to yield a dot product less than 0, and weight points in the other half-\n",
      "space will cause the corresponding pattern to yield a dot product greater than\n",
      "0.\n",
      "We show a schematic representation of such a weight space in Fig. 4.5.\n",
      "There are four pattern hyperplanes, 1, 2, 3, 4 , corresponding to patterns Y1,\n",
      "4.1. THRESHOLD LOGIC UNITS 41\n",
      "Y2,Y3,Y4, respectively, and we indicate by an arrow the half-space for each\n",
      "in which weight vectors give dot products greater than 0. Suppose we wanted\n",
      "weight values that would give positive responses for patterns Y1,Y3, and Y4,\n",
      "and a negative response for pattern Y2. The weight point, V, indicated in the\n",
      "\f",
      "gure is one such set of weight values.\n",
      "23\n",
      "41\n",
      "V\n",
      "Figure 4.5: Weight Space\n",
      "The question of whether or not there exists a weight vector that gives desired\n",
      "responses for a given set of patterns can be given a geometric interpretation. To\n",
      "do so involves reversing the \\polarity\" of those hyperplanes corresponding to\n",
      "patterns for which a negative response is desired. If we do that for our example\n",
      "above, we get the weight space diagram shown in Fig. 4.6.\n",
      "23\n",
      "41\n",
      "V01\n",
      "123\n",
      "234\n",
      "Figure 4.6: Solution Region in Weight Space\n",
      "42 CHAPTER 4. NEURAL NETWORKS\n",
      "If a weight vector exists that correctly classi\f",
      "es a set of patterns, then the\n",
      "half-spaces de\f",
      "ned by the correct responses for these patterns will have a non-\n",
      "empty intersection, called the solution region. The solution region will be a\n",
      "\\hyper-wedge\" region whose vertex is at the origin of weight space and whose\n",
      "cross-section increases with increasing distance from the origin. This region\n",
      "is shown shaded in Fig. 4.6. (The boxed numbers show, for later purposes,\n",
      "the number of errors made by weight vectors in each of the regions.) The\n",
      "\f",
      "xed-increment error-correction procedure changes a weight vector by moving it\n",
      "normal to any pattern hyperplane for which that weight vector gives an incorrect\n",
      "response. Suppose in our example that we present the patterns in the sequence\n",
      "Y1,Y2,Y3,Y4, and start the process with a weight point V1, as shown in Fig.\n",
      "4.7. Starting at V1, we see that it gives an incorrect response for pattern Y1, so\n",
      "we move V1toV2in a direction normal to plane 1. (That is what adding Y1to\n",
      "V1does.) Y2gives an incorrect response for pattern Y2, and so on. Ultimately,\n",
      "the responses are only incorrect for planes bounding the solution region. Some\n",
      "of the subsequent corrections may overshoot the solution region, but eventually\n",
      "we work our way out far enough in the solution region that corrections (for\n",
      "a \f",
      "xed increment size) take us within it. The proofs for convergence of the\n",
      "\f",
      "xed-increment rule make this intuitive argument precise.\n",
      "23\n",
      "41\n",
      "VV1\n",
      "V2\n",
      "V3V4V5\n",
      "V6\n",
      "Figure 4.7: Moving Into the Solution Region\n",
      "4.1.5 The Widrow-Ho\u000b",
      " Procedure\n",
      "The Widrow-Ho\u000b",
      " procedure (also called the LMS or the delta procedure) at-\n",
      "tempts to \f",
      "nd weights that minimize a squared-error function between the pat-\n",
      "tern labels and the dot product computed by a TLU. For this purpose, the\n",
      "pattern labels are assumed to be either +1 or \u00001 (instead of 1 or 0). The\n",
      "4.1. THRESHOLD LOGIC UNITS 43\n",
      "squared error for a pattern, Xi, with label di(for desired output) is:\n",
      "\"i= (di\u0000n+1X\n",
      "j=1xijwj)2\n",
      "wherexijis thej-th component of Xi. The total squared error (over all patterns\n",
      "in a training set, \u0004, containing mpatterns) is then:\n",
      "\"=mX\n",
      "i=1(di\u0000n+1X\n",
      "j=1xijwj)2\n",
      "We want to choose the weights wjto minimize this squared error. One way to\n",
      "\f",
      "nd such a set of weights is to start with an arbitrary weight vector and move it\n",
      "along the negative gradient of \"as a function of the weights. Since \"is quadratic\n",
      "in thewj, we know that it has a global minimum, and thus this steepest descent\n",
      "procedure is guaranteed to \f",
      "nd the minimum. Each component of the gradient\n",
      "is the partial derivative of \"with respect to one of the weights. One problem\n",
      "with taking the partial derivative of \"is that\"depends on allthe input vectors\n",
      "in \u0004. Often, it is preferable to use an incremental procedure in which we try the\n",
      "TLU on just one element, Xi, of \u0004 at a time, compute the gradient of the single-\n",
      "pattern squared error, \"i, make the appropriate adjustment to the weights, and\n",
      "then try another member of \u0004. Of course, the results of the incremental version\n",
      "can only approximate those of the batch one, but the approximation is usually\n",
      "quite e\u000b",
      "ective. We will be describing the incremental version here.\n",
      "Thej-th component of the gradient of the single-pattern error is:\n",
      "@\"i\n",
      "@wj=\u00002(di\u0000n+1X\n",
      "j=1xijwj)xij\n",
      "An adjustment in the direction of the negative gradient would then change each\n",
      "weight as follows:\n",
      "wj \u0000wj+ci(di\u0000fi)xij\n",
      "wherefi=Pn+1\n",
      "j=1xijwj, andcigoverns the size of the adjustment. The entire\n",
      "weight vector (in augmented, or V, notation) is thus adjusted according to the\n",
      "following rule:\n",
      "V \u0000V+ci(di\u0000fi)Yi\n",
      "where, as before, Yiis thei-th augmented pattern vector.\n",
      "The Widrow-Ho\u000b",
      " procedure makes adjustments to the weight vector when-\n",
      "ever the dot product itself, Yi\u000fV, does not equal the speci\f",
      "ed desired target\n",
      "44 CHAPTER 4. NEURAL NETWORKS\n",
      "value,di(which is either 1 or \u00001). The learning-rate factor, ci, might de-\n",
      "crease with time toward 0 to achieve asymptotic convergence. The Widrow-\n",
      "Ho\u000b",
      " formula for changing the weight vector has the same form as the standard\n",
      "\f",
      "xed-increment error-correction formula. The only di\u000b",
      "erence is that fiis the\n",
      "thresholded response of the TLU in the error-correction case while it is the dot\n",
      "product itself for the Widrow-Ho\u000b",
      " procedure.\n",
      "Finding weight values that give the desired dot products corresponds to solv-\n",
      "ing a set of linear equalities, and the Widrow-Ho\u000b",
      " procedure can be interpreted\n",
      "as a descent procedure that attempts to minimize the mean-squared-error be-\n",
      "tween the actual and desired values of the dot product. (For more on Widrow-\n",
      "Ho\u000b",
      " and other related procedures, see [Duda & Hart, 1973, pp. 151\u000b",
      "].) Examples of training curves for\n",
      "TLU's; performance on training\n",
      "set; performance on test set;\n",
      "cumulative number of corrections.4.1.6 Training a TLU on Non-Linearly-Separable Training\n",
      "Sets\n",
      "When the training set is not linearly separable (perhaps because of noise or\n",
      "perhaps inherently), it may still be desired to \f",
      "nd a \\best\" separating hy-\n",
      "perplane. Typically, the error-correction procedures will not do well on non-\n",
      "linearly-separable training sets because they will continue to attempt to correct\n",
      "inevitable errors, and the hyperplane will never settle into an acceptable place.\n",
      "Several methods have been proposed to deal with this case. First, we might\n",
      "use the Widrow-Ho\u000b",
      " procedure, which (although it will not converge to zero\n",
      "error on non-linearly separable problems) will give us a weight vector that min-\n",
      "imizes the mean-squared-error. A mean-squared-error criterion often gives un-\n",
      "satisfactory results, however, because it prefers many small errors to a few large\n",
      "ones. As an alternative, error correction with a continuous decrease toward zero\n",
      "of the value of the learning rate constant, c, will result in ever decreasing changes\n",
      "to the hyperplane. Duda [Duda, 1966] has suggested keeping track of the average\n",
      "value of the weight vector during error correction and using this average to give a\n",
      "separating hyperplane that performs reasonably well on non-linearly-separable\n",
      "problems. Gallant [Gallant, 1986] proposed what he called the \\pocket algo-\n",
      "rithm.\" As described in [Hertz, Krogh, & Palmer, 1991, p. 160]:\n",
      ". . . the pocket algorithm . . . consists simply in storing (or \\putting\n",
      "in your pocket\") the set of weights which has had the longest un-\n",
      "modi\f",
      "ed run of successes so far. The algorithm is stopped after some\n",
      "chosen time t. . .\n",
      "After stopping, the weights in the pocket are used as a set that should give a\n",
      "small number of errors on the training set. Error-correction proceeds as usual\n",
      "with the ordinary set of weights. Also see methods proposed by\n",
      "[John, 1995] and by\n",
      "[Marchand & Golea, 1993]. The\n",
      "latter is claimed to outperform the\n",
      "pocket algorithm. 4.2 Linear Machines\n",
      "The natural generalization of a (two-category) TLU to an R-category classi\f",
      "er\n",
      "is the structure, shown in Fig. 4.8, called a linear machine . Here, to use more\n",
      "4.2. LINEAR MACHINES 45\n",
      "familiar notation, the Ws and Xare meant to be augmented vectors (with an\n",
      "(n+1)-st component). Such a structure is also sometimes called a \\competitive\"\n",
      "net or a \\winner-take-all\" net. The output of the linear machine is one of\n",
      "the numbers,f1;:::;Rg, corresponding to which dot product is largest. Note\n",
      "that when R= 2, the linear machine reduces to a TLU with weight vector\n",
      "W= (W1\u0000W2).\n",
      "XW1\n",
      "WR. . .Y\n",
      "YARGMAXW1.X\n",
      "WR.X\n",
      "Figure 4.8: A Linear Machine\n",
      "The diagram in Fig. 4.9 shows the character of the regions in a 2-dimensional\n",
      "space created by a linear machine for R= 5. Inndimensions, every pair of\n",
      "regions is either separated by a section of a hyperplane or is non-adjacent.\n",
      "R1\n",
      "R3\n",
      "R4\n",
      "R5\n",
      "X.W4 * X.Wi for i & 4R2\n",
      "In this region:\n",
      "Figure 4.9: Regions For a Linear Machine\n",
      "To train a linear machine, there is a straightforward generalization of the\n",
      "2-category error-correction rule. Assemble the patterns in the training set into\n",
      "a sequence as before.\n",
      "a. If the machine classi\f",
      "es a pattern correctly, no change is made to any of\n",
      "46 CHAPTER 4. NEURAL NETWORKS\n",
      "the weight vectors.\n",
      "b. If the machine mistakenly classi\f",
      "es a category upattern, Xi, in category\n",
      "v(u6=v), then:\n",
      "Wu \u0000Wu+ciXi\n",
      "and\n",
      "Wv \u0000Wv\u0000ciXi\n",
      "and all other weight vectors are not changed.\n",
      "This correction increases the value of the u-th dot product and decreases the\n",
      "value of the v-th dot product. Just as in the 2-category \f",
      "xed increment proce-\n",
      "dure, this procedure is guaranteed to terminate, for constant ci, if there exists\n",
      "weight vectors that make correct separations of the training set. Note that when\n",
      "R= 2, this procedure reduces to the ordinary TLU error-correction procedure.\n",
      "A proof that this procedure terminates is given in [Nilsson, 1990, pp. 88-90]\n",
      "and in [Duda & Hart, 1973, pp. 174-177].\n",
      "4.3 Networks of TLUs\n",
      "4.3.1 Motivation and Examples\n",
      "Layered Networks\n",
      "To classify correctly all of the patterns in non-linearly-separable training sets re-\n",
      "quires separating surfaces more complex than hyperplanes. One way to achieve\n",
      "more complex surfaces is with networks of TLUs. Consider, for example, the 2-\n",
      "dimensional, even parity function, f=x1x2+x1x2. No single line through the\n",
      "2-dimensional square can separate the vertices (1,1) and (0,0) from the vertices\n",
      "(1,0) and (0,1)|the function is not linearly separable and thus cannot be im-\n",
      "plemented by a single TLU. But, the network of three TLUs shown in Fig. 4.10\n",
      "does implement this function. In the \f",
      "gure, we show the weight values along\n",
      "input lines to each TLU and the threshold value inside the circle representing\n",
      "the TLU.\n",
      "The function implemented by a network of TLUs depends on its topology\n",
      "as well as on the weights of the individual TLUs. Feedforward networks have\n",
      "no cycles; in a feedforward network no TLU's input depends (through zero\n",
      "or more intermediate TLUs) on that TLU's output. (Networks that are not\n",
      "feedforward are called recurrent networks). If the TLUs of a feedforward network\n",
      "are arranged in layers, with the elements of layer jreceiving inputs only from\n",
      "TLUs in layer j\u00001, then we say that the network is a layered, feedforward\n",
      "4.3. NETWORKS OF TLUS 47\n",
      "fx1\n",
      "x21.5\n",
      "-0.50.51\n",
      "1-1\n",
      "-111\n",
      "Figure 4.10: A Network for the Even Parity Function\n",
      "network . The network shown in Fig. 4.10 is a layered, feedforward network\n",
      "having two layers (of weights). (Some people count the layers of TLUs and\n",
      "include the inputs as a layer also; they would call this network a three-layer\n",
      "network.) In general, a feedforward, layered network has the structure shown\n",
      "in Fig. 4.11. All of the TLUs except the \\output\" units are called hidden units\n",
      "(they are \\hidden\" from the output).\n",
      "X\n",
      "hidden unitsoutput units\n",
      "Figure 4.11: A Layered, Feedforward Network\n",
      "Implementing DNF Functions by Two-Layer Networks\n",
      "We have already de\f",
      "ned k-term DNF functions|they are DNF functions having\n",
      "kterms. Ak-term DNF function can be implemented by a two-layer network\n",
      "withkunits in the hidden layer|to implement the kterms|and one output\n",
      "unit to implement the disjunction of these terms. Since any Boolean function\n",
      "has a DNF form, any Boolean function can be implemented by some two-layer\n",
      "network of TLUs. As an example, consider the function f=x1x2+x2x3+\n",
      "x1x3. The form of the network that implements this function is shown in Fig.\n",
      "4.12. (We leave it to the reader to calculate appropriate values of weights and\n",
      "48 CHAPTER 4. NEURAL NETWORKS\n",
      "thresholds.) The 3-cube representation of the function is shown in Fig. 4.13.\n",
      "The network of Fig. 4.12 can be designed so that each hidden unit implements\n",
      "one of the planar boundaries shown in Fig. 4.13.\n",
      "x\n",
      "conjunctsdisjunct\n",
      "A Feedforward, 2-layer NetworkTLUs\n",
      "disjunction\n",
      "of terms\n",
      "conjunctions\n",
      "of literals\n",
      "(terms)\n",
      "Figure 4.12: A Two-Layer Network\n",
      "x2\n",
      "x1x3f = x1x2 + x2x3 + x1x3\n",
      "Figure 4.13: Three Planes Implemented by the Hidden Units\n",
      "To train a two-layer network that implements a k-term DNF function, we\n",
      "\f",
      "rst note that the output unit implements a disjunction, so the weights in the\n",
      "\f",
      "nal layer are \f",
      "xed. The weights in the \f",
      "rst layer (except for the \\threshold\n",
      "weights\") can all have values of 1, \u00001, or 0. Later, we will present a training\n",
      "procedure for this \f",
      "rst layer of weights. Discuss half-space intersections,\n",
      "half-space unions, NP-hardness of\n",
      "optimal versions,\n",
      "single-side-error-hypeplane\n",
      "methods, relation to \\AQ\"\n",
      "methods.\n",
      "4.3. NETWORKS OF TLUS 49\n",
      "Important Comment About Layered Networks\n",
      "Adding additional layers cannot compensate for an inadequate \f",
      "rst layer of\n",
      "TLUs. The \f",
      "rst layer of TLUs partitions the feature space so that no two dif-\n",
      "ferently labeled vectors are in the same region (that is, so that no two such\n",
      "vectors yield the same set of outputs of the \f",
      "rst-layer units). If the \f",
      "rst layer\n",
      "does not partition the feature space in this way, then regardless of what subse-\n",
      "quent layers do, the \f",
      "nal outputs will not be consistent with the labeled training\n",
      "set. Add diagrams showing the\n",
      "non-linear transformation\n",
      "performed by a layered network.\n",
      "4.3.2 Madalines\n",
      "Two-Category Networks\n",
      "An interesting example of a layered, feedforward network is the two-layer one\n",
      "which has an odd number of hidden units, and a \\vote-taking\" TLU as the\n",
      "output unit. Such a network was called a \\Madaline\" (for m any adaline s by\n",
      "Widrow. Typically, the response of the vote taking unit is de\f",
      "ned to be the\n",
      "response of the majority of the hidden units, although other output logics are\n",
      "possible. Ridgway [Ridgway, 1962] proposed the following error-correction rule\n",
      "for adjusting the weights of the hidden units of a Madaline:\n",
      "\u000fIf the Madaline correctly classi\f",
      "es a pattern, Xi, no corrections are made\n",
      "to any of the hidden units' weight vectors,\n",
      "\u000fIf the Madaline incorrectly classi\f",
      "es a pattern, Xi, then determine the\n",
      "minimum number of hidden units whose responses need to be changed\n",
      "(from 0 to 1 or from 1 to 0|depending on the type of error) in order that\n",
      "the Madaline would correctly classify Xi. Suppose that minimum number\n",
      "iski. Of those hidden units voting incorrectly, change the weight vectors\n",
      "of thosekiof them whose dot products are closest to 0 by using the error\n",
      "correction rule:\n",
      "W \u0000W+ci(di\u0000fi)Xi\n",
      "wherediis the desired response of the hidden unit (0 or 1) and fiis the\n",
      "actual response (0 or 1). (We assume augmented vectors here even though\n",
      "we are using X,Wnotation.)\n",
      "That is, we perform error-correction on just enough hidden units to correct\n",
      "the vote to a majority voting correctly, and we change those that are easiest to\n",
      "change. There are example problems in which even though a set of weight values\n",
      "exists for a given Madaline structure such that it could classify all members of\n",
      "a training set correctly, this procedure will fail to \f",
      "nd them. Nevertheless, the\n",
      "procedure works e\u000b",
      "ectively in most experiments with it.\n",
      "We leave it to the reader to think about how this training procedure could\n",
      "be modi\f",
      "ed if the output TLU implemented an orfunction (or an andfunction).\n",
      "50 CHAPTER 4. NEURAL NETWORKS\n",
      "R-Category Madalines and Error-Correcting Output Codes\n",
      "If there are khidden units ( k > 1) in a two-layer network, their responses\n",
      "correspond to vertices of a k-dimensional hypercube. The ordinary two-category\n",
      "Madaline identi\f",
      "es two special points in this space, namely the vertex consisting\n",
      "ofk1's and the vertex consisting of k0's. The Madaline's response is 1 if the\n",
      "point in \\hidden-unit-space\" is closer to the all 1's vertex than it is to the all\n",
      "0's vertex. We could design an R-category Madaline by identifying Rvertices\n",
      "in hidden-unit space and then classifying a pattern according to which of these\n",
      "vertices the hidden-unit response is closest to. A machine using that idea was\n",
      "implemented in the early 1960s at SRI [Brain, et al. , 1962]. It used the fact\n",
      "that the 2pso-called maximal-length shift-register sequences [Peterson, 1961, pp.\n",
      "147\u000b",
      "] in a (2p\u00001)-dimensional Boolean space are mutually equidistant (for any\n",
      "integerp). For similar, more recent work see [Dietterich & Bakiri, 1991].\n",
      "4.3.3 Piecewise Linear Machines\n",
      "A two-category training set is linearly separable if there exists a threshold func-\n",
      "tion that correctly classi\f",
      "es all members of the training set. Similarly, we can\n",
      "say that an R-category training set is linearly separable if there exists a linear\n",
      "machine that correctly classi\f",
      "es all members of the training set. When an R-\n",
      "category problem is not linearly separable, we need a more powerful classi\f",
      "er.\n",
      "A candidate is a structure called a piecewise linear (PWL) machine illustrated\n",
      "in Fig. 4.14.\n",
      "XW1\n",
      "W1. . .Y\n",
      "YMAX\n",
      ". . .Y\n",
      "YMAX. . .\n",
      "WR\n",
      "WRARG\n",
      "MAX1\n",
      "R1\n",
      "N1\n",
      "1\n",
      "NR\n",
      "Figure 4.14: A Piecewise Linear Machine\n",
      "4.3. NETWORKS OF TLUS 51\n",
      "The PWL machine groups its weighted summing units into Rbanks corre-\n",
      "sponding to the Rcategories. An input vector Xis assigned to that category\n",
      "corresponding to the bank with the largest weighted sum. We can use an error-\n",
      "correction training algorithm similar to that used for a linear machine. If a\n",
      "pattern is classi\f",
      "ed incorrectly, we subtract (a constant times) the pattern vec-\n",
      "tor from the weight vector producing the largest dot product (it was incorrectly\n",
      "the largest) and add (a constant times) the pattern vector to that weight vector\n",
      "in the correct bank of weight vectors whose dot product is locally largest in\n",
      "that bank. (Again, we use augmented vectors here.) Unfortunately, there are\n",
      "example training sets that are separable by a given PWL machine structure\n",
      "but for which this error-correction training method fails to \f",
      "nd a solution. The\n",
      "method does appear to work well in some situations [Duda & Fossum, 1966], al-\n",
      "though [Nilsson, 1965, page 89] observed that \\it is probably not a very e\u000b",
      "ective\n",
      "method for training PWL machines having more than three [weight vectors] in\n",
      "each bank.\"\n",
      "4.3.4 Cascade Networks\n",
      "Another interesting class of feedforward networks is that in which all of the TLUs\n",
      "are ordered and each TLU receives inputs from all of the pattern components\n",
      "and from all TLUs lower in the ordering. Such a network is called a cascade\n",
      "network. An example is shown in Fig. 4.15 in which the TLUs are labeled by\n",
      "the linearly separable functions (of their inputs) that they implement. Each\n",
      "TLU in the network implements a set of 2kparallel hyperplanes, where kis\n",
      "the number of TLUs from which it receives inputs. (Each of the kpreceding\n",
      "TLUs can have an output of 1 or 0; that's 2kdi\u000b",
      "erent combinations|resulting\n",
      "in 2kdi\u000b",
      "erent positions for the parallel hyperplanes.) We show a 3-dimensional\n",
      "sketch for a network of two TLUs in Fig. 4.16. The reader might consider how\n",
      "then-dimensional parity function might be implemented by a cascade network\n",
      "having log2nTLUs.\n",
      "xL1\n",
      "L2\n",
      "output\n",
      "L3\n",
      "Figure 4.15: A Cascade Network\n",
      "52 CHAPTER 4. NEURAL NETWORKS\n",
      "L1L2\n",
      "L2\n",
      "Figure 4.16: Planes Implemented by a Cascade Network with Two TLUs\n",
      "Cascade networks might be trained by \f",
      "rst training L1to do as good a job\n",
      "as possible at separating all the training patterns (perhaps by using the pocket\n",
      "algorithm, for example), then training L2(including the weight from L1toL2)\n",
      "also to do as good a job as possible at separating all the training patterns,\n",
      "and so on until the resulting network classi\f",
      "es the patterns in the training set\n",
      "satisfactorily. Also mention the\n",
      "\\cascade-correlation\" method of\n",
      "[Fahlman & Lebiere, 1990].\n",
      "4.4 Training Feedforward Networks by Back-\n",
      "propagation\n",
      "4.4.1 Notation\n",
      "The general problem of training a network of TLUs is di\u000ecult. Consider, for\n",
      "example, the layered, feedforward network of Fig. 4.11. If such a network makes\n",
      "an error on a pattern, there are usually several di\u000b",
      "erent ways in which the error\n",
      "can be corrected. It is di\u000ecult to assign \\blame\" for the error to any particular\n",
      "TLU in the network. Intuitively, one looks for weight-adjusting procedures that\n",
      "move the network in the correct direction (relative to the error) by making\n",
      "minimal changes. In this spirit, the Widrow-Ho\u000b",
      " method of gradient descent\n",
      "has been generalized to deal with multilayer networks.\n",
      "In explaining this generalization, we use Fig. 4.17 to introduce some nota-\n",
      "tion. This network has only one output unit, but, of course, it is possible to have\n",
      "several TLUs in the output layer|each implementing a di\u000b",
      "erent function. Each\n",
      "of the layers of TLUs will have outputs that we take to be the components of\n",
      "vectors, just as the input features are components of an input vector. The j-th\n",
      "layer of TLUs (1\u0014j <k ) will have as their outputs the vector X(j). The input\n",
      "feature vector is denoted by X(0), and the \f",
      "nal output (of the k-th layer TLU)\n",
      "isf. Each TLU in each layer has a weight vector (connecting it to its inputs)\n",
      "and a threshold; the i-th TLU in the j-th layer has a weight vector denoted by\n",
      "W(j)\n",
      "i. (We will assume that the \\threshold weight\" is the last component of\n",
      "the associated weight vector; we might have used Vnotation instead to include\n",
      "4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION 53\n",
      "this threshold component, but we have chosen here to use the familiar X,W\n",
      "notation, assuming that these vectors are \\augmented\" as appropriate.) We\n",
      "denote the weighted sum input to the i-th threshold unit in the j-th layer by\n",
      "s(j)\n",
      "i. (That is, s(j)\n",
      "i=X(j\u00001)\u000fW(j)\n",
      "i.) The number of TLUs in the j-th layer is\n",
      "given bymj. The vector W(j)\n",
      "ihas components w(j)\n",
      "l;iforl= 1;:::;m (j\u00001)+ 1.\n",
      "X(0)\n",
      ". . .\n",
      ". . .. . .\n",
      ". . .Wi(1)W(k)X(1)\n",
      "m1 TLUs. . .\n",
      "Wi(j)\n",
      ". . .X(j)\n",
      ". . .\n",
      "Wi(k-1)X(k-1)\n",
      "mj TLUs m(k-1) TLUswli(j)wl(k)First Layer j-th Layer ( k-1)-th Layer k-th Layer\n",
      ". . .f\n",
      "si(1)si(j)si(k-1)s(k)\n",
      "Figure 4.17: A k-layer Network\n",
      "4.4.2 The Backpropagation Method\n",
      "A gradient descent method, similar to that used in the Widrow Ho\u000b",
      " method,\n",
      "has been proposed by various authors for training a multi-layer, feedforward\n",
      "network. As before, we de\f",
      "ne an error function on the \f",
      "nal output of the\n",
      "network and we adjust each weight in the network so as to minimize the error.\n",
      "If we have a desired response, di, for thei-th input vector, Xi, in the training\n",
      "set, \u0004, we can compute the squared error over the entire training set to be:\n",
      "\"=X\n",
      "Xi\u000f\u0004(di\u0000fi)2\n",
      "wherefiis the actual response of the network for input Xi. To do gradient\n",
      "descent on this squared error, we adjust each weight in the network by an\n",
      "amount proportional to the negative of the partial derivative of \"with respect\n",
      "to that weight. Again, we use a single-pattern error function so that we can\n",
      "use an incremental weight adjustment procedure. The squared error for a single\n",
      "input vector, X, evoking an output of fwhen the desired output is dis:\n",
      "54 CHAPTER 4. NEURAL NETWORKS\n",
      "\"= (d\u0000f)2\n",
      "It is convenient to take the partial derivatives of \"with respect to the various\n",
      "weights in groups corresponding to the weight vectors. We de\f",
      "ne a partial\n",
      "derivative of a quantity \u001e",
      ", say, with respect to a weight vector, W(j)\n",
      "i, thus:\n",
      "@\u001e",
      "\n",
      "@W(j)\n",
      "idef=\"\n",
      "@\u001e",
      "\n",
      "@w(j)\n",
      "1i;:::;@\u001e",
      "\n",
      "@w(j)\n",
      "li;:::;@\u001e",
      "\n",
      "@w(j)\n",
      "mj\u00001+1;i#\n",
      "wherew(j)\n",
      "liis thel-th component of W(j)\n",
      "i. This vector partial derivative of \u001e",
      "is\n",
      "called the gradient of\u001e",
      "with respect to Wand is sometimes denoted by rW\u001e",
      ".\n",
      "Since\"'s dependence on W(j)\n",
      "iis entirely through s(j)\n",
      "i, we can use the chain\n",
      "rule to write:\n",
      "@\"\n",
      "@W(j)\n",
      "i=@\"\n",
      "@s(j)\n",
      "i@s(j)\n",
      "i\n",
      "@W(j)\n",
      "i\n",
      "Becauses(j)\n",
      "i=X(j\u00001)\u000fW(j)\n",
      "i,@s(j)\n",
      "i\n",
      "@W(j)\n",
      "i=X(j\u00001). Substituting yields:\n",
      "@\"\n",
      "@W(j)\n",
      "i=@\"\n",
      "@s(j)\n",
      "iX(j\u00001)\n",
      "Note that@\"\n",
      "@s(j)\n",
      "i=\u00002(d\u0000f)@f\n",
      "@s(j)\n",
      "i. Thus,\n",
      "@\"\n",
      "@W(j)\n",
      "i=\u00002(d\u0000f)@f\n",
      "@s(j)\n",
      "iX(j\u00001)\n",
      "The quantity ( d\u0000f)@f\n",
      "@s(j)\n",
      "iplays an important role in our calculations; we shall\n",
      "denote it by \u000e(j)\n",
      "i. Each of the \u000e(j)\n",
      "i's tells us how sensitive the squared error of\n",
      "the network output is to changes in the input to each threshold function. Since\n",
      "we will be changing weight vectors in directions along their negative gradient,\n",
      "our fundamental rule for weight changes throughout the network will be:\n",
      "W(j)\n",
      "i W(j)\n",
      "i+c(j)\n",
      "i\u000e(j)\n",
      "iX(j\u00001)\n",
      "wherec(j)\n",
      "iis the learning rate constant for this weight vector. (Usually, the\n",
      "learning rate constants for all weight vectors in the network are the same.) We\n",
      "see that this rule is quite similar to that used in the error correction procedure\n",
      "4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION 55\n",
      "for a single TLU. A weight vector is changed by the addition of a constant times\n",
      "its vector of (unweighted) inputs.\n",
      "Now, we must turn our attention to the calculation of the \u000e(j)\n",
      "i's. Using the\n",
      "de\f",
      "nition, we have:\n",
      "\u000e(j)\n",
      "i= (d\u0000f)@f\n",
      "@s(j)\n",
      "i\n",
      "We have a problem, however, in attempting to carry out the partial deriva-\n",
      "tives offwith respect to the s's. The network output, f, is not continuously\n",
      "di\u000b",
      "erentiable with respect to the s's because of the presence of the threshold\n",
      "functions. Most small changes in these sums do not change fat all, and when\n",
      "fdoes change, it changes abruptly from 1 to 0 or vice versa.\n",
      "A way around this di\u000eculty was proposed by Werbos [Werbos, 1974] and\n",
      "(perhaps independently) pursued by several other researchers, for example\n",
      "[Rumelhart, Hinton, & Williams, 1986]. The trick involves replacing all the\n",
      "threshold functions by di\u000b",
      "erentiable functions called sigmoids .1The output\n",
      "of a sigmoid function, superimposed on that of a threshold function, is shown\n",
      "in Fig. 4.18. Usually, the sigmoid function used is f(s) =1\n",
      "1+e\u0000s, wheresis\n",
      "the input and fis the output.\n",
      "sigmoidthreshold functionf (s)\n",
      "sf (s) = 1/[1 + e<s]\n",
      "Figure 4.18: A Sigmoid Function\n",
      "1[Russell & Norvig 1995, page 595] attributes the use of this idea to [Bryson & Ho 1969].\n",
      "56 CHAPTER 4. NEURAL NETWORKS\n",
      "We show the network containing sigmoid units in place of TLUs in Fig. 4.19.\n",
      "The output of the i-th sigmoid unit in the j-th layer is denoted by f(j)\n",
      "i. (That\n",
      "is,f(j)\n",
      "i=1\n",
      "1+e\u0000s(j)\n",
      "i.)\n",
      "X(0)\n",
      ". . .\n",
      ". . .. . .\n",
      ". . .Wi(1)\n",
      "si(1)W(k)X(1)\n",
      "fi(1)\n",
      "m1 sigmoids. . .\n",
      "Wi(j)fi(j)\n",
      "si(j)\n",
      ". . .X(j)\n",
      ". . .\n",
      "Wi(k-1)\n",
      "fi(k-1)\n",
      "si(k-1)f(k)\n",
      "s(k)X(k-1)\n",
      "mj sigmoidsm(k-1) sigmoidswli(j)wl(k)\n",
      "bi(j)bi(1)bi(k-1)b(k)First Layer j-th Layer ( k-1)-th Layer k-th Layer\n",
      ". . .\n",
      "Figure 4.19: A Network with Sigmoid Units\n",
      "4.4.3 Computing Weight Changes in the Final Layer\n",
      "We \f",
      "rst calculate \u000e(k)in order to compute the weight change for the \f",
      "nal sigmoid\n",
      "unit:\n",
      "4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION 57\n",
      "\u000e(k)= (d\u0000f(k))@f(k)\n",
      "@s(k)\n",
      "Given the sigmoid function that we are using, namely f(s) =1\n",
      "1+e\u0000s, we have\n",
      "that@f\n",
      "@s=f(1\u0000f). Substituting gives us:\n",
      "\u000e(k)= (d\u0000f(k))f(k)(1\u0000f(k))\n",
      "Rewriting our general rule for weight vector changes, the weight vector in\n",
      "the \f",
      "nal layer is changed according to the rule:\n",
      "W(k) W(k)+c(k)\u000e(k)X(k\u00001)\n",
      "where\u000e(k)= (d\u0000f(k))f(k)(1\u0000f(k))\n",
      "It is interesting to compare backpropagation to the error-correction rule and\n",
      "to the Widrow-Ho\u000b",
      " rule. The backpropagation weight adjustment for the single\n",
      "element in the \f",
      "nal layer can be written as:\n",
      "W \u0000W+c(d\u0000f)f(1\u0000f)X\n",
      "Written in the same format, the error-correction rule is:\n",
      "W \u0000W+c(d\u0000f)X\n",
      "and the Widrow-Ho\u000b",
      " rule is:\n",
      "W \u0000W+c(d\u0000f)X\n",
      "The only di\u000b",
      "erence (except for the fact that fis not thresholded in Widrow-\n",
      "Ho\u000b",
      ") is the f(1\u0000f) term due to the presence of the sigmoid function. With\n",
      "the sigmoid function, f(1\u0000f) can vary in value from 0 to 1. When fis 0,\n",
      "f(1\u0000f) is also 0; when fis 1,f(1\u0000f) is 0;f(1\u0000f) obtains its maximum\n",
      "value of 1/4 when fis 1/2 (that is, when the input to the sigmoid is 0). The\n",
      "sigmoid function can be thought of as implementing a \\fuzzy\" hyperplane. For\n",
      "a pattern far away from this fuzzy hyperplane, f(1\u0000f) has value close to 0,\n",
      "and the backpropagation rule makes little or no change to the weight values\n",
      "regardless of the desired output. (Small changes in the weights will have little\n",
      "e\u000b",
      "ect on the output for inputs far from the hyperplane.) Weight changes are\n",
      "only made within the region of \\fuzz\" surrounding the hyperplane, and these\n",
      "changes are in the direction of correcting the error, just as in the error-correction\n",
      "and Widrow-Ho\u000b",
      " rules.\n",
      "58 CHAPTER 4. NEURAL NETWORKS\n",
      "4.4.4 Computing Changes to the Weights in Intermediate\n",
      "Layers\n",
      "Using our expression for the \u000e's, we can similarly compute how to change each\n",
      "of the weight vectors in the network. Recall:\n",
      "\u000e(j)\n",
      "i= (d\u0000f)@f\n",
      "@s(j)\n",
      "i\n",
      "Again we use a chain rule. The \f",
      "nal output, f, depends on s(j)\n",
      "ithrough\n",
      "each of the summed inputs to the sigmoids in the ( j+ 1)-th layer. So:\n",
      "\u000e(j)\n",
      "i= (d\u0000f)@f\n",
      "@s(j)\n",
      "i\n",
      "= (d\u0000f)\"\n",
      "@f\n",
      "@s(j+1)\n",
      "1@s(j+1)\n",
      "1\n",
      "@s(j)\n",
      "i+\u0001\u0001\u0001+@f\n",
      "@s(j+1)\n",
      "l@s(j+1)\n",
      "l\n",
      "@s(j)\n",
      "i+\u0001\u0001\u0001+@f\n",
      "@s(j+1)\n",
      "mj+1@s(j+1)\n",
      "mj+1\n",
      "@s(j)\n",
      "i#\n",
      "=mj+1X\n",
      "l=1(d\u0000f)@f\n",
      "@s(j+1)\n",
      "l@s(j+1)\n",
      "l\n",
      "@s(j)\n",
      "i=mj+1X\n",
      "l=1\u000e(j+1)\n",
      "l@s(j+1)\n",
      "l\n",
      "@s(j)\n",
      "i\n",
      "It remains to compute the@s(j+1)\n",
      "l\n",
      "@s(j)\n",
      "i's. To do that we \f",
      "rst write:\n",
      "s(j+1)\n",
      "l=X(j)\u000fW(j+1)\n",
      "l\n",
      "=mj+1X\n",
      "\u0017=1f(j)\n",
      "\u0017w(j+1)\n",
      "\u0017l\n",
      "And then, since the weights do not depend on the s's:\n",
      "@s(j+1)\n",
      "l\n",
      "@s(j)\n",
      "i=@hPmj+1\n",
      "\u0017=1f(j)\n",
      "\u0017w(j+1)\n",
      "\u0017li\n",
      "@s(j)\n",
      "i=mj+1X\n",
      "\u0017=1w(j+1)\n",
      "\u0017l@f(j)\n",
      "\u0017\n",
      "@s(j)\n",
      "i\n",
      "Now, we note that@f(j)\n",
      "\u0017\n",
      "@s(j)\n",
      "i= 0 unless \u0017=i, in which case@f(j)\n",
      "\u0017\n",
      "@s(j)\n",
      "\u0017=f(j)\n",
      "\u0017(1\u0000f(j)\n",
      "\u0017).\n",
      "Therefore:\n",
      "@s(j+1)\n",
      "l\n",
      "@s(j)\n",
      "i=w(j+1)\n",
      "ilf(j)\n",
      "i(1\u0000f(j)\n",
      "i)\n",
      "4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION 59\n",
      "We use this result in our expression for \u000e(j)\n",
      "ito give:\n",
      "\u000e(j)\n",
      "i=f(j)\n",
      "i(1\u0000f(j)\n",
      "i)mj+1X\n",
      "l=1\u000e(j+1)\n",
      "lw(j+1)\n",
      "il\n",
      "The above equation is recursive in the \u000e's. (It is interesting to note that\n",
      "this expression is independent of the error function; the error function explicitly\n",
      "a\u000b",
      "ects only the computation of \u000e(k).) Having computed the \u000e(j+1)\n",
      "i 's for layer\n",
      "j+ 1, we can use this equation to compute the \u000e(j)\n",
      "i's. The base case is \u000e(k),\n",
      "which we have already computed:\n",
      "\u000e(k)= (d\u0000f(k))f(k)(1\u0000f(k))\n",
      "We use this expression for the \u000e's in our generic weight changing rule, namely:\n",
      "W(j)\n",
      "i W(j)\n",
      "i+c(j)\n",
      "i\u000e(j)\n",
      "iX(j\u00001)\n",
      "Although this rule appears complex, it has an intuitively reasonable explanation.\n",
      "The quantity \u000e(k)= (d\u0000f)f(1\u0000f) controls the overall amount and sign of all\n",
      "weight adjustments in the network. (Adjustments diminish as the \f",
      "nal output,\n",
      "f, approaches either 0 or 1, because they have vanishing e\u000b",
      "ect on fthen.) As\n",
      "the recursion equation for the \u000e's shows, the adjustments for the weights going\n",
      "into a sigmoid unit in the j-th layer are proportional to the e\u000b",
      "ect that such\n",
      "adjustments have on that sigmoid unit's output (its f(j)(1\u0000f(j)) factor). They\n",
      "are also proportional to a kind of \\average\" e\u000b",
      "ect that any change in the output\n",
      "of that sigmoid unit will have on the \f",
      "nal output. This average e\u000b",
      "ect depends\n",
      "on the weights going outof the sigmoid unit in the j-th layer (small weights\n",
      "produce little downstream e\u000b",
      "ect) and the e\u000b",
      "ects that changes in the outputs of\n",
      "(j+ 1)-th layer sigmoid units will have on the \f",
      "nal output (as measured by the\n",
      "\u000e(j+1)'s). These calculations can be simply implemented by \\backpropagating\"\n",
      "the\u000e's through the weights in reverse direction (thus, the name backprop for\n",
      "this algorithm).\n",
      "4.4.5 Variations on Backprop\n",
      "[To be written: problem of local minima, simulated annealing, momemtum\n",
      "(Plaut, et al. , 1986, see [Hertz, Krogh, & Palmer, 1991]), quickprop, regulariza-\n",
      "tion methods]\n",
      "Simulated Annealing\n",
      "To apply simulated annealing, the value of the learning rate constant is gradually\n",
      "decreased with time. If we fall early into an error-function valley that is not\n",
      "very deep (a local minimum), it typically will neither be very broad, and soon\n",
      "60 CHAPTER 4. NEURAL NETWORKS\n",
      "a subsequent large correction will jostle us out of it. It is less likely that we will\n",
      "move out of deep valleys, and at the end of the process (with very small values\n",
      "of the learning rate constant), we descend to its deepest point. The process\n",
      "gets its name by analogy with annealing in metallurgy, in which a material's\n",
      "temperature is gradually decreased allowing its crystalline structure to reach a\n",
      "minimal energy state.\n",
      "4.4.6 An Application: Steering a Van\n",
      "A neural network system called ALVINN (A utonomous L and V ehicle i n a N eural\n",
      "Network) has been trained to steer a Chevy van successfully on ordinary roads\n",
      "and highways at speeds of 55 mph [Pomerleau, 1991, Pomerleau, 1993]. The\n",
      "input to the network is derived from a low-resolution (30 x32) television image.\n",
      "The TV camera is mounted on the van and looks at the road straight ahead.\n",
      "This image is sampled and produces a stream of 960-dimensional input vectors\n",
      "to the neural network. The network is shown in Fig. 4.20.\n",
      "960 inputs\n",
      "30 x 32 retina\n",
      ". . .\n",
      "5 hidden\n",
      "units connected\n",
      "to all 960 inputs\n",
      "30 output units\n",
      "connected to all\n",
      "hidden units. . .sharp left\n",
      "sharp rightstraight aheadcentroid\n",
      "of outputs\n",
      "steers\n",
      "vehicle\n",
      "Figure 4.20: The ALVINN Network\n",
      "The network has \f",
      "ve hidden units in its \f",
      "rst layer and 30 output units in the\n",
      "second layer; all are sigmoid units. The output units are arranged in a linear\n",
      "order and control the van's steering angle. If a unit near the top of the array\n",
      "of output units has a higher output than most of the other units, the van is\n",
      "steered to the left; if a unit near the bottom of the array has a high output, the\n",
      "van is steered to the right. The \\centroid\" of the responses of all of the output\n",
      "4.5. SYNERGIES BETWEEN NEURAL NETWORK AND KNOWLEDGE-BASED METHODS 61\n",
      "units is computed, and the van's steering angle is set at a corresponding value\n",
      "between hard left and hard right.\n",
      "The system is trained by a modi\f",
      "ed on-line training regime. A driver drives\n",
      "the van, and his actual steering angles are taken as the correct labels for the\n",
      "corresponding inputs. The network is trained incrementally by backprop to\n",
      "produce the driver-speci\f",
      "ed steering angles in response to each visual pattern\n",
      "as it occurs in real time while driving.\n",
      "This simple procedure has been augmented to avoid two potential problems.\n",
      "First, since the driver is usually driving well, the network would never get any\n",
      "experience with far-from-center vehicle positions and/or incorrect vehicle orien-\n",
      "tations. Also, on long, straight stretches of road, the network would be trained\n",
      "for a long time only to produce straight-ahead steering angles; this training\n",
      "would swamp out earlier training to follow a curved road. We wouldn't want\n",
      "to try to avoid these problems by instructing the driver to drive erratically\n",
      "occasionally, because the system would learn to mimic this erratic behavior.\n",
      "Instead, each original image is shifted and rotated in software to create 14\n",
      "additional images in which the vehicle appears to be situated di\u000b",
      "erently relative\n",
      "to the road. Using a model that tells the system what steering angle ought to\n",
      "be used for each of these shifted images, given the driver-speci\f",
      "ed steering angle\n",
      "for the original image, the system constructs an additional 14 labeled training\n",
      "patterns to add to those encountered during ordinary driver training.\n",
      "4.5 Synergies Between Neural Network and\n",
      "Knowledge-Based Methods\n",
      "To be written; discuss\n",
      "rule-generating procedures (such as\n",
      "[Towell & Shavlik, 1992]) and how\n",
      "expert-provided rules can aid\n",
      "neural net training and vice-versa\n",
      "[Towell, Shavlik, & Noordweier, 1990].4.6 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "62 CHAPTER 4. NEURAL NETWORKS\n",
      "Chapter 5\n",
      "Statistical Learning\n",
      "5.1 Using Statistical Decision Theory\n",
      "5.1.1 Background and General Method\n",
      "Suppose the pattern vector, X, is a random variable whose probability distri-\n",
      "bution for category 1 is di\u000b",
      "erent than it is for category 2. (The treatment given\n",
      "here can easily be generalized to R-category problems.) Speci\f",
      "cally, suppose we\n",
      "have the two probability distributions (perhaps probability density functions),\n",
      "p(Xj1) andp(Xj2). Given a pattern, X, we want to use statistical tech-\n",
      "niques to determine its category|that is, to determine from which distribution\n",
      "it was drawn. These techniques are based on the idea of minimizing the ex-\n",
      "pected value of a quantity similar to the error function we used in deriving the\n",
      "weight-changing rules for backprop.\n",
      "In developing a decision method, it is necessary to know the relative serious-\n",
      "ness of the two kinds of mistakes that might be made. (We might decide that a\n",
      "pattern really in category 1 is in category 2, and vice versa.) We describe this\n",
      "information by a loss function ,\u0015(ijj), fori;j= 1;2.\u0015(ijj) represents the loss\n",
      "incurred when we decide a pattern is in category iwhen really it is in category\n",
      "j. We assume here that \u0015(1j1) and\u0015(2j2) are both 0. For any given pattern,\n",
      "X, we want to decide its category in such a way that minimizes the expected\n",
      "value of this loss.\n",
      "Given a pattern, X, if we decide category i, the expected value of the loss\n",
      "will be:\n",
      "LX(i) =\u0015(ij1)p(1jX) +\u0015(ij2)p(2jX)\n",
      "wherep(jjX) is the probability that given a pattern X, its category is j. Our\n",
      "decision rule will be to decide that Xbelongs to category 1 if LX(1)\u0014LX(2),\n",
      "and to decide on category 2 otherwise.\n",
      "63\n",
      "64 CHAPTER 5. STATISTICAL LEARNING\n",
      "We can use Bayes' Rule to get expressions for p(jjX) in terms of p(Xjj),\n",
      "which we assume to be known (or estimatible):\n",
      "p(jjX) =p(Xjj)p(j)\n",
      "p(X)\n",
      "wherep(j) is the (a priori) probability of category j(one category may be much\n",
      "more probable than the other); and p(X) is the (a priori) probability of pattern\n",
      "Xbeing the pattern we are asked to classify. Performing the substitutions given\n",
      "by Bayes' Rule, our decision rule becomes:\n",
      "Decide category 1 i\u000b",
      ":\n",
      "\u0015(1j1)p(Xj1)p(1)\n",
      "p(X)+\u0015(1j2)p(Xj2)p(2)\n",
      "p(X)\n",
      "\u0014\u0015(2j1)p(Xj1)p(1)\n",
      "p(X)+\u0015(2j2)p(Xj2)p(2)\n",
      "p(X)\n",
      "Using the fact that \u0015(iji) = 0, and noticing that p(X) is common to both\n",
      "expressions, we obtain,\n",
      "Decide category 1 i\u000b",
      ":\n",
      "\u0015(1j2)p(Xj2)p(2)\u0014\u0015(2j1)p(Xj1)p(1)\n",
      "If\u0015(1j2) =\u0015(2j1) and ifp(1) =p(2), then the decision becomes particu-\n",
      "larly simple:\n",
      "Decide category 1 i\u000b",
      ":\n",
      "p(Xj2)\u0014p(Xj1)\n",
      "Sincep(Xjj) is called the likelihood ofjwith respect to X, this simple decision\n",
      "rule implements what is called a maximum-likelihood decision. More generally,\n",
      "if we de\f",
      "ne k(ijj) as\u0015(ijj)p(j), then our decision rule is simply,\n",
      "Decide category1 i\u000b",
      ":\n",
      "k(1j2)p(Xj2)\u0014k(2j1)p(Xj1)\n",
      "In any case, we need to compare the (perhaps weighted) quantities p(Xji) for\n",
      "i= 1 and 2. The exact decision rule depends on the the probability distributions\n",
      "assumed. We will treat two interesting distributions.\n",
      "5.1. USING STATISTICAL DECISION THEORY 65\n",
      "5.1.2 Gaussian (or Normal) Distributions\n",
      "The multivariate ( n-dimensional) Gaussian distribution is given by the proba-\n",
      "bility density function:\n",
      "p(X) =1\n",
      "(2\u0019)n=2j\u0006j1=2e\u0000(X\u0000M)t\u0006\u00001\n",
      "(X\u0000M)\n",
      "2\n",
      "wherenis the dimension of the column vector X, the column vector Mis called\n",
      "themean vector , (X\u0000M)tis the transpose of the vector ( X\u0000M),\u0006is the\n",
      "covariance matrix of the distribution (an n\u0002nsymmetric, positive de\f",
      "nite\n",
      "matrix), \u0006\u00001is the inverse of the covariance matrix, and j\u0006jis the determinant\n",
      "of the covariance matrix.\n",
      "The mean vector, M, with components ( m1;:::;mn), is the expected value\n",
      "ofX(using this distribution); that is, M=E[X]. The components of the\n",
      "covariance matrix are given by:\n",
      "\u001b2\n",
      "ij=E[(xi\u0000mi)(xj\u0000mj)]\n",
      "In particular, \u001b2\n",
      "iiis called the variance ofxi.\n",
      "Although the formula appears complex, an intuitive idea for Gaussian dis-\n",
      "tributions can be given when n= 2. We show a two-dimensional Gaussian\n",
      "distribution in Fig. 5.1. A three-dimensional plot of the distribution is shown\n",
      "at the top of the \f",
      "gure, and contours of equal probability are shown at the bot-\n",
      "tom. In this case, the covariance matrix, \u0006, is such that the elliptical contours\n",
      "of equal probability are skewed. If the covariance matrix were diagonal, that is\n",
      "if all o\u000b",
      "-diagonal terms were 0, then the major axes of the elliptical contours\n",
      "would be aligned with the coordinate axes. In general the principal axes are\n",
      "given by the eigenvectors of \u0006. In any case, the equi-probability contours are\n",
      "all centered on the mean vector, M, which in our \f",
      "gure happens to be at the\n",
      "origin. In general, the formula in the exponent in the Gaussian distribution\n",
      "is apositive de\f",
      "nite quadratic form (that is, its value is always positive); thus\n",
      "equi-probability contours are hyper-ellipsoids in n-dimensional space.\n",
      "Suppose we now assume that the two classes of pattern vectors that we\n",
      "want to distinguish are each distributed according to a Gaussian distribution\n",
      "but with di\u000b",
      "erent means and covariance matrices. That is, one class tends to\n",
      "have patterns clustered around one point in the n-dimensional space, and the\n",
      "other class tends to have patterns clustered around another point. We show a\n",
      "two-dimensional instance of this problem in Fig. 5.2. (In that \f",
      "gure, we have\n",
      "plotted the sum of the two distributions.) What decision rule should we use to\n",
      "separate patterns into the two appropriate categories?\n",
      "Substituting the Gaussian distributions into our maximum likelihood for-\n",
      "mula yields:\n",
      "66 CHAPTER 5. STATISTICAL LEARNING\n",
      "-5\n",
      "0\n",
      "5-505\n",
      "00.250.50.751\n",
      "-5\n",
      "0\n",
      "5-505\n",
      "025.5751\n",
      "-6 -4 -2 0 2 4 6-6-4-20246x1x2p(x1,x2)\n",
      "246\n",
      "24 6x1x2\n",
      "Figure 5.1: The Two-Dimensional Gaussian Distribution\n",
      "Decide category 1 i\u000b",
      ":\n",
      "1\n",
      "(2\u0019)n=2j\u00062j1=2e\u00001=2(X\u0000M2)t\u0006\u00001\n",
      "2(X\u0000M2)\n",
      "is less than or equal to\n",
      "1\n",
      "(2\u0019)n=2j\u00061j1=2e\u00001=2(X\u0000M1)t\u0006\u00001\n",
      "1(X\u0000M1)\n",
      "where the category 1 patterns are distributed with mean and covariance M1\n",
      "and\u00061, respectively, and the category 2 patterns are distributed with mean\n",
      "and covariance M2and\u00062.\n",
      "The result of the comparison isn't changed if we compare logarithms instead.\n",
      "After some manipulation, our decision rule is then:\n",
      "5.1. USING STATISTICAL DECISION THEORY 67\n",
      "-5\n",
      "0\n",
      "5\n",
      "10-50510\n",
      "00.250.50.751\n",
      "-5\n",
      "0\n",
      "5\n",
      "10-50510\n",
      "025.5751\n",
      "x1x2p(x1,x2)\n",
      "-5 -2.5 0 2.5 5 7.5 10-5-2.502.557.510\n",
      "Figure 5.2: The Sum of Two Gaussian Distributions\n",
      "Decide category 1 i\u000b",
      ":\n",
      "(X\u0000M1)t\u0006\u00001\n",
      "1(X\u0000M1)<(X\u0000M2)t\u0006\u00001\n",
      "2(X\u0000M2) +B\n",
      "whereB, a constant bias term, incorporates the logarithms of the fractions\n",
      "preceding the exponential, etc.\n",
      "When the quadratic forms are multiplied out and represented in terms of\n",
      "the components xi, the decision rule involves a quadric surface (a hyperquadric)\n",
      "inn-dimensional space. The exact shape and position of this hyperquadric is\n",
      "determined by the means and the covariance matrices. The surface separates\n",
      "the space into two parts, one of which contains points that will be assigned to\n",
      "category 1 and the other contains points that will be assigned to category 2.\n",
      "It is interesting to look at a special case of this surface. If the covariance\n",
      "matrices for each category are identical and diagonal, with all \u001biiequal to each\n",
      "other, then the contours of equal probability for each of the two distributions\n",
      "68 CHAPTER 5. STATISTICAL LEARNING\n",
      "are hyperspherical. The quadric forms then become (1 =j\u0006j)(X\u0000Mi)t(X\u0000Mi),\n",
      "and the decision rule is:\n",
      "Decide category 1 i\u000b",
      ":\n",
      "(X\u0000M1)t(X\u0000M1)<(X\u0000M2)t(X\u0000M2)\n",
      "Multiplying out yields:\n",
      "X\u000fX\u00002X\u000fM1+M1\u000fM1<X\u000fX\u00002X\u000fM2+M2\u000fM2\n",
      "or \f",
      "nally,\n",
      "Decide category 1 i\u000b",
      ":\n",
      "X\u000fM1\u0015X\u000fM2+ Constant\n",
      "or\n",
      "X\u000f(M1\u0000M2)\u0015Constant\n",
      "where the constant depends on the lengths of the mean vectors.\n",
      "We see that the optimal decision surface in this special case is a hyperplane.\n",
      "In fact, the hyperplane is perpendicular to the line joining the two means. The\n",
      "weights in a TLU implementation are equal to the di\u000b",
      "erence in the mean vectors.\n",
      "If the parameters ( Mi;\u0006i) of the probability distributions of the categories\n",
      "are not known, there are various techniques for estimating them, and then using\n",
      "those estimates in the decision rule. For example, if there are su\u000ecient training\n",
      "patterns, one can use sample means and sample covariance matrices. (Caution:\n",
      "the sample covariance matrix will be singular if the training patterns happen to\n",
      "lie on a subspace of the whole n-dimensional space|as they certainly will, for\n",
      "example, if the number of training patterns is less than n.)\n",
      "5.1.3 Conditionally Independent Binary Components\n",
      "Suppose the vector Xis a random variable having binary (0,1) components.\n",
      "We continue to denote the two probability distributions by p(Xj1) andp(Xj\n",
      "2). Further suppose that the components of these vectors are conditionally\n",
      "independent given the category. By conditional independence in this case, we\n",
      "mean that the formulas for the distribution can be expanded as follows:\n",
      "5.1. USING STATISTICAL DECISION THEORY 69\n",
      "p(Xji) =p(x1ji)p(x2ji)\u0001\u0001\u0001p(xnji)\n",
      "fori= 1;2\n",
      "Recall the minimum-average-loss decision rule,\n",
      "Decide category 1 i\u000b",
      ":\n",
      "\u0015(1j2)p(Xj2)p(2)\u0014\u0015(2j1)p(Xj1)p(1)\n",
      "Assuming conditional independence of the components and that \u0015(1j2) =\u0015(2j\n",
      "1), we obtain,\n",
      "Decide category 1 i\u000b",
      ":\n",
      "p(1)p(x1j1)p(x2j1)\u0001\u0001\u0001p(xnj1)\u0015p(x1j2)p(x2j2)\u0001\u0001\u0001p(xnj2)p(2)\n",
      "or i\u000b",
      ":\n",
      "p(x1j1)p(x2j1):::p(xnj1)\n",
      "p(x1j2)p(x2j2):::p(xnj2)\u0015p(2)\n",
      "p(1)\n",
      "or i\u000b",
      ":\n",
      "logp(x1j1)\n",
      "p(x1j2)+ logp(x2j1)\n",
      "p(x2j2)+\u0001\u0001\u0001+ logp(xnj1)\n",
      "p(xnj2)+ logp(1)\n",
      "p(2)\u00150\n",
      "Let us de\f",
      "ne values of the components of the distribution for speci\f",
      "c values of\n",
      "their arguments, xi:\n",
      "p(xi= 1j1) =pi\n",
      "p(xi= 0j1) = 1\u0000pi\n",
      "p(xi= 1j2) =qi\n",
      "p(xi= 0j2) = 1\u0000qi\n",
      "Now, we note that since xican only assume the values of 1 or 0:\n",
      "logp(xij1)\n",
      "p(xij2)=xilogpi\n",
      "qi+ (1\u0000xi) log(1\u0000pi)\n",
      "(1\u0000qi)\n",
      "70 CHAPTER 5. STATISTICAL LEARNING\n",
      "=xilogpi(1\u0000qi)\n",
      "qi(1\u0000pi)+ log(1\u0000pi)\n",
      "(1\u0000qi)\n",
      "Substituting these expressions into our decision rule yields:\n",
      "Decide category 1 i\u000b",
      ":\n",
      "nX\n",
      "i=1xilogpi(1\u0000qi)\n",
      "qi(1\u0000pi)+nX\n",
      "i=1log(1\u0000pi)\n",
      "(1\u0000qi)+ logp(1)\n",
      "p(2)\u00150\n",
      "We see that we can achieve this decision with a TLU with weight values as\n",
      "follows:\n",
      "wi= logpi(1\u0000qi)\n",
      "qi(1\u0000pi)\n",
      "fori= 1;:::;n , and\n",
      "wn+1= logp(1)\n",
      "1\u0000p(1)+nX\n",
      "i=1log(1\u0000pi)\n",
      "(1\u0000qi)\n",
      "If we do not know the pi;qiandp(1), we can use a sample of labeled training\n",
      "patterns to estimate these parameters.\n",
      "5.2 Learning Belief Networks\n",
      "To be added.\n",
      "5.3 Nearest-Neighbor Methods\n",
      "Another class of methods can be related to the statistical ones. These are called\n",
      "nearest-neighbor methods or, sometimes, memory-based methods. (A collection\n",
      "of papers on this subject is in [Dasarathy, 1991].) Given a training set \u0004 of m\n",
      "labeled patterns, a nearest-neighbor procedure decides that some new pattern,\n",
      "X, belongs to the same category as do its closest neighbors in \u0004. More precisely,\n",
      "ak-nearest-neighbor method assigns a new pattern, X, to that category to which\n",
      "the plurality of its kclosest neighbors belong. Using relatively large values of\n",
      "kdecreases the chance that the decision will be unduly in\r",
      "uenced by a noisy\n",
      "training pattern close to X. But large values of kalso reduce the acuity of the\n",
      "method. The k-nearest-neighbor method can be thought of as estimating the\n",
      "values of the probabilities of the classes given X. Of course the denser are the\n",
      "points around X, and the larger the value of k, the better the estimate.\n",
      "5.3. NEAREST-NEIGHBOR METHODS 71\n",
      "The distance metric used in nearest-neighbor methods (for numerical at-\n",
      "tributes) can be simple Euclidean distance. That is, the distance between two\n",
      "patterns (x11;x12;:::;x 1n) and (x21;x22;:::;x 2n) isqPn\n",
      "j=1(x1j\u0000x2j)2. This\n",
      "distance measure is often modi\f",
      "ed by scaling the features so that the spread of\n",
      "attribute values along each dimension is approximately the same. In that case,\n",
      "the distance between the two vectors would beqPn\n",
      "j=1a2\n",
      "j(x1j\u0000x2j)2, where\n",
      "ajis the scale factor for dimension j.\n",
      "An example of a nearest-neighbor decision problem is shown in Fig. 5.3. In\n",
      "the \f",
      "gure the class of a training pattern is indicated by the number next to it.\n",
      "k = 8X(a pattern to be classified)11\n",
      "111\n",
      "11\n",
      "12\n",
      "122\n",
      "22\n",
      "222\n",
      "2\n",
      "3\n",
      "33\n",
      "333\n",
      "333training pattern class of training pattern\n",
      "four patterns of category 1\n",
      "two patterns of category 2\n",
      "two patterns of category 3\n",
      "plurality are in category 1, so\n",
      "decide X is in category 1\n",
      "Figure 5.3: An 8-Nearest-Neighbor Decision\n",
      "See [Baum, 1994] for theoretical\n",
      "analysis of error rate as a function\n",
      "of the number of training patterns\n",
      "for the case in which points are\n",
      "randomly distributed on the surface\n",
      "of a unit sphere and underlying\n",
      "function is linearly separable.Nearest-neighbor methods are memory intensive because a large number of\n",
      "training patterns must be stored to achieve good generalization. Since memory\n",
      "cost is now reasonably low, the method and its derivatives have seen several\n",
      "practical applications. (See, for example, [Moore, 1992, Moore, et al. , 1994].\n",
      "Also, the distance calculations required to \f",
      "nd nearest neighbors can often be\n",
      "e\u000eciently computed by kd-tree methods [Friedman, et al. , 1977].\n",
      "A theorem by Cover and Hart [Cover & Hart, 1967] relates the performance\n",
      "of the 1-nearest-neighbor method to the performance of a minimum-probability-\n",
      "of-error classi\f",
      "er. As mentioned earlier, the minimum-probability-of-error clas-\n",
      "si\f",
      "er would assign a new pattern Xto that category that maximized p(i)p(Xji),\n",
      "wherep(i) is the a priori probability of category i, andp(Xji) is the probability\n",
      "(or probability density function) of Xgiven that Xbelongs to category i, for\n",
      "categoriesi= 1;:::;R . Suppose the probability of error in classifying patterns\n",
      "of such a minimum-probability-of-error classi\f",
      "er is \". The Cover-Hart theo-\n",
      "rem states that under very mild conditions (having to do with the smoothness\n",
      "72 CHAPTER 5. STATISTICAL LEARNING\n",
      "of probability density functions) the probability of error, \"nn, of a 1-nearest-\n",
      "neighbor classi\f",
      "er is bounded by:\n",
      "\"\u0014\"nn\u0014\"\u0012\n",
      "2\u0000\"R\n",
      "R\u00001\u0013\n",
      "\u00142\"\n",
      "whereRis the number of categories. Also see [Aha, 1991].\n",
      "5.4 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "Chapter 6\n",
      "Decision Trees\n",
      "6.1 De\f",
      "nitions\n",
      "Adecision tree (generally de\f",
      "ned) is a tree whose internal nodes are tests (on\n",
      "input patterns) and whose leaf nodes are categories (of patterns). We show an\n",
      "example in Fig. 6.1. A decision tree assigns a class number (or output) to an\n",
      "input pattern by \f",
      "ltering the pattern down through the tests in the tree. Each\n",
      "test has mutually exclusive and exhaustive outcomes. For example, test T2in\n",
      "the tree of Fig. 6.1 has three outcomes; the left-most one assigns the input\n",
      "pattern to class 3, the middle one sends the input pattern down to test T4, and\n",
      "the right-most one assigns the pattern to class 1. We follow the usual convention\n",
      "of depicting the leaf nodes by the class number.1Note that in discussing decision\n",
      "trees we are not limited to implementing Boolean functions|they are useful for\n",
      "general, categorically valued functions.\n",
      "There are several dimensions along which decision trees might di\u000b",
      "er:\n",
      "a. The tests might be multivariate (testing on several features of the input\n",
      "at once) or univariate (testing on only one of the features).\n",
      "b. The tests might have two outcomes or more than two. (If all of the tests\n",
      "have two outcomes, we have a binary decision tree .)\n",
      "c. The features or attributes might be categorical or numeric. (Binary-valued\n",
      "ones can be regarded as either.)\n",
      "1One of the researchers who has done a lot of work on learning decision trees is Ross\n",
      "Quinlan. Quinlan distinguishes between classes and categories. He calls the subsets of patterns\n",
      "that \f",
      "lter down to each tip categories and subsets of patterns having the same label classes .\n",
      "In Quinlan's terminology, our example tree has nine categories and three classes. We will not\n",
      "make this distinction, however, but will use the words \\category\" and \\class\" interchangeably\n",
      "to refer to what Quinlan calls \\class.\"\n",
      "73\n",
      "74 CHAPTER 6. DECISION TREES\n",
      "T1\n",
      "T2T3\n",
      "T4\n",
      "T4T4\n",
      "3\n",
      "1\n",
      "3 212 3\n",
      "21\n",
      "Figure 6.1: A Decision Tree\n",
      "d. We might have two classes or more than two. If we have two classes and\n",
      "binary inputs, the tree implements a Boolean function, and is called a\n",
      "Boolean decision tree.\n",
      "It is straightforward to represent the function implemented by a univariate\n",
      "Boolean decision tree in DNF form. The DNF form implemented by such a tree\n",
      "can be obtained by tracing down each path leading to a tip node corresponding\n",
      "to an output value of 1, forming the conjunction of the tests along this path,\n",
      "and then taking the disjunction of these conjunctions. We show an example in\n",
      "Fig. 6.2. In drawing univariate decision trees, each non-leaf node is depicted by\n",
      "a single attribute. If the attribute has value 0 in the input pattern, we branch\n",
      "left; if it has value 1, we branch right.\n",
      "Thek-DL class of Boolean functions can be implemented by a multivariate\n",
      "decision tree having the (highly unbalanced) form shown in Fig. 6.3. Each test,\n",
      "ci, is a term of size k or less. The viall have values of 0 or 1.\n",
      "6.2 Supervised Learning of Univariate Decision\n",
      "Trees\n",
      "Several systems for learning decision trees have been proposed. Prominent\n",
      "among these are ID3 and its new version, C4.5 [Quinlan, 1986, Quinlan, 1993],\n",
      "and CART [Breiman, et al. , 1984] We discuss here only batch methods, al-\n",
      "though incremental ones have also been proposed [Utgo\u000b",
      ", 1989].\n",
      "6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES 75\n",
      "x3\n",
      "x2 x4\n",
      "x11 0\n",
      "1\n",
      "100\n",
      "01\n",
      "x3x2\n",
      "x3x2x3x4\n",
      "x3x4x1 x3x4x1\n",
      "f = x3x2 + x3x4x1100\n",
      "10\n",
      "Figure 6.2: A Decision Tree Implementing a DNF Function\n",
      "6.2.1 Selecting the Type of Test\n",
      "As usual, we have nfeatures or attributes. If the attributes are binary, the\n",
      "tests are simply whether the attribute's value is 0 or 1. If the attributes are\n",
      "categorical, but non-binary, the tests might be formed by dividing the attribute\n",
      "values into mutually exclusive and exhaustive subsets. A decision tree with such\n",
      "tests is shown in Fig. 6.4. If the attributes are numeric, the tests might involve\n",
      "\\interval tests,\" for example 7 \u0014xi\u001413.2.\n",
      "6.2.2 Using Uncertainty Reduction to Select Tests\n",
      "The main problem in learning decision trees for the binary-attribute case is\n",
      "selecting the order of the tests. For categorical and numeric attributes, we\n",
      "must also decide what the tests should be (besides selecting the order). Several\n",
      "techniques have been tried; the most popular one is at each stage to select that\n",
      "test that maximally reduces an entropy-like measure.\n",
      "We show how this technique works for the simple case of tests with binary\n",
      "outcomes. Extension to multiple-outcome tests is straightforward computation-\n",
      "ally but gives poor results because entropy is always decreased by having more\n",
      "outcomes.\n",
      "The entropy or uncertainty still remaining about the class of a pattern|\n",
      "knowing that it is in some set, \u0004, of patterns is de\f",
      "ned as:\n",
      "H(\u0004) =\u0000X\n",
      "ip(ij\u0004) log2p(ij\u0004)\n",
      "76 CHAPTER 6. DECISION TREES\n",
      "cq\n",
      "cq-1\n",
      "ci\n",
      "1vn\n",
      "vn-1\n",
      "vi\n",
      "v1\n",
      "Figure 6.3: A Decision Tree Implementing a Decision List\n",
      "wherep(ij\u0004) is the probability that a pattern drawn at random from \u0004 belongs\n",
      "to classi, and the summation is over all of the classes. We want to select tests at\n",
      "each node such that as we travel down the decision tree, the uncertainty about\n",
      "the class of a pattern becomes less and less.\n",
      "Since we do not in general have the probabilities p(ij\u0004), we estimate them by\n",
      "sample statistics. Although these estimates might be errorful, they are never-\n",
      "theless useful in estimating uncertainties. Let ^ p(ij\u0004) be the number of patterns\n",
      "in \u0004 belonging to class idivided by the total number of patterns in \u0004. Then an\n",
      "estimate of the uncertainty is:\n",
      "^H(\u0004) =\u0000X\n",
      "i^p(ij\u0004) log2^p(ij\u0004)\n",
      "For simplicity, from now on we'll drop the \\hats\" and use sample statistics as\n",
      "if they were real probabilities.\n",
      "If we perform a test, T, havingkpossible outcomes on the patterns in \u0004, we\n",
      "will createksubsets, \u0004 1;\u00042;:::; \u0004k. Suppose that niof the patterns in \u0004 are in\n",
      "\u0004ifori= 1;:::;k . (Somenimay be 0.) If we knew that Tapplied to a pattern\n",
      "in \u0004 resulted in the j-th outcome (that is, we knew that the pattern was in \u0004 j),\n",
      "the uncertainty about its class would be:\n",
      "H(\u0004j) =\u0000X\n",
      "ip(ij\u0004j) log2p(ij\u0004j)\n",
      "and the reduction in uncertainty (beyond knowing only that the pattern was in\n",
      "\u0004) would be:\n",
      "6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES 77\n",
      "x3 = a, b, c, or d \n",
      "{a, c}{b}\n",
      "x1 = e, b, or d \n",
      "{e,b}{d}x4 = a, e, f, or g\n",
      "{a, g} {e, f}\n",
      "x2 = a, or g\n",
      "{a}{g}1\n",
      "2 11 2{d}\n",
      "2\n",
      "Figure 6.4: A Decision Tree with Categorical Attributes\n",
      "H(\u0004)\u0000H(\u0004j)\n",
      "Of course we cannot say that the test Tis guaranteed always to produce that\n",
      "amount of reduction in uncertainty because we don't know that the result of\n",
      "the test will be the j-th outcome. But we can estimate the average uncertainty\n",
      "over all the \u0004 j, by:\n",
      "E[HT(\u0004)] =X\n",
      "jp(\u0004j)H(\u0004j)\n",
      "where byHT(\u0004) we mean the average uncertainty after performing test Ton\n",
      "the patterns in \u0004, p(\u0004j) is the probability that the test has outcome j, and the\n",
      "sum is taken from 1 to k. Again, we don't know the probabilities p(\u0004j), but we\n",
      "can use sample values. The estimate ^ p(\u0004j) ofp(\u0004j) is just the number of those\n",
      "patterns in \u0004 that have outcome jdivided by the total number of patterns in\n",
      "\u0004. The average reduction in uncertainty achieved by test T(applied to patterns\n",
      "in \u0004) is then:\n",
      "RT(\u0004) =H(\u0004)\u0000E[HT(\u0004)]\n",
      "An important family of decision tree learning algorithms selects for the root\n",
      "of the tree that test that gives maximum reduction of uncertainty, and then\n",
      "applies this criterion recursively until some termination condition is met (which\n",
      "we shall discuss in more detail later). The uncertainty calculations are particu-\n",
      "larly simple when the tests have binary outcomes and when the attributes have\n",
      "78 CHAPTER 6. DECISION TREES\n",
      "binary values. We'll give a simple example to illustrate how the test selection\n",
      "mechanism works in that case.\n",
      "Suppose we want to use the uncertainty-reduction method to build a decision\n",
      "tree to classify the following patterns:\n",
      "pattern class\n",
      "(0, 0, 0) 0\n",
      "(0, 0, 1) 0\n",
      "(0, 1, 0) 0\n",
      "(0, 1, 1) 0\n",
      "(1, 0, 0) 0\n",
      "(1, 0, 1) 1\n",
      "(1, 1, 0) 0\n",
      "(1, 1, 1) 1\n",
      "What single test, x1,x2, orx3, should be performed \f",
      "rst? The illustration in\n",
      "Fig. 6.5 gives geometric intuition about the problem.\n",
      "x1x2x3\n",
      "The test x1\n",
      "Figure 6.5: Eight Patterns to be Classi\f",
      "ed by a Decision Tree\n",
      "The initial uncertainty for the set, \u0004, containing all eight points is:\n",
      "H(\u0004) =\u0000(6=8) log2(6=8)\u0000(2=8) log2(2=8) = 0:81\n",
      "Next, we calculate the uncertainty reduction if we perform x1\f",
      "rst. The left-\n",
      "hand branch has only patterns belonging to class 0 (we call them the set \u0004 l), and\n",
      "the right-hand-branch (\u0004 r) has two patterns in each class. So, the uncertainty\n",
      "of the left-hand branch is:\n",
      "6.3. NETWORKS EQUIVALENT TO DECISION TREES 79\n",
      "Hx1(\u0004l) =\u0000(4=4) log2(4=4)\u0000(0=4) log2(0=4) = 0\n",
      "And the uncertainty of the right-hand branch is:\n",
      "Hx1(\u0004r) =\u0000(2=4) log2(2=4)\u0000(2=4) log2(2=4) = 1\n",
      "Half of the patterns \\go left\" and half \\go right\" on test x1. Thus, the average\n",
      "uncertainty after performing the x1test is:\n",
      "1=2Hx1(\u0004l) + 1=2Hx1(\u0004r) = 0:5\n",
      "Therefore the uncertainty reduction on \u0004 achieved by x1is:\n",
      "Rx1(\u0004) = 0:81\u00000:5 = 0:31\n",
      "By similar calculations, we see that the test x3achieves exactly the same\n",
      "uncertainty reduction, but x2achieves no reduction whatsoever. Thus, our\n",
      "\\greedy\" algorithm for selecting a \f",
      "rst test would select either x1orx3. Suppose\n",
      "x1is selected. The uncertainty-reduction procedure would select x3as the next\n",
      "test. The decision tree that this procedure creates thus implements the Boolean\n",
      "function:f=x1x3. See [Quinlan, 1986, sect. 4] for\n",
      "another example.\n",
      "6.2.3 Non-Binary Attributes\n",
      "If the attributes are non-binary, we can still use the uncertainty-reduction tech-\n",
      "nique to select tests. But now, in addition to selecting an attribute, we must\n",
      "select a test on that attribute. Suppose for example that the value of an at-\n",
      "tribute is a real number and that the test to be performed is to set a threshold\n",
      "and to test to see if the number is greater than or less than that threshold. In\n",
      "principle, given a set of labeled patterns, we can measure the uncertainty reduc-\n",
      "tion for each test that is achieved by every possible threshold (there are only\n",
      "a \f",
      "nite number of thresholds that give di\u000b",
      "erent test results if there are only\n",
      "a \f",
      "nite number of training patterns). Similarly, if an attribute is categorical\n",
      "(with a \f",
      "nite number of categories), there are only a \f",
      "nite number of mutually\n",
      "exclusive and exhaustive subsets into which the values of the attribute can be\n",
      "split. We can calculate the uncertainty reduction for each split.\n",
      "6.3 Networks Equivalent to Decision Trees\n",
      "Since univariate Boolean decision trees are implementations of DNF functions,\n",
      "they are also equivalent to two-layer, feedforward neural networks. We show\n",
      "an example in Fig. 6.6. The decision tree at the left of the \f",
      "gure implements\n",
      "80 CHAPTER 6. DECISION TREES\n",
      "the same function as the network at the right of the \f",
      "gure. Of course, when\n",
      "implemented as a network, all of the features are evaluated in parallel for any\n",
      "input pattern, whereas when implemented as a decision tree only those features\n",
      "on the branch traveled down by the input pattern need to be evaluated. The\n",
      "decision-tree induction methods discussed in this chapter can thus be thought of\n",
      "as particular ways to establish the structure and the weight values for networks.\n",
      "Xx1\n",
      "x2\n",
      "x3\n",
      "x4\n",
      "terms-1\n",
      "+1\n",
      "disjunction\n",
      "x3x2x3x4x1\n",
      "+1\n",
      "-1+1f1.5\n",
      "0.5x3\n",
      "x2 x4\n",
      "x11 0\n",
      "1\n",
      "100\n",
      "01\n",
      "x3x2\n",
      "x3x2x3x4\n",
      "x3x4x1 x3x4x1f = x3x2 + x3x4x1\n",
      "100\n",
      "10\n",
      "Figure 6.6: A Univariate Decision Tree and its Equivalent Network\n",
      "Multivariate decision trees with linearly separable functions at each node can\n",
      "also be implemented by feedforward networks|in this case three-layer ones. We\n",
      "show an example in Fig. 6.7 in which the linearly separable functions, each im-\n",
      "plemented by a TLU, are indicated by L1;L2;L3, andL4. Again, the \f",
      "nal layer\n",
      "has \f",
      "xed weights, but the weights in the \f",
      "rst two layers must be trained. Dif-\n",
      "ferent approaches to training procedures have been discussed by [Brent, 1990],\n",
      "by [John, 1995], and (for a special case) by [Marchand & Golea, 1993].\n",
      "6.4 Over\f",
      "tting and Evaluation\n",
      "6.4.1 Over\f",
      "tting\n",
      "In supervised learning, we must choose a function to \f",
      "t the training set from\n",
      "among a set of hypotheses. We have already showed that generalization is\n",
      "impossible without bias. When we know a priori that the function we are\n",
      "trying to guess belongs to a small subset of all possible functions, then, even\n",
      "with an incomplete set of training samples, it is possible to reduce the subset\n",
      "of functions that are consistent with the training set su\u000eciently to make useful\n",
      "guesses about the value of the function for inputs not in the training set. And,\n",
      "6.4. OVERFITTING AND EVALUATION 81\n",
      "L1\n",
      "L2 L3\n",
      "L41 0\n",
      "1\n",
      "100\n",
      "01\n",
      "100\n",
      "10XL1\n",
      "L2\n",
      "L3\n",
      "L4\n",
      "conjunctionsL1L2\n",
      "L1 L3 L4<\n",
      "+\n",
      "++\n",
      "disjunction<f\n",
      "Figure 6.7: A Multivariate Decision Tree and its Equivalent Network\n",
      "the larger the training set, the more likely it is that even a randomly selected\n",
      "consistent function will have appropriate outputs for patterns not yet seen.\n",
      "However, even with bias, if the training set is not su\u000eciently large compared\n",
      "with the size of the hypothesis space, there will still be too many consistent\n",
      "functions for us to make useful guesses, and generalization performance will be\n",
      "poor. When there are too many hypotheses that are consistent with the training\n",
      "set, we say that we are over\f",
      "tting the training data. Over\f",
      "tting is a problem\n",
      "that we must address for all learning methods.\n",
      "Since a decision tree of su\u000ecient size can implement anyBoolean function\n",
      "there is a danger of over\f",
      "tting|especially if the training set is small. That\n",
      "is, even if the decision tree is synthesized to classify all the members of the\n",
      "training set correctly, it might perform poorly on new patterns that were not\n",
      "used to build the decision tree. Several techniques have been proposed to avoid\n",
      "over\f",
      "tting, and we shall examine some of them here. They make use of methods\n",
      "for estimating how well a given decision tree might generalize|methods we shall\n",
      "describe next.\n",
      "6.4.2 Validation Methods\n",
      "The most straightforward way to estimate how well a hypothesized function\n",
      "(such as a decision tree) performs on a test set is to test it on the test set! But,\n",
      "if we are comparing several learning systems (for example, if we are comparing\n",
      "di\u000b",
      "erent decision trees) so that we can select the one that performs the best on\n",
      "the test set, then such a comparison amounts to \\training on the test data.\"\n",
      "True, training on the test data enlarges the training set, with a consequent ex-\n",
      "pected improvement in generalization, but there is still the danger of over\f",
      "tting\n",
      "if we are comparing several di\u000b",
      "erent learning systems. Another technique is to\n",
      "82 CHAPTER 6. DECISION TREES\n",
      "split the training set|using (say) two-thirds for training and the other third\n",
      "for estimating generalization performance. But splitting reduces the size of the\n",
      "training set and thereby increases the possibility of over\f",
      "tting. We next describe\n",
      "some validation techniques that attempt to avoid these problems.\n",
      "Cross-Validation\n",
      "Incross-validation , we divide the training set \u0004 into Kmutually exclusive and\n",
      "exhaustive equal-sized subsets: \u0004 1;:::; \u0004K. For each subset, \u0004 i, train on the\n",
      "union of all of the other subsets, and empirically determine the error rate, \"i,\n",
      "on \u0004i. (The error rate is the number of classi\f",
      "cation errors made on \u0004 idivided\n",
      "by the number of patterns in \u0004 i.) An estimate of the error rate that can be\n",
      "expected on new patterns of a classi\f",
      "er trained on allthe patterns in \u0004 is then\n",
      "the average of the \"i.\n",
      "Leave-one-out Validation\n",
      "Leave-one-out validation is the same as cross validation for the special case in\n",
      "whichKequals the number of patterns in \u0004, and each \u0004 iconsists of a single\n",
      "pattern. When testing on each \u0004 i, we simply note whether or not a mistake\n",
      "was made. We count the total number of mistakes and divide by Kto get\n",
      "the estimated error rate. This type of validation is, of course, more expensive\n",
      "computationally, but useful when a more accurate estimate of the error rate for\n",
      "a classi\f",
      "er is needed. Describe \\bootstrapping\" also\n",
      "[Efron, 1982].\n",
      "6.4.3 Avoiding Over\f",
      "tting in Decision Trees\n",
      "Near the tips of a decision tree there may be only a few patterns per node.\n",
      "For these nodes, we are selecting a test based on a very small sample, and thus\n",
      "we are likely to be over\f",
      "tting. This problem can be dealt with by terminating\n",
      "the test-generating procedure before all patterns are perfectly split into their\n",
      "separate categories. That is, a leaf node may contain patterns of more than one\n",
      "class, but we can decide in favor of the most numerous class. This procedure\n",
      "will result in a few errors but often accepting a small number of errors on the\n",
      "training set results in fewer errors on a testing set.\n",
      "This behavior is illustrated in Fig. 6.8.\n",
      "One can use cross-validation techniques to determine when to stop splitting\n",
      "nodes. If the cross validation error increases as a consequence of a node split,\n",
      "then don't split. One has to be careful about when to stop, though, because\n",
      "under\f",
      "tting usually leads to more errors on test sets than does over\f",
      "tting. There\n",
      "is a general rule that the lowest error-rate attainable by a sub-tree of a fully\n",
      "expanded tree can be no less than 1/2 of the error rate of the fully expanded\n",
      "tree [Weiss & Kulikowski, 1991, page 126].\n",
      "6.4. OVERFITTING AND EVALUATION 83\n",
      "(From Weiss, S., and Kulikowski, C., Computer Systems that Learn ,\n",
      "Morgan Kaufmann, 1991)training errors\n",
      "validation errors\n",
      "1 2 34 5 6 78 90.20.40.60.81.0\n",
      "0\n",
      "0Error Rate\n",
      "Number of Terminal\n",
      "NodesIris Data Decision Tree\n",
      "Figure 6.8: Determining When Over\f",
      "tting Begins\n",
      "Rather than stopping the growth of a decision tree, one might grow it to\n",
      "its full size and then prune away leaf nodes and their ancestors until cross-\n",
      "validation accuracy no longer increases. This technique is called post-pruning .\n",
      "Various techniques for pruning are discussed in [Weiss & Kulikowski, 1991].\n",
      "6.4.4 Minimum-Description Length Methods\n",
      "An important tree-growing and pruning technique is based on the minimum-\n",
      "description-length (MDL) principle. (MDL is an important idea that extends\n",
      "beyond decision-tree methods [Rissanen, 1978].) The idea is that the simplest\n",
      "decision tree that can predict the classes of the training patterns is the best\n",
      "one. Consider the problem of transmitting just the labels of a training set of\n",
      "patterns, assuming that the receiver of this information already has the ordered\n",
      "set of patterns. If there are mpatterns, each labeled by one of Rclasses,\n",
      "one could transmit a list of m R-valued numbers. Assuming equally probable\n",
      "classes, this transmission would require mlog2Rbits. Or, one could transmit a\n",
      "decision tree that correctly labelled all of the patterns. The number of bits that\n",
      "this transmission would require depends on the technique for encoding decision\n",
      "trees and on the size of the tree. If the tree is small and accurately classi\f",
      "es\n",
      "all of the patterns, it might be more economical to transmit the tree than to\n",
      "transmit the labels directly. In between these extremes, we might transmit a\n",
      "tree plus a list of labels of all the patterns that the tree misclassi\f",
      "es.\n",
      "In general, the number of bits (or description length of the binary encoded\n",
      "message) is t+d, wheretis the length of the message required to transmit\n",
      "the tree, and dis the length of the message required to transmit the labels of\n",
      "84 CHAPTER 6. DECISION TREES\n",
      "the patterns misclassi\f",
      "ed by the tree. In a sense, that tree associated with the\n",
      "smallest value of t+dis the best or most economical tree. The MDL method\n",
      "is one way of adhering to the Occam's razor principle.\n",
      "Quinlan and Rivest [Quinlan & Rivest, 1989] have proposed techniques for\n",
      "encoding decision trees and lists of exception labels and for calculating the\n",
      "description length ( t+d) of these trees and labels. They then use the description\n",
      "length as a measure of quality of a tree in two ways:\n",
      "a. In growing a tree, they use the reduction in description length to select\n",
      "tests (instead of reduction in uncertainty).\n",
      "b. In pruning a tree after it has been grown to zero error, they prune away\n",
      "those nodes (starting at the tips) that achieve a decrease in the description\n",
      "length.\n",
      "These techniques compare favorably with the uncertainty-reduction method,\n",
      "although they are quite sensitive to the coding schemes used.\n",
      "6.4.5 Noise in Data\n",
      "Noise in the data means that one must inevitably accept some number of\n",
      "errors|depending on the noise level. Refusal to tolerate errors on the training\n",
      "set when there is noise leads to the problem of \\\f",
      "tting the noise.\" Dealing with\n",
      "noise, then, requires accepting some errors at the leaf nodes just as does the\n",
      "fact that there are a small number of patterns at leaf nodes.\n",
      "6.5 The Problem of Replicated Subtrees\n",
      "Decision trees are not the most economical means of implementing some Boolean\n",
      "functions. Consider, for example, the function f=x1x2+x3x4. A decision tree\n",
      "for this function is shown in Fig. 6.9. Notice the replicated subtrees shown\n",
      "circled. The DNF-form equivalent to the function implemented by this decision\n",
      "tree isf=x1x2+x1x2x3x4+x1x3x4. This DNF form is non-minimal (in the\n",
      "number of disjunctions) and is equivalent to f=x1x2+x3x4.\n",
      "The need for replication means that it takes longer to learn the tree and\n",
      "that subtrees replicated further down the tree must be learned using a smaller\n",
      "training subset. This problem is sometimes called the fragmentation problem .\n",
      "Several approaches might be suggested for dealing with fragmenta-\n",
      "tion. One is to attempt to build a decision graph instead of a tree\n",
      "[Oliver, Dowe, & Wallace, 1992, Kohavi, 1994]. A decision graph that imple-\n",
      "ments the same decisions as that of the decision tree of Fig. 6.9 is shown in Fig.\n",
      "6.10.\n",
      "Another approach is to use multivariate (rather than univariate tests at each\n",
      "node). In our example of learning f=x1x2+x3x4, if we had a test for x1x2\n",
      "6.6. THE PROBLEM OF MISSING ATTRIBUTES 85\n",
      "x1\n",
      "x3x2\n",
      "10\n",
      "x4\n",
      "01x3\n",
      "0\n",
      "x4\n",
      "01\n",
      "Figure 6.9: A Decision Tree with Subtree Replication\n",
      "and a test for x3x4, the decision tree could be much simpli\f",
      "ed, as shown in Fig.\n",
      "6.11. Several researchers have proposed techniques for learning decision trees in\n",
      "which the tests at each node are linearly separable functions. [John, 1995] gives\n",
      "a nice overview (with several citations) of learning such linear discriminant trees\n",
      "and presents a method based on \\soft entropy.\"\n",
      "A third method for dealing with the replicated subtree problem involves ex-\n",
      "tracting propositional \\rules\" from the decision tree. The rules will have as an-\n",
      "tecedents the conjunctions that lead down to the leaf nodes, and as consequents\n",
      "the name of the class at the corresponding leaf node. An example rule from the\n",
      "tree with the repeating subtree of our example would be: x1^:x2^x3^x4\u001b1.\n",
      "Quinlan [Quinlan, 1987] discusses methods for reducing a set of rules to a sim-\n",
      "pler set by 1) eliminating from the antecedent of each rule any \\unnecessary\"\n",
      "conjuncts, and then 2) eliminating \\unnecessary\" rules. A conjunct or rule is\n",
      "determined to be unnecessary if its elimination has little e\u000b",
      "ect on classi\f",
      "cation\n",
      "accuracy|as determined by a chi-square test, for example. After a rule set is\n",
      "processed, it might be the case that more than one rule is \\active\" for any given\n",
      "pattern, and care must be taken that the active rules do not con\r",
      "ict in their\n",
      "decision about the class of a pattern.\n",
      "86 CHAPTER 6. DECISION TREES\n",
      "x1\n",
      "x3x2\n",
      "1\n",
      "0\n",
      "x4\n",
      "01\n",
      "Figure 6.10: A Decision Graph\n",
      "6.6 The Problem of Missing Attributes\n",
      "To be added.\n",
      "6.7 Comparisons\n",
      "Several experimenters have compared decision-tree, neural-net, and nearest-\n",
      "neighbor classi\f",
      "ers on a wide variety of problems. For a comparison of\n",
      "neural nets versus decision trees, for example, see [Dietterich, et al. , 1990,\n",
      "Shavlik, Mooney, & Towell, 1991, Quinlan, 1994]. In their StatLog project,\n",
      "[Taylor, Michie, & Spiegalhalter, 1994] give thorough comparisons of several\n",
      "machine learning algorithms on several di\u000b",
      "erent types of problems. There seems\n",
      "x1x2\n",
      "1\n",
      "0x3x4\n",
      "1\n",
      "Figure 6.11: A Multivariate Decision Tree\n",
      "6.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 87\n",
      "to be no single type of classi\f",
      "er that is best for all problems. And, there do\n",
      "not seem to be any general conclusions that would enable one to say which\n",
      "classi\f",
      "er method is best for which sorts of classi\f",
      "cation problems, although\n",
      "[Quinlan, 1994] does provide some intuition about properties of problems that\n",
      "might render them ill suited for decision trees, on the one hand, or backpropa-\n",
      "gation, on the other.\n",
      "6.8 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "88 CHAPTER 6. DECISION TREES\n",
      "Chapter 7\n",
      "Inductive Logic\n",
      "Programming\n",
      "There are many di\u000b",
      "erent representational forms for functions of input vari-\n",
      "ables. So far, we have seen (Boolean) algebraic expressions, decision trees, and\n",
      "neural networks, plus other computational mechanisms such as techniques for\n",
      "computing nearest neighbors. Of course, the representation most important\n",
      "in computer science is a computer program. For example, a Lisp predicate of\n",
      "binary-valued inputs computes a Boolean function of those inputs. Similarly, a\n",
      "logic program (whose ordinary application is to compute bindings for variables)\n",
      "can also be used simply to decide whether or not a predicate has value True\n",
      "(T)orFalse (F) . For example, the Boolean exclusive-or (odd parity) function\n",
      "of two variables can be computed by the following logic program:\n",
      "Parity(x,y) :- True(x), :True(y)\n",
      ":- True(y),:True(x)\n",
      "We follow Prolog syntax (see, for example, [Mueller & Page, 1988]), except that\n",
      "our convention is to write variables as strings beginning with lower-case letters\n",
      "and predicates as strings beginning with upper-case letters. The unary function\n",
      "\\True \" returnsTif and only if the value of its argument is T. (We now think\n",
      "of Boolean functions and arguments as having values of TandFinstead of 0\n",
      "and 1.) Programs will be written in \\ typewriter \" font.\n",
      "In this chapter, we consider the matter of learning logic programs given\n",
      "a set of variable values for which the logic program should return T(the\n",
      "positive instances ) and a set of variable values for which it should return\n",
      "F(the negative instances ). The subspecialty of machine learning that deals\n",
      "with learning logic programs is called inductive logic programming (ILP)\n",
      "[Lavra\u0014 c & D\u0014 zeroski, 1994]. As with any learning problem, this one can be quite\n",
      "complex and intractably di\u000ecult unless we constrain it with biases of some sort.\n",
      "89\n",
      "90 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "In ILP, there are a variety of possible biases (called language biases ). One might\n",
      "restrict the program to Horn clauses, not allow recursion, not allow functions,\n",
      "and so on.\n",
      "As an example of an ILP problem, suppose we are trying to induce a func-\n",
      "tion Nonstop(x,y) , that is to have value Tfor pairs of cities connected by a\n",
      "non-stop air \r",
      "ight and Ffor all other pairs of cities. We are given a training set\n",
      "consisting of positive and negative examples. As positive examples, we might\n",
      "have (A,B) ,(A, A1) , and some other pairs; as negative examples, we might\n",
      "have (A1, A2) , and some other pairs. In ILP, we usually have additional infor-\n",
      "mation about the examples, called \\background knowledge.\" In our air-\r",
      "ight\n",
      "problem, the background information might be such ground facts as Hub(A) ,\n",
      "Hub(B) ,Satellite(A1,A) , plus others. ( Hub(A) is intended to mean that the\n",
      "city denoted by Ais a hub city, and Satellite(A1,A) is intended to mean that\n",
      "the city denoted by A1is a satellite of the city denoted by A.) From these train-\n",
      "ing facts, we want to induce a program Nonstop(x,y) , written in terms of the\n",
      "background relations HubandSatellite , that has value Tfor all the positive\n",
      "instances and has value Ffor all the negative instances. Depending on the exact\n",
      "set of examples, we might induce the program:\n",
      "Nonstop(x,y) :- Hub(x), Hub(y)\n",
      ":- Satellite(x,y)\n",
      ":- Satellite(y,x)\n",
      "which would have value Tif both of the two cities were hub cities or if one were\n",
      "a satellite of the other. As with other learning problems, we want the induced\n",
      "program to generalize well; that is, if presented with arguments not represented\n",
      "in the training set (but for which we have the needed background knowledge),\n",
      "we would like the function to guess well.\n",
      "7.1 Notation and De\f",
      "nitions\n",
      "In evaluating logic programs in ILP, we implicitly append the background facts\n",
      "to the program and adopt the usual convention that a program has value Tfor\n",
      "a set of inputs if and only if the program interpreter returns Twhen actually\n",
      "running the program (with background facts appended) on those inputs; oth-\n",
      "erwise it has value F. Using the given background facts, the program above\n",
      "would return Tfor input (A, A1) , for example. If a logic program, \u0019, returns\n",
      "Tfor a set of arguments X, we say that the program covers the arguments and\n",
      "write covers( \u0019;X). Following our terminology introduced in connection with\n",
      "version spaces, we will say that a program is su\u000ecient if it covers all of the\n",
      "positive instances and that it is necessary if it does not cover any of the neg-\n",
      "ative instances. (That is, a program implements a su\u000ecient condition that a\n",
      "training instance is positive if it covers allof the positive training instances; it\n",
      "7.2. A GENERIC ILP ALGORITHM 91\n",
      "implements a necessary condition if it covers none of the negative instances.) In\n",
      "the noiseless case, we want to induce a program that is both su\u000ecient and nec-\n",
      "essary, in which case we will call it consistent . With imperfect (noisy) training\n",
      "sets, we might relax this criterion and settle for a program that covers all but\n",
      "some fraction of the positive instances while allowing it to cover some fraction\n",
      "of the negative instances. We illustrate these de\f",
      "nitions schematically in Fig.\n",
      "7.1.\n",
      "<<\n",
      "<\n",
      "<<<</1 is a necessary program\n",
      "/2 is a sufficient program\n",
      "/3 is a consistent program+\n",
      "++\n",
      "+\n",
      "++\n",
      "++\n",
      "+\n",
      "+<\n",
      "<A positive instance\n",
      " covered by /2 and /3\n",
      "Figure 7.1: Su\u000ecient, Necessary, and Consistent Programs\n",
      "As in version spaces, if a program is su\u000ecient but not necessary it can be\n",
      "made to cover fewer examples by specializing it. Conversely, if it is necessary\n",
      "but not su\u000ecient, it can be made to cover more examples by generalizing it.\n",
      "Suppose we are attempting to induce a logic program to compute the relation\n",
      "\u001a. The most general logic program, which is certainly su\u000ecient, is the one that\n",
      "has valueTforallinputs, namely a single clause with an empty body, [ \u001a:-\n",
      "], which is called a factin Prolog. The most special logic program, which is\n",
      "certainly necessary, is the one that has value Fforallinputs, namely [ \u001a:-\n",
      "F]. Two of the many di\u000b",
      "erent ways to search for a consistent logic program\n",
      "are: 1) start with [ \u001a:- ] and specialize until the program is consistent, or 2)\n",
      "start with [ \u001a:- F ] and generalize until the program is consistent. We will\n",
      "be discussing a method that starts with [ \u001a:- ], specializes until the program\n",
      "is necessary (but might no longer be su\u000ecient), then reachieves su\u000eciency in\n",
      "stages by generalizing|ensuring within each stage that the program remains\n",
      "necessary (by specializing).\n",
      "7.2 A Generic ILP Algorithm\n",
      "Since the primary operators in our search for a consistent program are special-\n",
      "ization and generalization, we must next discuss those operations. There are\n",
      "92 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "three major ways in which a logic program might be generalized:\n",
      "a. Replace some terms in a program clause by variables. (Readers familiar\n",
      "with substitutions in the predicate calculus will note that this process is\n",
      "the inverse of substitution.)\n",
      "b. Remove literals from the body of a clause.\n",
      "c. Add a clause to the program\n",
      "Analogously, there are three ways in which a logic program might be specialized:\n",
      "a. Replace some variables in a program clause by terms (a substitution ).\n",
      "b. Add literals to the body of a clause.\n",
      "c. Remove a clause from the program\n",
      "We will be presenting an ILP learning method that adds clauses to a program\n",
      "when generalizing and that adds literals to the body of a clause when special-\n",
      "izing. When we add a clause, we will always add the clause [ \u001a:-] and then\n",
      "specialize it by adding literals to the body. Thus, we need only describe the\n",
      "process for adding literals.\n",
      "Clauses can be partially ordered by the specialization relation. In general,\n",
      "clausec1is more special than clause c2ifc2j=c1. A special case, which is what\n",
      "we use here, is that a clause c1is more special than a clause c2if the set of\n",
      "literals in the body of c2is a subset of those in c1. This ordering relation can\n",
      "be used in a structure of partially ordered clauses, called the re\f",
      "nement graph ,\n",
      "that is similar to a version space. Clause c1is an immediate successor of clause\n",
      "c2in this graph if and only if clause c1can be obtained from clause c2by adding\n",
      "a literal to the body of c2. A re\f",
      "nement graph then tells us the ways in which\n",
      "we can specialize a clause by adding a literal to it.\n",
      "Of course there are unlimited possible literals we might add to the body of\n",
      "a clause. Practical ILP systems restrict the literals in various ways. Typical\n",
      "allowed additions are:\n",
      "a. Literals used in the background knowledge.\n",
      "b. Literals whose arguments are a subset of those in the head of the clause.\n",
      "c. Literals that introduce a new distinct variable di\u000b",
      "erent from those in the\n",
      "head of the clause.\n",
      "d. A literal that equates a variable in the head of the clause with another\n",
      "such variable or with a term mentioned in the background knowledge.\n",
      "(This possibility is equivalent to forming a specialization by making a\n",
      "substitution.)\n",
      "7.2. A GENERIC ILP ALGORITHM 93\n",
      "e. A literal that is the same (except for its arguments) as that in the head\n",
      "of the clause. (This possibility admits recursive programs, which are dis-\n",
      "allowed in some systems.)\n",
      "We can illustrate these possibilities using our air-\r",
      "ight example. We start\n",
      "with the program [ Nonstop(x,y) :- ]. The literals used in the background\n",
      "knowledge are Huband Satellite . Thus the literals that we might consider\n",
      "adding are:\n",
      "Hub(x)\n",
      "Hub(y)\n",
      "Hub(z)\n",
      "Satellite(x,y)\n",
      "Satellite(y,x)\n",
      "Satellite(x,z)\n",
      "Satellite(z,y)\n",
      "(x = y)\n",
      "(If recursive programs are allowed, we could also add the literals Nonstop(x,z)\n",
      "and Nonstop(z,y) .) These possibilities are among those illustrated in the re-\n",
      "\f",
      "nement graph shown in Fig. 7.2. Whatever restrictions on additional literals\n",
      "are imposed, they are all syntactic ones from which the successors in the re\f",
      "ne-\n",
      "ment graph are easily computed. ILP programs that follow the approach we\n",
      "are discussing (of specializing clauses by adding a literal) thus have well de\f",
      "ned\n",
      "methods of computing the possible literals to add to a clause.\n",
      "Now we are ready to write down a simple generic algorithm for inducing a\n",
      "logic program, \u0019for inducing a relation \u001a. We are given a training set, \u0004 of\n",
      "argument sets some known to be in the relation \u001aand some not in \u001a; \u0004+are\n",
      "the positive instances, and \u0004\u0000are the negative instances. The algorithm has\n",
      "an outer loop in which it successively adds clauses to make \u0019more and more\n",
      "su\u000ecient. It has an inner loop for constructing a clause, c, that is more and\n",
      "more necessary and in which it refers only to a subset, \u0004 cur, of the training\n",
      "instances. (The positive instances in \u0004 curwill be denoted by \u0004+\n",
      "cur, and the\n",
      "negative ones by \u0004\u0000\n",
      "cur.) The algorithm is also given background relations and\n",
      "the means for adding literals to a clause. It uses a logic program interpreter to\n",
      "compute whether or not the program it is inducing covers training instances.\n",
      "The algorithm can be written as follows:\n",
      "Generic ILP Algorithm\n",
      "(Adapted from [Lavra\u0014 c & D\u0014 zeroski, 1994, p. 60].)\n",
      "94 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "Nonstop(x,y) :-\n",
      "Nonstop(x,y) :-\n",
      "   Hub(x)Nonstop(x,y) :-\n",
      "   Satellite(x,y)Nonstop(x,y) :-\n",
      "   (x = y). . .\n",
      ". . .\n",
      ". . . . . .\n",
      "Nonstop(x,y) :- Hub(x), Hub(y). . .\n",
      ". . .. . .\n",
      "Figure 7.2: Part of a Re\f",
      "nement Graph\n",
      "Initialize \u0004 cur:= \u0004.\n",
      "Initialize\u0019:= empty set of clauses.\n",
      "repeat [The outer loop works to make \u0019su\u000ecient.]\n",
      "Initializec:=\u001a:\u0000.\n",
      "repeat [The inner loop makes cnecessary.]\n",
      "Select a literal lto add toc. [This is a nondeterministic choice point.]\n",
      "Assignc:=c;l.\n",
      "untilcis necessary. [That is, until ccovers no negative instances in \u0004 cur.]\n",
      "Assign\u0019:=\u0019;c. [We add the clause cto the program.]\n",
      "Assign \u0004cur:= \u0004cur\u0000(the positive instances in \u0004 curcovered by \u0019).\n",
      "until\u0019is su\u000ecient.\n",
      "(The termination tests for the inner and outer loops can be relaxed as appro-\n",
      "priate for the case of noisy instances.)\n",
      "7.3 An Example\n",
      "We illustrate how the algorithm works by returning to our example of airline\n",
      "\r",
      "ights. Consider the portion of an airline route map, shown in Fig. 7.3. Cities\n",
      "A,B, and Care \\hub\" cities, and we know that there are nonstop \r",
      "ights between\n",
      "all hub cities (even those not shown on this portion of the route map). The other\n",
      "7.3. AN EXAMPLE 95\n",
      "cities are \\satellites\" of one of the hubs, and we know that there are nonstop\n",
      "\r",
      "ights between each satellite city and its hub. The learning program is given a\n",
      "set of positive instances, \u0004+, of pairs of cities between which there are nonstop\n",
      "\r",
      "ights and a set of negative instances, \u0004\u0000, of pairs of cities between which there\n",
      "are not nonstop \r",
      "ights. \u0004+contains just the pairs:\n",
      "f<A;B >;<A;C >;<B;C >;<B;A>;<C;A>;<C;B >;\n",
      "<A;A 1>;<A;A 2>;<A 1;A>;<A 2;A>;<B;B 1>;<B;B 2>;\n",
      "<B1;B >;<B 2;B >;<C;C 1>;<C;C 2>;<C 1;C >;<C 2;C >g\n",
      "For our example, we will assume that \u0004\u0000contains all those pairs of cities shown\n",
      "in Fig. 7.3 that are not in \u0004+(a type of closed-world assumption ). These are:\n",
      "f<A;B 1>;<A;B 2>;<A;C 1>;<A;C 2>;<B;C 1>;<B;C 2>;\n",
      "<B;A 1>;<B;A 2>;<C;A 1>;<C;A 2>;<C;B 1>;<C;B 2>;\n",
      "<B1;A>;<B 2;A>;<C 1;A>;<C 2;A>;<C 1;B >;<C 2;B >;\n",
      "<A1;B >;<A 2;B >;<A 1;C >;<A 2;C >;<B 1;C >;<B 2;C >g\n",
      "There may be other cities not shown on this map, so the training set does not\n",
      "necessarily exhaust all the cities.\n",
      "AB\n",
      "CC1\n",
      "C2B1B2\n",
      "A1\n",
      "A2\n",
      "Figure 7.3: Part of an Airline Route Map\n",
      "We want the learning program to induce a program for computing the value\n",
      "of the relation Nonstop . The training set, \u0004, can be thought of as a partial\n",
      "96 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "description of this relation in extensional form|it explicitly names some pairs\n",
      "in the relation and some pairs not in the relation. We desire to learn the\n",
      "Nonstop relation as a logic program in terms of the background relations, Hub\n",
      "andSatellite , which are also given in extensional form. Doing so will give us\n",
      "a more compact, intensional , description of the relation, and this description\n",
      "could well generalize usefully to other cities not mentioned in the map.\n",
      "We assume the learning program has the following extensional de\f",
      "nitions of\n",
      "the relations HubandSatellite :\n",
      "Hub\n",
      "f<A>;<B >;<C > g\n",
      "All other cities mentioned in the map are assumed not in the relation Hub. We\n",
      "will use the notation Hub(x) to express that the city named xis in the relation\n",
      "Hub.\n",
      "Satellite\n",
      "f<A1;A;>;<A 2;A>;<B 1;B >;<B 2;B >;<C 1;C >;<C 2;C >g\n",
      "All other pairs of cities mentioned in the map are not in the relation Satellite .\n",
      "We will use the notation Satellite(x,y) to express that the pair < x;y > is\n",
      "in the relation Satellite .\n",
      "Knowing that the predicate Nonstop is a two-place predicate, the inner loop\n",
      "of our algorithm initializes the \f",
      "rst clause to Nonstop(x,y) :- . This clause\n",
      "is not necessary because it covers all the negative examples (since it covers all\n",
      "examples). So we must add a literal to its (empty) body. Suppose (selecting\n",
      "a literal from the re\f",
      "nement graph) the algorithm adds Hub(x) . The following\n",
      "positive instances in \u0004 are covered by Nonstop(x,y) :- Hub(x) :\n",
      "f<A;B >;<A;C >;<B;C >;<B;A>;<C;A>;<C;B >;\n",
      "<A;A 1>;<A;A 2>;<B;B 1>;<B;B 2>;<C;C 1>;<C;C 2>g\n",
      "To compute this covering, we interpret the logic program Nonstop(x,y) :-\n",
      "Hub(x) for all pairs of cities in \u0004, using the pairs given in the background\n",
      "relation Hubas ground facts. The following negative instances are also covered:\n",
      "7.3. AN EXAMPLE 97\n",
      "f<A;B 1>;<A;B 2>;<A;C 1>;<A;C 2>;<C;A 1>;<C;A 2>;\n",
      "<C;B 1>;<C;B 2>;<B;A 1>;<B;A 2>;<B;C 1>;<B;C 2>g\n",
      "Thus, the clause is not yet necessary and another literal must be added. Sup-\n",
      "pose we next add Hub(y) . The following positive instances are covered by\n",
      "Nonstop(x,y) :- Hub(x), Hub(y) :\n",
      "f<A;B >;<A;C >;<B;C >;<B;A>;<C;A>;<C;B > g\n",
      "There are no longer any negative instances in \u0004 covered so the clause\n",
      "Nonstop(x,y) :- Hub(x), Hub(y) is necessary, and we can terminate the \f",
      "rst\n",
      "pass through the inner loop.\n",
      "But the program, \u0019, consisting of just this clause is not su\u000ecient. These\n",
      "positive instances are notcovered by the clause:\n",
      "f<A;A 1>;<A;A 2>;<A 1;A>;<A 2;A>;<B;B 1>;<B;B 2>;\n",
      "<B1;B >;<B 2;B >;<C;C 1>;<C;C 2>;<C 1;C >;<C 2;C >g\n",
      "The positive instances that were covered by Nonstop(x,y) :- Hub(x), Hub(y)\n",
      "are removed from \u0004 to form the \u0004 curto be used in the next pass through the\n",
      "inner loop. \u0004 curconsists of all the negative instances in \u0004 plus the positive\n",
      "instances (listed above) that are not yet covered. In order to attempt to cover\n",
      "them, the inner loop creates another clause c, initially set to Nonstop(x,y)\n",
      ":-. This clause covers all the negative instances, and so we must add liter-\n",
      "als to make it necessary. Suppose we add the literal Satellite(x,y) . The\n",
      "clause Nonstop(x,y) :- Satellite(x,y) covers no negative instances, so it is\n",
      "necessary. It does cover the following positive instances in \u0004 cur:\n",
      "f<A1;A>;<A 2;A>;<B 1;B >;<B 2;B >;<C 1;C >;<C 2;C >g\n",
      "These instances are removed from \u0004 curfor the next pass through the inner loop.\n",
      "The program now contains two clauses:\n",
      "Nonstop(x,y) :- Hub(x), Hub(y)\n",
      ":- Satellite(x,y)\n",
      "This program is not yet su\u000ecient since it does not cover the following positive\n",
      "instances:\n",
      "f<A;A 1>;<A;A 2>;<B;B 1>;<B;B 2>;<C;C 1>;<C;C 2>g\n",
      "98 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "During the next pass through the inner loop, we add the clause Nonstop(x,y)\n",
      ":- Satellite(y,x) . This clause is necessary, and since the program containing\n",
      "all three clauses is now su\u000ecient, the procedure terminates with:\n",
      "Nonstop(x,y) :- Hub(x), Hub(y)\n",
      ":- Satellite(x,y)\n",
      ":- Satellite(y,x)\n",
      "Since each clause is necessary, and the whole program is su\u000ecient, the pro-\n",
      "gram is also consistent with all instances of the training set. Note that this\n",
      "program can be applied (perhaps with good generalization) to other cities be-\n",
      "sides those in our partial map|so long as we can evaluate the relations Huband\n",
      "Satellite for these other cities. In the next section, we show how the technique\n",
      "can be extended to use recursion on the relation we are inducing. With that\n",
      "extension, the method can be used to induce more general logic programs.\n",
      "7.4 Inducing Recursive Programs\n",
      "To induce a recursive program, we allow the addition of a literal having the\n",
      "same predicate letter as that in the head of the clause. Various mechanisms\n",
      "must be used to ensure that such a program will terminate; one such is to make\n",
      "sure that the new literal has di\u000b",
      "erent variables than those in the head literal.\n",
      "The process is best illustrated with another example. Our example continues\n",
      "the one using the airline map, but we make the map somewhat simpler in order\n",
      "to reduce the size of the extensional relations used. Consider the map shown\n",
      "in Fig. 7.4. Again, Band Care hub cities, B1and B2are satellites of B,C1\n",
      "and C2are satellites of C. We have introduced two new cities, B3and C3. No\n",
      "\r",
      "ights exist between these cities and any other cities|perhaps there are only\n",
      "bus routes as shown by the grey lines in the map.\n",
      "We now seek to learn a program for Canfly(x,y) that covers only those\n",
      "pairs of cities that can be reached by one or more nonstop \r",
      "ights. The relation\n",
      "Canfly is satis\f",
      "ed by the following pairs of postive instances:\n",
      "f<B1;B >;<B 1;B2>;<B 1;C >;<B 1;C1>;<B 1;C2>;\n",
      "<B;B 1>;<B 2;B1>;<C;B 1>;<C 1;B1>;<C 2;B1>;\n",
      "<B2;B >;<B 2;C >;<B 2;C1>;<B 2;C2>;<B;B 2>;\n",
      "<C;B 2>;<C 1;B2>;<C 2;B2>;<B;C >;<B;C 1>;\n",
      "<B;C 2>;<C;B >;<C 1;B >;<C 2;B >;<C;C 1>;\n",
      "<C;C 2>;<C 1;C >;<C 2;C >;<C 1;C2>;<C 2;C1>g\n",
      "7.4. INDUCING RECURSIVE PROGRAMS 99\n",
      "B\n",
      "CC1\n",
      "C2B1\n",
      "B2B3\n",
      "C3\n",
      "Figure 7.4: Another Airline Route Map\n",
      "Using a closed-world assumption on our map, we take the negative instances of\n",
      "Canfly to be:\n",
      "f<B3;B2>;<B 3;B >;<B 3;B1>;<B 3;C >;<B 3;C1>;\n",
      "<B3;C2>;<B 3;C3>;<B 2;B3>;<B;B 3>;<B 1;B3>;\n",
      "<C;B 3>;<C 1;B3>;<C 2;B3>;<C 3;B3>;<C 3;B2>;\n",
      "<C3;B >;<C 3;B1>;<C 3;C >;<C 3;C1>;<C 3;C2>;\n",
      "<B2;C3>;<B;C 3>;<B 1;C3>;<C;C 3>;<C 1;C3>;\n",
      "<C2;C3>g\n",
      "We will induce Canfly(x,y) using the extensionally de\f",
      "ned background\n",
      "relation Nonstop given earlier (modi\f",
      "ed as required for our reduced airline map)\n",
      "andCanfly itself (recursively).\n",
      "As before, we start with the empty program and proceed to the inner loop\n",
      "to construct a clause that is necessary. Suppose that the inner loop adds the\n",
      "background literal Nonstop(x,y) . The clause Canfly(x,y) :- Nonstop(x,y)\n",
      "is necessary; it covers no negative instances. But it is not su\u000ecient because it\n",
      "does not cover the following positive instances:\n",
      "f<B1;B2>;<B 1;C >;<B 1;C1>;<B 1;C2>;<B 2;B1>;\n",
      "<C;B 1>;<C 1;B1>;<C 2;B1>;<B 2;C >;<B 2;C1>;\n",
      "<B2;C2>;<C;B 2>;<C 1;B2>;<C 2;B2>;<B;C 1>;\n",
      "100 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "<B;C 2>;<C 1;B >;<C 2;B >;<C 1;C2>;<C 2;C1>g\n",
      "Thus, we must add another clause to the program. In the inner loop, we \f",
      "rst\n",
      "create the clause Canfly(x,y) :- Nonstop(x,z) which introduces the new\n",
      "variablez. We digress brie\r",
      "y to describe how a program containing a clause\n",
      "with unbound variables in its body is interpreted. Suppose we try to inter-\n",
      "pret it for the positive instance Canfly(B1,B2) . The interpreter attempts to\n",
      "establish Nonstop(B1,z) for somez. Since Nonstop(B1, B) , for example, is\n",
      "a background fact, the interpreter returns T|which means that the instance\n",
      "< B 1;B2>is covered. Suppose now, we attempt to interpret the clause\n",
      "for the negative instance Canfly(B3,B) . The interpreter attempts to estab-\n",
      "lishNonstop(B3,z) for somez. There are no background facts that match, so\n",
      "the clause does not cover < B3;B > . Using the interpreter, we see that the\n",
      "clause Canfly(x,y) :- Nonstop(x,z) covers all of the positive instances not\n",
      "already covered by the \f",
      "rst clause, but it also covers many negative instances\n",
      "such as<B2;B3>, and<B;B 3>. So the inner loop must add another literal.\n",
      "This time, suppose it adds Canfly(z,y) to yield the clause Canfly(x,y) :-\n",
      "Nonstop(x,z), Canfly(z,y) . This clause is necessary; no negative instances\n",
      "are covered. The program is now su\u000ecient and consistent; it is:\n",
      "Canfly(x,y) :- Nonstop(x,y)\n",
      ":- Nonstop(x,z), Canfly(z,y)\n",
      "7.5 Choosing Literals to Add\n",
      "One of the \f",
      "rst practical ILP systems was Quinlan's FOIL [Quinlan, 1990]. A\n",
      "major problem involves deciding how to select a literal to add in the inner loop\n",
      "(from among the literals that are allowed). In FOIL, Quinlan suggested that\n",
      "candidate literals can be compared using an information-like measure|similar\n",
      "to the measures used in inducing decision trees. A measure that gives the same\n",
      "comparison as does Quinlan's is based on the amount by which adding a literal\n",
      "increases the odds that an instance drawn at random from those covered by the\n",
      "new clause is a positive instance beyond what these odds were before adding\n",
      "the literal.\n",
      "Letpbe an estimate of the probability that an instance drawn at random\n",
      "from those covered by a clause before adding the literal is a positive instance.\n",
      "That is,p=(number of positive instances covered by the clause)/(total number\n",
      "of instances covered by the clause). It is convenient to express this probability\n",
      "in \\odds form.\" The odds, o, that a covered instance is positive is de\f",
      "ned to\n",
      "beo=p=(1\u0000p). Expressing the probability in terms of the odds, we obtain\n",
      "p=o=(1 +o).\n",
      "7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION 101\n",
      "After selecting a literal, l, to add to a clause, some of the instances previously\n",
      "covered are still covered; some of these are positive and some are negative. Let\n",
      "pldenote the probability that an instance drawn at random from the instances\n",
      "covered by the new clause (with ladded) is positive. The odds will be denoted\n",
      "byol. We want to select a literal, l, that gives maximal increase in these\n",
      "odds. That is, if we de\f",
      "ne \u0015l=ol=o, we want a literal that gives a high\n",
      "value of\u0015l. Specializing the clause in such a way that it fails to cover many of\n",
      "the negative instances previously covered but still covers most of the positive\n",
      "instances previously covered will result in a high value of \u0015l. (It turns out that\n",
      "the value of Quinlan's information theoretic measure increases monotonically\n",
      "with\u0015l, so we could just as well use the latter instead.)\n",
      "Besides \f",
      "nding a literal with a high value of \u0015l, Quinlan's FOIL system also\n",
      "restricts the choice to literals that:\n",
      "a) contain at least one variable that has already been used,\n",
      "b) place further restrictions on the variables if the literal selected has the\n",
      "same predicate letter as the literal being induced (in order to prevent in\f",
      "nite\n",
      "recursion), and\n",
      "c) survive a pruning test based on the values of \u0015lfor those literals selected\n",
      "so far.\n",
      "We refer the reader to Quinlan's paper for further discussion of these points.\n",
      "Quinlan also discusses post-processing pruning methods and presents experi-\n",
      "mental results of the method applied to learning recursive relations on lists, on\n",
      "learning rules for chess endgames and for the card game Eleusis, and for some\n",
      "other standard tasks mentioned in the machine learning literature.\n",
      "The reader should also refer to [Pazzani & Kibler, 1992,\n",
      "Lavra\u0014 c & D\u0014 zeroski, 1994, Muggleton, 1991, Muggleton, 1992]. Discuss preprocessing,\n",
      "postprocessing, bottom-up\n",
      "methods, and LINUS.\n",
      "7.6 Relationships Between ILP and Decision\n",
      "Tree Induction\n",
      "The generic ILP algorithm can also be understood as a type of decision tree\n",
      "induction. Recall the problem of inducing decision trees when the values of\n",
      "attributes are categorical. When splitting on a single variable, the split at\n",
      "each node involves asking to which of several mutually exclusive and exhaustive\n",
      "subsets the value of a variable belongs. For example, if a node tested the variable\n",
      "xi, and ifxicould have values drawn from fA;B;C;D;E;Fg, then one possible\n",
      "split (among many) might be according to whether the value of xihad as value\n",
      "one offA;B;Cgor one offD;E;Fg.\n",
      "It is also possible to make a multi-variate split|testing the values of two or\n",
      "more variables at a time. With categorical variables, an n-variable split would\n",
      "be based on which of several n-ary relations the values of the variables satis\f",
      "ed.\n",
      "For example, if a node tested the variables xiandxj, and ifxiandxjboth\n",
      "could have values drawn from fA;B;C;D;E;Fg, then one possible binary split\n",
      "102 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "(among many) might be according to whether or not < xi;xj>satis\f",
      "ed the\n",
      "relationf<A;C >;<C;D> g. (Note that our subset method of forming single-\n",
      "variable splits could equivalently have been framed using 1-ary relations|which\n",
      "are usually called properties.)\n",
      "In this framework, the ILP problem is as follows: We are given a training set,\n",
      "\u0004, of positively and negatively labeled patterns whose components are drawn\n",
      "from a set of variables fx;y;z;:::g. The positively labeled patterns in \u0004 form an\n",
      "extensional de\f",
      "nition of a relation, R. We are also given background relations,\n",
      "R1;:::;Rk, on various subsets of these variables. (That is, we are given sets\n",
      "of tuples that are in these relations.) We desire to construct an intensional\n",
      "de\f",
      "nition of Rin terms of the R1;:::;Rk, such that all of the positively labeled\n",
      "patterns in \u0004 are satis\f",
      "ed by Rand none of the negatively labeled patterns\n",
      "are. The intensional de\f",
      "nition will be in terms of a logic program in which the\n",
      "relationRis the head of a set of clauses whose bodies involve the background\n",
      "relations.\n",
      "The generic ILP algorithm can be understood as decision tree induction,\n",
      "where each node of the decision tree is itself a sub-decision tree, and each sub-\n",
      "decision tree consists of nodes that make binary splits on several variables using\n",
      "the background relations, Ri. Thus we will speak of a top-level decision tree\n",
      "and various sub-decision trees. (Actually, our decision trees will be decision\n",
      "lists|a special case of decision trees, but we will refer to them as trees in our\n",
      "discussions.)\n",
      "In broad outline, the method for inducing an intensional version of the rela-\n",
      "tionRis illustrated by considering the decision tree shown in Fig. 7.5. In this\n",
      "diagram, the patterns in \u0004 are \f",
      "rst \f",
      "ltered through the decision tree in top-\n",
      "level node 1. The background relation R1is satis\f",
      "ed by some of these patterns;\n",
      "these are \f",
      "ltered to the right (to relation R2), and the rest are \f",
      "ltered to the\n",
      "left (more on what happens to these later). Right-going patterns are \f",
      "ltered\n",
      "through a sequence of relational tests until only positively labeled patterns sat-\n",
      "isfy the last relation|in this case R3. That is, the subset of patterns satisfying\n",
      "all the relations, R1,R2, andR3contains only positive instances from \u0004. (We\n",
      "might say that this combination of tests is necessary. They correspond to the\n",
      "clause created in the \f",
      "rst pass through the inner loop of the generic ILP algo-\n",
      "rithm.) Let us call the subset of patterns satisfying these relations, \u0004 1; these\n",
      "satisfy Node 1 at the top level. All other patterns, that is f\u0004\u0000\u00041g= \u0004 2are\n",
      "\f",
      "ltered to the left by Node 1.\n",
      "\u00042is then \f",
      "ltered by top-level Node 2 in much the same manner, so that\n",
      "Node 2 is satis\f",
      "ed only by the positively labeled samples in \u0004 2. We continue\n",
      "\f",
      "ltering through top-level nodes until only the negatively labeled patterns fail to\n",
      "satisfy a top node. In our example, \u0004 4contains only negatively labeled patterns\n",
      "and the union of \u0004 1and \u0004 3contains all the positively labeled patterns. The\n",
      "relation,R, that distinguishes positive from negative patterns in \u0004 is then given\n",
      "in terms of the following logic program:\n",
      "R :- R1, R2, R3\n",
      "7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION 103\n",
      "R1\n",
      "R2\n",
      "R3T\n",
      "T\n",
      "TF\n",
      "F\n",
      "F\n",
      "TF\n",
      "R4\n",
      "R5T\n",
      "TF\n",
      "F\n",
      "T FU\n",
      "U1U2 = U < U1\n",
      "U3 U4= U2 < U3Node 1\n",
      "Node 2(only positive\n",
      "instances\n",
      "satisfy all three\n",
      "tests)\n",
      "(only positivel\n",
      "instances satisfy\n",
      "these two tests)\n",
      "(only negative\n",
      "instances)\n",
      "Figure 7.5: A Decision Tree for ILP\n",
      ":- R4, R5\n",
      "If we apply this sort of decision-tree induction procedure to the problem\n",
      "of generating a logic program for the relation Nonstop (refer to Fig. 7.3), we\n",
      "obtain the decision tree shown in Fig. 7.6. The logic program resulting from\n",
      "this decision tree is the same as that produced by the generic ILP algorithm.\n",
      "In setting up the problem, the training set, \u0004 can be expressed as a set of 2-\n",
      "dimensional vectors with components xandy. The values of these components\n",
      "range over the cities fA;B;C;A 1;A2;B1;B2;C1;C2gexcept (for simplicity)\n",
      "we do not allow patterns in which xandyhave the same value. As before, the\n",
      "relation, Nonstop , contains the following pairs of cities, which are the positive\n",
      "instances:\n",
      "f<A;B >;<A;C >;<B;C >;<B;A>;<C;A>;<C;B >;\n",
      "<A;A 1>;<A;A 2>;<A 1;A>;<A 2;A>;<B;B 1>;<B;B 2>;\n",
      "<B1;B >;<B 2;B >;<C;C 1>;<C;C 2>;<C 1;C >;<C 2;C >g\n",
      "All other pairs of cities named in the map of Fig. 7.3 (using the closed world\n",
      "assumption) are not in the relation Nonstop and thus are negative instances.\n",
      "Because the values of xandyare categorical, decision-tree induction would\n",
      "be a very di\u000ecult task|involving as it does the need to invent relations on\n",
      "104 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "xandyto be used as tests. But with the background relations, Ri(in this\n",
      "case Huband Satellite ), the problem is made much easier. We select these\n",
      "relations in the same way that we select literals; from among the available tests,\n",
      "we make a selection based on which leads to the largest value of \u0015Ri.\n",
      "7.7 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "7.7. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 105\n",
      "Hub(x)T\n",
      "FU\n",
      "Node 1\n",
      "(top level)\n",
      "{<A,B>, <A,C>,\n",
      "<B,C>, <B,A>,\n",
      "<C,A>, <C,B>}Hub(y)T\n",
      "T\n",
      "F Node 2\n",
      "(top level)\n",
      "Satellite(x,y)\n",
      "F T\n",
      "T{<A1,A>, <A2,A>, <B1,B>,\n",
      "<B2,B>, <C1,C>, <C2,C>}\n",
      "F{<A,A1>, <A,A2>,<B,B1>,\n",
      "<B,B2>,  <C,C1>, <C,C2>}Satellite(y,x)\n",
      "FF\n",
      "TNode 3\n",
      "(top level)\n",
      "T\n",
      "{Only negative instances}(Only positive instances)\n",
      "(Only positive instances)\n",
      "(Only positive instances)F\n",
      "Figure 7.6: A Decision Tree for the Airline Route Problem\n",
      "106 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "Chapter 8\n",
      "Computational Learning\n",
      "Theory\n",
      "In chapter one we posed the problem of guessing a function given a set of\n",
      "sample inputs and their values. We gave some intuitive arguments to support\n",
      "the claim that after seeing only a small fraction of the possible inputs (and\n",
      "their values) that we could guess almost correctly the values of most subsequent\n",
      "inputs|if we knew that the function we were trying to guess belonged to an\n",
      "appropriately restricted subset of functions. That is, a given training set of\n",
      "sample patterns might be adequate to allow us to select a function, consistent\n",
      "with the labeled samples , from among a restricted set of hypotheses such that\n",
      "with high probability the function we select will be approximately correct (small\n",
      "probability of error) on subsequent samples drawn at random according to the\n",
      "same distribution from which the labeled samples were drawn. This insight\n",
      "led to the theory of probably approximately correct (PAC) learning|initially\n",
      "developed by Leslie Valiant [Valiant, 1984]. We present here a brief description\n",
      "of the theory for the case of Boolean functions. [Dietterich, 1990, Haussler, 1988,\n",
      "Haussler, 1990] give nice surveys of the important results. Other overviews?\n",
      "8.1 Notation and Assumptions for PAC Learn-\n",
      "ing Theory\n",
      "We assume a training set \u0004 of n-dimensional vectors, Xi,i= 1;:::;m , each\n",
      "labeled (by 1 or 0) according to a target function, f, which is unknown to\n",
      "the learner. The probability of any given vector Xbeing in \u0004, or later being\n",
      "presented to the learner, is P(X). The probability distribution, P, can be\n",
      "arbitrary. (In the literature of PAC learning theory, the target function is usually\n",
      "called the target concept and is denoted by c, but to be consistent with our\n",
      "previous notation we will continue to denote it by f.) Our problem is to guess\n",
      "107\n",
      "108 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "a function, h(X), based on the labeled samples in \u0004. In PAC theory such a\n",
      "guessed function is called the hypothesis . We assume that the target function\n",
      "is some element of a set of functions, C. We also assume that the hypothesis,\n",
      "h, is an element of a set, H, of hypotheses, which includes the set, C, of target\n",
      "functions.His called the hypothesis space .\n",
      "In general, hwon't be identical to f, but we can strive to have the value of\n",
      "h(X) = the value of f(X) for mostX's. That is, we want hto be approximately\n",
      "correct. To quantify this notion, we de\f",
      "ne the error ofh,\"h, as the probability\n",
      "that an Xdrawn randomly according to Pwill be misclassi\f",
      "ed:\n",
      "\"h=X\n",
      "[X:h(X)6=f(X)]P(X)\n",
      "Boldface symbols need to be\n",
      "smaller when they are subscripts in\n",
      "math environments.We say that hisapproximately (except for \")correct if\"h\u0014\", where\"is the\n",
      "accuracy parameter .\n",
      "Suppose we are able to \f",
      "nd an hthat classi\f",
      "es allmrandomly drawn training\n",
      "samples correctly; that is, his consistent with this randomly selected training\n",
      "set, \u0004. If mis large enough, will such an hbe approximately correct (and\n",
      "for what value of \")? On some training occasions, using mrandomly drawn\n",
      "training samples, such an hmight turn out to be approximately correct (for a\n",
      "given value of \"), and on others it might not. We say that hisprobably (except\n",
      "for\u000e)approximately correct (PAC) if the probability that it is approximately\n",
      "correct is greater than 1 \u0000\u000e, where\u000eis the con\f",
      "dence parameter . We shall show\n",
      "that ifmis greater than some bound whose value depends on \"and\u000e, such an\n",
      "his guaranteed to be probably approximately correct.\n",
      "In general, we say that a learning algorithm PAC-learns functions fromCin\n",
      "terms ofHi\u000b",
      " for every function f\u000fC, it outputs a hypothesis h\u000fH, such that\n",
      "with probability at least (1 \u0000\u000e),\"h\u0014\". Such a hypothesis is called probably\n",
      "(except for \u000e)approximately (except for \")correct .\n",
      "We want learning algorithms that are tractable, so we want an algorithm\n",
      "that PAC-learns functions in polynomial time. This can only be done for certain\n",
      "classes of functions. If there are a \f",
      "nite number of hypotheses in a hypothesis\n",
      "set (as there are for many of the hypothesis sets we have considered), we could\n",
      "always produce a consistent hypothesis from this set by testing all of them\n",
      "against the training data. But if there are an exponential number of hypotheses,\n",
      "that would take exponential time. We seek training methods that produce\n",
      "consistent hypotheses in less time. The time complexities for various hypothesis\n",
      "sets have been determined, and these are summarized in a table to be presented\n",
      "later.\n",
      "A class,C, ispolynomially PAC learnable in terms ofHprovided there exists\n",
      "a polynomial-time learning algorithm (polynomial in the number of samples\n",
      "needed,m, in the dimension, n, in 1=\", and in 1=\u000e) that PAC-learns functions\n",
      "inCin terms ofH.\n",
      "Initial work on PAC assumed H=C, but it was later shown that some func-\n",
      "tions cannot be polynomially PAC-learned under such an assumption (assuming\n",
      "8.2. PAC LEARNING 109\n",
      "P6= NP)|but canbe polynomially PAC-learned if His a strict superset of C!\n",
      "Also our de\f",
      "nition does not specify the distribution, P, from which patterns\n",
      "are drawn nor does it say anything about the properties of the learning algo-\n",
      "rithm. SinceCandHdo not have to be identical, we have the further restrictive\n",
      "de\f",
      "nition:\n",
      "Aproperly PAC-learnable class is a classCfor which there exists an algorithm\n",
      "that polynomially PAC-learns functions from Cin terms ofC.\n",
      "8.2 PAC Learning\n",
      "8.2.1 The Fundamental Theorem\n",
      "Suppose our learning algorithm selects some hrandomly from among those that\n",
      "are consistent with the values of fon themtraining patterns. The probability\n",
      "that the error of this randomly selected hisgreater than some\", withhconsis-\n",
      "tent with the values of f(X) forminstances of X(drawn according to arbitrary\n",
      "P), is less than or equal to jHje\u0000\"m, wherejHjis the number of hypotheses in\n",
      "H. We state this result as a theorem [Blumer, et al. , 1987]:\n",
      "Theorem 8.1 (Blumer, et al.)LetHbe any set of hypotheses, \u0004be a set of\n",
      "m\u00151training examples drawn independently according to some distribution\n",
      "P,fbe any classi\f",
      "cation function in H, and\">0. Then, the probability that\n",
      "there exists a hypothesis hconsistent with ffor the members of \u0004but with error\n",
      "greater than \"is at mostjHje\u0000\"m.\n",
      "Proof:\n",
      "Consider the set of all hypotheses, fh1;h2;:::;hi;:::;hSg, inH, whereS=\n",
      "jHj. The error for hiis\"hi= the probability that hiwill classify a pattern in\n",
      "error (that is, di\u000b",
      "erently than fwould classify it). The probability that hiwill\n",
      "classify a pattern correctly is (1 \u0000\"hi). A subset,HB, ofHwill have error greater\n",
      "than\". We will call the hypotheses in this subset bad. The probability that any\n",
      "particular one of these bad hypotheses, say hb, would classify a pattern correctly\n",
      "is (1\u0000\"hb). Since\"hb>\", the probability that hb(or any other bad hypothesis)\n",
      "would classify a pattern correctly is less than (1 \u0000\"). The probability that it\n",
      "would classify allmindependently drawn patterns correctly is then less than\n",
      "(1\u0000\")m.\n",
      "That is,\n",
      "prob[hbclassi\f",
      "es all mpatterns correctly jhb\u000fHB]\u0014(1\u0000\")m.\n",
      "prob[ someh \u000fHBclassi\f",
      "es all mpatterns correctly]\n",
      "=P\n",
      "hb\u000fHBprob[hbclassi\f",
      "es all mpatterns correctly jhb\u000fHB]\n",
      "\u0014K(1\u0000\")m, whereK=jHBj.\n",
      "110 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "That is,\n",
      "prob[there is a bad hypothesis that classi\f",
      "es all mpatterns correctly]\n",
      "\u0014K(1\u0000\")m.\n",
      "SinceK\u0014jHj and (1\u0000\")m\u0014e\u0000\"m, we have:\n",
      "prob[there is a bad hypothesis that classi\f",
      "es all mpatterns correctly]\n",
      "= prob[there is a hypothesis with error >\"and that classi\f",
      "es all mpatterns\n",
      "correctly]\u0014jHje\u0000\"m.\n",
      "QED\n",
      "A corollary of this theorem is:\n",
      "Corollary 8.2 Givenm\u0015(1=\")(lnjHj+ ln(1=\u000e))independent samples, the\n",
      "probability that there exists a hypothesis in Hthat is consistent with fon these\n",
      "samples and has error greater than \"is at most\u000e.\n",
      "Proof: We are to \f",
      "nd a bound on mthat guarantees that\n",
      "prob[there is a hypothesis with error > \"and that classi\f",
      "es all mpatterns\n",
      "correctly]\u0014\u000e. Thus, using the result of the theorem, we must show that\n",
      "jHje\u0000\"m\u0014\u000e. Taking the natural logarithm of both sides yields:\n",
      "lnjHj\u0000\"m\u0014ln\u000e\n",
      "or\n",
      "m\u0015(1=\")(lnjHj+ ln(1=\u000e))\n",
      "QED\n",
      "This corollary is important for two reasons. First it clearly states that we\n",
      "can select anyhypothesis consistent with the msamples and be assured that\n",
      "with probability (1 \u0000\u000e) its error will be less than \". Also, it shows that in\n",
      "order formto increase no more than polynomially with n,jHjcan be no larger\n",
      "than 2O(nk). No class larger than that can be guaranteed to be properly PAC\n",
      "learnable.\n",
      "Here is a possible point of confusion: The bound given in the corollary is\n",
      "anupper bound on the value of mneeded to guarantee polynomial probably ap-\n",
      "proximately correct learning. Values of mgreater than that bound are su\u000ecient\n",
      "(but might not be necessary). We will present a lower (necessary) bound later\n",
      "in the chapter.\n",
      "8.2. PAC LEARNING 111\n",
      "8.2.2 Examples\n",
      "Terms\n",
      "LetHbe the set of terms (conjunctions of literals). Then, jHj= 3n, and\n",
      "m\u0015(1=\")(ln(3n) + ln(1=\u000e))\n",
      "\u0015(1=\")(1:1n+ ln(1=\u000e))\n",
      "Note that the bound on mincreases only polynomially with n, 1=\", and 1=\u000e.\n",
      "Forn= 50,\"= 0:01 and\u000e= 0:01,m\u00155;961 guarantees PAC learnability.\n",
      "In order to show that terms are properly PAC learnable , we additionally\n",
      "have to show that one can \f",
      "nd in time polynomial in mandna hypothesis\n",
      "hconsistent with a set of mpatterns labeled by the value of a term. The\n",
      "following procedure for \f",
      "nding such a consistent hypothesis requires O(nm)\n",
      "steps (adapted from [Dietterich, 1990, page 268]):\n",
      "We are given a training sequence, \u0004, of mexamples. Find the \f",
      "rst pattern,\n",
      "sayX1, in that list that is labeled with a 1. Initialize a Boolean function,\n",
      "h, to the conjunction of the nliterals corresponding to the values of the n\n",
      "components of X1. (Components with value 1 will have corresponding positive\n",
      "literals; components with value 0 will have corresponding negative literals.) If\n",
      "there are no patterns labeled by a 1, we exit with the null concept ( h\u00110 for\n",
      "all patterns). Then, for each additional pattern, Xi, that is labeled with a 1,\n",
      "we delete from hany Boolean variables appearing in Xiwith a sign di\u000b",
      "erent\n",
      "from their sign in h. After processing all the patterns labeled with a 1, we check\n",
      "all of the patterns labeled with a 0 to make sure that none of them is assigned\n",
      "value 1 by h. If, at any stage of the algorithm, any patterns labeled with a 0\n",
      "are assigned a 1 by h, then there exists no term that consistently classi\f",
      "es the\n",
      "patterns in \u0004, and we exit with failure. Otherwise, we exit with h. Change this paragraph if this\n",
      "algorithm was presented in Chapter\n",
      "Three. As an example, consider the following patterns, all labeled with a 1 (from\n",
      "[Dietterich, 1990]):\n",
      "(0;1;1;0)\n",
      "(1;1;1;0)\n",
      "(1;1;0;0)\n",
      "After processing the \f",
      "rst pattern, we have h=x1x2x3x4; after processing the\n",
      "second pattern, we have h=x2x3x4; \f",
      "nally, after the third pattern, we have\n",
      "h=x2x4.\n",
      "Linearly Separable Functions\n",
      "LetHbe the set of all linearly separable functions. Then, jHj\u0014 2n2, and\n",
      "112 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "m\u0015(1=\")\u0000\n",
      "n2ln 2 + ln(1=\u000e)\u0001\n",
      "Again, note that the bound on mincreases only polynomially with n, 1=\", and\n",
      "1=\u000e.\n",
      "Forn= 50,\"= 0:01 and\u000e= 0:01,m\u0015173;748 guarantees PAC learnabil-\n",
      "ity.\n",
      "To show that linearly separable functions are properly PAC learnable , we\n",
      "would have additionally to show that one can \f",
      "nd in time polynomial in mand\n",
      "na hypothesis hconsistent with a set of mlabeled linearly separable patterns. Linear programming is polynomial.\n",
      "8.2.3 Some Properly PAC-Learnable Classes\n",
      "Some properly PAC-learnable classes of functions are given in the following\n",
      "table. (Adapted from [Dietterich, 1990, pages 262 and 268] which also gives\n",
      "references to proofs of some of the time complexities.)\n",
      "H jHj Time Complexity P. Learnable?\n",
      "terms 3npolynomial yes\n",
      "k-term DNF 2O(kn)NP-hard no\n",
      "(kdisjunctive terms)\n",
      "k-DNF 2O(nk)polynomial yes\n",
      "(a disjunction of k-sized terms)\n",
      "k-CNF 2O(nk)polynomial yes\n",
      "(a conjunction of k-sized clauses)\n",
      "k-DL 2O(nkklgn)polynomial yes\n",
      "(decision lists with k-sized terms)\n",
      "lin. sep. 2O(n2)polynomial yes\n",
      "lin. sep. with (0,1) weights ? NP-hard no\n",
      "k-2NN ? NP-hard no\n",
      "DNF 22npolynomial no\n",
      "(all Boolean functions)\n",
      "(Members of the class k-2NN are two-layer, feedforward neural networks with\n",
      "exactlykhidden units and one output unit.)\n",
      "Summary: In order to show that a class of functions is Properly PAC-\n",
      "Learnable :\n",
      "a. Show that there is an algorithm that produces a consistent hypothesis on\n",
      "m n-dimensional samples in time polynomial in mandn.\n",
      "b. Show that the sample size, m, needed to ensure PAC learnability is polyno-\n",
      "mial (or better) in (1 =\"), (1=\u000e), andnby showing that ln jHjis polynomial\n",
      "or better in the number of dimensions.\n",
      "8.3. THE VAPNIK-CHERVONENKIS DIMENSION 113\n",
      "As hinted earlier, sometimes enlarging the class of hypotheses makes learning\n",
      "easier. For example, the table above shows that k-CNF is PAC learnable, but\n",
      "k-term-DNF is not. And yet, k-term-DNF is a subclass of k-CNF! So, even if\n",
      "the target function were in k-term-DNF, one would be able to \f",
      "nd a hypothesis\n",
      "ink-CNF that is probably approximately correct for the target function. Sim-\n",
      "ilarly, linearly separable functions implemented by TLUs whose weight values\n",
      "are restricted to 0 and 1 are not properly PAC learnable, whereas unrestricted\n",
      "linearly separable functions are. It is possible that enlarging the space of hy-\n",
      "potheses makes \f",
      "nding one that is consistent with the training examples easier.\n",
      "An interesting question is whether or not the class of functions in k-2NN is poly-\n",
      "nomially PAC learnable if the hypotheses are drawn from k0-2NN with k0>k.\n",
      "(At the time of writing, this matter is still undecided.)\n",
      "Although PAC learning theory is a powerful analytic tool, it (like complexity\n",
      "theory) deals mainly with worst-case results. The fact that the class of two-\n",
      "layer, feedforward neural networks is not polynomially PAC learnable is more an\n",
      "attack on the theory than it is on the networks, which have had many successful\n",
      "applications. As [Baum, 1994, page 416-17] says: \\ :::humans are capable of\n",
      "learning in the natural world. Therefore, a proof within some model of learning\n",
      "that learning is not feasible is an indictment of the model. We should examine\n",
      "the model to see what constraints can be relaxed and made more realistic.\"\n",
      "8.3 The Vapnik-Chervonenkis Dimension\n",
      "8.3.1 Linear Dichotomies\n",
      "Consider a set,H, of functions, and a set, \u0004, of (unlabeled) patterns. One\n",
      "measure of the expressive power of a set of hypotheses, relative to \u0004, is its\n",
      "ability to make arbitrary classi\f",
      "cations of the patterns in \u0004.1If there are m\n",
      "patterns in \u0004, there are 2mdi\u000b",
      "erent ways to divide these patterns into two\n",
      "disjoint and exhaustive subsets. We say there are 2mdi\u000b",
      "erent dichotomies of\n",
      "\u0004. If \u0004 were to include allof the 2nBoolean patterns, for example, there are\n",
      "22nways to dichotomize them, and (of course) the set of all possible Boolean\n",
      "functions dichotomizes them in all of these ways. But a subset, H, of the Boolean\n",
      "functions might not be able to dichotomize an arbitrary set, \u0004, of mBoolean\n",
      "patterns in all 2mways. In general (that is, even in the non-Boolean case), we\n",
      "say that if a subset, H, of functions can dichotomize a set, \u0004, of mpatterns in\n",
      "all 2mways, thenHshatters \u0004.\n",
      "As an example, consider a set \u0004 of mpatterns in the n-dimensional space,\n",
      "Rn. (That is, the ncomponents of these patterns are real numbers.) We de\f",
      "ne\n",
      "alinear dichotomy as one implemented by an ( n\u00001)-dimensional hyperplane in\n",
      "then-dimensional space. How many linear dichotomies of mpatterns in ndi-\n",
      "mensions are there? For example, as shown in Fig. 8.1, there are 14 dichotomies\n",
      "1And, of course, if a hypothesis drawn from a set that could make arbitrary classi\f",
      "cations\n",
      "of a set of training patterns, there is little likelihood that such a hypothesis will generalize\n",
      "well beyond the training set.\n",
      "114 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "of four points in two dimensions (each separating line yields two dichotomies\n",
      "depending on whether the points on one side of the line are classi\f",
      "ed as 1 or 0).\n",
      "(Note that even though there are an in\f",
      "nite number of hyperplanes, there are,\n",
      "nevertheless, only a \f",
      "nite number of ways in which hyperplanes can dichotomize\n",
      "a \f",
      "nite number of patterns. Small movements of a hyperplane typically do not\n",
      "change the classi\f",
      "cations of any patterns.)\n",
      "1 2\n",
      "3\n",
      "4\n",
      "14 dichotomies of 4 points in 2 dimensions567\n",
      "Figure 8.1: Dichotomizing Points in Two Dimensions\n",
      "The number of dichotomies achievable by hyperplanes depends on how the\n",
      "patterns are disposed. For the maximum number of linear dichotomies, the\n",
      "points must be in what is called general position . Form>n , we say that a set\n",
      "ofmpoints is in general position in ann-dimensional space if and only if no\n",
      "subset of (n+1) points lies on an ( n\u00001)-dimensional hyperplane. When m\u0014n,\n",
      "a set ofmpoints is in general position if no ( m\u00002)-dimensional hyperplane\n",
      "contains the set. Thus, for example, a set of m\u00154 points is in general position\n",
      "in a three-dimensional space if no four of them lie on a (two-dimensional) plane.\n",
      "We will denote the number of linear dichotomies of mpoints in general position\n",
      "in ann-dimensional space by the expression \u0005 L(m;n).\n",
      "It is not too di\u000ecult to verify that: Include the derivation.\n",
      "\u0005L(m;n) = 2nX\n",
      "i=0C(m\u00001;i) form>n; and\n",
      "= 2mform\u0014n\n",
      "8.3. THE VAPNIK-CHERVONENKIS DIMENSION 115\n",
      "whereC(m\u00001;i) is the binomial coe\u000ecient(m\u00001)!\n",
      "(m\u00001\u0000i)!i!.\n",
      "The table below shows some values for \u0005 L(m;n).\n",
      "m n\n",
      "(no. of patterns) (dimension)\n",
      "1 2 3 4 5\n",
      "1 2 2 2 2 2\n",
      "2 4 4 4 4 4\n",
      "3 68 8 8 8\n",
      "4 8 14 16 16 16\n",
      "5 10 22 30 32 32\n",
      "6 12 32 52 62 64\n",
      "7 14 44 84 114 126\n",
      "8 16 58 128 198 240\n",
      "Note that the class of linear dichotomies shatters the mpatterns ifm\u0014n+ 1.\n",
      "The bold-face entries in the table correspond to the highest values of mfor\n",
      "which linear dichotomies shatter mpatterns in ndimensions.\n",
      "8.3.2 Capacity\n",
      "LetPm;n=\u0005L(m;n)\n",
      "2m = the probability that a randomly selected dichotomy (out\n",
      "of the 2mpossible dichotomies of mpatterns in ndimensions) will be linearly\n",
      "separable. In Fig. 8.2 we plot P\u0015(n+1);nversus\u0015andn, where\u0015=m=(n+ 1).\n",
      "Note that for large n(sayn > 30) how quickly Pm;nfalls from 1 to 0 as\n",
      "mgoes above 2( n+ 1). Form < 2(n+ 1), anydichotomy of the mpoints is\n",
      "almost certainly linearly separable. But for m> 2(n+ 1), a randomly selected\n",
      "dichotomy of the mpoints is almost certainly not linearly separable. For this\n",
      "reasonm= 2(n+ 1) is called the capacity of a TLU [Cover, 1965]. Unless the\n",
      "number of training patterns exceeds the capacity, the fact that a TLU separates\n",
      "those training patterns according to their labels means nothing in terms of how\n",
      "well that TLU will generalize to new patterns. There is nothing special about\n",
      "a separation found for m< 2(n+ 1) patterns|almost anydichotomy of those\n",
      "patterns would have been linearly separable. To make sure that the separation\n",
      "found is forced by the training set and thus generalizes well, it has to be the\n",
      "case that there are very few linearly separable functions that would separate\n",
      "themtraining patterns.\n",
      "Analogous results about the generalizing abilities of neural networks have\n",
      "been developed by [Baum & Haussler, 1989] and given intuitive and experimen-\n",
      "tal justi\f",
      "cation in [Baum, 1994, page 438]:\n",
      "\\The results seemed to indicate the following heuristic rule holds. If\n",
      "Mexamples [can be correctly classi\f",
      "ed by] a net with Wweights (for\n",
      "M >>W ), the net will make a fraction \"of errors on new examples\n",
      "chosen from the same [uniform] distribution where \"=W=M .\"\n",
      "116 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "41020304050\n",
      "00.250.50.751\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "41020304050\n",
      "025.5751Ph(n + 1), n\n",
      "hn\n",
      "Figure 8.2: Probability that a Random Dichotomy is Linearly Separable\n",
      "8.3.3 A More General Capacity Result\n",
      "Corollary 7.2 gave us an expression for the number of training patterns su\u000ecient\n",
      "to guarantee a required level of generalization|assuming that the function we\n",
      "were guessing was a function belonging to a class of known and \f",
      "nite cardinality.\n",
      "The capacity result just presented applies to linearly separable functions for non-\n",
      "binary patterns. We can extend these ideas to general dichotomies of non-binary\n",
      "patterns.\n",
      "In general, let us denote the maximum number of dichotomies of anyset\n",
      "ofm n-dimensional patterns by hypotheses in Has \u0005H(m;n). The number of\n",
      "dichotomies will, of course, depend on the disposition of the mpoints in the\n",
      "n-dimensional space; we take \u0005 H(m;n) to be the maximum over all possible\n",
      "arrangements of the mpoints. (In the case of the class of linearly separable\n",
      "functions, the maximum number is achieved when the mpoints are in general\n",
      "position.) For each class, H, there will be some maximum value of mfor which\n",
      "\u0005H(m;n) = 2m, that is, for which Hshatters the mpatterns. This maximum\n",
      "number is called the Vapnik-Chervonenkis (VC) dimension and is denoted by\n",
      "VCdim(H) [Vapnik & Chervonenkis, 1971].\n",
      "We saw that for the class of linear dichotomies, VCdim( Linear ) = (n+ 1).\n",
      "As another example, let us calculate the VC dimension of the hypothesis space\n",
      "of single intervals on the real line|used to classify points on the real line. We\n",
      "show an example of how points on the line might be dichotomized by a single\n",
      "interval in Fig. 8.3. The set \u0004 could be, for example, f0.5, 2.5, - 2.3, 3.14 g, and\n",
      "one of the hypotheses in our set would be [1, 4.5]. This hypothesis would label\n",
      "the points 2.5 and 3.14 with a 1 and the points - 2.3 and 0.5 with a 0. This\n",
      "8.3. THE VAPNIK-CHERVONENKIS DIMENSION 117\n",
      "set of hypotheses (single intervals on the real line) can arbitrarily classify any\n",
      "two points. But no single interval can classify three points such that the outer\n",
      "two are classi\f",
      "ed as 1 and the inner one as 0. Therefore the VC dimension of\n",
      "single intervals on the real line is 2. As soon as we have many more than 2\n",
      "training patterns on the real line and provided we know that the classi\f",
      "cation\n",
      "function we are trying to guess is a single interval, then we begin to have good\n",
      "generalization.\n",
      "Figure 8.3: Dichotomizing Points by an Interval\n",
      "The VC dimension is a useful measure of the expressive power of a hypothesis\n",
      "set. Since anydichotomy of VCdim( H) or fewer patterns in general position in n\n",
      "dimensions can be achieved by some hypothesis inH, we must have many more\n",
      "than VCdim(H) patterns in the training set in order that a hypothesis consistent\n",
      "with the training set is su\u000eciently constrained to imply good generalization.\n",
      "Our examples have shown that the concept of VC dimension is not restricted\n",
      "to Boolean functions.\n",
      "8.3.4 Some Facts and Speculations About the VC Dimen-\n",
      "sion\n",
      "\u000fIf there are a \f",
      "nite number, jHj, of hypotheses in H, then:\n",
      "VCdim(H)\u0014log(jHj)\n",
      "\u000fThe VC dimension of terms in ndimensions is n.\n",
      "\u000fSuppose we generalize our example that used a hypothesis set of single\n",
      "intervals on the real line. Now let us consider an n-dimensional feature\n",
      "space and tests of the form Li\u0014xi\u0014Hi. We allow only one such test per\n",
      "dimension. A hypothesis space consisting of conjunctions of these tests\n",
      "(called axis-parallel hyper-rectangles ) has VC dimension bounded by:\n",
      "n\u0014VCdim\u00142n\n",
      "\u000fAs we have already seen, TLUs with ninputs have a VC dimension of\n",
      "n+ 1.\n",
      "\u000f[Baum, 1994, page 438] gives experimental evidence for the proposition\n",
      "that \\:::multilayer [neural] nets have a VC dimension roughly equal to\n",
      "their total number of [adjustable] weights.\"\n",
      "118 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "8.4 VC Dimension and PAC Learning\n",
      "There are two theorems that connect the idea of VC dimension with PAC learn-\n",
      "ing [Blumer, et al. , 1990]. We state these here without proof.\n",
      "Theorem 8.3 (Blumer, et al.)A hypothesis space His PAC learnable i\u000b",
      " it\n",
      "has \f",
      "nite VC dimension.\n",
      "Theorem 8.4 A set of hypotheses, H, is properly PAC learnable if:\n",
      "a.m\u0015(1=\") max [4 lg(2 =\u000e);8 VCdim lg(13 =\")], and\n",
      "b. if there is an algorithm that outputs a hypothesis h\u000fHconsistent with the\n",
      "training set in polynomial (in mandn) time.\n",
      "The second of these two theorems improves the bound on the number of\n",
      "training patterns needed for linearly separable functions to one that is linear\n",
      "inn. In our previous example of how many training patterns were needed to\n",
      "ensure PAC learnability of a linearly separable function if n= 50,\"= 0:01, and\n",
      "\u000e= 0:01, we obtained m\u0015173;748. Using the Blumer, et al. result we would\n",
      "getm\u001552;756.\n",
      "As another example of the second theorem, let us take Hto be the set of\n",
      "closed intervals on the real line. The VC dimension is 2 (as shown previously).\n",
      "Withn= 50,\"= 0:01, and\u000e= 0:01,m\u001516;551 ensures PAC learnability.\n",
      "There is also a theorem that gives a lower (necessary) bound on the number\n",
      "of training patterns required for PAC learning [Ehrenfeucht, et al. , 1988]:\n",
      "Theorem 8.5 Any PAC learning algorithm must examine at least\n",
      "\n",
      "(1=\"lg(1=\u000e) + VCdim(H))training patterns.\n",
      "The di\u000b",
      "erence between the lower and upper bounds is\n",
      "O(log(1=\")VCdim(H)=\").\n",
      "8.5 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "Chapter 9\n",
      "Unsupervised Learning\n",
      "9.1 What is Unsupervised Learning?\n",
      "Consider the various sets of points in a two-dimensional space illustrated in Fig.\n",
      "9.1. The \f",
      "rst set (a) seems naturally partitionable into two classes, while the\n",
      "second (b) seems di\u000ecult to partition at all, and the third (c) is problematic.\n",
      "Unsupervised learning uses procedures that attempt to \f",
      "nd natural partitions\n",
      "of patterns. There are two stages:\n",
      "\u000fForm anR-way partition of a set \u0004 of unlabeled training patterns (where\n",
      "the value of R, itself, may need to be induced from the patterns). The\n",
      "partition separates \u0004 into Rmutually exclusive and exhaustive subsets,\n",
      "\u00041;:::; \u0004R, called clusters .\n",
      "\u000fDesign a classi\f",
      "er based on the labels assigned to the training patterns by\n",
      "the partition.\n",
      "We will explain shortly various methods for deciding how many clusters there\n",
      "should be and for separating a set of patterns into that many clusters. We can\n",
      "base some of these methods, and their motivation, on minimum-description-\n",
      "length (MDL) principles. In that setting, we assume that we want to encode\n",
      "a description of a set of points, \u0004, into a message of minimal length. One\n",
      "encoding involves a description of each point separately; other, perhaps shorter,\n",
      "encodings might involve a description of clusters of points together with how\n",
      "each point in a cluster can be described given the cluster it belongs to. The\n",
      "speci\f",
      "c techniques described in this chapter do not explicitly make use of MDL\n",
      "principles, but the MDL method has been applied with success. One of the\n",
      "MDL-based methods, Autoclass II [Cheeseman, et al. , 1988] discovered a new\n",
      "classi\f",
      "cation of stars based on the properties of infrared sources.\n",
      "Another type of unsupervised learning involves \f",
      "nding hierarchies of par-\n",
      "titionings or clusters of clusters. A hierarchical partition is one in which \u0004 is\n",
      "119\n",
      "120 CHAPTER 9. UNSUPERVISED LEARNING\n",
      "a)  two clusters\n",
      "b) one cluster\n",
      "c) ?\n",
      "Figure 9.1: Unlabeled Patterns\n",
      "divided into mutually exclusive and exhaustive subsets, \u0004 1;:::; \u0004R; each set,\n",
      "\u0004i, (i= 1;:::;R ) is divided into mutually exclusive and exhaustive subsets,\n",
      "and so on. We show an example of such a hierarchical partition in Fig. 9.2.\n",
      "The hierarchical form is best displayed as a tree, as shown in Fig. 9.3. The tip\n",
      "nodes of the tree can further be expanded into their individual pattern elements.\n",
      "One application of such hierarchical partitions is in organizing individuals into\n",
      "taxonomic hierarchies such as those used in botany and zoology.\n",
      "9.2 Clustering Methods\n",
      "9.2.1 A Method Based on Euclidean Distance\n",
      "Most of the unsupervised learning methods use a measure of similarity between\n",
      "patterns in order to group them into clusters. The simplest of these involves\n",
      "de\f",
      "ning a distance between patterns. For patterns whose features are numeric,\n",
      "the distance measure can be ordinary Euclidean distance between two points in\n",
      "ann-dimensional space.\n",
      "There is a simple, iterative clustering method based on distance. It can\n",
      "be described as follows. Suppose we have Rrandomly chosen cluster seekers ,\n",
      "C1;:::;CR. These are points in an n-dimensional space that we want to adjust\n",
      "so that they each move toward the center of one of the clusters of patterns.\n",
      "We present the (unlabeled) patterns in the training set, \u0004, to the algorithm\n",
      "9.2. CLUSTERING METHODS 121\n",
      "U11\n",
      "U12U21\n",
      "U22\n",
      "U23\n",
      "U31\n",
      "U32U11 F U12 = U1U21 F U22 F U23 = U2\n",
      "U31 F U32 = U3U1 F U2 F U3 = U\n",
      "Figure 9.2: A Hierarchy of Clusters\n",
      "one-by-one. For each pattern, Xi, presented, we \f",
      "nd that cluster seeker, Cj,\n",
      "that is closest to Xiand move it closer to Xi:\n",
      "Cj \u0000(1\u0000\u000b",
      "j)Cj+\u000b",
      "jXi\n",
      "where\u000b",
      "jis a learning rate parameter for the j-th cluster seeker; it determines\n",
      "how far Cjis moved toward Xi.\n",
      "Re\f",
      "nements on this procedure make the cluster seekers move less far as\n",
      "training proceeds. Suppose each cluster seeker, Cj, has a mass ,mj, equal to\n",
      "the number of times that it has moved. As a cluster seeker's mass increases it\n",
      "moves less far towards a pattern. For example, we might set \u000b",
      "j= 1=(1 +mj)\n",
      "and use the above rule together with mj \u0000mj+1. With this adjustment rule,\n",
      "a cluster seeker is always at the center of gravity (sample mean) of the set of\n",
      "patterns toward which it has so far moved. Intuitively, if a cluster seeker ever\n",
      "gets within some reasonably well clustered set of patterns (and if that cluster\n",
      "seeker is the only one so located), it will converge to the center of gravity of\n",
      "that cluster.\n",
      "122 CHAPTER 9. UNSUPERVISED LEARNING\n",
      "U\n",
      "U2\n",
      "U11U12 U31U32U21U22 U23U1 U3\n",
      "Figure 9.3: Displaying a Hierarchy as a Tree\n",
      "Once the cluster seekers have converged, the classi\f",
      "er implied by the now-\n",
      "labeled patterns in \u0004 can be based on a Voronoi partitioning of the space (based\n",
      "on distances to the various cluster seekers). This kind of classi\f",
      "cation, an ex-\n",
      "ample of which is shown in Fig. 9.4, can be implemented by a linear machine.\n",
      "Georgy Fedoseevich Voronoi, was a\n",
      "Russian mathematician who lived\n",
      "from 1868 to 1909. When basing partitioning on distance, we seek clusters whose patterns are\n",
      "as close together as possible. We can measure the badness ,V, of a cluster of\n",
      "patterns,fXig, by computing its sample variance de\f",
      "ned by:\n",
      "V= (1=K)X\n",
      "i(Xi\u0000M)2\n",
      "where Mis the sample mean of the cluster, which is de\f",
      "ned to be:\n",
      "M= (1=K)X\n",
      "iXi\n",
      "andKis the number of points in the cluster.\n",
      "We would like to partition a set of patterns into clusters such that the sum of\n",
      "the sample variances (badnesses) of these clusters is small. Of course if we have\n",
      "one cluster for each pattern, the sample variances will all be zero, so we must\n",
      "arrange that our measure of the badness of a partition must increase with the\n",
      "number of clusters. In this way, we can seek a trade-o\u000b",
      " between the variances of\n",
      "9.2. CLUSTERING METHODS 123\n",
      "C1C2\n",
      "C3Separating boundaries\n",
      "Figure 9.4: Minimum-Distance Classi\f",
      "cation\n",
      "the clusters and the number of them in a way somewhat similar to the principle\n",
      "of minimal description length discussed earlier.\n",
      "Elaborations of our basic cluster-seeking procedure allow the number of clus-\n",
      "ter seekers to vary depending on the distances between them and depending on\n",
      "the sample variances of the clusters. For example, if the distance, dij, between\n",
      "two cluster seekers, CiandCj, ever falls below some threshold \", then we can\n",
      "replace them both by a single cluster seeker placed at their center of gravity\n",
      "(taking into account their respective masses). In this way we can decrease the\n",
      "overall badness of a partition by reducing the number of clusters for compara-\n",
      "tively little penalty in increased variance.\n",
      "On the other hand, if any of the cluster seekers, say Ci, de\f",
      "nes a cluster\n",
      "whose sample variance is larger than some amount \u000e, then we can place a new\n",
      "cluster seeker, Cj, at some random location somewhat adjacent to Ciand reset\n",
      "the masses of both CiandCjto zero. In this way the badness of the par-\n",
      "tition might ultimately decrease by decreasing the total sample variance with\n",
      "comparatively little penalty for the additional cluster seeker. The values of the\n",
      "parameters \"and\u000eare set depending on the relative weights given to sample\n",
      "variances and numbers of clusters.\n",
      "In distance-based methods, it is important to scale the components of the\n",
      "pattern vectors. The variation of values along some dimensions of the pattern\n",
      "vector may be much di\u000b",
      "erent than that of other dimensions. One commonly\n",
      "used technique is to compute the standard deviation ( i.e., the square root of the\n",
      "variance) of each of the components over the entire training set and normalize\n",
      "the values of the components so that their adjusted standard deviations are\n",
      "equal.\n",
      "124 CHAPTER 9. UNSUPERVISED LEARNING\n",
      "9.2.2 A Method Based on Probabilities\n",
      "Suppose we have a partition of the training set, \u0004, into Rmutually exclusive\n",
      "and exhaustive clusters, C1;:::;CR. We can decide to which of these clusters\n",
      "some arbitrary pattern, X, should be assigned by selecting the Cifor which\n",
      "the probability, p(CijX), is largest, providing p(CijX) is larger than some \f",
      "xed\n",
      "threshold,\u000e. As we saw earlier, we can use Bayes rule and base our decision on\n",
      "maximizing p(XjCi)p(Ci). Assuming conditional independence of the pattern\n",
      "components, xi, the quantity to be maximized is:\n",
      "S(X;Ci) =p(x1jCi)p(x2jCi)\u0001\u0001\u0001p(xnjCi)p(Ci)\n",
      "Thep(xjjCi) can be estimated from the sample statistics of the patterns in the\n",
      "clusters and then used in the above expression. (Recall the linear form that this\n",
      "formula took in the case of binary-valued components.)\n",
      "We callS(X;Ci) the similarity ofXto a cluster, Ci, of patterns. Thus, we\n",
      "assign Xto the cluster to which it is most similar, providing the similarity is\n",
      "larger than \u000e.\n",
      "Just as before, we can de\f",
      "ne the sample mean of a cluster, Ci, to be:\n",
      "Mi= (1=Ki)X\n",
      "Xj\u000f CiXj\n",
      "whereKiis the number of patterns in Ci.\n",
      "We can base an iterative clustering algorithm on this measure of similarity\n",
      "[Mahadevan & Connell, 1992]. It can be described as follows:\n",
      "a. Begin with a set of unlabeled patterns \u0004 and an empty list, L, of clusters.\n",
      "b. For the next pattern, X, in \u0004, compute S(X;Ci) for each cluster, Ci.\n",
      "(Initially, these similarities are all zero.) Suppose the largest of these\n",
      "similarities is S(X;Cmax).\n",
      "(a) IfS(X;Cmax)>\u000e, assign XtoCmax. That is,\n",
      "Cmax \u0000Cmax[fXg\n",
      "Update the sample statistics p(x1jCmax);p(x2jCmax);:::;p (xnjCmax),\n",
      "andp(Cmax) to take the new pattern into account. Go to 3.\n",
      "(b) IfS(X;Cmax)\u0014\u000e, create a new cluster, Cnew=fXgand addCnew\n",
      "toL. Go to 3.\n",
      "c. Merge any existing clusters, CiandCjif (Mi\u0000Mj)2< \". Compute\n",
      "new sample statistics p(x1jCmerge );p(x2jCmerge );:::;p (xnjCmerge ), and\n",
      "p(Cmerge ) for the merged cluster, Cmerge =Ci[Cj.\n",
      "9.3. HIERARCHICAL CLUSTERING METHODS 125\n",
      "d. If the sample statistics of the clusters have not changed during an entire\n",
      "iteration through \u0004, then terminate with the clusters in L; otherwise go\n",
      "to 2.\n",
      "The value of the parameter \u000econtrols the number of clusters. If \u000eis high,\n",
      "there will be a large number of clusters with few patterns in each cluster. For\n",
      "small values of \u000e, there will be a small number of clusters with many patterns in\n",
      "each cluster. Similarly, the larger the value of \", the smaller the number clusters\n",
      "that will be found.\n",
      "Designing a classi\f",
      "er based on the patterns labeled by the partitioning is\n",
      "straightforward. We assign any pattern, X, to that category that maximizes\n",
      "S(X;Ci). Mention \\k-means and \\EM\"\n",
      "methods.\n",
      "9.3 Hierarchical Clustering Methods\n",
      "9.3.1 A Method Based on Euclidean Distance\n",
      "Suppose we have a set, \u0004, of unlabeled training patterns. We can form a hi-\n",
      "erarchical classi\f",
      "cation of the patterns in \u0004 by a simple agglomerative method.\n",
      "(The description of this algorithm is based on an unpublished manuscript by\n",
      "Pat Langley.) Our description here gives the general idea; we leave it to the\n",
      "reader to generate a precise algorithm.\n",
      "We \f",
      "rst compute the Euclidean distance between all pairs of patterns in \u0004.\n",
      "(Again, appropriate scaling of the dimensions is assumed.) Suppose the smallest\n",
      "distance is between patterns XiandXj. We collect XiandXjinto a cluster,\n",
      "C, eliminate XiandXjfrom \u0004 and replace them by a cluster vector ,C, equal\n",
      "to the average of XiandXj. Next we compute the Euclidean distance again\n",
      "between all pairs of points in \u0004. If the smallest distance is between pairs of\n",
      "patterns, we form a new cluster, C, as before and replace the pair of patterns\n",
      "in \u0004 by their average. If the shortest distance is between a pattern, Xi, and\n",
      "a cluster vector, Cj(representing a cluster, Cj), we form a new cluster, C,\n",
      "consisting of the union of CjandfXig. In this case, we replace CjandXi\n",
      "in \u0004 by their (appropriately weighted) average and continue. If the shortest\n",
      "distance is between two cluster vectors, CiandCj, we form a new cluster, C,\n",
      "consisting of the union of CiandCj. In this case, we replace CiandCjby their\n",
      "(appropriately weighted) average and continue. Since we reduce the number of\n",
      "points in \u0004 by one each time, we ultimately terminate with a tree of clusters\n",
      "rooted in the cluster containing all of the points in the original training set.\n",
      "An example of how this method aggregates a set of two dimensional patterns\n",
      "is shown in Fig. 9.5. The numbers associated with each cluster indicate the order\n",
      "in which they were formed. These clusters can be organized hierarchically in a\n",
      "binary tree with cluster 9 as root, clusters 7 and 8 as the two descendants of the\n",
      "root, and so on. A ternary tree could be formed instead if one searches for the\n",
      "three points in \u0004 whose triangle de\f",
      "ned by those patterns has minimal area.\n",
      "126 CHAPTER 9. UNSUPERVISED LEARNING\n",
      "1\n",
      "23\n",
      "54\n",
      "67\n",
      "89\n",
      "Figure 9.5: Agglommerative Clustering\n",
      "9.3.2 A Method Based on Probabilities\n",
      "A probabilistic quality measure for partitions\n",
      "We can develop a measure of the goodness of a partitioning based on how\n",
      "accurately we can guess a pattern given only what partition it is in. Suppose\n",
      "we are given a partitioning of \u0004 into Rclasses,C1;:::;CR. As before, we can\n",
      "compute the sample statistics p(xijCk) which give probability values for each\n",
      "component given the class assigned to it by the partitioning. Suppose each\n",
      "component xiofXcan take on the values vij, where the index jsteps over the\n",
      "domain of that component. We use the notation pi(vijjCk) = probability( xi=\n",
      "vijjCk).\n",
      "Suppose we use the following probabilistic guessing rule about the values\n",
      "of the components of a vector Xgiven only that it is in class k. Guess that\n",
      "xi=vijwith probability pi(vijjCk). Then, the probability that we guess the\n",
      "i-th component correctly is:\n",
      "X\n",
      "jprobability(guess is vij)pi(vijjCk) =X\n",
      "j[pi(vijjCk)]2\n",
      "The average number of (the n) components whose values are guessed correctly\n",
      "by this method is then given by the sum of these probabilities over all of the\n",
      "components of X:\n",
      "X\n",
      "iX\n",
      "j[pi(vijjCk)]2\n",
      "9.3. HIERARCHICAL CLUSTERING METHODS 127\n",
      "Given our partitioning into Rclasses, the goodness measure, G, of this parti-\n",
      "tioning is the average of the above expression over all classes:\n",
      "G=X\n",
      "kp(Ck)X\n",
      "iX\n",
      "j[pi(vijjCk)]2\n",
      "wherep(Ck) is the probability that a pattern is in class Ck. In order to penalize\n",
      "this measure for having a large number of classes, we divide it by Rto get an\n",
      "overall \\quality\" measure of a partitioning:\n",
      "Z= (1=R)X\n",
      "kp(Ck)X\n",
      "iX\n",
      "j[pi(vijjCk)]2\n",
      "We give an example of the use of this measure for a trivially simple\n",
      "clustering of the four three-dimensional patterns shown in Fig. 9.6. There\n",
      "are several di\u000b",
      "erent partitionings. Let's evaluate Zvalues for the follow-\n",
      "ing ones:P1=fa;b;c;dg,P2=ffa;bg;fc;dgg,P3=ffa;cg;fb;dgg, and\n",
      "P4=ffag;fbg;fcg;fdgg. The \f",
      "rst, P1, puts all of the patterns into a single\n",
      "cluster. The sample probabilities pi(vi1= 1) andpi(vi0= 0) are all equal to 1/2\n",
      "for each of the three components. Summing over the values of the components\n",
      "(0 and 1) gives (1 =2)2+ (1=2)2= 1=2. Summing over the three components\n",
      "gives 3=2. Averaging over all of the clusters (there is just one) also gives 3 =2.\n",
      "Finally, dividing by the number of clusters produces the \f",
      "nal Zvalue of this\n",
      "partition,Z(P1) = 3=2.\n",
      "The second partition, P2, gives the following sample probabilities:\n",
      "p1(v11= 1jC1) = 1\n",
      "p2(v21= 1jC1) = 1=2\n",
      "p3(v31= 1jC1) = 1\n",
      "Summing over the values of the components (0 and 1) gives (1)2+ (0)2= 1 for\n",
      "component 1, (1 =2)2+ (1=2)2= 1=2 for component 2, and (1)2+ (0)2= 1 for\n",
      "component 3. Summing over the three components gives 2 1 =2 for class 1. A\n",
      "similar calculation also gives 2 1 =2 for class 2. Averaging over the two clusters\n",
      "also gives 2 1 =2. Finally, dividing by the number of clusters produces the \f",
      "nal\n",
      "Zvalue of this partition, Z(P2) = 1 1=4, not quite as high as Z(P1).\n",
      "Similar calculations yield Z(P3) = 1 and Z(P4) = 3=4, so this method of\n",
      "evaluating partitions would favor placing all patterns in a single cluster.\n",
      "128 CHAPTER 9. UNSUPERVISED LEARNING\n",
      "x2x3\n",
      "x1abc d\n",
      "Figure 9.6: Patterns in 3-Dimensional Space\n",
      "An iterative method for hierarchical clustering\n",
      "Evaluating all partitionings of mpatterns and then selecting the best would be\n",
      "computationally intractable. The following iterative method is based on a hi-\n",
      "erarchical clustering procedure called COBWEB [Fisher, 1987]. The procedure\n",
      "grows a tree each node of which is labeled by a set of patterns. At the end\n",
      "of the process, the root node contains all of the patterns in \u0004. The successors\n",
      "of the root node will contain mutually exclusive and exhaustive subsets of \u0004.\n",
      "In general, the successors of a node, \u0011, are labeled by mutually exclusive and\n",
      "exhaustive subsets of the pattern set labelling node \u0011. The tips of the tree will\n",
      "contain singleton sets. The method uses Zvalues to place patterns at the vari-\n",
      "ous nodes; sample statistics are used to update the Zvalues whenever a pattern\n",
      "is placed at a node. The algorithm is as follows:\n",
      "a. We start with a tree whose root node contains all of the patterns in \u0004\n",
      "and a single empty successor node. We arrange that at all times dur-\n",
      "ing the process every non-empty node in the tree has (besides any other\n",
      "successors) exactly one empty successor.\n",
      "b. Select a pattern Xiin \u0004 (if there are no more patterns to select, terminate).\n",
      "c. Set\u0016to the root node.\n",
      "d. For each of the successors of \u0016(including the empty successor!), calculate\n",
      "thebest host forXi. A best host is determined by tentatively placing\n",
      "Xiin one of the successors and calculating the resulting Zvalue for each\n",
      "9.3. HIERARCHICAL CLUSTERING METHODS 129\n",
      "one of these ways of accomodating Xi. The best host corresponds to the\n",
      "assignment with the highest Zvalue.\n",
      "e. If the best host is an empty node, \u0011, we place Xiin\u0011, generate an empty\n",
      "successor node of \u0011, generate an empty sibling node of \u0011, and go to 2.\n",
      "f. If the best host is a non-empty, singleton (tip) node, \u0011, we place Xiin\u0011,\n",
      "create one successor node of \u0011containing the singleton pattern that was\n",
      "in\u0011, create another successor node of \u0011containing Xi, create an empty\n",
      "successor node of \u0011, create empty successor nodes of the new non-empty\n",
      "successors of \u0011, and go to 2.\n",
      "g. If the best host is a non-empty, non-singleton node, \u0011, we place Xiin\u0011,\n",
      "set\u0016to\u0011, and go to 4.\n",
      "This process is rather sensitive to the order in which patterns are presented.\n",
      "To make the \f",
      "nal classi\f",
      "cation tree less order dependent, the COBWEB proce-\n",
      "dure incorporates node merging and splitting .\n",
      "Node merging:\n",
      "It may happen that two nodes having the same parent could be merged with\n",
      "an overall increase in the quality of the resulting classi\f",
      "cation performed by the\n",
      "successors of that parent. Rather than try all pairs to merge, a good heuristic\n",
      "is to attempt to merge the two best hosts. When such a merging improves the\n",
      "Zvalue, a new node containing the union of the patterns in the merged nodes\n",
      "replaces the merged nodes, and the two nodes that were merged are installed\n",
      "as successors of the new node.\n",
      "Node splitting:\n",
      "A heuristic for node splitting is to consider replacing the best host among a\n",
      "group of siblings by that host's successors. This operation is performed only if\n",
      "it increases the Zvalue of the classi\f",
      "cation performed by a group of siblings.\n",
      "Example results from COBWEB\n",
      "We mention two experiments with COBWEB. In the \f",
      "rst, the program at-\n",
      "tempted to \f",
      "nd two categories (we will call them Class 1 andClass 2 ) of United\n",
      "States Senators based on their votes ( yesorno) on six issues. After the clus-\n",
      "ters were established, the majority vote in each class was computed. These are\n",
      "shown in the table below.\n",
      "Issue Class 1 Class 2\n",
      "Toxic Waste yes no\n",
      "Budget Cuts yes no\n",
      "SDI Reduction no yes\n",
      "Contra Aid yes no\n",
      "Line-Item Veto yes no\n",
      "MX Production yes no\n",
      "130 CHAPTER 9. UNSUPERVISED LEARNING\n",
      "In the second experiment, the program attempted to classify soybean dis-\n",
      "eases based on various characteristics. COBWEB grouped the diseases in the\n",
      "taxonomy shown in Fig. 9.7.\n",
      "N0\n",
      "soybean\n",
      "diseasesN1\n",
      "  Diaporthe\n",
      "Stem CankerN2\n",
      "Charcoal\n",
      "     RotN3N31\n",
      "Rhizoctonia\n",
      "       RotN32\n",
      "Phytophthora\n",
      "       Rot\n",
      "Figure 9.7: Taxonomy Induced for Soybean Diseases\n",
      "9.4 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "Chapter 10\n",
      "Temporal-Di\u000b",
      "erence\n",
      "Learning\n",
      "10.1 Temporal Patterns and Prediction Prob-\n",
      "lems\n",
      "In this chapter, we consider problems in which we wish to learn to predict the\n",
      "future value of some quantity, say z, from ann-dimensional input pattern, X.\n",
      "In many of these problems, the patterns occur in temporal sequence, X1,X2,\n",
      ". . ., Xi,Xi+1,:::,Xm, and are generated by a dynamical process. The\n",
      "components of Xiare features whose values are available at time, t=i. We\n",
      "distinguish two kinds of prediction problems. In one, we desire to predict the\n",
      "value ofzat timet=i+ 1 based on input Xifor everyi. For example, we\n",
      "might wish to predict some aspects of tomorrow's weather based on a set of\n",
      "measurements made today. In the other kind of prediction problem, we desire\n",
      "to make a sequence of predictions about the value of zat some \f",
      "xed time, say\n",
      "t=m+ 1, based on each of the Xi,i= 1;:::;m . For example, we might wish\n",
      "to make a series of predictions about some aspect of the weather on next New\n",
      "Year's Day, based on measurements taken every day before New Year's. Sutton\n",
      "[Sutton, 1988] has called this latter problem, multi-step prediction , and that is\n",
      "the problem we consider here. In multi-step prediction, we might expect that\n",
      "the prediction accuracy should get better and better as iincreases toward m.\n",
      "10.2 Supervised and Temporal-Di\u000b",
      "erence Meth-\n",
      "ods\n",
      "A training method that naturally suggests itself is to use the actual value of\n",
      "zat timem+ 1 (once it is known) in a supervised learning procedure using a\n",
      "131\n",
      "132 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "sequence of training patterns, fX1,X2,:::,Xi,Xi+1,:::,Xmg. That is, we\n",
      "seek to learn a function, f, such thatf(Xi) is as close as possible to zfor eachi.\n",
      "Typically, we would need a training set, \u0004, consisting of several such sequences.\n",
      "We will show that a method that is better than supervised learning for some\n",
      "important problems is to base learning on the di\u000b",
      "erence between f(Xi+1) and\n",
      "f(Xi) rather than on the di\u000b",
      "erence between zandf(Xi). Such methods involve\n",
      "what is called temporal-di\u000b",
      "erence (TD) learning .\n",
      "We assume that our prediction, f(X), depends on a vector of modi\f",
      "able\n",
      "weights, W. To make that dependence explicit, we write f(X;W). For su-\n",
      "pervised learning, we consider procedures of the following type: For each Xi,\n",
      "the prediction f(Xi;W) is computed and compared to z, and the learning rule\n",
      "(whatever it is) computes the change, (\u0001 Wi), to be made to W. Then, taking\n",
      "into account the weight changes for each pattern in a sequence all at once after\n",
      "having made all of the predictions with the old weight vector, we change Was\n",
      "follows:\n",
      "W \u0000W+mX\n",
      "i=1(\u0001W)i\n",
      "Whenever we are attempting to minimize the squared error between zand\n",
      "f(Xi;W) by gradient descent, the weight-changing rule for each pattern is:\n",
      "(\u0001W)i=c(z\u0000fi)@fi\n",
      "@W\n",
      "wherecis a learning rate parameter, fiis our prediction of z,f(Xi;W),\n",
      "at timet=i, and@fi\n",
      "@Wis, by de\f",
      "nition, the vector of partial derivatives\n",
      "(@fi\n",
      "@w1;:::;@fi\n",
      "@wi;:::;@fi\n",
      "@wn) in which the wiare the individual components of W.\n",
      "(The expression@fi\n",
      "@Wis sometimes written rWfi.) The reader will recall that\n",
      "we used an equivalent expression for (\u0001 W)iin deriving the backpropagation\n",
      "formulas used in training multi-layer neural networks.\n",
      "The Widrow-Ho\u000b",
      " rule results when f(X;W) =X\u000fW. Then:\n",
      "(\u0001W)i=c(z\u0000fi)Xi\n",
      "An interesting form for (\u0001 W)ican be developed if we note that\n",
      "(z\u0000fi) =mX\n",
      "k=i(fk+1\u0000fk)\n",
      "where we de\f",
      "ne fm+1=z. Substituting in our formula for (\u0001 W)iyields:\n",
      "(\u0001W)i=c(z\u0000fi)@fi\n",
      "@W\n",
      "10.2. SUPERVISED AND TEMPORAL-DIFFERENCE METHODS 133\n",
      "=c@fi\n",
      "@WmX\n",
      "k=i(fk+1\u0000fk)\n",
      "In this form, instead of using the di\u000b",
      "erence between a prediction and the value\n",
      "ofz, we use the di\u000b",
      "erences between successive predictions|thus the phrase\n",
      "temporal-di\u000b",
      "erence (TD) learning.\n",
      "In the case when f(X;W) =X\u000fW, the temporal di\u000b",
      "erence form of the\n",
      "Widrow-Ho\u000b",
      " rule is:\n",
      "(\u0001W)i=cXimX\n",
      "k=i(fk+1\u0000fk)\n",
      "One reason for writing (\u0001 W)iin temporal-di\u000b",
      "erence form is to permit an\n",
      "interesting generalization as follows:\n",
      "(\u0001W)i=c@fi\n",
      "@WmX\n",
      "k=i\u0015(k\u0000i)(fk+1\u0000fk)\n",
      "where 0< \u0015\u00141. Here, the \u0015term gives exponentially decreasing weight to\n",
      "di\u000b",
      "erences later in time than t=i. When\u0015= 1, we have the same rule with\n",
      "which we began|weighting all di\u000b",
      "erences equally, but as \u0015!0, we weight only\n",
      "the (fi+1\u0000fi) di\u000b",
      "erence. With the \u0015term, the method is called TD( \u0015).\n",
      "It is interesting to compare the two extreme cases:\n",
      "For TD(0):\n",
      "(\u0001W)i=c(fi+1\u0000fi)@fi\n",
      "@W\n",
      "For TD(1):\n",
      "(\u0001W)i=c(z\u0000fi)@fi\n",
      "@W\n",
      "Both extremes can be handled by the same learning mechanism; only the error\n",
      "term is di\u000b",
      "erent. In TD(0), the error is the di\u000b",
      "erence between successive predic-\n",
      "tions, and in TD(1), the error is the di\u000b",
      "erence between the \f",
      "nally revealed value\n",
      "ofzand the prediction. Intermediate values of \u0015take into account di\u000b",
      "erently\n",
      "weighted di\u000b",
      "erences between future pairs of successive predictions.\n",
      "Only TD(1) can be considered a pure supervised learning procedure, sensitive\n",
      "to the \f",
      "nal value of zprovided by the teacher. For \u0015<1, we have various degrees\n",
      "of unsupervised learning, in which the prediction function strives to make each\n",
      "prediction more like successive ones (whatever they might be). We shall soon\n",
      "see that these unsupervised procedures result in better learning than do the\n",
      "supervised ones for an important class of problems.\n",
      "134 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "10.3 Incremental Computation of the (\u0001W)i\n",
      "We can rewrite our formula for (\u0001 W)i, namely\n",
      "(\u0001W)i=c@fi\n",
      "@WmX\n",
      "k=i\u0015(k\u0000i)(fk+1\u0000fk)\n",
      "to allow a type of incremental computation. First we write the expression for\n",
      "the weight change rule that takes into account all of the (\u0001 W)i:\n",
      "W \u0000W+mX\n",
      "i=1c@fi\n",
      "@WmX\n",
      "k=i\u0015(k\u0000i)(fk+1\u0000fk)\n",
      "Interchanging the order of the summations yields:\n",
      "W \u0000W+mX\n",
      "k=1ckX\n",
      "i=1\u0015(k\u0000i)(fk+1\u0000fk)@fi\n",
      "@W\n",
      "=W+mX\n",
      "k=1c(fk+1\u0000fk)kX\n",
      "i=1\u0015(k\u0000i)@fi\n",
      "@W\n",
      "Interchanging the indices kandi\f",
      "nally yields:\n",
      "W \u0000W+mX\n",
      "i=1c(fi+1\u0000fi)iX\n",
      "k=1\u0015(i\u0000k)@fk\n",
      "@W\n",
      "If, as earlier, we want to use an expression of the form W \u0000W+Pm\n",
      "i=1(\u0001W)i,\n",
      "we see that we can write:\n",
      "(\u0001W)i=c(fi+1\u0000fi)iX\n",
      "k=1\u0015(i\u0000k)@fk\n",
      "@W\n",
      "Now, if we let ei=Pi\n",
      "k=1\u0015(i\u0000k)@fk\n",
      "@W, we can develop a computationally e\u000ecient\n",
      "recurrence equation for ei+1as follows:\n",
      "ei+1=i+1X\n",
      "k=1\u0015(i+1\u0000k)@fk\n",
      "@W\n",
      "=@fi+1\n",
      "@W+iX\n",
      "k=1\u0015(i+1\u0000k)@fk\n",
      "@W\n",
      "10.4. AN EXPERIMENT WITH TD METHODS 135\n",
      "=@fi+1\n",
      "@W+\u0015ei\n",
      "Rewriting (\u0001 W)iin these terms, we obtain:\n",
      "(\u0001W)i=c(fi+1\u0000fi)ei\n",
      "where:\n",
      "e1=@f1\n",
      "@W\n",
      "e2=@f2\n",
      "@W+\u0015e1\n",
      "etc.\n",
      "Quoting Sutton [Sutton, 1988, page 15] (about a di\u000b",
      "erent equation, but the\n",
      "quote applies equally well to this one):\n",
      "\\:::this equation can be computed incrementally, because each\n",
      "(\u0001W)idepends only on a pair of successive predictions and on the\n",
      "[weighted] sum of all past values for@fi\n",
      "@W. This saves substantially on\n",
      "memory, because it is no longer necessary to individually remember\n",
      "all past values of@fi\n",
      "@W.\"\n",
      "10.4 An Experiment with TD Methods\n",
      "TD prediction methods [especially TD(0)] are well suited to situations in which\n",
      "the patterns are generated by a dynamic process. In that case, sequences of\n",
      "temporally presented patterns contain important information that is ignored\n",
      "by a conventional supervised method such as the Widrow-Ho\u000b",
      " rule. Sutton\n",
      "[Sutton, 1988, page 19] gives an interesting example involving a random walk,\n",
      "which we repeat here. In Fig. 10.1, sequences of vectors, X, are generated as\n",
      "follows: We start with vector XD; the next vector in the sequence is equally\n",
      "likely to be one of the adjacent vectors in the diagram. If the next vector is\n",
      "XC(orXE), the next one after that is equally likely to be one of the vectors\n",
      "adjacent to XC(orXE). When XBis in the sequence, it is equally likely that\n",
      "the sequence terminates with z= 0 or that the next vector is XC. Similarly,\n",
      "when XFis in the sequence, it is equally likely that the sequence terminates\n",
      "withz= 1 or that the next vector is XE. Thus the sequences are random, but\n",
      "they always start with XD. Some sample sequences are shown in the \f",
      "gure.\n",
      "136 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "1\n",
      "0\n",
      "0\n",
      "00\n",
      "0\n",
      "1\n",
      "0\n",
      "00\n",
      "0\n",
      "0\n",
      "1\n",
      "00\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "z = 0 z = 1XBXCXDXEXF\n",
      "Typical Sequences:\n",
      "XDXCXDXEXF  1\n",
      "XDXCXBXCXDXEXDXEXF  1\n",
      "XDXEXDXCXB  0\n",
      "Figure 10.1: A Markov Process\n",
      "This random walk is an example of a Markov process ; transitions from state i\n",
      "to statejoccur with probabilities that depend only on iandj.\n",
      "Given a set of sequences generated by this process as a training set, we want\n",
      "to be able to predict the value of zfor each Xin a test sequence. We assume\n",
      "that the learning system does not know the transition probabilities.\n",
      "For his experiments with this process, Sutton used a linear predictor, that\n",
      "isf(X;W) =X\u000fW. The learning problem is to \f",
      "nd a weight vector, W, that\n",
      "minimizes the mean-squared error between zand the predicted value of z. Given\n",
      "the \f",
      "ve di\u000b",
      "erent values that Xcan take on, we have the following predictions:\n",
      "f(XB) =w1,f(XC) =w2,f(XD) =w3,f(XE) =w4,f(XF) =w5, where\n",
      "wiis thei-th component of the weight vector. (Note that the values of the\n",
      "predictions are not limited to 1 or 0|even though zcan only have one of\n",
      "those values|because we are minimizing mean-squared error.) After training,\n",
      "these predictions will be compared with the optimal ones|given the transition\n",
      "probabilities.\n",
      "The experimental setup was as follows: ten random sequences were generated\n",
      "using the transition probabilities. Each of these sequences was presented in turn\n",
      "to a TD(\u0015) method for various values of \u0015. Weight vector increments, (\u0001 W)i,\n",
      "were computed after each pattern presentation but no weight changes were\n",
      "made until all ten sequences were presented. The weight vector increments were\n",
      "summed after all ten sequences were presented, and this sum was used to change\n",
      "the weight vector to be used for the next pass through the ten sequences. This\n",
      "process was repeated over and over (using the same training sequences) until\n",
      "(quoting Sutton) \\the procedure no longer produced any signi\f",
      "cant changes in\n",
      "the weight vector. For small c, the weight vector always converged in this way,\n",
      "10.4. AN EXPERIMENT WITH TD METHODS 137\n",
      "and always to the same \f",
      "nal value [for 100 di\u000b",
      "erent training sets of ten random\n",
      "sequences], independent of its initial value.\" (Even though, for \f",
      "xed, small c,\n",
      "the weight vector always converged to the same vector, it might converge to a\n",
      "somewhat di\u000b",
      "erent vector for di\u000b",
      "erent values of c.)\n",
      "After convergence, the predictions made by the \f",
      "nal weight vector are com-\n",
      "pared with the optimal predictions made using the transition probabilities.\n",
      "These optimal predictions are simply p(z= 1jX). We can compute these proba-\n",
      "bilities to be 1/6, 1/3, 1/2, 2/3, and 5/6 for XB,XC,XD,XE,XF, respectively.\n",
      "The root-mean-squared di\u000b",
      "erences between the best learned predictions (over\n",
      "allc) and these optimal ones are plotted in Fig. 10.2 for seven di\u000b",
      "erent values\n",
      "of\u0015. (For each data point, the standard error is approximately \u001b= 0:01.)\n",
      "0.100.120.140.160.180.20\n",
      "0.0 0.1 0.3 0.5 0.7 0.9 1.0\n",
      "hError using\n",
      "best c\n",
      "Widrow-Hoff\n",
      "TD(1)\n",
      "TD(0)\n",
      "(Adapted from Sutton, p. 20, 1988)\n",
      "Figure 10.2: Prediction Errors for TD( \u0015)\n",
      "Notice that the Widrow-Ho\u000b",
      " procedure does not perform as well as other\n",
      "versions of TD( \u0015) for\u0015<1! Quoting [Sutton, 1988, page 21]:\n",
      "\\This result contradicts conventional wisdom. It is well known that,\n",
      "under repeated presentations, the Widrow-Ho\u000b",
      " procedure minimizes\n",
      "the RMS error between its predictions and the actual outcomes in\n",
      "the training set ([Widrow & Stearns, 1985]). How can it be that this\n",
      "optimal method peformed worse than all the TD methods for \u0015 <\n",
      "1? The answer is that the Widrow-Ho\u000b",
      " procedure only minimizes\n",
      "error on the training set ; it does not necessarily minimize error for\n",
      "future experience. [Later] we prove that in fact it is linear TD(0)\n",
      "that converges to what can be considered the optimal estimates for\n",
      "138 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "matching future experience|those consistent with the maximum-\n",
      "likelihood estimate of the underlying Markov process.\"\n",
      "10.5 Theoretical Results\n",
      "It is possible to analyze the performance of the linear-prediction TD( \u0015) methods\n",
      "on Markov processes. We state some theorems here without proof.\n",
      "Theorem 10.1 (Sutton, page 24, 1988) For any absorbing Markov chain,\n",
      "and for any linearly independent set of observation vectors fXigfor the non-\n",
      "terminal states, there exists an \">0such that for all positive c<\" and for any\n",
      "initial weight vector, the predictions of linear TD(0) (with weight updates after\n",
      "each sequence) converge in expected value to the optimal (maximum likelihood)\n",
      "predictions of the true process.\n",
      "Even though the expected values of the predictions converge, the predictions\n",
      "themselves do not converge but vary around their expected values depending on\n",
      "their most recent experience. Sutton conjectures that if cis made to approach\n",
      "0 as training progresses, the variance of the predictions will approach 0 also.\n",
      "Dayan [Dayan, 1992] has extended the result of Theorem 9.1 to TD( \u0015) for\n",
      "arbitrary\u0015between 0 and 1. (Also see [Dayan & Sejnowski, 1994].)\n",
      "10.6 Intra-Sequence Weight Updating\n",
      "Our standard weight updating rule for TD( \u0015) methods is:\n",
      "W \u0000W+mX\n",
      "i=1c(fi+1\u0000fi)iX\n",
      "k=1\u0015(i\u0000k)@fk\n",
      "@W\n",
      "where the weight update occurs after an entire sequence is observed. To make\n",
      "the method truly incremental (in analogy with weight updating rules for neural\n",
      "nets), it would be desirable to change the weight vector after every pattern\n",
      "presentation. The obvious extension is:\n",
      "Wi+1 \u0000Wi+c(fi+1\u0000fi)iX\n",
      "k=1\u0015(i\u0000k)@fk\n",
      "@W\n",
      "wherefi+1is computed before making the weight change; that is, fi+1=\n",
      "f(Xi+1;Wi). But that would make fi=f(Xi;Wi\u00001), and such a rule would\n",
      "make the prediction di\u000b",
      "erence, namely ( fi+1\u0000fi), sensitive both to changes in\n",
      "Xand changes in Wand could lead to instabilities. Instead, we modify the rule\n",
      "so that, for every pair of predictions, fi+1=f(Xi+1;Wi) andfi=f(Xi;Wi).\n",
      "This version of the rule has been used in practice with excellent results.\n",
      "10.6. INTRA-SEQUENCE WEIGHT UPDATING 139\n",
      "For TD(0) and linear predictors, the rule is:\n",
      "Wi+1=Wi+c(fi+1\u0000fi)Xi\n",
      "The rule is implemented as follows:\n",
      "a. Initialize the weight vector, W, arbitrarily.\n",
      "b. Fori= 1;:::;m ,do:\n",
      "(a)fi \u0000Xi\u000fW\n",
      "(We compute fianew each time through rather than use the value\n",
      "offi+1the previous time through.)\n",
      "(b)fi+1 \u0000Xi+1\u000fW\n",
      "(c)di+1 \u0000fi+1\u0000fi\n",
      "(d)W \u0000W+c di+1Xi\n",
      "(Iffiwere computed again with this changed weight vector, its value\n",
      "would be closer to fi+1as desired.)\n",
      "The linear TD(0) method can be regarded as a technique for training a\n",
      "very simple network consisting of a single dot product unit (and no threshold\n",
      "or sigmoid function). TD methods can also be used in combination with back-\n",
      "propagation to train neural networks. For TD(0) we change the network weights\n",
      "according to the expression:\n",
      "Wi+1=Wi+c(fi+1\u0000fi)@fi\n",
      "@W\n",
      "The only change that must be made to the standard backpropagation weight-\n",
      "changing rule is that the di\u000b",
      "erence term between the desired output and the\n",
      "output of the unit in the \f",
      "nal ( k-th) layer, namely ( d\u0000f(k)), must be replaced\n",
      "by a di\u000b",
      "erence term between successive outputs, ( fi+1\u0000fi). This change has a\n",
      "direct e\u000b",
      "ect only on the expression for \u000e(k)which becomes:\n",
      "\u000e(k)= 2(f0(k)\u0000f(k))f(k)(1\u0000f(k))\n",
      "wheref0(k)andf(k)are two successive outputs of the network.\n",
      "The weight changing rule for the i-th weight vector in the j-th layer of weights\n",
      "has the same form as before, namely:\n",
      "W(j)\n",
      "i \u0000W(j)\n",
      "i+c\u000e(j)\n",
      "iX(j\u00001)\n",
      "where the\u000e(j)\n",
      "iare given recursively by:\n",
      "\u000e(j)\n",
      "i=f(j)\n",
      "i(1\u0000f(j)\n",
      "i)mj+1X\n",
      "l=1\u000e(j+1)\n",
      "lw(j+1)\n",
      "il\n",
      "andw(j+1)\n",
      "ilis thel-th component of the i-th weight vector in the ( j+1)-th layer\n",
      "of weights. Of course, here also it is assumed that f0(k)andf(k)are computed\n",
      "using the same weights and then the weights are changed. In the next section\n",
      "we shall see an interesting example of this application of TD learning.\n",
      "140 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "10.7 An Example Application: TD-gammon\n",
      "A program called TD-gammon [Tesauro, 1992] learns to play backgammon by\n",
      "training a neural network via temporal-di\u000b",
      "erence methods. The structure of\n",
      "the neural net, and its coding is as shown in Fig. 10.3. The network is trained\n",
      "to minimize the error between actual payo\u000b",
      " and estimated payo\u000b",
      ", where the\n",
      "actual payo\u000b",
      " is de\f",
      "ned to be df=p1+ 2p2\u0000p3\u00002p4, and thepiare the actual\n",
      "probabilities of the various outcomes as de\f",
      "ned in the \f",
      "gure.\n",
      ". . .p3 = pr(black wins)\n",
      "p4 = pr(black gammons)p1 = pr(white wins)\n",
      "p2 = pr(white gammons)estimated payoff:\n",
      "d = p1 + 2p2 < p3 < 2p4\n",
      "no. of white\n",
      "on cell 1\n",
      "no. on bar,\n",
      "off board,\n",
      "and who\n",
      "moves\n",
      "198 inputs1\n",
      "2\n",
      "3\n",
      "# > 3\n",
      ". . .\n",
      "up to 40 hidden units2 x 24\n",
      "cells\n",
      "4 output units\n",
      "hidden and output units are sigmoids\n",
      "learning rate:  c = 0.1; initial weights chosen\n",
      "randomly between <0.5 and +0.5.estimated probabilities:\n",
      "Figure 10.3: The TD-gammon Network\n",
      "TD-gammon learned by using the network to select that move that results\n",
      "in the best predicted payo\u000b",
      ". That is, at any stage of the game some \f",
      "nite set of\n",
      "moves is possible and these lead to the set, fXg, of new board positions. Each\n",
      "member of this set is evaluated by the network, and the one with the largest\n",
      "10.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 141\n",
      "predicted payo\u000b",
      " is selected if it is white's move (and the smallest if it is black's).\n",
      "The move is made, and the network weights are adjusted to make the predicted\n",
      "payo\u000b",
      " from the original position closer to that of the resulting position.\n",
      "The weight adjustment procedure combines temporal-di\u000b",
      "erence (TD( \u0015))\n",
      "learning with backpropagation. If dtis the network's estimate of the payo\u000b",
      "\n",
      "at timet(before a move is made), and dt+1is the estimate at time t+ 1 (after\n",
      "a move is made), the weight adjustment rule is:\n",
      "\u0001Wt=c(dt+1\u0000dt)tX\n",
      "k=1\u0015t\u0000k@dk\n",
      "@W\n",
      "where Wtis a vector of allweights in the network at time t, and@dk\n",
      "@Wis the\n",
      "gradient of dkin this weight space. (For a layered, feedforward network, such\n",
      "as that of TD-gammon, the weight changes for the weight vectors in each layer\n",
      "can be expressed in the usual manner.)\n",
      "To make the special cases clear, recall that for TD(0), the network would be\n",
      "trained so that, for all t, its output, dt, for input Xttended toward its expected\n",
      "output,dt+1, for input Xt+1. For TD(1), the network would be trained so that,\n",
      "for allt, its output, dt, for input Xttended toward the expected \f",
      "nal payo\u000b",
      ",\n",
      "df, given that input. The latter case is the same as the Widrow-Ho\u000b",
      " rule.\n",
      "After about 200,000 games the following results were obtained. TD-gammon\n",
      "(with 40 hidden units, \u0015= 0:7, andc= 0:1) won 66.2% of 10,000 games against\n",
      "SUN Microsystems Gammontool and 55% of 10,000 games against a neural\n",
      "network trained using expert moves. Commenting on a later version of TD-\n",
      "gammon, incorporating special features as inputs, Tesauro said: \\It appears to\n",
      "be the strongest program ever seen by this author.\"\n",
      "10.8 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "142 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "Chapter 11\n",
      "Delayed-Reinforcement\n",
      "Learning\n",
      "11.1 The General Problem\n",
      "Imagine a robot that exists in an environment in which it can sense and act.\n",
      "Suppose (as an extreme case) that it has no idea about the e\u000b",
      "ects of its actions.\n",
      "That is, it doesn't know how acting will change its sensory inputs. Along with\n",
      "its sensory inputs are \\rewards,\" which it occasionally receives. How should it\n",
      "choose its actions so as to maximize its rewards over the long run? To maximize\n",
      "rewards, it will need to be able to predict how actions change inputs, and in\n",
      "particular, how actions lead to rewards.\n",
      "We formalize the problem in the following way: The robot exists in an\n",
      "environment consisting of a set, S, of states. We assume that the robot's sensory\n",
      "apparatus constructs an input vector, X, from the environment, which informs\n",
      "the robot about which state the environment is in. For the moment, we will\n",
      "assume that the mapping from states to vectors is one-to-one, and, in fact, will\n",
      "use the notation Xto refer to the state of the environment as well as to the\n",
      "input vector. When presented with an input vector, the robot decides which\n",
      "action from a set, A, of actions to perform. Performing the action produces an\n",
      "e\u000b",
      "ect on the environment|moving it to a new state. The new state results in\n",
      "the robot perceiving a new input vector, and the cycle repeats. We assume a\n",
      "discrete time model; the input vector at time t=iisXi, the action taken at\n",
      "that time is ai, and the expected reward, ri, received at t=idepends on the\n",
      "action taken and on the state, that is ri=r(Xi;ai). The learner's goal is to \f",
      "nd\n",
      "apolicy ,\u0019(X), that maps input vectors to actions in such a way that maximizes\n",
      "rewards accumulated over time. This type of learning is called reinforcement\n",
      "learning . The learner must \f",
      "nd the policy by trial and error; it has no initial\n",
      "knowledge of the e\u000b",
      "ects of its actions. The situation is as shown in Fig. 11.1.\n",
      "143\n",
      "144 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Xi\n",
      "riLearner\n",
      "Environment(reward)(state)\n",
      "(action)\n",
      "ai\n",
      "Figure 11.1: Reinforcement Learning\n",
      "11.2 An Example\n",
      "A \\grid world,\" such as the one shown in Fig. 11.2 is often used to illustrate\n",
      "reinforcement learning. Imagine a robot initially in cell (2,3). The robot receives\n",
      "input vector ( x1;x2) telling it what cell it is in; it is capable of four actions,\n",
      "n;e;s;w moving the robot one cell up, right, down, or left, respectively. It is\n",
      "rewarded one negative unit whenever it bumps into the wall or into the blocked\n",
      "cells. For example, if the input to the robot is (1,3), and the robot chooses\n",
      "actionw, the next input to the robot is still (1,3) and it receives a reward of\n",
      "\u00001. If the robot lands in the cell marked G(for goal), it receives a reward of\n",
      "+10. Let's suppose that whenever the robot lands in the goal cell and gets its\n",
      "reward, it is immediately transported out to some random cell, and the quest\n",
      "for reward continues.\n",
      "Apolicy for our robot is a speci\f",
      "cation of what action to take for every one\n",
      "of its inputs, that is, for every one of the cells in the grid. For example, a com-\n",
      "ponent of such a policy would be \\when in cell (3,1), move right.\" An optimal\n",
      "policy is a policy that maximizes long-term reward. One way of displaying a\n",
      "policy for our grid-world robot is by an arrow in each cell indicating the direc-\n",
      "tion the robot should move when in that cell. In Fig. 11.3, we show an optimal\n",
      "policy displayed in this manner. In this chapter we will describe methods for\n",
      "learning optimal policies based on reward values received by the learner.\n",
      "11.3. TEMPORAL DISCOUNTING AND OPTIMAL POLICIES 145\n",
      "RG\n",
      "12345 6712345678\n",
      "Figure 11.2: A Grid World\n",
      "11.3 Temporal Discounting and Optimal Poli-\n",
      "cies\n",
      "In delayed reinforcement learning, one often assumes that rewards in the distant\n",
      "future are not as valuable as are more immediate rewards. This preference can\n",
      "be accomodated by a temporal discount factor , 0\u0014\r",
      " <1. The present value of\n",
      "a reward,ri, occuringitime units in the future, is taken to be \r",
      "iri. Suppose\n",
      "we have a policy \u0019(X) that maps input vectors into actions, and let r\u0019(X)\n",
      "i be\n",
      "the reward that will be received on the i-th time step after one begins executing\n",
      "policy\u0019starting in state X. Then the total reward accumulated over all time\n",
      "steps by policy \u0019beginning in state Xis:\n",
      "V\u0019(X) =1X\n",
      "i=0\r",
      "ir\u0019(X)\n",
      "i\n",
      "One reason for using a temporal discount factor is so that the above sum will\n",
      "be \f",
      "nite. An optimal policy is one that maximizes V\u0019(X) for all inputs, X.\n",
      "In general, we want to consider the case in which the rewards, ri, are random\n",
      "variables and in which the e\u000b",
      "ects of actions on environmental states are random.\n",
      "In Markovian environments, for example, the probability that action ain state\n",
      "Xiwill lead to state Xjis given by a transition probability p[XjjXi;a]. Then,\n",
      "we will want to maximize expected future reward and would de\f",
      "ne V\u0019(X) as:\n",
      "V\u0019(X) =E\"1X\n",
      "i=0\r",
      "ir\u0019(X)\n",
      "i#\n",
      "In either case, we call V\u0019(X) the value of policy\u0019for input X.\n",
      "146 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "RG\n",
      "12345 6712345678\n",
      "Figure 11.3: An Optimal Policy in the Grid World\n",
      "If the action prescribed by \u0019taken in state Xleads to state X0(randomly\n",
      "according to the transition probabilities), then we can write V\u0019(X) in terms of\n",
      "V\u0019(X0) as follows:\n",
      "V\u0019(X) =r[X;\u0019(X)] +\r",
      "X\n",
      "X0p[X0jX;\u0019(X)]V\u0019(X0)\n",
      "where (in summary):\n",
      "\r",
      "= the discount factor,\n",
      "V\u0019(X) = the value of state Xunder policy \u0019,\n",
      "r[X;\u0019(X)] = the expected immediate reward received when we execute the\n",
      "action prescribed by \u0019in state X, and\n",
      "p[X0jX;\u0019(X)] = the probability that the environment transitions to state\n",
      "X0when we execute the action prescribed by \u0019in state X.\n",
      "In other words, the value of state Xunder policy \u0019is the expected value of\n",
      "the immediate reward received when executing the action recommended by \u0019\n",
      "plus the average value (under \u0019) of all of the states accessible from X.\n",
      "For an optimal policy, \u0019\u0003(and no others!), we have the famous \\optimality\n",
      "equation:\"\n",
      "V\u0019\u0003(X) = max\n",
      "a\"\n",
      "r(X;a) +\r",
      "X\n",
      "X0p[X0jX;a]V\u0019\u0003(X0)#\n",
      "The theory of dynamic programming (DP) [Bellman, 1957, Ross, 1983] assures\n",
      "us that there is at least one optimal policy, \u0019\u0003, that satis\f",
      "es this equation. DP\n",
      "11.4.Q-LEARNING 147\n",
      "also provides methods for calculating V\u0019\u0003(X) and at least one \u0019\u0003, assuming\n",
      "that we know the average rewards and the transition probabilities. If we knew\n",
      "the transition probabilities, the average rewards, and V\u0019\u0003(X) for all Xanda,\n",
      "then it would be easy to implement an optimal policy. We would simply select\n",
      "thatathat maximizes r(X;a) +\r",
      "P\n",
      "X0p[X0jX;a]V\u0019\u0003(X0). That is,\n",
      "\u0019\u0003(X) = arg max\n",
      "a\"\n",
      "r(X;a) +\r",
      "X\n",
      "X0p[X0jX;a]V\u0019\u0003(X0)#\n",
      "But, of course, we are assuming that we do not know these average rewards nor\n",
      "the transition probabilities, so we have to \f",
      "nd a method that e\u000b",
      "ectively learns\n",
      "them.\n",
      "If we had a model of actions, that is, if we knew for every state, X, and\n",
      "actiona, which state, X0resulted, then we could use a method called value\n",
      "iteration to \f",
      "nd an optimal policy. Value iteration works as follows: We begin\n",
      "by assigning, randomly, an estimated value ^V(X) to every state, X. On thei-th\n",
      "step of the process, suppose we are at state Xi(that is, our input on the i-th\n",
      "step is Xi), and that the estimated value of state Xion thei-th step is ^Vi(Xi).\n",
      "We then select that action athat maximizes the estimated value of the predicted\n",
      "subsequent state. Suppose this subsequent state having the highest estimated\n",
      "value is X0\n",
      "i. Then we update the estimated value, ^Vi(Xi), of state Xias follows:\n",
      "^Vi(X) = (1\u0000ci)^Vi\u00001(X) +cih\n",
      "ri+\r",
      "^Vi\u00001(X0\n",
      "i)i\n",
      "ifX=Xi,\n",
      "=^Vi\u00001(X)\n",
      "otherwise.\n",
      "We see that this adjustment moves the value of ^Vi(Xi) an increment (depend-\n",
      "ing onci) closer toh\n",
      "ri+\r",
      "^Vi(X0\n",
      "i)i\n",
      ". Assuming that ^Vi(X0\n",
      "i) is a good estimate for\n",
      "Vi(X0\n",
      "i), then this adjustment helps to make the two estimates more consistent.\n",
      "Providing that 0 < ci<1 and that we visit each state in\f",
      "nitely often, this\n",
      "process of value iteration will converge to the optimal values. Discuss synchronous dynamic\n",
      "programming, asynchronous\n",
      "dynamic programming, and policy\n",
      "iteration.\n",
      "11.4 Q-Learning\n",
      "Watkins [Watkins, 1989] has proposed a technique that he calls incremental\n",
      "dynamic programming . Leta;\u0019stand for the policy that chooses action aonce,\n",
      "and thereafter chooses actions according to policy \u0019. We de\f",
      "ne:\n",
      "Q\u0019(X;a) =Va;\u0019(X)\n",
      "148 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Then the optimal value from state Xis given by:\n",
      "V\u0019\u0003(X) = max\n",
      "aQ\u0019\u0003(X;a)\n",
      "This equation holds only for an optimal policy, \u0019\u0003. The optimal policy is given\n",
      "by:\n",
      "\u0019\u0003(X) = arg max\n",
      "aQ\u0019\u0003(X;a)\n",
      "Note that if an action amakesQ\u0019(X;a) larger than V\u0019(X), then we can improve\n",
      "\u0019by changing it so that \u0019(X) =a. Making such a change is the basis for a\n",
      "powerful learning rule that we shall describe shortly.\n",
      "Suppose action ain state Xleads to state X0. Then using the de\f",
      "nitions of\n",
      "QandV, it is easy to show that:\n",
      "Q\u0019(X;a) =r(X;a) +\r",
      "E[V\u0019(X0)]\n",
      "wherer(X;a) is the average value of the immediate reward received when we\n",
      "execute action ain state X. For an optimal policy (and no others), we have\n",
      "another version of the optimality equation in terms of Qvalues:\n",
      "Q\u0019\u0003(X;a) = max\n",
      "ah\n",
      "r(X;a) +\r",
      "Eh\n",
      "Q\u0019\u0003(X0;a)ii\n",
      "for all actions, a, and states, X. Now, if we had the optimal Qvalues (for all\n",
      "aandX), then we could implement an optimal policy simply by selecting that\n",
      "action that maximized r(X;a) +\r",
      "E\u0002\n",
      "Q\u0019\u0003(X0;a)\u0003\n",
      ".\n",
      "That is,\n",
      "\u0019\u0003(X) = arg max\n",
      "ah\n",
      "r(X;a) +\r",
      "Eh\n",
      "Q\u0019\u0003(X0;a)ii\n",
      "Watkins' proposal amounts to a TD(0) method of learning the Qvalues.\n",
      "We quote (with minor notational changes) from [Watkins & Dayan, 1992, page\n",
      "281]:\n",
      "\\InQ-Learning, the agent's experience consists of a sequence of dis-\n",
      "tinct stages or episodes . In thei-th episode, the agent:\n",
      "\u000fobserves its current state Xi,\n",
      "\u000fselects [using the method described below] and performs an\n",
      "actionai,\n",
      "\u000fobserves the subsequent state X0\n",
      "i,\n",
      "\u000freceives an immediate reward ri, and\n",
      "11.4.Q-LEARNING 149\n",
      "\u000fadjusts itsQi\u00001values using a learning factor ci, according to:\n",
      "Qi(X;a) = (1\u0000ci)Qi\u00001(X;a) +ci[ri+\r",
      "Vi\u00001(X0\n",
      "i)]\n",
      "ifX=Xianda=ai,\n",
      "=Qi\u00001(X;a)\n",
      "otherwise,\n",
      "where\n",
      "Vi\u00001(X0) = max\n",
      "b[Qi\u00001(X0;b)]\n",
      "is the best the agent thinks it can do from state X0.:::The\n",
      "initialQvalues,Q0(X;a), for all states and actions are assumed\n",
      "given.\"\n",
      "Using the current Qvalues,Qi(X;a), the agent always selects that action\n",
      "that maximizes Qi(X;a). Note that only the Qvalue corresponding to the\n",
      "state just exited and the action just taken is adjusted. And that Qvalue is\n",
      "adjusted so that it is closer (by an amount determined by ci) to the sum of\n",
      "the immediate reward plus the discounted maximum (over all actions) of the Q\n",
      "values of the state just entered. If we imagine the Qvalues to be predictions of\n",
      "ultimate (in\f",
      "nite horizon) total reward, then the learning procedure described\n",
      "above is exactly a TD(0) method of learning how to predict these Qvalues.\n",
      "Qlearning strengthens the usual TD methods, however, because TD (applied\n",
      "to reinforcement problems using value iteration) requires a one-step lookahead,\n",
      "using a model of the e\u000b",
      "ects of actions, whereas Qlearning does not.\n",
      "A convenient notation (proposed by [Schwartz, 1993]) for representing the\n",
      "change inQvalue is:\n",
      "Q(X;a)\f",
      " \u0000r+\r",
      "V(X0)\n",
      "whereQ(X;a) is the new Qvalue for input Xand action a,ris the immediate\n",
      "reward when action ais taken in response to input X,V(X0) is the maximum\n",
      "(over all actions) of the Qvalue of the state next reached when action ais taken\n",
      "from state X, and\f",
      "is the fraction of the way toward which the new Qvalue,\n",
      "Q(X;a), is adjusted to equal r+\r",
      "V(X0).\n",
      "Watkins and Dayan [Watkins & Dayan, 1992] prove that, under certain con-\n",
      "ditions, the Qvalues computed by this learning procedure converge to optimal\n",
      "ones (that is, to ones on which an optimal policy can be based).\n",
      "We de\f",
      "neni(X;a) as the index (episode number) of the i-th time that action\n",
      "ais tried in state X. Then, we have:\n",
      "150 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Theorem 11.1 (Watkins and Dayan) For Markov problems with states fXg\n",
      "and actionsfag, and given bounded rewards jrnj\u0014R, learning rates 0\u0014cn<1,\n",
      "and\n",
      "1X\n",
      "i=0cni(X;a)=1;1X\n",
      "i=0\u0002\n",
      "cni(X;a)\u00032<1\n",
      "for all Xanda, then\n",
      "Qn(X;a)!Q\u0003\n",
      "n(X;a)asn!1 , for all Xanda, with probability 1, where\n",
      "Q\u0003\n",
      "n(X;a)corresponds to the Qvalues of an optimal policy.\n",
      "Again, we quote from [Watkins & Dayan, 1992, page 281]:\n",
      "\\The most important condition implicit in the convergence theorem\n",
      ":::is that the sequence of episodes that forms the basis of learning\n",
      "must include an in\f",
      "nite number of episodes for each starting state\n",
      "and action. This may be considered a strong condition on the way\n",
      "states and actions are selected|however, under the stochastic con-\n",
      "ditions of the theorem, no method could be guaranteed to \f",
      "nd an\n",
      "optimal policy under weaker conditions. Note, however, that the\n",
      "episodes need not form a continuous sequence|that is the X0of one\n",
      "episode need not be the Xof the next episode.\"\n",
      "The relationships among Qlearning, dynamic programming, and control\n",
      "are very well described in [Barto, Bradtke, & Singh, 1994]. Qlearning is best\n",
      "thought of as a stochastic approximation method for calculating the Qvalues.\n",
      "Although the de\f",
      "nition of the optimal Qvalues for any state depends recursively\n",
      "on expected values of the Qvalues for subsequent states (and on the expected\n",
      "values of rewards), no expected values are explicitly computed by the procedure.\n",
      "Instead, these values are approximated by iterative sampling using the actual\n",
      "stochastic mechanism that produces successor states.\n",
      "11.5 Discussion, Limitations, and Extensions of\n",
      "Q-Learning\n",
      "11.5.1 An Illustrative Example\n",
      "The Q-learning procedure requires that we maintain a table of Q(X;a) values\n",
      "for all state-action pairs. In the grid world that we described earlier, such a\n",
      "table would not be excessively large. We might start with random entries in the\n",
      "table; a portion of such an intial table might be as follows:\n",
      "11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING 151\n",
      "XaQ(X;a)r(X;a)\n",
      "(2,3)w 7 0\n",
      "(2,3)n 4 0\n",
      "(2,3)e 3 0\n",
      "(2,3)s 6 0\n",
      "(1,3)w 4 -1\n",
      "(1,3)n 5 0\n",
      "(1,3)e 2 0\n",
      "(1,3)s 4 0\n",
      "Suppose the robot is in cell (2,3). The maximum Qvalue occurs for a=w, so the\n",
      "robot moves west to cell (1,3)|receiving no immediate reward. The maximum\n",
      "Qvalue in cell (1,3) is 5, and the learning mechanism attempts to make the\n",
      "value ofQ((2;3);w) closer to the discounted value of 5 plus the immediate\n",
      "reward (which was 0 in this case). With a learning rate parameter c= 0:5\n",
      "and\r",
      "= 0:9, theQvalue ofQ((2;3);w) is adjusted from 7 to 5.75. No other\n",
      "changes are made to the table at this episode. The reader might try this learning\n",
      "procedure on the grid world with a simple computer program. Notice that an\n",
      "optimal policy might not be discovered if some cells are not visited nor some\n",
      "actions not tried frequently enough.\n",
      "The learning problem faced by the agent is to associate speci\f",
      "c actions with\n",
      "speci\f",
      "c input patterns. Qlearning gradually reinforces those actions that con-\n",
      "tribute to positive rewards by increasing the associated Qvalues. Typically, as\n",
      "in this example, rewards occur somewhat after the actions that lead to them|\n",
      "hence the phrase delayed-reinforcement learning. One can imagine that better\n",
      "and better approximations to the optimal Qvalues gradually propagate back\n",
      "from states producing rewards toward all of the other states that the agent fre-\n",
      "quently visits. With random Qvalues to begin, the agent's actions amount to a\n",
      "random walk through its space of states. Only when this random walk happens\n",
      "to stumble into rewarding states does Qlearning begin to produce Qvalues\n",
      "that are useful, and, even then, the Qvalues have to work their way outward\n",
      "from these rewarding states. The general problem of associating rewards with\n",
      "state-action pairs is called the temporal credit assignment problem |how should\n",
      "credit for a reward be apportioned to the actions leading up to it? Qlearning is,\n",
      "to date, the most successful technique for temporal credit assignment, although\n",
      "a related method, called the bucket brigade algorithm , has been proposed by\n",
      "[Holland, 1986].\n",
      "Learning problems similar to that faced by the agent in our grid world have\n",
      "been thoroughly studied by Sutton who has proposed an architecture, called\n",
      "DYNA, for solving them [Sutton, 1990]. DYNA combines reinforcement learning\n",
      "with planning. Sutton characterizes planning as learning in a simulated world\n",
      "that models the world that the agent inhabits. The agent's model of the world\n",
      "is obtained by Qlearning in its actual world, and planning is accomplished by\n",
      "Qlearning in its model of the world.\n",
      "We should note that the learning problem faced by our grid-world robot\n",
      "152 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "could be modi\f",
      "ed to have several places in the grid that give positive rewards.\n",
      "This possibility presents an interesting way to generalize the classical notion of\n",
      "a \\goal\" in AI planning systems|even in those that do no learning. Instead of\n",
      "representing a goal as a condition to be achieved, we represent a \\goal struc-\n",
      "ture\" as a set of rewards to be given for achieving various conditions. Then,\n",
      "the generalized \\goal\" becomes maximizing discounted future reward instead of\n",
      "simply achieving some particular condition. This generalization can be made to\n",
      "encompass so-called goals of maintenance and goals of avoidance . The exam-\n",
      "ple presented above included avoiding bumping into the grid-world boundary.\n",
      "A goal of maintenance, of a particular state, could be expressed in terms of a\n",
      "reward that was earned whenever the agent was in that state and performed an\n",
      "action that transitioned back to that state in one step.\n",
      "11.5.2 Using Random Actions\n",
      "When the next pattern presentation in a sequence of patterns is the one caused\n",
      "by the agent's own action in response to the last pattern, we have what is called\n",
      "anon-line learning method. In Watkins and Dayan's terminology, in on-line\n",
      "learning the episodes form a continous sequence. As already mentioned, the\n",
      "convergence theorem for Qlearning does not require on-line learning; indeed,\n",
      "special precautions must be taken to ensure that on-line learning meets the\n",
      "conditions of the theorem. If on-line learning discovers some good paths to\n",
      "rewards, the agent may \f",
      "xate on these and never discover a policy that leads\n",
      "to a possibly greater long-term reward. In reinforcement learning phraseology,\n",
      "this problem is referred to as the problem of exploitation (of already learned\n",
      "behavior) versus exploration (of possibly better behavior).\n",
      "One way to force exploration is to perform occasional random actions (in-\n",
      "stead of that single action prescribed by the current Qvalues). For example,\n",
      "in the grid-world problem, one could imagine selecting an action randomly ac-\n",
      "cording to a probability distribution over the actions ( n;e;s; andw). This\n",
      "distribution, in turn, could depend on the Qvalues. For example, we might\n",
      "\f",
      "rst \f",
      "nd that action prescribed by the Qvalues and then choose that action\n",
      "with probability 1/2, choose the two orthogonal actions with probability 3/16\n",
      "each, and choose the opposite action with probability 1/8. This policy might be\n",
      "modi\f",
      "ed by \\simulated annealing\" which would gradually increase the probabil-\n",
      "ity of the action prescribed by the Qvalues more and more as time goes on. This\n",
      "strategy would favor exploration at the beginning of learning and exploitation\n",
      "later.\n",
      "Other methods, also, have been proposed for dealing with exploration, in-\n",
      "cluding making unvisited states intrinsically rewarding and using an \\interval\n",
      "estimate,\" which is related to the uncertainty in the estimate of a state's value\n",
      "[Kaelbling, 1993].\n",
      "11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING 153\n",
      "11.5.3 Generalizing Over Inputs\n",
      "For large problems it would be impractical to maintain a table like that used\n",
      "in our grid-world example. Various researchers have suggested mechanisms for\n",
      "computing Qvalues, given pattern inputs and actions. One method that sug-\n",
      "gests itself is to use a neural network. For example, consider the simple linear\n",
      "machine shown in Fig. 11.4.\n",
      "X. . .\n",
      ". . .Y\n",
      "Y\n",
      "Ytrainable weights\n",
      "Y\n",
      "Wi\n",
      "R dot product unitsQ(ai, X) = X . WiQ(a1, X)\n",
      "Q(a2, X)\n",
      "Q(aR, X)\n",
      "Figure 11.4: A Net that Computes QValues\n",
      "Such a neural net could be used by an agent that has Ractions to select\n",
      "from. TheQvalues (as a function of the input pattern Xand the action ai) are\n",
      "computed as dot products of weight vectors (one for each action) and the input\n",
      "vector. Weight adjustments are made according to a TD(0) procedure to bring\n",
      "theQvalue for the action last selected closer to the sum of the immediate reward\n",
      "(if any) and the (discounted) maximum Qvalue for the next input pattern.\n",
      "If the optimum Qvalues for the problem (whatever they might be) are more\n",
      "complex than those that can be computed by a linear machine, a layered neural\n",
      "network might be used. Sigmoid units in the \f",
      "nal layer would compute Qvalues\n",
      "in the range 0 to 1. The TD(0) method for updating Qvalues would then have to\n",
      "be combined with a multi-layer weight-changing rule, such as backpropagation.\n",
      "Networks of this sort are able to aggregate di\u000b",
      "erent input vectors into regions\n",
      "for which the same action should be performed. This kind of aggregation is an\n",
      "example of what has been called structural credit assignment . Combining TD( \u0015)\n",
      "and backpropagation is a method for dealing with both the temporal and the\n",
      "structural credit assignment problems.\n",
      "154 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Interesting examples of delayed-reinforcement training of simulated and\n",
      "actual robots requiring structural credit assignment have been reported by\n",
      "[Lin, 1992, Mahadevan & Connell, 1992].\n",
      "11.5.4 Partially Observable States\n",
      "So far, we have identi\f",
      "ed the input vector, X, with the actual state of the envi-\n",
      "ronment. When the input vector results from an agent's perceptual apparatus\n",
      "(as we assume it does), there is no reason to suppose that it uniquely identi\f",
      "es\n",
      "the environmental state. Because of inevitable perceptual limitations, several\n",
      "di\u000b",
      "erent environmental states might give rise to the same input vector. This\n",
      "phenomenon has been referred to as perceptual aliasing . With perceptual alias-\n",
      "ing, we can no longer guarantee that Qlearning will result in even useful action\n",
      "policies, let alone optimal ones. Several researchers have attempted to deal with\n",
      "this problem using a variety of methods including attempting to model \\hid-\n",
      "den\" states by using internal memory [Lin, 1993]. That is, if some aspect of\n",
      "the environment cannot be sensed currently, perhaps it was sensed once and\n",
      "can be remembered by the agent. When such is the case, we no longer have a\n",
      "Markov problem; that is, the next Xvector, given any action, may depend on\n",
      "a sequence of previous ones rather than just the immediately preceding one. It\n",
      "might be possible to reinstate a Markov framework (over the X's) ifXincludes\n",
      "not only current sensory precepts but information from the agent's memory.\n",
      "11.5.5 Scaling Problems\n",
      "Several di\u000eculties have so far prohibited wide application of reinforcement learn-\n",
      "ing to large problems. (The TD-gammon program, mentioned in the last chap-\n",
      "ter, is probably unique in terms of success on a high-dimensional problem.)\n",
      "We have already touched on some di\u000eculties; these and others are summarized\n",
      "below with references to attempts to overcome them.\n",
      "a. Exploration versus exploitation.\n",
      "\u000fuse random actions\n",
      "\u000ffavor states not visited recently\n",
      "\u000fseparate the learning phase from the use phase\n",
      "\u000femploy a teacher to guide exploration\n",
      "b. Slow time to convergence\n",
      "\u000fcombine learning with prior knowledge; use estimates of Qvalues\n",
      "(rather than random values) initially\n",
      "\u000fuse a hierarchy of actions; learn primitive actions \f",
      "rst and freeze the\n",
      "useful sequences into macros and then learn how to use the macros\n",
      "11.6. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 155\n",
      "\u000femploy a teacher; use graded \\lessons\"|starting near the rewards\n",
      "and then backing away, and use examples of good behavior [Lin, 1992]\n",
      "\u000fuse more e\u000ecient computations; e.g.do several updates per episode\n",
      "[Moore & Atkeson, 1993]\n",
      "c. Large state spaces\n",
      "\u000fuse hand-coded features\n",
      "\u000fuse neural networks\n",
      "\u000fuse nearest-neighbor methods [Moore, 1990]\n",
      "d. Temporal discounting problems. Using small \r",
      "can make the learner too\n",
      "greedy for present rewards and indi\u000b",
      "erent to the future; but using large \r\n",
      "slows down learning.\n",
      "\u000fuse a learning method based on average rewards [Schwartz, 1993]\n",
      "e. No \\transfer\" of learning . What is learned depends on the reward struc-\n",
      "ture; if the rewards change, learning has to start over.\n",
      "\u000fSeparate the learning into two parts: learn an \\action model\" which\n",
      "predicts how actions change states (and is constant over all prob-\n",
      "lems), and then learn the \\values\" of states by reinforcement learn-\n",
      "ing for each di\u000b",
      "erent set of rewards. Sometimes the reinforcement\n",
      "learning part can be replaced by a \\planner\" that uses the action\n",
      "model to produce plans to achieve goals.\n",
      "Also see other articles in the special issue on reinforcement learning: Machine\n",
      "Learning , 8, May, 1992.\n",
      "11.6 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "156 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Chapter 12\n",
      "Explanation-Based\n",
      "Learning\n",
      "12.1 Deductive Learning\n",
      "In the learning methods studied so far, typically the training set does not ex-\n",
      "haust the version space. Using logical terminology, we could say that the classi-\n",
      "\f",
      "er's output does not logically follow from the training set. In this sense, these\n",
      "methods are inductive . In logic, a deductive system is one whose conclusions\n",
      "logically follow from a set of input facts, if the system is sound.1\n",
      "To contrast inductive with deductive systems in a logical setting, suppose\n",
      "we have a set of facts (the training set) that includes the following formulas:\n",
      "fRound (Obj1);Round (Obj2);Round (Obj3);Round (Obj4);\n",
      "Ball(Obj1);Ball (Obj2);Ball (Obj3);Ball (Obj4)g\n",
      "A learning system that forms the conclusion ( 8x)[Ball(x)\u001bRound (x)] is in-\n",
      "ductive. This conclusion may be useful (if there are no facts of the form\n",
      "Ball(\u001b)^:Round (\u001b)), but it does not logically follow from the facts. On the\n",
      "other hand, if we had the facts Green (Obj5) andGreen (Obj5)\u001bRound (Obj5),\n",
      "then we could logically conclude Round (Obj5). Making this conclusion and sav-\n",
      "ing it is an instance of deductive learning|a topic we study in this chapter.\n",
      "Suppose that some logical proposition, \u001e",
      ", logically follows from some set of\n",
      "facts, \u0001. Under what circumstances might we say that the process of deducing\n",
      "\u001e",
      "from \u0001 results in our learning\u001e",
      "? In a sense, we implicitly knew \u001e",
      "all along,\n",
      "since it was inherent in knowing \u0001. Yet, \u001e",
      "might not be obvious given \u0001, and\n",
      "1Logical reasoning systems that are not sound, for example those using non-monotonic\n",
      "reasoning, themselves might produce inductive conclusions that do not logically follow from\n",
      "the input facts.\n",
      "157\n",
      "158 CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "the deduction process to establish \u001e",
      "might have been arduous. Rather than have\n",
      "to deduce\u001e",
      "again, we might want to save it, perhaps along with its deduction,\n",
      "in case it is needed later. Shouldn't that process count as learning? Dietterich\n",
      "[Dietterich, 1990] has called this type of learning speed-up learning.\n",
      "Strictly speaking, speed-up learning does not result in a system being able to\n",
      "make decisions that, in principle, could not have been made before the learning\n",
      "took place. Speed-up learning simply makes it possible to make those decisions\n",
      "more e\u000eciently. But, in practice, this type of learning might make possible\n",
      "certain decisions that might otherwise have been infeasible.\n",
      "To take an extreme case, a chess player can be said to learn chess even though\n",
      "optimal play is inherent in the rules of chess. On the surface, there seems to be\n",
      "no real di\u000b",
      "erence between the experience-based hypotheses that a chess player\n",
      "makes about what constitutes good play and the kind of learning we have been\n",
      "studying so far.\n",
      "As another example, suppose we are given some theorems about geometry\n",
      "and are asked to prove that the sum of the angles of a right triangle is 180\n",
      "degrees. Let us further suppose that the proof we constructed did not depend\n",
      "on the given triangle being a right triangle; in that case we can learn a more\n",
      "general fact. The learning technique that we are going to study next is related\n",
      "to this example. It is called explanation-based learning (EBL) . EBL can be\n",
      "thought of as a process in which implicit knowledge is converted into explicit\n",
      "knowledge.\n",
      "In EBL, we specialize parts of a domain theory toexplain a particular ex-\n",
      "ample , then we generalize the explanation to produce another element of the\n",
      "domain theory that will be useful on similar examples. This process is illustrated\n",
      "in Fig. 12.1.\n",
      "12.2 Domain Theories\n",
      "Two types of information were present in the inductive methods we have studied:\n",
      "the information inherent in the training samples and the information about the\n",
      "domain that is implied by the \\bias\" (for example, the hypothesis set from which\n",
      "we choose functions). The learning methods are successful only if the hypothesis\n",
      "set is appropriate for the problem. Typically, the smaller the hypothesis set (that\n",
      "is, the more a priori information we have about the function being sought), the\n",
      "less dependent we are on information being supplied by a training set (that\n",
      "is, fewer samples). A priori information about a problem can be expressed in\n",
      "several ways. The methods we have studied so far restrict the hypotheses in a\n",
      "rather direct way. A less direct method involves making assertions in a logical\n",
      "language about the property we are trying to learn. A set of such assertions is\n",
      "usually called a \\domain theory.\"\n",
      "Suppose, for example, that we wanted to classify people according to whether\n",
      "or not they were good credit risks. We might represent a person by a set of\n",
      "properties (income, marital status, type of employment, etc.), assemble such\n",
      "12.3. AN EXAMPLE 159\n",
      "Domain\n",
      "Theory\n",
      "Example\n",
      "(X is P)Prove: X is Pspecialize\n",
      "Explanation\n",
      "(Proof)\n",
      "generalize\n",
      "A New Domain Rule:\n",
      "Things \"like\" X are P\n",
      "Y is like XComplex Proof\n",
      "Process\n",
      "Trivial  Proof\n",
      "Y is P\n",
      "Figure 12.1: The EBL Process\n",
      "data about people who are known to be good and bad credit risks and train a\n",
      "classi\f",
      "er to make decisions. Or, we might go to a loan o\u000ecer of a bank, ask him\n",
      "or her what sorts of things s/he looks for in making a decision about a loan,\n",
      "encode this knowledge into a set of rules for an expert system, and then use\n",
      "the expert system to make decisions. The knowledge used by the loan o\u000ecer\n",
      "might have originated as a set of \\policies\" (the domain theory), but perhaps the\n",
      "application of these policies were specialized and made more e\u000ecient through\n",
      "experience with the special cases of loans made in his or her district.\n",
      "12.3 An Example\n",
      "To make our discussion more concrete, let's consider the following fanciful exam-\n",
      "ple. We want to \f",
      "nd a way to classify robots as \\robust\" or not. The attributes\n",
      "that we use to represent a robot might include some that are relevant to this\n",
      "decision and some that are not.\n",
      "160 CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "Suppose we have a domain theory of logical sentences that taken together,\n",
      "help to de\f",
      "ne whether or not a robot can be classi\f",
      "ed as robust. (The same\n",
      "domain theory may be useful for several other purposes also, but among other\n",
      "things, it describes the concept \\robust.\")\n",
      "In this example, let's suppose that our domain theory includes the sentences:\n",
      "Fixes (u;u)\u001bRobust (u)\n",
      "(An individual that can \f",
      "x itself is robust.)\n",
      "Sees(x;y)^Habile (x)\u001bFixes (x;y)\n",
      "(A habile individual that can see another entity can \f",
      "x that entity.)\n",
      "Robot (w)\u001bSees(w;w)\n",
      "(All robots can see themselves.)\n",
      "R2D2(x)\u001bHabile (x)\n",
      "(R2D2-class individuals are habile.)\n",
      "C3PO(x)\u001bHabile (x)\n",
      "(C3PO-class individuals are habile.)\n",
      ":::\n",
      "(By convention, variables are assumed to be universally quanti\f",
      "ed.) We could\n",
      "use theorem-proving methods operating on this domain theory to conclude\n",
      "whether certain robots are robust. These methods might be computationally\n",
      "quite expensive because extensive search may have to be performed to derive a\n",
      "conclusion. But after having found a proof for some particular robot, we might\n",
      "be able to derive some new sentence whose use allows a much faster conclusion.\n",
      "We next show how such a new rule might be derived in this example. Suppose\n",
      "we are given a number of facts about Num5, such as:\n",
      "Robot (Num 5)\n",
      "R2D2(Num 5)\n",
      "Age(Num 5;5)\n",
      "Manufacturer (Num 5;GR)\n",
      ":::\n",
      "12.3. AN EXAMPLE 161\n",
      "Fixes(u, u) => Robust(u)Robust(Num5)Fixes(Num5, Num5)\n",
      "Sees(Num5,Num5)Habile(Num5)Sees(x,y) & Habile(x)\n",
      "              => Fixes(x,y)\n",
      "Robot(w)\n",
      "     => Sees(w,w)\n",
      "Robot(Num5)R2D2(x)\n",
      "         => Habile(x)\n",
      "R2D2(Num5)\n",
      "Figure 12.2: A Proof Tree\n",
      "We are also told that Robust (Num 5) is true, but we nevertheless attempt to\n",
      "\f",
      "nd a proof of that assertion using these facts about Num5 and the domain\n",
      "theory. The facts about Num5 correspond to the features that we might use\n",
      "to represent Num5. In this example, not all of them are relevant to a decision\n",
      "aboutRobust (Num 5). The relevant ones are those used or needed in proving\n",
      "Robust (Num 5) using the domain theory. The proof tree in Fig. 12.2 is one that\n",
      "a typical theorem-proving system might produce.\n",
      "In the language of EBL, this proof is an explanation for the fact\n",
      "Robust (Num 5). We see from this explanation that the only facts about Num5\n",
      "that were used were Robot (Num 5) andR2D2(Num 5). In fact, we could con-\n",
      "struct the following rule from this explanation:\n",
      "Robot (Num 5)^R2D2(Num 5)\u001bRobust (Num 5)\n",
      "The explanation has allowed us to prune some attributes about Num5 that are\n",
      "irrelevant (at least for deciding Robust (Num 5)). This type of pruning is the \f",
      "rst\n",
      "sense in which an explanation is used to generalize the classi\f",
      "cation problem.\n",
      "([DeJong & Mooney, 1986] call this aspect of explanation-based learning feature\n",
      "elimination .) But the rule we extracted from the explanation applies only to\n",
      "Num5. There might be little value in learning that rule since it is so speci\f",
      "c.\n",
      "Can it be generalized so that it can be applied to other individuals as well?\n",
      "162 CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "Examination of the proof shows that the same proof structure, using the\n",
      "same sentences from the domain theory, could be used independently of whether\n",
      "we are talking about Num5 or some other individual. We can generalize the\n",
      "proof by a process that replaces constants in the tip nodes of the proof tree\n",
      "with variables and works upward|using uni\f",
      "cation to constrain the values of\n",
      "variables as needed to obtain a proof.\n",
      "In this example, we replace Robot (Num 5) byRobot (r) andR2D2(Num 5)\n",
      "byR2D2(s) and redo the proof|using the explanation proof as a template.\n",
      "Note that we use di\u000b",
      "erent values for the two di\u000b",
      "erent occurrences of Num 5 at\n",
      "the tip nodes. Doing so sometimes results in more general, but nevertheless\n",
      "valid rules. We now apply the rules used in the proof in the forward direction,\n",
      "keeping track of the substitutions imposed by the most general uni\f",
      "ers used in\n",
      "the proof. (Note that we always substitute terms that are already in the tree for\n",
      "variables in rules.) This process results in the generalized proof tree shown in\n",
      "Fig. 12.3. Note that the occurrence of Sees(r;r) as a node in the tree forces the\n",
      "uni\f",
      "cation of xwithyin the domain rule, Sees(x;y)^Habile (y)\u001bFixes (x;y).\n",
      "The substitutions are then applied to the variables in the tip nodes and the root\n",
      "node to yield the general rule: Robot (r)^R2D2(r)\u001bRobust (r).\n",
      "This rule is the end result of EBL for this example. The process\n",
      "by which Num 5 in this example was generalized to a variable is what\n",
      "[DeJong & Mooney, 1986] call identity elimination (the precise identity of Num5\n",
      "turned out to be irrelevant). (The generalization process described in this ex-\n",
      "ample is based on that of [DeJong & Mooney, 1986] and di\u000b",
      "ers from that of\n",
      "[Mitchell, et al. , 1986]. It is also similar to that used in [Fikes, et al. , 1972].)\n",
      "Clearly, under certain assumptions, this general rule is more easily used to con-\n",
      "cludeRobust about an individual than the original proof process was.\n",
      "It is important to note that we could have derived the general rule from the\n",
      "domain theory without using the example. (In the literature, doing so is called\n",
      "static analysis [Etzioni, 1991].) In fact, the example told us nothing new other\n",
      "than what it told us about Num5. The sole role of the example in this instance\n",
      "of EBL was to provide a template for a proof to help guide the generalization\n",
      "process. Basing the generalization process on examples helps to insure that we\n",
      "learn rules matched to the distribution of problems that occur.\n",
      "There are a number of quali\f",
      "cations and elaborations about EBL that need\n",
      "to be mentioned.\n",
      "12.4 Evaluable Predicates\n",
      "The domain theory includes a number of predicates other than the one occuring\n",
      "in the formula we are trying to prove and other than those that might custom-\n",
      "arily be used to describe an individual. One might note, for example, that if we\n",
      "usedHabile (Num 5) to describe Num5, the proof would have been shorter. Why\n",
      "didn't we? The situation is analogous to that of using a data base augmented\n",
      "by logical rules. In the latter application, the formulas in the actual data base\n",
      "12.4. EVALUABLE PREDICATES 163\n",
      "Robust(r)Fixes(r, r)\n",
      "Sees(r,r)Habile(s)\n",
      "Robot(r)R2D2(s){r/w}{s/x}{r/x, r/y, r/s}{r/u}\n",
      "Robot(w)\n",
      "     => Sees(w,w)R2D2(x)\n",
      "         => Habile(x)Sees(x,y) & Habile(x)\n",
      "              => Fixes(x,y)Fixes(u, u) => Robust(u)\n",
      "becomes R2D2(r) after\n",
      "applying {r/s}\n",
      "Figure 12.3: A Generalized Proof Tree\n",
      "are \\extensional,\" and those in the logical rules are \\intensional.\" This usage\n",
      "re\r",
      "ects the fact that the predicates in the data base part are de\f",
      "ned by their\n",
      "extension|we explicitly list all the tuples sastisfying a relation. The logical\n",
      "rules serve to connect the data base predicates with higher level abstractions\n",
      "that are described (if not de\f",
      "ned) by the rules. We typically cannot look up\n",
      "the truth values of formulas containing these intensional predicates; they have\n",
      "to be derived using the rules and the database.\n",
      "The EBL process assumes something similar. The domain theory is useful\n",
      "for connecting formulas that we might want to prove with those whose truth\n",
      "values can be \\looked up\" or otherwise evaluated. In the EBL literature, such\n",
      "formulas satisfy what is called the operationality criterion . Perhaps another\n",
      "analogy might be to neural networks. The evaluable predicates correspond to\n",
      "the components of the input pattern vector; the predicates in the domain theory\n",
      "correspond to the hidden units. Finding the new rule corresponds to \f",
      "nding a\n",
      "simpler expression for the formula to be proved in terms only of the evaluable\n",
      "predicates.\n",
      "164 CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "12.5 More General Proofs\n",
      "Examining the domain theory for our example reveals that an alternative rule\n",
      "might have been: Robot (u)^C3PO(u)\u001bRobust (u). Such a rule might\n",
      "have resulted if we were given fC3PO(Num 6);Robot (Num 6);:::gand proved\n",
      "Robust (Num 6). After considering these two examples (Num5 and Num6),\n",
      "the question arises, do we want to generalize the two rules to something like:\n",
      "Robot (u)^[C3PO(u)_R2D2(u)]\u001bRobust (u)? Doing so is an example of what\n",
      "[DeJong & Mooney, 1986] call structural generalization (via disjunctive augmen-\n",
      "tation ).\n",
      "Adding disjunctions for every alternative proof can soon become cumbersome\n",
      "and destroy any e\u000eciency advantage of EBL. In our example, the e\u000eciency\n",
      "might be retrieved if there were another evaluable predicate, say, Bionic (u) such\n",
      "that the domain theory also contained R2D2(x)\u001bBionic (x) andC3PO(x)\u001b\n",
      "Bionic (x). After seeing a number of similar examples, we might be willing to\n",
      "induce the formula Bionic (u)\u001b[C3PO(u)_R2D2(u)] in which case the rule\n",
      "with the disjunction could be replaced with Robot (u)^Bionic (u)\u001bRobust (u).\n",
      "12.6 Utility of EBL\n",
      "It is well known in theorem proving that the complexity of \f",
      "nding a proof\n",
      "depends both on the number of formulas in the domain theory and on the depth\n",
      "of the shortest proof. Adding a new rule decreases the depth of the shortest\n",
      "proof but it also increases the number of formulas in the domain theory. In\n",
      "realistic applications, the added rules will be relevant for some tasks and not for\n",
      "others. Thus, it is unclear whether the overall utility of the new rules will turn\n",
      "out to be positive. EBL methods have been applied in several settings, usually\n",
      "with positive utility. (See [Minton, 1990] for an analysis).\n",
      "12.7 Applications\n",
      "There have been several applications of EBL methods. We mention two here,\n",
      "namely the formation of macro-operators in automatic plan generation and\n",
      "learning how to control search.\n",
      "12.7.1 Macro-Operators in Planning\n",
      "In automatic planning systems, e\u000eciency can sometimes be enhanced by chain-\n",
      "ing together a sequence of operators into macro-operators . We show an exam-\n",
      "ple of a process for creating macro-operators based on techniques explored by\n",
      "[Fikes, et al. , 1972].\n",
      "Referring to Fig. 12.4, consider the problem of \f",
      "nding a plan for a robot in\n",
      "roomR1 to fetch a box, B1, by going to an adjacent room, R2, and pushing it\n",
      "12.7. APPLICATIONS 165\n",
      "back toR1. The goal for the robot is INROOM (B1;R1), and the facts that\n",
      "are true in the initial state are listed in the \f",
      "gure.\n",
      "R1 R2\n",
      "R3D1\n",
      "D2B1\n",
      "Initial State:\n",
      "INROOM(ROBOT, R1)\n",
      "INROOM(B1,R2)\n",
      "CONNECTS(D1,R1,R2)\n",
      "CONNECTS(D1,R2,R1)\n",
      ". . .\n",
      "Figure 12.4: Initial State of a Robot Problem\n",
      "We will construct the plan from a set of STRIPS operators that include:\n",
      "GOTHRU(d;r1;r2)\n",
      "Preconditions: INROOM (ROBOT;r 1);CONNECTS (d;r1;r2)\n",
      "Delete list: INROOM (ROBOT;r 1)\n",
      "Add list:INROOM (ROBOT;r 2)\n",
      "PUSHTHRU( b;d;r 1;r2)\n",
      "Preconditions: INROOM (ROBOT;r 1);CONNECTS (d;r1;r2);INROOM (b;r1)\n",
      "Delete list: INROOM (ROBOT;r 1);INROOM (b;r1)\n",
      "Add list:INROOM (ROBOT;r 2);INROOM (b;r2)\n",
      "A backward-reasoning STRIPS system might produce the plan shown in\n",
      "Fig. 12.5. We show there the main goal and the subgoals along a solution path.\n",
      "(The conditions in each subgoal that are true in the initial state are shown\n",
      "underlined.) The preconditions for this plan, true in the initial state, are:\n",
      "INROOM (ROBOT;R 1)\n",
      "166 CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "CONNECTS (D1;R1;R2)\n",
      "CONNECTS (D1;R2;R1)\n",
      "INROOM (B1;R2)\n",
      "Saving this speci\f",
      "c plan, valid only for the speci\f",
      "c constants it mentions, would\n",
      "not be as useful as would be saving a more general one. We \f",
      "rst generalize\n",
      "these preconditions by substituting variables for constants. We then follow the\n",
      "structure of the speci\f",
      "c plan to produce the generalized plan shown in Fig. 12.6\n",
      "that achieves INROOM (b1;r4). Note that the generalized plan does not require\n",
      "pushing the box back to the place where the robot started. The preconditions\n",
      "for the generalized plan are:\n",
      "INROOM (ROBOT;r 1)\n",
      "CONNECTS (d1;r1;r2)\n",
      "CONNECTS (d2;r2;r4)\n",
      "INROOM (b;r4)\n",
      "INROOM(B1,R1)\n",
      "PUSHTHRU(B1,d,r1,R1)\n",
      "INROOM(ROBOT, r1),\n",
      "CONNECTS(d, r1, R1),\n",
      "INROOM(B1, r1)INROOM(ROBOT, R2),\n",
      "CONNECTS(D1, R2, R1),\n",
      "INROOM(B1, R2){R2/r1,\n",
      "D1/d}\n",
      "GOTHRU(d2, r3, R2)\n",
      "INROOM(ROBOT, r3),\n",
      "CONNECTS(d2, r3, R2),\n",
      "CONNECTS(D1, R2, R1),\n",
      "INROOM(B1, R2)\n",
      "{R1/r3, D1/d2}\n",
      "INROOM(ROBOT, R1),\n",
      "CONNECTS(D1, R1, R2),\n",
      "CONNECTS(D1, R2, R1),\n",
      "INROOM(B1, R2)R1 R2\n",
      "R3D1\n",
      "D2\n",
      "GOTHRU(D1,R1,R2)\n",
      "PUSHTHRU(B1,D1,R2,R1)B1\n",
      "PLAN:\n",
      "Figure 12.5: A Plan for the Robot Problem\n",
      "Another related technique that chains together sequences of operators to\n",
      "form more general ones is the chunking mechanism in Soar [Laird, et al. , 1986].\n",
      "12.7. APPLICATIONS 167\n",
      "INROOM(b1,r4)\n",
      "PUSHTHRU(b1,d2,r2,r4)\n",
      "INROOM(ROBOT, r2),\n",
      "CONNECTS(d1, r1, r2),\n",
      "CONNECTS(d2, r2, r4),\n",
      "INROOM(b1, r4)\n",
      "GOTHRU(d1, r1, r2)\n",
      "INROOM(ROBOT, r1),\n",
      "CONNECTS(d1, r1, r2),\n",
      "CONNECTS(d2, r2, r4),\n",
      "INROOM(b1, r4)\n",
      "Figure 12.6: A Generalized Plan\n",
      "12.7.2 Learning Search Control Knowledge\n",
      "Besides their use in creating macro-operators, EBL methods can be used to\n",
      "improve the e\u000eciency of planning in another way also. In his system called\n",
      "PRODIGY, Minton proposed using EBL to learn e\u000b",
      "ective ways to control\n",
      "search [Minton, 1988]. PRODIGY is a STRIPS-like system that solves planning\n",
      "problems in the blocks-world, in a simple mobile robot world, and in job-shop\n",
      "scheduling. PRODIGY has a domain theory involving both the domain of the\n",
      "problem and a simple (meta) theory about planning. Its meta theory includes\n",
      "statements about whether a control choice about a subgoal to work on, an oper-\n",
      "ator to apply, etc.either succeeds orfails. After producing a plan, it analyzes its\n",
      "successful and its unsuccessful choices and attempts to explain them in terms\n",
      "of its domain theory. Using an EBL-like process, it is able to produce useful\n",
      "control rules such as:\n",
      "168 CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "IF(AND(CURRENT\u0000NODE node )\n",
      "(CANDIDATE\u0000GOAL node (ON x y ))\n",
      "(CANDIDATE\u0000GOAL node (ON y z )))\n",
      "THEN (PREFER GOAL (ON y z )TO(ON x y ))\n",
      "PRODIGY keeps statistics on how often these learned rules are used, their\n",
      "savings (in time to \f",
      "nd plans), and their cost of application. It saves only the\n",
      "rules whose utility, thus measured, is judged to be high. Minton [Minton, 1990]\n",
      "has shown that there is an overall advantage of using these rules (as against not\n",
      "having any rules and as against hand-coded search control rules).\n",
      "12.8 Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "Bibliography\n",
      "[Acorn & Walden, 1992] Acorn, T., and Walden, S., \\SMART: Support Man-\n",
      "agement Automated Reasoning Technology for COMPAQ Customer Ser-\n",
      "vice,\" Proc. Fourth Annual Conf. on Innovative Applications of Arti\f",
      "cial\n",
      "Intelligence , Menlo Park, CA: AAAI Press, 1992.\n",
      "[Aha, 1991] Aha, D., Kibler, D., and Albert, M., \\Instance-Based Learning\n",
      "Algorithms,\" Machine Learning , 6, 37-66, 1991.\n",
      "[Anderson & Bower, 1973] Anderson, J. R., and Bower, G. H., Human Asso-\n",
      "ciative Memory , Hillsdale, NJ: Erlbaum, 1973.\n",
      "[Anderson, 1958] Anderson, T. W., An Introduction to Multivariate Statistical\n",
      "Analysis , New York: John Wiley, 1958.\n",
      "[Barto, Bradtke, & Singh, 1994] Barto, A., Bradtke, S., and Singh, S., \\Learn-\n",
      "ing to Act Using Real-Time Dynamic Programming,\" to appear in Ar-\n",
      "ti\f",
      "cial Intelligence , 1994.\n",
      "[Baum & Haussler, 1989] Baum, E, and Haussler, D., \\What Size Net Gives\n",
      "Valid Generalization?\" Neural Computation , 1, pp. 151-160, 1989.\n",
      "[Baum, 1994] Baum, E., \\When Are k-Nearest Neighbor and Backpropagation\n",
      "Accurate for Feasible-Sized Sets of Examples?\" in Hanson, S., Drastal,\n",
      "G., and Rivest, R., (eds.), Computational Learning Theory and Natural\n",
      "Learning Systems, Volume 1: Constraints and Prospects , pp. 415-442,\n",
      "Cambridge, MA: MIT Press, 1994.\n",
      "[Bellman, 1957] Bellman, R. E., Dynamic Programming , Princeton: Princeton\n",
      "University Press, 1957.\n",
      "[Blumer, et al. , 1987] Blumer, A., et al. , \\Occam's Razor,\" Info. Process. Lett.,\n",
      "vol 24 , pp. 377-80, 1987.\n",
      "[Blumer, et al. , 1990] Blumer, A., et al ., \\Learnability and the Vapnik-\n",
      "Chervonenkis Dimension,\" JACM , 1990.\n",
      "[Bollinger & Du\u000ee, 1988] Bollinger, J., and Du\u000ee, N., Computer Control of\n",
      "Machines and Processes , Reading, MA: Addison-Wesley, 1988.\n",
      "169\n",
      "170 BIBLIOGRAPHY\n",
      "[Brain, et al. , 1962] Brain, A. E., et al. , \\Graphical Data Processing Research\n",
      "Study and Experimental Investigation,\" Report No. 8 (pp. 9-13) and No.\n",
      "9 (pp. 3-10), Contract DA 36-039 SC-78343, SRI International, Menlo\n",
      "Park, CA, June 1962 and September 1962.\n",
      "[Breiman, et al. , 1984] Breiman, L., Friedman, J., Olshen, R., and Stone, C.,\n",
      "Classi\f",
      "cation and Regression Trees , Monterey, CA: Wadsworth, 1984.\n",
      "[Brent, 1990] Brent, R. P., \\Fast Training Algorithms for Multi-Layer Neural\n",
      "Nets,\" Numerical Analysis Project Manuscript NA-90-03, Computer Sci-\n",
      "ence Department, Stanford University, Stanford, CA 94305, March 1990.\n",
      "[Bryson & Ho 1969] Bryson, A., and Ho, Y.-C., Applied Optimal Control , New\n",
      "York: Blaisdell.\n",
      "[Buchanan & Wilkins, 1993] Buchanan, B. and Wilkins, D., (eds.), Readings in\n",
      "Knowledge Acquisition and Learning , San Francisco: Morgan Kaufmann,\n",
      "1993.\n",
      "[Carbonell, 1983] Carbonell, J., \\Learning by Analogy,\" in Machine Learning:\n",
      "An Arti\f",
      "cial Intelligence Approach , Michalski, R., Carbonell, J., and\n",
      "Mitchell, T., (eds.), San Francisco: Morgan Kaufmann, 1983.\n",
      "[Cheeseman, et al. , 1988] Cheeseman, P., et al. , \\AutoClass: A Bayesian Clas-\n",
      "si\f",
      "cation System,\" Proc. Fifth Intl. Workshop on Machine Learning ,\n",
      "Morgan Kaufmann, San Mateo, CA, 1988. Reprinted in Shavlik, J. and\n",
      "Dietterich, T., Readings in Machine Learning , Morgan Kaufmann, San\n",
      "Francisco, pp. 296-306, 1990.\n",
      "[Cover & Hart, 1967] Cover, T., and Hart, P., \\Nearest Neighbor Pattern Clas-\n",
      "si\f",
      "cation,\" IEEE Trans. on Information Theory , 13, 21-27, 1967.\n",
      "[Cover, 1965] Cover, T., \\Geometrical and Statistical Properties of Systems\n",
      "of Linear Inequalities with Applications in Pattern Recognition,\" IEEE\n",
      "Trans. Elec. Comp. , EC-14, 326-334, June, 1965.\n",
      "[Dasarathy, 1991] Dasarathy, B. V., Nearest Neighbor Pattern Classi\f",
      "cation\n",
      "Techniques , IEEE Computer Society Press, 1991.\n",
      "[Dayan & Sejnowski, 1994] Dayan, P., and Sejnowski, T., \\ TD(\u0015) Converges\n",
      "with Probability 1,\" Machine Learning , 14, pp. 295-301, 1994.\n",
      "[Dayan, 1992] Dayan, P., \\The Convergence of TD( \u0015) for General \u0015,\"Machine\n",
      "Learning , 8, 341-362, 1992.\n",
      "[DeJong & Mooney, 1986] DeJong, G., and Mooney, R., \\Explanation-Based\n",
      "Learning: An Alternative View,\" Machine Learning , 1:145-176, 1986.\n",
      "Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\n",
      "ing, San Francisco: Morgan Kaufmann, 1990, pp 452-467.\n",
      "BIBLIOGRAPHY 171\n",
      "[Dietterich & Bakiri, 1991] Dietterich, T. G., and Bakiri, G., \\Error-Correcting\n",
      "Output Codes: A General Method for Improving Multiclass Induc-\n",
      "tive Learning Programs,\" Proc. Ninth Nat. Conf. on A.I. , pp. 572-577,\n",
      "AAAI-91, MIT Press, 1991.\n",
      "[Dietterich, et al. , 1990] Dietterich, T., Hild, H., and Bakiri, G., \\A Compara-\n",
      "tive Study of ID3 and Backpropagation for English Text-to-Speech Map-\n",
      "ping,\" Proc. Seventh Intl. Conf. Mach. Learning , Porter, B. and Mooney,\n",
      "R. (eds.), pp. 24-31, San Francisco: Morgan Kaufmann, 1990.\n",
      "[Dietterich, 1990] Dietterich, T., \\Machine Learning,\" Annu. Rev. Comput.\n",
      "Sci., 4:255-306, Palo Alto: Annual Reviews Inc., 1990.\n",
      "[Duda & Fossum, 1966] Duda, R. O., and Fossum, H., \\Pattern Classi\f",
      "cation\n",
      "by Iteratively Determined Linear and Piecewise Linear Discriminant\n",
      "Functions,\" IEEE Trans. on Elect. Computers , vol. EC-15, pp. 220-232,\n",
      "April, 1966.\n",
      "[Duda & Hart, 1973] Duda, R. O., and Hart, P.E., Pattern Classi\f",
      "cation and\n",
      "Scene Analysis , New York: Wiley, 1973.\n",
      "[Duda, 1966] Duda, R. O., \\Training a Linear Machine on Mislabeled Patterns,\"\n",
      "SRI Tech. Report prepared for ONR under Contract 3438(00), SRI In-\n",
      "ternational, Menlo Park, CA, April 1966.\n",
      "[Efron, 1982] Efron, B., The Jackknife, the Bootstrap and Other Resampling\n",
      "Plans , Philadelphia: SIAM, 1982.\n",
      "[Ehrenfeucht, et al. , 1988] Ehrenfeucht, A., et al. , \\A General Lower Bound on\n",
      "the Number of Examples Needed for Learning,\" in Proc. 1988 Workshop\n",
      "on Computational Learning Theory , pp. 110-120, San Francisco: Morgan\n",
      "Kaufmann, 1988.\n",
      "[Etzioni, 1991] Etzioni, O., \\STATIC: A Problem-Space Compiler for\n",
      "PRODIGY,\" Proc. of Ninth National Conf. on Arti\f",
      "cial Intelligence ,\n",
      "pp. 533-540, Menlo Park: AAAI Press, 1991.\n",
      "[Etzioni, 1993] Etzioni, O., \\A Structural Theory of Explanation-Based Learn-\n",
      "ing,\" Arti\f",
      "cial Intelligence , 60:1, pp. 93-139, March, 1993.\n",
      "[Evans & Fisher, 1992] Evans, B., and Fisher, D., Process Delay Analyses Using\n",
      "Decision-Tree Induction , Tech. Report CS92-06, Department of Com-\n",
      "puter Science, Vanderbilt University, TN, 1992.\n",
      "[Fahlman & Lebiere, 1990] Fahlman, S., and Lebiere, C., \\The Cascade-\n",
      "Correlation Learning Architecture,\" in Touretzky, D., (ed.), Advances in\n",
      "Neural Information Processing Systems, 2 , pp. 524-532, San Francisco:\n",
      "Morgan Kaufmann, 1990.\n",
      "172 BIBLIOGRAPHY\n",
      "[Fayyad, et al. , 1993] Fayyad, U. M., Weir, N., and Djorgovski, S., \\SKICAT:\n",
      "A Machine Learning System for Automated Cataloging of Large Scale\n",
      "Sky Surveys,\" in Proc. Tenth Intl. Conf. on Machine Learning , pp. 112-\n",
      "119, San Francisco: Morgan Kaufmann, 1993. (For a longer version of\n",
      "this paper see: Fayyad, U. Djorgovski, G., and Weir, N., \\Automating\n",
      "the Analysis and Cataloging of Sky Surveys,\" in Fayyad, U., et al. (eds.),\n",
      "Advances in Knowledge Discovery and Data Mining , Chapter 19, pp.\n",
      "471\u000b",
      "., Cambridge: The MIT Press, March, 1996.)\n",
      "[Feigenbaum, 1961] Feigenbaum, E. A., \\The Simulation of Verbal Learning Be-\n",
      "havior,\" Proceedings of the Western Joint Computer Conference , 19:121-\n",
      "132, 1961.\n",
      "[Fikes, et al. , 1972] Fikes, R., Hart, P., and Nilsson, N., \\Learning and Execut-\n",
      "ing Generalized Robot Plans,\" Arti\f",
      "cial Intelligence , pp 251-288, 1972.\n",
      "Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\n",
      "ing, San Francisco: Morgan Kaufmann, 1990, pp 468-486.\n",
      "[Fisher, 1987] Fisher, D., \\Knowledge Acquisition via Incremental Conceptual\n",
      "Clustering,\" Machine Learning , 2:139-172, 1987. Reprinted in Shavlik,\n",
      "J. and Dietterich, T., Readings in Machine Learning , San Francisco:\n",
      "Morgan Kaufmann, 1990, pp. 267{283.\n",
      "[Friedman, et al. , 1977] Friedman, J. H., Bentley, J. L., and Finkel, R. A., \\An\n",
      "Algorithm for Finding Best Matches in Logarithmic Expected Time,\"\n",
      "ACM Trans. on Math. Software , 3(3):209-226, September 1977.\n",
      "[Fu, 1994] Fu, L., Neural Networks in Arti\f",
      "cial Intelligence , New York:\n",
      "McGraw-Hill, 1994.\n",
      "[Gallant, 1986] Gallant, S. I., \\Optimal Linear Discriminants,\" in Eighth Inter-\n",
      "national Conf. on Pattern Recognition , pp. 849-852, New York: IEEE,\n",
      "1986.\n",
      "[Genesereth & Nilsson, 1987] Genesereth, M., and Nilsson, N., Logical Founda-\n",
      "tions of Arti\f",
      "cial Intelligence , San Francisco: Morgan Kaufmann, 1987.\n",
      "[Gluck & Rumelhart, 1989] Gluck, M. and Rumelhart, D., Neuroscience and\n",
      "Connectionist Theory , The Developments in Connectionist Theory, Hills-\n",
      "dale, NJ: Erlbaum Associates, 1989.\n",
      "[Hammerstrom, 1993] Hammerstrom, D., \\Neural Networks at Work,\" IEEE\n",
      "Spectrum , pp. 26-32, June 1993.\n",
      "[Haussler, 1988] Haussler, D., \\Quantifying Inductive Bias: AI Learning Al-\n",
      "gorithms and Valiant's Learning Framework,\" Arti\f",
      "cial Intelligence ,\n",
      "36:177-221, 1988. Reprinted in Shavlik, J. and Dietterich, T., Readings in\n",
      "Machine Learning , San Francisco: Morgan Kaufmann, 1990, pp. 96-107.\n",
      "BIBLIOGRAPHY 173\n",
      "[Haussler, 1990] Haussler, D., \\Probably Approximately Correct Learning,\"\n",
      "Proc. Eighth Nat. Conf. on AI , pp. 1101-1108. Cambridge, MA: MIT\n",
      "Press, 1990.\n",
      "[Hebb, 1949] Hebb, D. O., The Organization of Behaviour , New York: John\n",
      "Wiley, 1949.\n",
      "[Hertz, Krogh, & Palmer, 1991] Hertz, J., Krogh, A, and Palmer, R., Introduc-\n",
      "tion to the Theory of Neural Computation , Lecture Notes, vol. 1, Santa\n",
      "Fe Inst. Studies in the Sciences of Complexity, New York: Addison-\n",
      "Wesley, 1991.\n",
      "[Hirsh, 1994] Hirsh, H., \\Generalizing Version Spaces,\" Machine Learning , 17,\n",
      "5-45, 1994.\n",
      "[Holland, 1975] Holland, J., Adaptation in Natural and Arti\f",
      "cial Systems , Ann\n",
      "Arbor: The University of Michigan Press, 1975. (Second edition printed\n",
      "in 1992 by MIT Press, Cambridge, MA.)\n",
      "[Holland, 1986] Holland, J. H., \\Escaping Brittleness; The Possibilities of\n",
      "General-Purpose Learning Algorithms Applied to Parallel Rule-Based\n",
      "Systems.\" In Michalski, R., Carbonell, J., and Mitchell, T. (eds.) , Ma-\n",
      "chine Learning: An Arti\f",
      "cial Intelligence Approach, Volume 2 , chapter\n",
      "20, San Francisco: Morgan Kaufmann, 1986.\n",
      "[Hunt, Marin, & Stone, 1966] Hunt, E., Marin, J., and Stone, P., Experiments\n",
      "in Induction , New York: Academic Press, 1966.\n",
      "[Jabbour, K., et al. , 1987] Jabbour, K., et al. , \\ALFA: Automated Load Fore-\n",
      "casting Assistant,\" Proc. of the IEEE Pwer Engineering Society Summer\n",
      "Meeting , San Francisco, CA, 1987.\n",
      "[John, 1995] John, G., \\Robust Linear Discriminant Trees,\" Proc. of the Conf.\n",
      "on Arti\f",
      "cial Intelligence and Statistics , Ft. Lauderdale, FL, January,\n",
      "1995.\n",
      "[Kaelbling, 1993] Kaelbling, L. P., Learning in Embedded Systems , Cambridge,\n",
      "MA: MIT Press, 1993.\n",
      "[Kohavi, 1994] Kohavi, R., \\Bottom-Up Induction of Oblivious Read-Once De-\n",
      "cision Graphs,\" Proc. of European Conference on Machine Learning\n",
      "(ECML-94) , 1994.\n",
      "[Kolodner, 1993] Kolodner, J., Case-Based Reasoning , San Francisco: Morgan\n",
      "Kaufmann, 1993.\n",
      "[Koza, 1992] Koza, J., Genetic Programming: On the Programming of Comput-\n",
      "ers by Means of Natural Selection , Cambridge, MA: MIT Press, 1992.\n",
      "[Koza, 1994] Koza, J., Genetic Programming II: Automatic Discovery of\n",
      "Reusable Programs , Cambridge, MA: MIT Press, 1994.\n",
      "174 BIBLIOGRAPHY\n",
      "[Laird, et al. , 1986] Laird, J., Rosenbloom, P., and Newell, A., \\Chunking in\n",
      "Soar: The Anatomy of a General Learning Mechanism,\" Machine Learn-\n",
      "ing, 1, pp. 11-46, 1986. Reprinted in Buchanan, B. and Wilkins, D.,\n",
      "(eds.), Readings in Knowledge Acquisition and Learning , pp. 518-535,\n",
      "Morgan Kaufmann, San Francisco, CA, 1993.\n",
      "[Langley, 1992] Langley, P., \\Areas of Application for Machine Learning,\" Proc.\n",
      "of Fifth Int'l. Symp. on Knowledge Engineering , Sevilla, 1992.\n",
      "[Langley, 1996] Langley, P., Elements of Machine Learning , San Francisco:\n",
      "Morgan Kaufmann, 1996.\n",
      "[Lavra\u0014 c & D\u0014 zeroski, 1994] Lavra\u0014 c, N., and D\u0014 zeroski, S., Inductive Logic Pro-\n",
      "gramming , Chichester, England: Ellis Horwood, 1994.\n",
      "[Lin, 1992] Lin, L., \\Self-Improving Reactive Agents Based on Reinforcement\n",
      "Learning, Planning, and Teaching,\" Machine Learning , 8, 293-321, 1992.\n",
      "[Lin, 1993] Lin, L., \\Scaling Up Reinforcement Learning for Robot Control,\"\n",
      "Proc. Tenth Intl. Conf. on Machine Learning , pp. 182-189, San Francisco:\n",
      "Morgan Kaufmann, 1993.\n",
      "[Littlestone, 1988] Littlestone, N., \\Learning Quickly When Irrelevant At-\n",
      "tributes Abound: A New Linear-Threshold Algorithm,\" Machine Learn-\n",
      "ing2: 285-318, 1988.\n",
      "[Maass & Tur\u0013 an, 1994] Maass, W., and Tur\u0013 an, G., \\How Fast Can a Thresh-\n",
      "old Gate Learn?,\" in Hanson, S., Drastal, G., and Rivest, R., (eds.),\n",
      "Computational Learning Theory and Natural Learning Systems, Volume\n",
      "1: Constraints and Prospects , pp. 381-414, Cambridge, MA: MIT Press,\n",
      "1994.\n",
      "[Mahadevan & Connell, 1992] Mahadevan, S., and Connell, J., \\Automatic\n",
      "Programming of Behavior-Based Robots Using Reinforcement Learn-\n",
      "ing,\" Arti\f",
      "cial Intelligence , 55, pp. 311-365, 1992.\n",
      "[Marchand & Golea, 1993] Marchand, M., and Golea, M., \\On Learning Sim-\n",
      "ple Neural Concepts: From Halfspace Intersections to Neural Decision\n",
      "Lists,\" Network , 4:67-85, 1993.\n",
      "[McCulloch & Pitts, 1943] McCulloch, W. S., and Pitts, W. H., \\A Logical Cal-\n",
      "culus of the Ideas Immanent in Nervous Activity,\" Bulletin of Mathe-\n",
      "matical Biophysics , Vol. 5, pp. 115-133, Chicago: University of Chicago\n",
      "Press, 1943.\n",
      "[Michie, 1992] Michie, D., \\Some Directions in Machine Intelligence,\" unpub-\n",
      "lished manuscript, The Turing Institute, Glasgow, Scotland, 1992.\n",
      "[Minton, 1988] Minton, S., Learning Search Control Knowledge: An\n",
      "Explanation-Based Approach , Kluwer Academic Publishers, Boston,\n",
      "MA, 1988.\n",
      "BIBLIOGRAPHY 175\n",
      "[Minton, 1990] Minton, S., \\Quantitative Results Concerning the Utility of\n",
      "Explanation-Based Learning,\" Arti\f",
      "cial Intelligence , 42, pp. 363-392,\n",
      "1990. Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine\n",
      "Learning , San Francisco: Morgan Kaufmann, 1990, pp. 573-587.\n",
      "[Mitchell, et al. , 1986] Mitchell, T., et al. , \\Explanation-Based Generalization:\n",
      "A Unifying View,\" Machine Learning , 1:1, 1986. Reprinted in Shavlik,\n",
      "J. and Dietterich, T., Readings in Machine Learning , San Francisco:\n",
      "Morgan Kaufmann, 1990, pp. 435-451.\n",
      "[Mitchell, 1982] Mitchell, T., \\Generalization as Search,\" Arti\f",
      "cial Intelligence ,\n",
      "18:203-226, 1982. Reprinted in Shavlik, J. and Dietterich, T., Readings in\n",
      "Machine Learning , San Francisco: Morgan Kaufmann, 1990, pp. 96{107.\n",
      "[Moore & Atkeson, 1993] Moore, A., and Atkeson, C., \\Prioritized Sweeping:\n",
      "Reinforcement Learning with Less Data and Less Time,\" Machine Learn-\n",
      "ing, 13, pp. 103-130, 1993.\n",
      "[Moore, et al. , 1994] Moore, A. W., Hill, D. J., and Johnson, M. P., \\An Em-\n",
      "pirical Investigation of Brute Force to Choose Features, Smoothers, and\n",
      "Function Approximators,\" in Hanson, S., Judd, S., and Petsche, T.,\n",
      "(eds.), Computational Learning Theory and Natural Learning Systems ,\n",
      "Vol. 3, Cambridge: MIT Press, 1994.\n",
      "[Moore, 1990] Moore, A., E\u000ecient Memory-based Learning for Robot Control ,\n",
      "PhD. Thesis; Technical Report No. 209, Computer Laboratory, Univer-\n",
      "sity of Cambridge, October, 1990.\n",
      "[Moore, 1992] Moore, A., \\Fast, Robust Adaptive Control by Learning Only\n",
      "Forward Models,\" in Moody, J., Hanson, S., and Lippman, R., (eds.),\n",
      "Advances in Neural Information Processing Systems 4 , San Francisco:\n",
      "Morgan Kaufmann, 1992.\n",
      "[Mueller & Page, 1988] Mueller, R. and Page, R., Symbolic Computing with\n",
      "Lisp and Prolog , New York: John Wiley & Sons, 1988.\n",
      "[Muggleton, 1991] Muggleton, S., \\Inductive Logic Programming,\" New Gen-\n",
      "eration Computing , 8, pp. 295-318, 1991.\n",
      "[Muggleton, 1992] Muggleton, S., Inductive Logic Programming , London: Aca-\n",
      "demic Press, 1992.\n",
      "[Muroga, 1971] Muroga, S., Threshold Logic and its Applications , New York:\n",
      "Wiley, 1971.\n",
      "[Natarjan, 1991] Natarajan, B., Machine Learning: A Theoretical Approach ,\n",
      "San Francisco: Morgan Kaufmann, 1991.\n",
      "176 BIBLIOGRAPHY\n",
      "[Nilsson, 1965] Nilsson, N. J., \\Theoretical and Experimental Investigations in\n",
      "Trainable Pattern-Classifying Systems,\" Tech. Report No. RADC-TR-\n",
      "65-257, Final Report on Contract AF30(602)-3448, Rome Air Develop-\n",
      "ment Center (Now Rome Laboratories), Gri\u000ess Air Force Base, New\n",
      "York, September, 1965.\n",
      "[Nilsson, 1990] Nilsson, N. J., The Mathematical Foundations of Learning Ma-\n",
      "chines , San Francisco: Morgan Kaufmann, 1990. (This book is a reprint\n",
      "ofLearning Machines: Foundations of Trainable Pattern-Classifying\n",
      "Systems , New York: McGraw-Hill, 1965.)\n",
      "[Oliver, Dowe, & Wallace, 1992] Oliver, J., Dowe, D., and Wallace, C., \\Infer-\n",
      "ring Decision Graphs using the Minimum Message Length Principle,\"\n",
      "Proc. 1992 Australian Arti\f",
      "cial Intelligence Conference , 1992.\n",
      "[Pagallo & Haussler, 1990] Pagallo, G. and Haussler, D., \\Boolean Feature Dis-\n",
      "covery in Empirical Learning,\" Machine Learning , vol.5, no.1, pp. 71-99,\n",
      "March 1990.\n",
      "[Pazzani & Kibler, 1992] Pazzani, M., and Kibler, D., \\The Utility of Knowl-\n",
      "edge in Inductive Learning,\" Machine Learning , 9, 57-94, 1992.\n",
      "[Peterson, 1961] Peterson, W., Error Correcting Codes , New York: John Wiley,\n",
      "1961.\n",
      "[Pomerleau, 1991] Pomerleau, D., \\Rapidly Adapting Arti\f",
      "cial Neural Net-\n",
      "works for Autonomous Navigation,\" in Lippmann, P., et al. (eds.), Ad-\n",
      "vances in Neural Information Processing Systems, 3 , pp. 429-435, San\n",
      "Francisco: Morgan Kaufmann, 1991.\n",
      "[Pomerleau, 1993] Pomerleau, D, Neural Network Perception for Mobile Robot\n",
      "Guidance , Boston: Kluwer Academic Publishers, 1993.\n",
      "[Quinlan & Rivest, 1989] Quinlan, J. Ross, and Rivest, Ron, \\Inferring Deci-\n",
      "sion Trees Using the Minimum Description Length Principle,\" Informa-\n",
      "tion and Computation , 80:227{248, March, 1989.\n",
      "[Quinlan, 1986] Quinlan, J. Ross, \\Induction of Decision Trees,\" Machine\n",
      "Learning , 1:81{106, 1986. Reprinted in Shavlik, J. and Dietterich, T.,\n",
      "Readings in Machine Learning , San Francisco: Morgan Kaufmann, 1990,\n",
      "pp. 57{69.\n",
      "[Quinlan, 1987] Quinlan, J. R., \\Generating Production Rules from Decision\n",
      "Trees,\" In IJCAI-87: Proceedings of the Tenth Intl. Joint Conf. on Ar-\n",
      "ti\f",
      "cial Intelligence , pp. 304-7, San Francisco: Morgan-Kaufmann, 1987.\n",
      "[Quinlan, 1990] Quinlan, J. R., \\Learning Logical De\f",
      "nitions from Relations,\"\n",
      "Machine Learning , 5, 239-266, 1990.\n",
      "BIBLIOGRAPHY 177\n",
      "[Quinlan, 1993] Quinlan, J. Ross, C4.5: Programs for Machine Learning , San\n",
      "Francisco: Morgan Kaufmann, 1993.\n",
      "[Quinlan, 1994] Quinlan, J. R., \\Comparing Connectionist and Symbolic Learn-\n",
      "ing Methods,\" in Hanson, S., Drastal, G., and Rivest, R., (eds.), Com-\n",
      "putational Learning Theory and Natural Learning Systems, Volume 1:\n",
      "Constraints and Prospects , pp. 445-456,, Cambridge, MA: MIT Press,\n",
      "1994.\n",
      "[Ridgway, 1962] Ridgway, W. C., An Adaptive Logic System with Generalizing\n",
      "Properties , PhD thesis, Tech. Rep. 1556-1, Stanford Electronics Labs.,\n",
      "Stanford, CA, April 1962.\n",
      "[Rissanen, 1978] Rissanen, J., \\Modeling by Shortest Data Description,\" Auto-\n",
      "matica , 14:465-471, 1978.\n",
      "[Rivest, 1987] Rivest, R. L., \\Learning Decision Lists,\" Machine Learning , 2,\n",
      "229-246, 1987.\n",
      "[Rosenblatt, 1958] Rosenblatt, F., Principles of Neurodynamics , Washington:\n",
      "Spartan Books, 1961.\n",
      "[Ross, 1983] Ross, S., Introduction to Stochastic Dynamic Programming , New\n",
      "York: Academic Press, 1983.\n",
      "[Rumelhart, Hinton, & Williams, 1986] Rumelhart, D. E., Hinton, G. E., and\n",
      "Williams, R. J., \\Learning Internal Representations by Error Propa-\n",
      "gation,\" In Rumelhart, D. E., and McClelland, J. L., (eds.) Parallel\n",
      "Distributed Processing , Vol 1, 318{362, 1986.\n",
      "[Russell & Norvig 1995] Russell, S., and Norvig, P., Arti\f",
      "cial Intelligence: A\n",
      "Modern Approach , Englewood Cli\u000b",
      "s, NJ: Prentice Hall, 1995.\n",
      "[Samuel, 1959] Samuel, A., \\Some Studies in Machine Learning Using the Game\n",
      "of Checkers,\" IBM Journal of Research and Development , 3:211-229, July\n",
      "1959.\n",
      "[Schwartz, 1993] Schwartz, A., \\A Reinforcement Learning Method for Max-\n",
      "imizing Undiscounted Rewards,\" Proc. Tenth Intl. Conf. on Machine\n",
      "Learning , pp. 298-305, San Francisco: Morgan Kaufmann, 1993.\n",
      "[Sejnowski, Koch, & Churchland, 1988] Sejnowski, T., Koch, C., and Church-\n",
      "land, P., \\Computational Neuroscience,\" Science ,241: 1299-1306, 1988.\n",
      "[Shavlik, Mooney, & Towell, 1991] Shavlik, J., Mooney, R., and Towell, G.,\n",
      "\\Symbolic and Neural Learning Algorithms: An Experimental Compar-\n",
      "ison,\" Machine Learning , 6, pp. 111-143, 1991.\n",
      "[Shavlik & Dietterich, 1990] Shavlik, J. and Dietterich, T., Readings in Ma-\n",
      "chine Learning , San Francisco: Morgan Kaufmann, 1990.\n",
      "178 BIBLIOGRAPHY\n",
      "[Sutton & Barto, 1987] Sutton, R. S., and Barto, A. G., \\A Temporal-\n",
      "Di\u000b",
      "erence Model of Classical Conditioning,\" in Proceedings of the Ninth\n",
      "Annual Conference of the Cognitive Science Society , Hillsdale, NJ: Erl-\n",
      "baum, 1987.\n",
      "[Sutton, 1988] Sutton, R. S., \\Learning to Predict by the Methods of Temporal\n",
      "Di\u000b",
      "erences,\" Machine Learning 3: 9-44, 1988.\n",
      "[Sutton, 1990] Sutton, R., \\Integrated Architectures for Learning, Planning,\n",
      "and Reacting Based on Approximating Dynamic Programming,\" Proc. of\n",
      "the Seventh Intl. Conf. on Machine Learning , pp. 216-224, San Francisco:\n",
      "Morgan Kaufmann, 1990.\n",
      "[Taylor, Michie, & Spiegalhalter, 1994] Taylor, C., Michie, D., and Spiegal-\n",
      "halter, D., Machine Learning, Neural and Statistical Classi\f",
      "cation ,\n",
      "Paramount Publishing International.\n",
      "[Tesauro, 1992] Tesauro, G., \\Practical Issues in Temporal Di\u000b",
      "erence Learn-\n",
      "ing,\" Machine Learning , 8, nos. 3/4, pp. 257-277, 1992.\n",
      "[Towell & Shavlik, 1992] Towell G., and Shavlik, J., \\Interpretation of Arti\f",
      "-\n",
      "cial Neural Networks: Mapping Knowledge-Based Neural Networks into\n",
      "Rules,\" in Moody, J., Hanson, S., and Lippmann, R., (eds.), Advances in\n",
      "Neural Information Processing Systems, 4 , pp. 977-984, San Francisco:\n",
      "Morgan Kaufmann, 1992.\n",
      "[Towell, Shavlik, & Noordweier, 1990] Towell, G., Shavlik, J., and Noordweier,\n",
      "M., \\Re\f",
      "nement of Approximate Domain Theories by Knowledge-Based\n",
      "Arti\f",
      "cial Neural Networks,\" Proc. Eighth Natl., Conf. on Arti\f",
      "cial In-\n",
      "telligence , pp. 861-866, 1990.\n",
      "[Unger, 1989] Unger, S., The Essence of Logic Circuits , Englewood Cli\u000b",
      "s, NJ:\n",
      "Prentice-Hall, 1989.\n",
      "[Utgo\u000b",
      ", 1989] Utgo\u000b",
      ", P., \\Incremental Induction of Decision Trees,\" Machine\n",
      "Learning , 4:161{186, Nov., 1989.\n",
      "[Valiant, 1984] Valiant, L., \\A Theory of the Learnable,\" Communications of\n",
      "the ACM, Vol. 27 , pp. 1134-1142, 1984.\n",
      "[Vapnik & Chervonenkis, 1971] Vapnik, V., and Chervonenkis, A., \\On the\n",
      "Uniform Convergence of Relative Frequencies, Theory of Probability and\n",
      "its Applications, Vol. 16 , No. 2, pp. 264-280, 1971.\n",
      "[Various Editors, 1989-1994] Advances in Neural Information Processing Sys-\n",
      "tems, vols 1 through 6, San Francisco: Morgan Kaufmann, 1989 -1994.\n",
      "[Watkins & Dayan, 1992] Watkins, C. J. C. H., and Dayan, P., \\Technical Note:\n",
      "Q-Learning,\" Machine Learning , 8, 279-292, 1992.\n",
      "BIBLIOGRAPHY 179\n",
      "[Watkins, 1989] Watkins, C. J. C. H., Learning From Delayed Rewards , PhD\n",
      "Thesis, University of Cambridge, England, 1989.\n",
      "[Weiss & Kulikowski, 1991] Weiss, S., and Kulikowski, C., Computer Systems\n",
      "that Learn , San Francisco: Morgan Kaufmann, 1991.\n",
      "[Werbos, 1974] Werbos, P., Beyond Regression: New Tools for Prediction and\n",
      "Analysis in the Behavioral Sciences , Ph.D. Thesis, Harvard University,\n",
      "1974.\n",
      "[Widrow & Lehr, 1990] Widrow, B., and Lehr, M. A., \\30 Years of Adaptive\n",
      "Neural Networks: Perceptron, Madaline and Backpropagation,\" Proc.\n",
      "IEEE , vol. 78, no. 9, pp. 1415-1442, September, 1990.\n",
      "[Widrow & Stearns, 1985] Widrow, B., and Stearns, S., Adaptive Signal Pro-\n",
      "cessing , Englewood Cli\u000b",
      "s, NJ: Prentice-Hall.\n",
      "[Widrow, 1962] Widrow, B., \\Generalization and Storage in Networks of Ada-\n",
      "line Neurons,\" in Yovits, Jacobi, and Goldstein (eds.), Self-organizing\n",
      "Systems|1962 , pp. 435-461, Washington, DC: Spartan Books, 1962.\n",
      "[Winder, 1961] Winder, R., \\Single Stage Threshold Logic,\" Proc. of the AIEE\n",
      "Symp. on Switching Circuits and Logical Design , Conf. paper CP-60-\n",
      "1261, pp. 321-332, 1961.\n",
      "[Winder, 1962] Winder, R., Threshold Logic , PhD Dissertation, Princeton Uni-\n",
      "versity, Princeton, NJ, 1962.\n",
      "[Wnek, et al. , 1990] Wnek, J., et al. , \\Comparing Learning Paradigms via Di-\n",
      "agrammatic Visualization,\" in Proc. Fifth Intl. Symp. on Methodologies\n",
      "for Intelligent Systems , pp. 428-437, 1990. (Also Tech. Report MLI90-2,\n",
      "University of Illinois at Urbana-Champaign.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efefac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTRODUCTION\n",
      "TO\n",
      "MACHINE LEARNING\n",
      "AN EARLY DRAFT OF A PROPOSED\n",
      "TEXTBOOK\n",
      "Nils J. Nilsson\n",
      "Robotics Laboratory\n",
      "Department of Computer Science\n",
      "Stanford University\n"
     ]
    }
   ],
   "source": [
    "print(text[0:157])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee02d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.21.1-cp39-cp39-win_amd64.whl (11.7 MB)\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.21.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57600ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTRODUCTION\n",
      "TO\n",
      "MACHINE LEARNING\n",
      "AN EARLY DRAFT OF A PROPOSED\n",
      "TEXTBOOK\n",
      "Nils J. Nilsson\n",
      "Robotics Laboratory\n",
      "Department of Computer Science\n",
      "Stanford University\n",
      "Stanford, CA 94305\n",
      "e-mail: nilsson@cs.stanford.edu\n",
      "November 3, 1998\n",
      "Copyright c⃝2005 Nils J. Nilsson\n",
      "This material may not be copied, reproduced, or distributed without the\n",
      "written permission of the copyright holder.\n",
      "ii\n",
      "Contents\n",
      "1\n",
      "Preliminaries\n",
      "1\n",
      "1.1\n",
      "Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "1\n",
      "1.1.1\n",
      "What is Machine Learning? . . . . . . . . . . . . . . . . .\n",
      "1\n",
      "1.1.2\n",
      "Wellsprings of Machine Learning . . . . . . . . . . . . . .\n",
      "3\n",
      "1.1.3\n",
      "Varieties of Machine Learning . . . . . . . . . . . . . . . .\n",
      "4\n",
      "1.2\n",
      "Learning Input-Output Functions . . . . . . . . . . . . . . . . . .\n",
      "5\n",
      "1.2.1\n",
      "Types of Learning\n",
      ". . . . . . . . . . . . . . . . . . . . . .\n",
      "5\n",
      "1.2.2\n",
      "Input Vectors . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "7\n",
      "1.2.3\n",
      "Outputs . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "8\n",
      "1.2.4\n",
      "Training Regimes . . . . . . . . . . . . . . . . . . . . . . .\n",
      "8\n",
      "1.2.5\n",
      "Noise\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "9\n",
      "1.2.6\n",
      "Performance Evaluation . . . . . . . . . . . . . . . . . . .\n",
      "9\n",
      "1.3\n",
      "Learning Requires Bias . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "9\n",
      "1.4\n",
      "Sample Applications . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "11\n",
      "1.5\n",
      "Sources\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "13\n",
      "1.6\n",
      "Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . .\n",
      "13\n",
      "2\n",
      "Boolean Functions\n",
      "15\n",
      "2.1\n",
      "Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "15\n",
      "2.1.1\n",
      "Boolean Algebra . . . . . . . . . . . . . . . . . . . . . . .\n",
      "15\n",
      "2.1.2\n",
      "Diagrammatic Representations . . . . . . . . . . . . . . .\n",
      "16\n",
      "2.2\n",
      "Classes of Boolean Functions\n",
      ". . . . . . . . . . . . . . . . . . . .\n",
      "17\n",
      "2.2.1\n",
      "Terms and Clauses . . . . . . . . . . . . . . . . . . . . . .\n",
      "17\n",
      "2.2.2\n",
      "DNF Functions . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "18\n",
      "2.2.3\n",
      "CNF Functions . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "21\n",
      "2.2.4\n",
      "Decision Lists . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "22\n",
      "2.2.5\n",
      "Symmetric and Voting Functions . . . . . . . . . . . . . .\n",
      "23\n",
      "2.2.6\n",
      "Linearly Separable Functions . . . . . . . . . . . . . . . .\n",
      "23\n",
      "2.3\n",
      "Summary\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "24\n",
      "2.4\n",
      "Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . .\n",
      "25\n",
      "iii\n",
      "3\n",
      "Using Version Spaces for Learning\n",
      "27\n",
      "3.1\n",
      "Version Spaces and Mistake Bounds\n",
      ". . . . . . . . . . . . . . . .\n",
      "27\n",
      "3.2\n",
      "Version Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "29\n",
      "3.3\n",
      "Learning as Search of a Version Space\n",
      ". . . . . . . . . . . . . . .\n",
      "32\n",
      "3.4\n",
      "The Candidate Elimination Method\n",
      ". . . . . . . . . . . . . . . .\n",
      "32\n",
      "3.5\n",
      "Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . .\n",
      "34\n",
      "4\n",
      "Neural Networks\n",
      "35\n",
      "4.1\n",
      "Threshold Logic Units . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "35\n",
      "4.1.1\n",
      "Deﬁnitions and Geometry . . . . . . . . . . . . . . . . . .\n",
      "35\n",
      "4.1.2\n",
      "Special Cases of Linearly Separable Functions . . . . . . .\n",
      "37\n",
      "4.1.3\n",
      "Error-Correction Training of a TLU\n",
      ". . . . . . . . . . . .\n",
      "38\n",
      "4.1.4\n",
      "Weight Space . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "40\n",
      "4.1.5\n",
      "The Widrow-Hoﬀ Procedure . . . . . . . . . . . . . . . . .\n",
      "42\n",
      "4.1.6\n",
      "Training a TLU on Non-Linearly-Separable Training Sets\n",
      "44\n",
      "4.2\n",
      "Linear Machines\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "44\n",
      "4.3\n",
      "Networks of TLUs\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "46\n",
      "4.3.1\n",
      "Motivation and Examples . . . . . . . . . . . . . . . . . .\n",
      "46\n",
      "4.3.2\n",
      "Madalines . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "49\n",
      "4.3.3\n",
      "Piecewise Linear Machines . . . . . . . . . . . . . . . . . .\n",
      "50\n",
      "4.3.4\n",
      "Cascade Networks\n",
      ". . . . . . . . . . . . . . . . . . . . . .\n",
      "51\n",
      "4.4\n",
      "Training Feedforward Networks by Backpropagation . . . . . . .\n",
      "52\n",
      "4.4.1\n",
      "Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "52\n",
      "4.4.2\n",
      "The Backpropagation Method . . . . . . . . . . . . . . . .\n",
      "53\n",
      "4.4.3\n",
      "Computing Weight Changes in the Final Layer . . . . . .\n",
      "56\n",
      "4.4.4\n",
      "Computing Changes to the Weights in Intermediate Layers 58\n",
      "4.4.5\n",
      "Variations on Backprop\n",
      ". . . . . . . . . . . . . . . . . . .\n",
      "59\n",
      "4.4.6\n",
      "An Application: Steering a Van . . . . . . . . . . . . . . .\n",
      "60\n",
      "4.5\n",
      "Synergies Between Neural Network and Knowledge-Based Methods 61\n",
      "4.6\n",
      "Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . .\n",
      "61\n",
      "5\n",
      "Statistical Learning\n",
      "63\n",
      "5.1\n",
      "Using Statistical Decision Theory . . . . . . . . . . . . . . . . . .\n",
      "63\n",
      "5.1.1\n",
      "Background and General Method . . . . . . . . . . . . . .\n",
      "63\n",
      "5.1.2\n",
      "Gaussian (or Normal) Distributions\n",
      ". . . . . . . . . . . .\n",
      "65\n",
      "5.1.3\n",
      "Conditionally Independent Binary Components . . . . . .\n",
      "68\n",
      "5.2\n",
      "Learning Belief Networks\n",
      ". . . . . . . . . . . . . . . . . . . . . .\n",
      "70\n",
      "5.3\n",
      "Nearest-Neighbor Methods . . . . . . . . . . . . . . . . . . . . . .\n",
      "70\n",
      "5.4\n",
      "Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . .\n",
      "72\n",
      "iv\n",
      "6\n",
      "Decision Trees\n",
      "73\n",
      "6.1\n",
      "Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "73\n",
      "6.2\n",
      "Supervised Learning of Univariate Decision Trees . . . . . . . . .\n",
      "74\n",
      "6.2.1\n",
      "Selecting the Type of Test . . . . . . . . . . . . . . . . . .\n",
      "75\n",
      "6.2.2\n",
      "Using Uncertainty Reduction to Select Tests\n",
      ". . . . . . .\n",
      "75\n",
      "6.2.3\n",
      "Non-Binary Attributes . . . . . . . . . . . . . . . . . . . .\n",
      "79\n",
      "6.3\n",
      "Networks Equivalent to Decision Trees . . . . . . . . . . . . . . .\n",
      "79\n",
      "6.4\n",
      "Overﬁtting and Evaluation\n",
      ". . . . . . . . . . . . . . . . . . . . .\n",
      "80\n",
      "6.4.1\n",
      "Overﬁtting\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "80\n",
      "6.4.2\n",
      "Validation Methods\n",
      ". . . . . . . . . . . . . . . . . . . . .\n",
      "81\n",
      "6.4.3\n",
      "Avoiding Overﬁtting in Decision Trees . . . . . . . . . . .\n",
      "82\n",
      "6.4.4\n",
      "Minimum-Description Length Methods . . . . . . . . . . .\n",
      "83\n",
      "6.4.5\n",
      "Noise in Data . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "84\n",
      "6.5\n",
      "The Problem of Replicated Subtrees . . . . . . . . . . . . . . . .\n",
      "84\n",
      "6.6\n",
      "The Problem of Missing Attributes . . . . . . . . . . . . . . . . .\n",
      "86\n",
      "6.7\n",
      "Comparisons\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "86\n",
      "6.8\n",
      "Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . .\n",
      "87\n",
      "7\n",
      "Inductive Logic Programming\n",
      "89\n",
      "7.1\n",
      "Notation and Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . .\n",
      "90\n",
      "7.2\n",
      "A Generic ILP Algorithm . . . . . . . . . . . . . . . . . . . . . .\n",
      "91\n",
      "7.3\n",
      "An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "94\n",
      "7.4\n",
      "Inducing Recursive Programs . . . . . . . . . . . . . . . . . . . .\n",
      "98\n",
      "7.5\n",
      "Choosing Literals to Add\n",
      ". . . . . . . . . . . . . . . . . . . . . . 100\n",
      "7.6\n",
      "Relationships Between ILP and Decision Tree Induction . . . . . 101\n",
      "7.7\n",
      "Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . . 104\n",
      "8\n",
      "Computational Learning Theory\n",
      "107\n",
      "8.1\n",
      "Notation and Assumptions for PAC Learning Theory . . . . . . . 107\n",
      "8.2\n",
      "PAC Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n",
      "8.2.1\n",
      "The Fundamental Theorem . . . . . . . . . . . . . . . . . 109\n",
      "8.2.2\n",
      "Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n",
      "8.2.3\n",
      "Some Properly PAC-Learnable Classes . . . . . . . . . . . 112\n",
      "8.3\n",
      "The Vapnik-Chervonenkis Dimension . . . . . . . . . . . . . . . . 113\n",
      "8.3.1\n",
      "Linear Dichotomies . . . . . . . . . . . . . . . . . . . . . . 113\n",
      "8.3.2\n",
      "Capacity\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n",
      "8.3.3\n",
      "A More General Capacity Result . . . . . . . . . . . . . . 116\n",
      "8.3.4\n",
      "Some Facts and Speculations About the VC Dimension\n",
      ". 117\n",
      "8.4\n",
      "VC Dimension and PAC Learning\n",
      ". . . . . . . . . . . . . . . . . 118\n",
      "8.5\n",
      "Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . . 118\n",
      "v\n",
      "9\n",
      "Unsupervised Learning\n",
      "119\n",
      "9.1\n",
      "What is Unsupervised Learning? . . . . . . . . . . . . . . . . . . 119\n",
      "9.2\n",
      "Clustering Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n",
      "9.2.1\n",
      "A Method Based on Euclidean Distance . . . . . . . . . . 120\n",
      "9.2.2\n",
      "A Method Based on Probabilities . . . . . . . . . . . . . . 124\n",
      "9.3\n",
      "Hierarchical Clustering Methods\n",
      ". . . . . . . . . . . . . . . . . . 125\n",
      "9.3.1\n",
      "A Method Based on Euclidean Distance . . . . . . . . . . 125\n",
      "9.3.2\n",
      "A Method Based on Probabilities . . . . . . . . . . . . . . 126\n",
      "9.4\n",
      "Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . . 130\n",
      "10 Temporal-Diﬀerence Learning\n",
      "131\n",
      "10.1 Temporal Patterns and Prediction Problems . . . . . . . . . . . . 131\n",
      "10.2 Supervised and Temporal-Diﬀerence Methods . . . . . . . . . . . 131\n",
      "10.3 Incremental Computation of the (∆W)i . . . . . . . . . . . . . . 134\n",
      "10.4 An Experiment with TD Methods\n",
      ". . . . . . . . . . . . . . . . . 135\n",
      "10.5 Theoretical Results . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n",
      "10.6 Intra-Sequence Weight Updating . . . . . . . . . . . . . . . . . . 138\n",
      "10.7 An Example Application: TD-gammon . . . . . . . . . . . . . . . 140\n",
      "10.8 Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . . 141\n",
      "11 Delayed-Reinforcement Learning\n",
      "143\n",
      "11.1 The General Problem\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . 143\n",
      "11.2 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n",
      "11.3 Temporal Discounting and Optimal Policies . . . . . . . . . . . . 145\n",
      "11.4 Q-Learning\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n",
      "11.5 Discussion, Limitations, and Extensions of Q-Learning . . . . . . 150\n",
      "11.5.1 An Illustrative Example . . . . . . . . . . . . . . . . . . . 150\n",
      "11.5.2 Using Random Actions\n",
      ". . . . . . . . . . . . . . . . . . . 152\n",
      "11.5.3 Generalizing Over Inputs\n",
      ". . . . . . . . . . . . . . . . . . 153\n",
      "11.5.4 Partially Observable States . . . . . . . . . . . . . . . . . 154\n",
      "11.5.5 Scaling Problems . . . . . . . . . . . . . . . . . . . . . . . 154\n",
      "11.6 Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . . 155\n",
      "vi\n",
      "12 Explanation-Based Learning\n",
      "157\n",
      "12.1 Deductive Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 157\n",
      "12.2 Domain Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n",
      "12.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n",
      "12.4 Evaluable Predicates . . . . . . . . . . . . . . . . . . . . . . . . . 162\n",
      "12.5 More General Proofs . . . . . . . . . . . . . . . . . . . . . . . . . 164\n",
      "12.6 Utility of EBL\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n",
      "12.7 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n",
      "12.7.1 Macro-Operators in Planning . . . . . . . . . . . . . . . . 164\n",
      "12.7.2 Learning Search Control Knowledge\n",
      ". . . . . . . . . . . . 167\n",
      "12.8 Bibliographical and Historical Remarks\n",
      ". . . . . . . . . . . . . . 168\n",
      "vii\n",
      "viii\n",
      "Preface\n",
      "These notes are in the process of becoming a textbook. The process is quite\n",
      "unﬁnished, and the author solicits corrections, criticisms, and suggestions from\n",
      "students and other readers. Although I have tried to eliminate errors, some un-\n",
      "doubtedly remain—caveat lector. Many typographical infelicities will no doubt\n",
      "persist until the ﬁnal version. More material has yet to be added. Please let\n",
      "Some of my plans for additions and\n",
      "other reminders are mentioned in\n",
      "marginal notes.\n",
      "me have your suggestions about topics that are too important to be left out.\n",
      "I hope that future versions will cover Hopﬁeld nets, Elman nets and other re-\n",
      "current nets, radial basis functions, grammar and automata learning, genetic\n",
      "algorithms, and Bayes networks . . .. I am also collecting exercises and project\n",
      "suggestions which will appear in future versions.\n",
      "My intention is to pursue a middle ground between a theoretical textbook\n",
      "and one that focusses on applications. The book concentrates on the important\n",
      "ideas in machine learning. I do not give proofs of many of the theorems that I\n",
      "state, but I do give plausibility arguments and citations to formal proofs. And, I\n",
      "do not treat many matters that would be of practical importance in applications;\n",
      "the book is not a handbook of machine learning practice. Instead, my goal is\n",
      "to give the reader suﬃcient preparation to make the extensive literature on\n",
      "machine learning accessible.\n",
      "Students in my Stanford courses on machine learning have already made\n",
      "several useful suggestions, as have my colleague, Pat Langley, and my teaching\n",
      "assistants, Ron Kohavi, Karl Pﬂeger, Robert Allen, and Lise Getoor.\n",
      "ix\n",
      "Chapter 1\n",
      "Preliminaries\n",
      "1.1\n",
      "Introduction\n",
      "1.1.1\n",
      "What is Machine Learning?\n",
      "Learning, like intelligence, covers such a broad range of processes that it is dif-\n",
      "ﬁcult to deﬁne precisely. A dictionary deﬁnition includes phrases such as “to\n",
      "gain knowledge, or understanding of, or skill in, by study, instruction, or expe-\n",
      "rience,” and “modiﬁcation of a behavioral tendency by experience.” Zoologists\n",
      "and psychologists study learning in animals and humans. In this book we fo-\n",
      "cus on learning in machines. There are several parallels between animal and\n",
      "machine learning. Certainly, many techniques in machine learning derive from\n",
      "the eﬀorts of psychologists to make more precise their theories of animal and\n",
      "human learning through computational models. It seems likely also that the\n",
      "concepts and techniques being explored by researchers in machine learning may\n",
      "illuminate certain aspects of biological learning.\n",
      "As regards machines, we might say, very broadly, that a machine learns\n",
      "whenever it changes its structure, program, or data (based on its inputs or in\n",
      "response to external information) in such a manner that its expected future\n",
      "performance improves. Some of these changes, such as the addition of a record\n",
      "to a data base, fall comfortably within the province of other disciplines and are\n",
      "not necessarily better understood for being called learning. But, for example,\n",
      "when the performance of a speech-recognition machine improves after hearing\n",
      "several samples of a person’s speech, we feel quite justiﬁed in that case to say\n",
      "that the machine has learned.\n",
      "Machine learning usually refers to the changes in systems that perform tasks\n",
      "associated with artiﬁcial intelligence (AI). Such tasks involve recognition, diag-\n",
      "nosis, planning, robot control, prediction, etc. The “changes” might be either\n",
      "enhancements to already performing systems or ab initio synthesis of new sys-\n",
      "tems. To be slightly more speciﬁc, we show the architecture of a typical AI\n",
      "1\n",
      "2\n",
      "CHAPTER 1. PRELIMINARIES\n",
      "“agent” in Fig. 1.1. This agent perceives and models its environment and com-\n",
      "putes appropriate actions, perhaps by anticipating their eﬀects. Changes made\n",
      "to any of the components shown in the ﬁgure might count as learning. Diﬀerent\n",
      "learning mechanisms might be employed depending on which subsystem is being\n",
      "changed. We will study several diﬀerent learning methods in this book.\n",
      "Sensory signals\n",
      "Perception\n",
      "Actions\n",
      "Action\n",
      "Computation\n",
      "Model\n",
      "Planning and\n",
      "Reasoning\n",
      "Goals\n",
      "Figure 1.1: An AI System\n",
      "One might ask “Why should machines have to learn? Why not design ma-\n",
      "chines to perform as desired in the ﬁrst place?” There are several reasons why\n",
      "machine learning is important. Of course, we have already mentioned that the\n",
      "achievement of learning in machines might help us understand how animals and\n",
      "humans learn. But there are important engineering reasons as well. Some of\n",
      "these are:\n",
      "• Some tasks cannot be deﬁned well except by example; that is, we might be\n",
      "able to specify input/output pairs but not a concise relationship between\n",
      "inputs and desired outputs. We would like machines to be able to adjust\n",
      "their internal structure to produce correct outputs for a large number of\n",
      "sample inputs and thus suitably constrain their input/output function to\n",
      "approximate the relationship implicit in the examples.\n",
      "• It is possible that hidden among large piles of data are important rela-\n",
      "tionships and correlations. Machine learning methods can often be used\n",
      "to extract these relationships (data mining).\n",
      "1.1. INTRODUCTION\n",
      "3\n",
      "• Human designers often produce machines that do not work as well as\n",
      "desired in the environments in which they are used. In fact, certain char-\n",
      "acteristics of the working environment might not be completely known\n",
      "at design time.\n",
      "Machine learning methods can be used for on-the-job\n",
      "improvement of existing machine designs.\n",
      "• The amount of knowledge available about certain tasks might be too large\n",
      "for explicit encoding by humans.\n",
      "Machines that learn this knowledge\n",
      "gradually might be able to capture more of it than humans would want to\n",
      "write down.\n",
      "• Environments change over time. Machines that can adapt to a changing\n",
      "environment would reduce the need for constant redesign.\n",
      "• New knowledge about tasks is constantly being discovered by humans.\n",
      "Vocabulary changes.\n",
      "There is a constant stream of new events in the\n",
      "world. Continuing redesign of AI systems to conform to new knowledge is\n",
      "impractical, but machine learning methods might be able to track much\n",
      "of it.\n",
      "1.1.2\n",
      "Wellsprings of Machine Learning\n",
      "Work in machine learning is now converging from several sources. These dif-\n",
      "ferent traditions each bring diﬀerent methods and diﬀerent vocabulary which\n",
      "are now being assimilated into a more uniﬁed discipline. Here is a brief listing\n",
      "of some of the separate disciplines that have contributed to machine learning;\n",
      "more details will follow in the the appropriate chapters:\n",
      "• Statistics: A long-standing problem in statistics is how best to use sam-\n",
      "ples drawn from unknown probability distributions to help decide from\n",
      "which distribution some new sample is drawn. A related problem is how\n",
      "to estimate the value of an unknown function at a new point given the\n",
      "values of this function at a set of sample points.\n",
      "Statistical methods\n",
      "for dealing with these problems can be considered instances of machine\n",
      "learning because the decision and estimation rules depend on a corpus of\n",
      "samples drawn from the problem environment. We will explore some of\n",
      "the statistical methods later in the book. Details about the statistical the-\n",
      "ory underlying these methods can be found in statistical textbooks such\n",
      "as [Anderson, 1958].\n",
      "• Brain\n",
      "Models:\n",
      "Non-linear\n",
      "elements\n",
      "with\n",
      "weighted\n",
      "inputs\n",
      "have\n",
      "been\n",
      "suggested\n",
      "as\n",
      "simple\n",
      "models\n",
      "of\n",
      "biological\n",
      "neu-\n",
      "rons.\n",
      "Networks\n",
      "of\n",
      "these\n",
      "elements\n",
      "have\n",
      "been\n",
      "studied\n",
      "by\n",
      "sev-\n",
      "eral\n",
      "researchers\n",
      "including\n",
      "[McCulloch & Pitts, 1943,\n",
      "Hebb, 1949,\n",
      "Rosenblatt, 1958] and,\n",
      "more recently by [Gluck & Rumelhart, 1989,\n",
      "Sejnowski, Koch, & Churchland, 1988].\n",
      "Brain modelers are interested\n",
      "in how closely these networks approximate the learning phenomena of\n",
      "4\n",
      "CHAPTER 1. PRELIMINARIES\n",
      "living brains.\n",
      "We shall see that several important machine learning\n",
      "techniques are based on networks of nonlinear elements—often called\n",
      "neural networks.\n",
      "Work inspired by this school is sometimes called\n",
      "connectionism, brain-style computation, or sub-symbolic processing.\n",
      "• Adaptive Control Theory: Control theorists study the problem of con-\n",
      "trolling a process having unknown parameters which must be estimated\n",
      "during operation. Often, the parameters change during operation, and the\n",
      "control process must track these changes. Some aspects of controlling a\n",
      "robot based on sensory inputs represent instances of this sort of problem.\n",
      "For an introduction see [Bollinger & Duﬃe, 1988].\n",
      "• Psychological Models: Psychologists have studied the performance of\n",
      "humans in various learning tasks. An early example is the EPAM net-\n",
      "work for storing and retrieving one member of a pair of words when\n",
      "given another [Feigenbaum, 1961].\n",
      "Related work led to a number of\n",
      "early decision tree [Hunt, Marin, & Stone, 1966] and semantic network\n",
      "[Anderson & Bower, 1973] methods.\n",
      "More recent work of this sort has\n",
      "been inﬂuenced by activities in artiﬁcial intelligence which we will be pre-\n",
      "senting.\n",
      "Some of the work in reinforcement learning can be traced to eﬀorts to\n",
      "model how reward stimuli inﬂuence the learning of goal-seeking behavior in\n",
      "animals [Sutton & Barto, 1987]. Reinforcement learning is an important\n",
      "theme in machine learning research.\n",
      "• Artiﬁcial Intelligence: From the beginning, AI research has been con-\n",
      "cerned with machine learning. Samuel developed a prominent early pro-\n",
      "gram that learned parameters of a function for evaluating board posi-\n",
      "tions in the game of checkers [Samuel, 1959].\n",
      "AI researchers have also\n",
      "explored the role of analogies in learning [Carbonell, 1983] and how fu-\n",
      "ture actions and decisions can be based on previous exemplary cases\n",
      "[Kolodner, 1993].\n",
      "Recent work has been directed at discovering rules\n",
      "for expert systems using decision-tree methods [Quinlan, 1990] and in-\n",
      "ductive logic programming [Muggleton, 1991, Lavraˇc & Dˇzeroski, 1994].\n",
      "Another theme has been saving and generalizing the results of prob-\n",
      "lem solving using explanation-based learning [DeJong & Mooney, 1986,\n",
      "Laird, et al., 1986, Minton, 1988, Etzioni, 1993].\n",
      "• Evolutionary Models:\n",
      "In nature, not only do individual animals learn to perform better, but\n",
      "species evolve to be better ﬁt in their individual niches. Since the distinc-\n",
      "tion between evolving and learning can be blurred in computer systems,\n",
      "techniques that model certain aspects of biological evolution have been\n",
      "proposed as learning methods to improve the performance of computer\n",
      "programs. Genetic algorithms [Holland, 1975] and genetic programming\n",
      "[Koza, 1992, Koza, 1994] are the most prominent computational tech-\n",
      "niques for evolution.\n",
      "1.2. LEARNING INPUT-OUTPUT FUNCTIONS\n",
      "5\n",
      "1.1.3\n",
      "Varieties of Machine Learning\n",
      "Orthogonal to the question of the historical source of any learning technique is\n",
      "the more important question of what is to be learned. In this book, we take it\n",
      "that the thing to be learned is a computational structure of some sort. We will\n",
      "consider a variety of diﬀerent computational structures:\n",
      "• Functions\n",
      "• Logic programs and rule sets\n",
      "• Finite-state machines\n",
      "• Grammars\n",
      "• Problem solving systems\n",
      "We will present methods both for the synthesis of these structures from examples\n",
      "and for changing existing structures.\n",
      "In the latter case, the change to the\n",
      "existing structure might be simply to make it more computationally eﬃcient\n",
      "rather than to increase the coverage of the situations it can handle. Much of\n",
      "the terminology that we shall be using throughout the book is best introduced\n",
      "by discussing the problem of learning functions, and we turn to that matter\n",
      "ﬁrst.\n",
      "1.2\n",
      "Learning Input-Output Functions\n",
      "We use Fig. 1.2 to help deﬁne some of the terminology used in describing the\n",
      "problem of learning a function. Imagine that there is a function, f, and the task\n",
      "of the learner is to guess what it is. Our hypothesis about the function to be\n",
      "learned is denoted by h. Both f and h are functions of a vector-valued input\n",
      "X = (x1, x2, . . . , xi, . . . , xn) which has n components. We think of h as being\n",
      "implemented by a device that has X as input and h(X) as output. Both f and\n",
      "h themselves may be vector-valued. We assume a priori that the hypothesized\n",
      "function, h, is selected from a class of functions H. Sometimes we know that\n",
      "f also belongs to this class or to a subset of this class. We select h based on a\n",
      "training set, Ξ, of m input vector examples. Many important details depend on\n",
      "the nature of the assumptions made about all of these entities.\n",
      "1.2.1\n",
      "Types of Learning\n",
      "There are two major settings in which we wish to learn a function. In one,\n",
      "called supervised learning, we know (sometimes only approximately) the values\n",
      "of f for the m samples in the training set, Ξ. We assume that if we can ﬁnd\n",
      "a hypothesis, h, that closely agrees with f for the members of Ξ, then this\n",
      "hypothesis will be a good guess for f—especially if Ξ is large.\n",
      "6\n",
      "CHAPTER 1. PRELIMINARIES\n",
      "h(X)\n",
      "h\n",
      "� = {X1, X2, . . . Xi, . . ., Xm}\n",
      "Training Set:\n",
      "X =\n",
      "x1\n",
      ".\n",
      ".\n",
      ".\n",
      "xi\n",
      ".\n",
      ".\n",
      ".\n",
      "xn\n",
      "h � H\n",
      "Figure 1.2: An Input-Output Function\n",
      "Curve-ﬁtting is a simple example of supervised learning of a function. Sup-\n",
      "pose we are given the values of a two-dimensional function, f, at the four sample\n",
      "points shown by the solid circles in Fig. 1.3. We want to ﬁt these four points\n",
      "with a function, h, drawn from the set, H, of second-degree functions. We show\n",
      "there a two-dimensional parabolic surface above the x1, x2 plane that ﬁts the\n",
      "points. This parabolic function, h, is our hypothesis about the function, f, that\n",
      "produced the four samples. In this case, h = f at the four samples, but we need\n",
      "not have required exact matches.\n",
      "In the other setting, termed unsupervised learning, we simply have a train-\n",
      "ing set of vectors without function values for them. The problem in this case,\n",
      "typically, is to partition the training set into subsets, Ξ1, . . . , ΞR, in some ap-\n",
      "propriate way. (We can still regard the problem as one of learning a function;\n",
      "the value of the function is the name of the subset to which an input vector be-\n",
      "longs.) Unsupervised learning methods have application in taxonomic problems\n",
      "in which it is desired to invent ways to classify data into meaningful categories.\n",
      "We shall also describe methods that are intermediate between supervised\n",
      "and unsupervised learning.\n",
      "We might either be trying to ﬁnd a new function, h, or to modify an existing\n",
      "one. An interesting special case is that of changing an existing function into an\n",
      "equivalent one that is computationally more eﬃcient. This type of learning is\n",
      "sometimes called speed-up learning. A very simple example of speed-up learning\n",
      "involves deduction processes. From the formulas A ⊃ B and B ⊃ C, we can\n",
      "deduce C if we are given A. From this deductive process, we can create the\n",
      "formula A ⊃ C—a new formula but one that does not sanction any more con-\n",
      "1.2. LEARNING INPUT-OUTPUT FUNCTIONS\n",
      "7\n",
      "-10\n",
      "-5\n",
      "0\n",
      "5\n",
      "10-10\n",
      "-5\n",
      "0\n",
      "5\n",
      "10\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "-10\n",
      "-5\n",
      "0\n",
      "5\n",
      "10-10\n",
      "-5\n",
      "0\n",
      "5\n",
      "10\n",
      "0\n",
      "00\n",
      "00\n",
      "0\n",
      "x1\n",
      "x2\n",
      "h\n",
      "sample f-value\n",
      "Figure 1.3: A Surface that Fits Four Points\n",
      "clusions than those that could be derived from the formulas that we previously\n",
      "had. But with this new formula we can derive C more quickly, given A, than\n",
      "we could have done before. We can contrast speed-up learning with methods\n",
      "that create genuinely new functions—ones that might give diﬀerent results after\n",
      "learning than they did before. We say that the latter methods involve inductive\n",
      "learning. As opposed to deduction, there are no correct inductions—only useful\n",
      "ones.\n",
      "1.2.2\n",
      "Input Vectors\n",
      "Because machine learning methods derive from so many diﬀerent traditions, its\n",
      "terminology is rife with synonyms, and we will be using most of them in this\n",
      "book. For example, the input vector is called by a variety of names. Some\n",
      "of these are: input vector, pattern vector, feature vector, sample, example, and\n",
      "instance. The components, xi, of the input vector are variously called features,\n",
      "attributes, input variables, and components.\n",
      "The values of the components can be of three main types.\n",
      "They might\n",
      "be real-valued numbers, discrete-valued numbers, or categorical values. As an\n",
      "example illustrating categorical values, information about a student might be\n",
      "represented by the values of the attributes class, major, sex, adviser. A par-\n",
      "ticular student would then be represented by a vector such as: (sophomore,\n",
      "history, male, higgins). Additionally, categorical values may be ordered (as in\n",
      "{small, medium, large}) or unordered (as in the example just given). Of course,\n",
      "mixtures of all these types of values are possible.\n",
      "In all cases, it is possible to represent the input in unordered form by listing\n",
      "the names of the attributes together with their values. The vector form assumes\n",
      "that the attributes are ordered and given implicitly by a form. As an example\n",
      "of an attribute-value representation, we might have: (major: history, sex: male,\n",
      "8\n",
      "CHAPTER 1. PRELIMINARIES\n",
      "class: sophomore, adviser: higgins, age: 19). We will be using the vector form\n",
      "exclusively.\n",
      "An important specialization uses Boolean values, which can be regarded as\n",
      "a special case of either discrete numbers (1,0) or of categorical variables (True,\n",
      "False).\n",
      "1.2.3\n",
      "Outputs\n",
      "The output may be a real number, in which case the process embodying the\n",
      "function, h, is called a function estimator, and the output is called an output\n",
      "value or estimate.\n",
      "Alternatively, the output may be a categorical value, in which case the pro-\n",
      "cess embodying h is variously called a classiﬁer, a recognizer, or a categorizer,\n",
      "and the output itself is called a label, a class, a category, or a decision. Classi-\n",
      "ﬁers have application in a number of recognition problems, for example in the\n",
      "recognition of hand-printed characters. The input in that case is some suitable\n",
      "representation of the printed character, and the classiﬁer maps this input into\n",
      "one of, say, 64 categories.\n",
      "Vector-valued outputs are also possible with components being real numbers\n",
      "or categorical values.\n",
      "An important special case is that of Boolean output values. In that case,\n",
      "a training pattern having value 1 is called a positive instance, and a training\n",
      "sample having value 0 is called a negative instance. When the input is also\n",
      "Boolean, the classiﬁer implements a Boolean function. We study the Boolean\n",
      "case in some detail because it allows us to make important general points in\n",
      "a simpliﬁed setting. Learning a Boolean function is sometimes called concept\n",
      "learning, and the function is called a concept.\n",
      "1.2.4\n",
      "Training Regimes\n",
      "There are several ways in which the training set, Ξ, can be used to produce a\n",
      "hypothesized function. In the batch method, the entire training set is available\n",
      "and used all at once to compute the function, h. A variation of this method\n",
      "uses the entire training set to modify a current hypothesis iteratively until an\n",
      "acceptable hypothesis is obtained. By contrast, in the incremental method, we\n",
      "select one member at a time from the training set and use this instance alone\n",
      "to modify a current hypothesis. Then another member of the training set is\n",
      "selected, and so on. The selection method can be random (with replacement)\n",
      "or it can cycle through the training set iteratively. If the entire training set\n",
      "becomes available one member at a time, then we might also use an incremental\n",
      "method—selecting and using training set members as they arrive. (Alterna-\n",
      "tively, at any stage all training set members so far available could be used in a\n",
      "“batch” process.) Using the training set members as they become available is\n",
      "called an online method. Online methods might be used, for example, when the\n",
      "1.3. LEARNING REQUIRES BIAS\n",
      "9\n",
      "next training instance is some function of the current hypothesis and the previ-\n",
      "ous instance—as it would be when a classiﬁer is used to decide on a robot’s next\n",
      "action given its current set of sensory inputs. The next set of sensory inputs\n",
      "will depend on which action was selected.\n",
      "1.2.5\n",
      "Noise\n",
      "Sometimes the vectors in the training set are corrupted by noise. There are two\n",
      "kinds of noise. Class noise randomly alters the value of the function; attribute\n",
      "noise randomly alters the values of the components of the input vector. In either\n",
      "case, it would be inappropriate to insist that the hypothesized function agree\n",
      "precisely with the values of the samples in the training set.\n",
      "1.2.6\n",
      "Performance Evaluation\n",
      "Even though there is no correct answer in inductive learning, it is important\n",
      "to have methods to evaluate the result of learning. We will discuss this matter\n",
      "in more detail later, but, brieﬂy, in supervised learning the induced function is\n",
      "usually evaluated on a separate set of inputs and function values for them called\n",
      "the testing set . A hypothesized function is said to generalize when it guesses\n",
      "well on the testing set. Both mean-squared-error and the total number of errors\n",
      "are common measures.\n",
      "1.3\n",
      "Learning Requires Bias\n",
      "Long before now the reader has undoubtedly asked why is learning a function\n",
      "possible at all? Certainly, for example, there are an uncountable number of\n",
      "diﬀerent functions having values that agree with the four samples shown in Fig.\n",
      "1.3. Why would a learning procedure happen to select the quadratic one shown\n",
      "in that ﬁgure? In order to make that selection we had at least to limit a priori\n",
      "the set of hypotheses to quadratic functions and then to insist that the one we\n",
      "chose passed through all four sample points. This kind of a priori information\n",
      "is called bias, and useful learning without bias is impossible.\n",
      "We can gain more insight into the role of bias by considering the special case\n",
      "of learning a Boolean function of n dimensions. There are 2n diﬀerent Boolean\n",
      "inputs possible. Suppose we had no bias; that is H is the set of all 22n Boolean\n",
      "functions, and we have no preference among those that ﬁt the samples in the\n",
      "training set. In this case, after being presented with one member of the training\n",
      "set and its value we can rule out precisely one-half of the members of H—those\n",
      "Boolean functions that would misclassify this labeled sample. The remaining\n",
      "functions constitute what is called a “version space;” we’ll explore that concept\n",
      "in more detail later. As we present more members of the training set, the graph\n",
      "of the number of hypotheses not yet ruled out as a function of the number of\n",
      "diﬀerent patterns presented is as shown in Fig. 1.4. At any stage of the process,\n",
      "10\n",
      "CHAPTER 1. PRELIMINARIES\n",
      "half of the remaining Boolean functions have value 1 and half have value 0 for\n",
      "any training pattern not yet seen. No generalization is possible in this case\n",
      "because the training patterns give no clue about the value of a pattern not yet\n",
      "seen. Only memorization is possible here, which is a trivial sort of learning.\n",
      "log2|Hv|\n",
      "2n\n",
      "2n\n",
      "j = no. of labeled\n",
      "patterns already seen\n",
      "0\n",
      "0\n",
      "2n � j\n",
      "(generalization is not possible)\n",
      "|Hv| = no. of functions not ruled out\n",
      "Figure 1.4: Hypotheses Remaining as a Function of Labeled Patterns Presented\n",
      "But suppose we limited H to some subset, Hc, of all Boolean functions.\n",
      "Depending on the subset and on the order of presentation of training patterns,\n",
      "a curve of hypotheses not yet ruled out might look something like the one\n",
      "shown in Fig. 1.5. In this case it is even possible that after seeing fewer than\n",
      "all 2n labeled samples, there might be only one hypothesis that agrees with\n",
      "the training set. Certainly, even if there is more than one hypothesis remaining,\n",
      "most of them may have the same value for most of the patterns not yet seen! The\n",
      "theory of Probably Approximately Correct (PAC) learning makes this intuitive\n",
      "idea precise. We’ll examine that theory later.\n",
      "Let’s look at a speciﬁc example of how bias aids learning. A Boolean function\n",
      "can be represented by a hypercube each of whose vertices represents a diﬀerent\n",
      "input pattern. We show a 3-dimensional version in Fig. 1.6. There, we show a\n",
      "training set of six sample patterns and have marked those having a value of 1 by\n",
      "a small square and those having a value of 0 by a small circle. If the hypothesis\n",
      "set consists of just the linearly separable functions—those for which the positive\n",
      "and negative instances can be separated by a linear surface, then there is only\n",
      "one function remaining in this hypothsis set that is consistent with the training\n",
      "set. So, in this case, even though the training set does not contain all possible\n",
      "patterns, we can already pin down what the function must be—given the bias.\n",
      "1.4. SAMPLE APPLICATIONS\n",
      "11\n",
      "log2|Hv|\n",
      "2n\n",
      "2n\n",
      "j = no. of labeled\n",
      "patterns already seen\n",
      "0\n",
      "0\n",
      "|Hv| = no. of functions not ruled out\n",
      "depends on order\n",
      "of presentation\n",
      "log2|Hc|\n",
      "Figure 1.5: Hypotheses Remaining From a Restricted Subset\n",
      "Machine learning researchers have identiﬁed two main varieties of bias, ab-\n",
      "solute and preference. In absolute bias (also called restricted hypothesis-space\n",
      "bias), one restricts H to a deﬁnite subset of functions. In our example of Fig. 1.6,\n",
      "the restriction was to linearly separable Boolean functions. In preference bias,\n",
      "one selects that hypothesis that is minimal according to some ordering scheme\n",
      "over all hypotheses. For example, if we had some way of measuring the complex-\n",
      "ity of a hypothesis, we might select the one that was simplest among those that\n",
      "performed satisfactorily on the training set. The principle of Occam’s razor,\n",
      "used in science to prefer simple explanations to more complex ones, is a type\n",
      "of preference bias. (William of Occam, 1285-?1349, was an English philosopher\n",
      "who said: “non sunt multiplicanda entia praeter necessitatem,” which means\n",
      "“entities should not be multiplied unnecessarily.”)\n",
      "1.4\n",
      "Sample Applications\n",
      "Our main emphasis in this book is on the concepts of machine learning—not\n",
      "on its applications. Nevertheless, if these concepts were irrelevant to real-world\n",
      "problems they would probably not be of much interest. As motivation, we give\n",
      "a short summary of some areas in which machine learning techniques have been\n",
      "successfully applied. [Langley, 1992] cites some of the following applications and\n",
      "others:\n",
      "a. Rule discovery using a variant of ID3 for a printing industry problem\n",
      "12\n",
      "CHAPTER 1. PRELIMINARIES\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "Figure 1.6: A Training Set That Completely Determines a Linearly Separable\n",
      "Function\n",
      "[Evans & Fisher, 1992].\n",
      "b. Electric power load forecasting using a k-nearest-neighbor rule system\n",
      "[Jabbour, K., et al., 1987].\n",
      "c. Automatic\n",
      "“help\n",
      "desk”\n",
      "assistant\n",
      "using\n",
      "a\n",
      "nearest-neighbor\n",
      "system\n",
      "[Acorn & Walden, 1992].\n",
      "d. Planning and scheduling for a steel mill using ExpertEase, a marketed\n",
      "(ID3-like) system [Michie, 1992].\n",
      "e. Classiﬁcation of stars and galaxies [Fayyad, et al., 1993].\n",
      "Many application-oriented papers are presented at the annual conferences\n",
      "on Neural Information Processing Systems. Among these are papers on: speech\n",
      "recognition, dolphin echo recognition, image processing, bio-engineering, diag-\n",
      "nosis, commodity trading, face recognition, music composition, optical character\n",
      "recognition, and various control applications [Various Editors, 1989-1994].\n",
      "As additional examples, [Hammerstrom, 1993] mentions:\n",
      "a. Sharp’s Japanese kanji character recognition system processes 200 char-\n",
      "acters per second with 99+% accuracy. It recognizes 3000+ characters.\n",
      "b. NeuroForecasting Centre’s (London Business School and University Col-\n",
      "lege London) trading strategy selection network earned an average annual\n",
      "proﬁt of 18% against a conventional system’s 12.3%.\n",
      "1.5. SOURCES\n",
      "13\n",
      "c. Fujitsu’s (plus a partner’s) neural network for monitoring a continuous\n",
      "steel casting operation has been in successful operation since early 1990.\n",
      "In summary, it is rather easy nowadays to ﬁnd applications of machine learn-\n",
      "ing techniques. This fact should come as no surprise inasmuch as many machine\n",
      "learning techniques can be viewed as extensions of well known statistical meth-\n",
      "ods which have been successfully applied for many years.\n",
      "1.5\n",
      "Sources\n",
      "Besides\n",
      "the\n",
      "rich\n",
      "literature\n",
      "in\n",
      "machine\n",
      "learning\n",
      "(a\n",
      "small\n",
      "part\n",
      "of\n",
      "which\n",
      "is\n",
      "referenced\n",
      "in\n",
      "the\n",
      "Bibliography),\n",
      "there\n",
      "are\n",
      "several\n",
      "text-\n",
      "books\n",
      "that\n",
      "are\n",
      "worth\n",
      "mentioning\n",
      "[Hertz, Krogh, & Palmer, 1991,\n",
      "Weiss & Kulikowski, 1991,\n",
      "Natarjan, 1991,\n",
      "Fu, 1994,\n",
      "Langley, 1996].\n",
      "[Shavlik & Dietterich, 1990,\n",
      "Buchanan & Wilkins, 1993]\n",
      "are\n",
      "edited\n",
      "vol-\n",
      "umes containing some of the most important papers.\n",
      "A survey paper by\n",
      "[Dietterich, 1990] gives a good overview of many important topics. There are\n",
      "also well established conferences and publications where papers are given and\n",
      "appear including:\n",
      "• The Annual Conferences on Advances in Neural Information Processing\n",
      "Systems\n",
      "• The Annual Workshops on Computational Learning Theory\n",
      "• The Annual International Workshops on Machine Learning\n",
      "• The Annual International Conferences on Genetic Algorithms\n",
      "(The Proceedings of the above-listed four conferences are published by\n",
      "Morgan Kaufmann.)\n",
      "• The journal Machine Learning (published by Kluwer Academic Publish-\n",
      "ers).\n",
      "There is also much information, as well as programs and datasets, available over\n",
      "the Internet through the World Wide Web.\n",
      "1.6\n",
      "Bibliographical and Historical Remarks\n",
      "To be added. Every chapter will\n",
      "contain a brief survey of the history\n",
      "of the material covered in that\n",
      "chapter.\n",
      "14\n",
      "CHAPTER 1. PRELIMINARIES\n",
      "Chapter 2\n",
      "Boolean Functions\n",
      "2.1\n",
      "Representation\n",
      "2.1.1\n",
      "Boolean Algebra\n",
      "Many important ideas about learning of functions are most easily presented\n",
      "using the special case of Boolean functions. There are several important sub-\n",
      "classes of Boolean functions that are used as hypothesis classes for function\n",
      "learning. Therefore, we digress in this chapter to present a review of Boolean\n",
      "functions and their properties. (For a more thorough treatment see, for example,\n",
      "[Unger, 1989].)\n",
      "A Boolean function, f(x1, x2, . . . , xn) maps an n-tuple of (0,1) values to\n",
      "{0, 1}. Boolean algebra is a convenient notation for representing Boolean func-\n",
      "tions. Boolean algebra uses the connectives ·, +, and\n",
      ". For example, the and\n",
      "function of two variables is written x1 · x2. By convention, the connective, “·”\n",
      "is usually suppressed, and the and function is written x1x2. x1x2 has value 1 if\n",
      "and only if both x1 and x2 have value 1; if either x1 or x2 has value 0, x1x2 has\n",
      "value 0. The (inclusive) or function of two variables is written x1 + x2. x1 + x2\n",
      "has value 1 if and only if either or both of x1 or x2 has value 1; if both x1 and\n",
      "x2 have value 0, x1 + x2 has value 0. The complement or negation of a variable,\n",
      "x, is written x. x has value 1 if and only if x has value 0; if x has value 1, x has\n",
      "value 0.\n",
      "These deﬁnitions are compactly given by the following rules for Boolean\n",
      "algebra:\n",
      "1 + 1 = 1, 1 + 0 = 1, 0 + 0 = 0,\n",
      "1 · 1 = 1, 1 · 0 = 0, 0 · 0 = 0, and\n",
      "1 = 0, 0 = 1.\n",
      "Sometimes the arguments and values of Boolean functions are expressed in\n",
      "terms of the constants T (True) and F (False) instead of 1 and 0, respectively.\n",
      "15\n",
      "16\n",
      "CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "The connectives · and + are each commutative and associative. Thus, for\n",
      "example, x1(x2x3) = (x1x2)x3, and both can be written simply as x1x2x3.\n",
      "Similarly for +.\n",
      "A Boolean formula consisting of a single variable, such as x1 is called an\n",
      "atom. One consisting of either a single variable or its complement, such as x1,\n",
      "is called a literal.\n",
      "The operators · and + do not commute between themselves. Instead, we\n",
      "have DeMorgan’s laws (which can be veriﬁed by using the above deﬁnitions):\n",
      "x1x2 = x1 + x2, and\n",
      "x1 + x2 = x1 x2.\n",
      "2.1.2\n",
      "Diagrammatic Representations\n",
      "We saw in the last chapter that a Boolean function could be represented by\n",
      "labeling the vertices of a cube. For a function of n variables, we would need\n",
      "an n-dimensional hypercube. In Fig. 2.1 we show some 2- and 3-dimensional\n",
      "examples. Vertices having value 1 are labeled with a small square, and vertices\n",
      "having value 0 are labeled with a small circle.\n",
      "x1\n",
      "x2\n",
      "x1\n",
      "x2\n",
      "x1\n",
      "x2\n",
      "and\n",
      "or\n",
      "xor (exclusive or)\n",
      "x1x2\n",
      "x1 + x2\n",
      "x1x2  +  x1x2\n",
      "even parity function\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "x1x2x3  +  x1x2x3\n",
      "+ x1x2x3 + x1x2x3\n",
      "Figure 2.1: Representing Boolean Functions on Cubes\n",
      "Using the hypercube representations, it is easy to see how many Boolean\n",
      "functions of n dimensions there are. A 3-dimensional cube has 23 = 8 vertices,\n",
      "and each may be labeled in two diﬀerent ways; thus there are 2(23) = 256\n",
      "2.2. CLASSES OF BOOLEAN FUNCTIONS\n",
      "17\n",
      "diﬀerent Boolean functions of 3 variables. In general, there are 22n Boolean\n",
      "functions of n variables.\n",
      "We will be using 2- and 3-dimensional cubes later to provide some intuition\n",
      "about the properties of certain Boolean functions. Of course, we cannot visualize\n",
      "hypercubes (for n > 3), and there are many surprising properties of higher\n",
      "dimensional spaces, so we must be careful in using intuitions gained in low\n",
      "dimensions. One diagrammatic technique for dimensions slightly higher than\n",
      "3 is the Karnaugh map. A Karnaugh map is an array of values of a Boolean\n",
      "function in which the horizontal rows are indexed by the values of some of\n",
      "the variables and the vertical columns are indexed by the rest. The rows and\n",
      "columns are arranged in such a way that entries that are adjacent in the map\n",
      "correspond to vertices that are adjacent in the hypercube representation. We\n",
      "show an example of the 4-dimensional even parity function in Fig. 2.2. (An\n",
      "even parity function is a Boolean function that has value 1 if there are an even\n",
      "number of its arguments that have value 1; otherwise it has value 0.) Note\n",
      "that all adjacent cells in the table correspond to inputs diﬀering in only one\n",
      "component.\n",
      "Also describe general logic\n",
      "diagrams, [Wnek, et al., 1990].\n",
      "00 01\n",
      "10\n",
      "11\n",
      "00\n",
      "01\n",
      "10\n",
      "11\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "x1,x2\n",
      "x3,x4\n",
      "Figure 2.2: A Karnaugh Map\n",
      "2.2\n",
      "Classes of Boolean Functions\n",
      "2.2.1\n",
      "Terms and Clauses\n",
      "To use absolute bias in machine learning, we limit the class of hypotheses. In\n",
      "learning Boolean functions, we frequently use some of the common sub-classes of\n",
      "those functions. Therefore, it will be important to know about these subclasses.\n",
      "One basic subclass is called terms. A term is any function written in the\n",
      "form l1l2 · · · lk, where the li are literals. Such a form is called a conjunction of\n",
      "literals. Some example terms are x1x7 and x1x2x4. The size of a term is the\n",
      "number of literals it contains. The examples are of sizes 2 and 3, respectively.\n",
      "(Strictly speaking, the class of conjunctions of literals is called the monomials,\n",
      "18\n",
      "CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "and a conjunction of literals itself is called a term. This distinction is a ﬁne one\n",
      "which we elect to blur here.)\n",
      "It is easy to show that there are exactly 3n possible terms of n variables.\n",
      "The number of terms of size k or less is bounded from above by �k\n",
      "i=0 C(2n, i) =\n",
      "O(nk), where C(i, j) =\n",
      "i!\n",
      "(i−j)!j! is the binomial coeﬃcient.\n",
      "Probably I’ll put in a simple\n",
      "term-learning algorithm here—so\n",
      "we can get started on learning!\n",
      "Also for DNF functions and\n",
      "decision lists—as they are deﬁned\n",
      "in the next few pages.\n",
      "A clause is any function written in the form l1 +l2 +· · ·+lk, where the li are\n",
      "literals. Such a form is called a disjunction of literals. Some example clauses\n",
      "are x3 + x5 + x6 and x1 + x4. The size of a clause is the number of literals it\n",
      "contains. There are 3n possible clauses and fewer than �k\n",
      "i=0 C(2n, i) clauses of\n",
      "size k or less. If f is a term, then (by De Morgan’s laws) f is a clause, and vice\n",
      "versa. Thus, terms and clauses are duals of each other.\n",
      "In psychological experiments, conjunctions of literals seem easier for humans\n",
      "to learn than disjunctions of literals.\n",
      "2.2.2\n",
      "DNF Functions\n",
      "A Boolean function is said to be in disjunctive normal form (DNF) if it can be\n",
      "written as a disjunction of terms. Some examples in DNF are: f = x1x2+x2x3x4\n",
      "and f = x1x3 + x2 x3 + x1x2x3. A DNF expression is called a k-term DNF\n",
      "expression if it is a disjunction of k terms; it is in the class k-DNF if the size of\n",
      "its largest term is k. The examples above are 2-term and 3-term expressions,\n",
      "respectively. Both expressions are in the class 3-DNF.\n",
      "Each term in a DNF expression for a function is called an implicant because\n",
      "it “implies” the function (if the term has value 1, so does the function). In\n",
      "general, a term, t, is an implicant of a function, f, if f has value 1 whenever\n",
      "t does. A term, t, is a prime implicant of f if the term, t′, formed by taking\n",
      "any literal out of an implicant t is no longer an implicant of f. (The implicant\n",
      "cannot be “divided” by any term and remain an implicant.)\n",
      "Thus, both x2x3 and x1 x3 are prime implicants of f = x2x3+x1 x3+x2x1x3,\n",
      "but x2x1x3 is not.\n",
      "The relationship between implicants and prime implicants can be geometri-\n",
      "cally illustrated using the cube representation for Boolean functions. Consider,\n",
      "for example, the function f = x2x3 + x1 x3 + x2x1x3. We illustrate it in Fig.\n",
      "2.3.\n",
      "Note that each of the three planes in the ﬁgure “cuts oﬀ” a group of\n",
      "vertices having value 1, but none cuts oﬀ any vertices having value 0. These\n",
      "planes are pictorial devices used to isolate certain lower dimensional subfaces\n",
      "of the cube. Two of them isolate one-dimensional edges, and the third isolates\n",
      "a zero-dimensional vertex. Each group of vertices on a subface corresponds to\n",
      "one of the implicants of the function, f, and thus each implicant corresponds\n",
      "to a subface of some dimension. A k-dimensional subface corresponds to an\n",
      "(n − k)-size implicant term. The function is written as the disjunction of the\n",
      "implicants—corresponding to the union of all the vertices cut oﬀ by all of the\n",
      "planes. Geometrically, an implicant is prime if and only if its corresponding\n",
      "subface is the largest dimensional subface that includes all of its vertices and\n",
      "2.2. CLASSES OF BOOLEAN FUNCTIONS\n",
      "19\n",
      "no other vertices having value 0. Note that the term x2x1x3 is not a prime\n",
      "implicant of f. (In this case, we don’t even have to include this term in the\n",
      "function because the vertex cut oﬀ by the plane corresponding to x2x1x3 is\n",
      "already cut oﬀ by the plane corresponding to x2x3.) The other two implicants\n",
      "are prime because their corresponding subfaces cannot be expanded without\n",
      "including vertices having value 0.\n",
      "x2\n",
      "x1\n",
      "x3\n",
      "1, 0, 0\n",
      "1, 0, 1\n",
      "1, 1, 1\n",
      "0, 0, 1\n",
      "f = x2x3 + x1x3 + x2x1x3\n",
      "   = x2x3 + x1x3\n",
      "x2x3 and  x1x3 are prime implicants\n",
      "Figure 2.3: A Function and its Implicants\n",
      "Note that all Boolean functions can be represented in DNF—trivially by\n",
      "disjunctions of terms of size n where each term corresponds to one of the vertices\n",
      "whose value is 1. Whereas there are 22n functions of n dimensions in DNF (since\n",
      "any Boolean function can be written in DNF), there are just 2O(nk) functions\n",
      "in k-DNF.\n",
      "All Boolean functions can also be represented in DNF in which each term is\n",
      "a prime implicant, but that representation is not unique, as shown in Fig. 2.4.\n",
      "If we can express a function in DNF form, we can use the consensus method\n",
      "to ﬁnd an expression for the function in which each term is a prime implicant.\n",
      "The consensus method relies on two results:\n",
      "We may replace this section with\n",
      "one describing the\n",
      "Quine-McCluskey method instead.\n",
      "• Consensus:\n",
      "20\n",
      "CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "x2\n",
      "x1\n",
      "x3\n",
      "1, 0, 0\n",
      "1, 0, 1\n",
      "1, 1, 1\n",
      "0, 0, 1\n",
      "f = x2x3 + x1x3 + x1x2\n",
      "   = x1x2 + x1x3\n",
      "All of the terms are prime implicants, but there\n",
      "is not a unique representation\n",
      "Figure 2.4: Non-Uniqueness of Representation by Prime Implicants\n",
      "xi · f1 + xi · f2 = xi · f1 + xi · f2 + f1 · f2\n",
      "where f1 and f2 are terms such that no literal appearing in f1 appears\n",
      "complemented in f2.\n",
      "f1 · f2 is called the consensus of xi · f1 and xi ·\n",
      "f2. Readers familiar with the resolution rule of inference will note that\n",
      "consensus is the dual of resolution.\n",
      "Examples: x1 is the consensus of x1x2 and x1x2. The terms x1x2 and x1x2\n",
      "have no consensus since each term has more than one literal appearing\n",
      "complemented in the other.\n",
      "• Subsumption:\n",
      "xi · f1 + f1 = f1\n",
      "where f1 is a term. We say that f1 subsumes xi · f1.\n",
      "Example: x1 x4x5 subsumes x1 x4 x2x5\n",
      "2.2. CLASSES OF BOOLEAN FUNCTIONS\n",
      "21\n",
      "The consensus method for ﬁnding a set of prime implicants for a function,\n",
      "f, iterates the following operations on the terms of a DNF expression for f until\n",
      "no more such operations can be applied:\n",
      "a. initialize the process with the set, T , of terms in the DNF expression of\n",
      "f,\n",
      "b. compute the consensus of a pair of terms in T and add the result to T ,\n",
      "c. eliminate any terms in T that are subsumed by other terms in T .\n",
      "When this process halts, the terms remaining in T are all prime implicants of\n",
      "f.\n",
      "Example: Let f = x1x2 + x1 x2x3 + x1 x2 x3 x4x5. We show a derivation of\n",
      "a set of prime implicants in the consensus tree of Fig. 2.5. The circled numbers\n",
      "adjoining the terms indicate the order in which the consensus and subsumption\n",
      "operations were performed. Shaded boxes surrounding a term indicate that it\n",
      "was subsumed. The ﬁnal form of the function in which all terms are prime\n",
      "implicants is: f = x1x2 +x1x3 +x1 x4x5. Its terms are all of the non-subsumed\n",
      "terms in the consensus tree.\n",
      " x1x2\n",
      "x1x2x3\n",
      "x1x2x3x4x5\n",
      " x1x3\n",
      "x1x2x4x5\n",
      "x1x4x5\n",
      "f =  x1x2 +\n",
      "+\n",
      " x1x3\n",
      "x1x4x5\n",
      "1\n",
      "2\n",
      "6\n",
      "4\n",
      "5\n",
      "3\n",
      "Figure 2.5: A Consensus Tree\n",
      "2.2.3\n",
      "CNF Functions\n",
      "Disjunctive normal form has a dual: conjunctive normal form (CNF). A Boolean\n",
      "function is said to be in CNF if it can be written as a conjunction of clauses.\n",
      "22\n",
      "CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "An example in CNF is: f = (x1 +x2)(x2 +x3 +x4). A CNF expression is called\n",
      "a k-clause CNF expression if it is a conjunction of k clauses; it is in the class\n",
      "k-CNF if the size of its largest clause is k. The example is a 2-clause expression\n",
      "in 3-CNF. If f is written in DNF, an application of De Morgan’s law renders f\n",
      "in CNF, and vice versa. Because CNF and DNF are duals, there are also 2O(nk)\n",
      "functions in k-CNF.\n",
      "2.2.4\n",
      "Decision Lists\n",
      "Rivest has proposed a class of Boolean functions called decision lists [Rivest, 1987].\n",
      "A decision list is written as an ordered list of pairs:\n",
      "(tq, vq)\n",
      "(tq−1, vq−1)\n",
      "· · ·\n",
      "(ti, vi)\n",
      "· · ·\n",
      "(t2, v2)\n",
      "(T, v1)\n",
      "where the vi are either 0 or 1, the ti are terms in (x1, . . . , xn), and T is a term\n",
      "whose value is 1 (regardless of the values of the xi). The value of a decision list\n",
      "is the value of vi for the ﬁrst ti in the list that has value 1. (At least one ti will\n",
      "have value 1, because the last one does; v1 can be regarded as a default value of\n",
      "the decision list.) The decision list is of size k, if the size of the largest term in\n",
      "it is k. The class of decision lists of size k or less is called k-DL.\n",
      "An example decision list is:\n",
      "f =\n",
      "(x1x2, 1)\n",
      "(x1 x2x3, 0)\n",
      "x2x3, 1)\n",
      "(1, 0)\n",
      "f has value 0 for x1 = 0, x2 = 0, and x3 = 1. It has value 1 for x1 = 1, x2 = 0,\n",
      "and x3 = 1. This function is in 3-DL.\n",
      "It has been shown that the class k-DL is a strict superset of the union of\n",
      "k-DNF and k-CNF. There are 2O[nkk log(n)] functions in k-DL [Rivest, 1987].\n",
      "Interesting generalizations of decision lists use other Boolean functions in\n",
      "place of the terms, ti. For example we might use linearly separable functions in\n",
      "place of the ti (see below and [Marchand & Golea, 1993]).\n",
      "2.2. CLASSES OF BOOLEAN FUNCTIONS\n",
      "23\n",
      "2.2.5\n",
      "Symmetric and Voting Functions\n",
      "A Boolean function is called symmetric if it is invariant under permutations\n",
      "of the input variables. For example, any function that is dependent only on\n",
      "the number of input variables whose values are 1 is a symmetric function. The\n",
      "parity functions, which have value 1 depending on whether or not the number\n",
      "of input variables with value 1 is even or odd is a symmetric function. (The\n",
      "exclusive or function, illustrated in Fig. 2.1, is an odd-parity function of two\n",
      "dimensions. The or and and functions of two dimensions are also symmetric.)\n",
      "An important subclass of the symmetric functions is the class of voting func-\n",
      "tions (also called m-of-n functions). A k-voting function has value 1 if and only\n",
      "if k or more of its n inputs has value 1. If k = 1, a voting function is the same\n",
      "as an n-sized clause; if k = n, a voting function is the same as an n-sized term;\n",
      "if k = (n + 1)/2 for n odd or k = 1 + n/2 for n even, we have the majority\n",
      "function.\n",
      "2.2.6\n",
      "Linearly Separable Functions\n",
      "The linearly separable functions are those that can be expressed as follows:\n",
      "f = thresh(\n",
      "n\n",
      "�\n",
      "i=1\n",
      "wixi, θ)\n",
      "where wi, i = 1, . . . , n, are real-valued numbers called weights, θ is a real-valued\n",
      "number called the threshold, and thresh(σ, θ) is 1 if σ ≥ θ and 0 otherwise.\n",
      "(Note that the concept of linearly separable functions can be extended to non-\n",
      "Boolean inputs.) The k-voting functions are all members of the class of linearly\n",
      "separable functions in which the weights all have unit value and the threshold\n",
      "depends on k. Thus, terms and clauses are special cases of linearly separable\n",
      "functions.\n",
      "A convenient way to write linearly separable functions uses vector notation:\n",
      "f = thresh(X · W, θ)\n",
      "where X = (x1, . . . , xn) is an n-dimensional vector of input variables, W =\n",
      "(w1, . . . , wn) is an n-dimensional vector of weight values, and X · W is the dot\n",
      "(or inner) product of the two vectors. Input vectors for which f has value 1 lie\n",
      "in a half-space on one side of (and on) a hyperplane whose orientation is normal\n",
      "to W and whose position (with respect to the origin) is determined by θ. We\n",
      "saw an example of such a separating plane in Fig. 1.6. With this idea in mind,\n",
      "it is easy to see that two of the functions in Fig. 2.1 are linearly separable, while\n",
      "two are not. Also note that the terms in Figs. 2.3 and 2.4 are linearly separable\n",
      "functions as evidenced by the separating planes shown.\n",
      "There is no closed-form expression for the number of linearly separable func-\n",
      "tions of n dimensions, but the following table gives the numbers for n up to 6.\n",
      "24\n",
      "CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "n\n",
      "Boolean\n",
      "Linearly Separable\n",
      "Functions\n",
      "Functions\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "16\n",
      "14\n",
      "3\n",
      "256\n",
      "104\n",
      "4\n",
      "65,536\n",
      "1,882\n",
      "5\n",
      "≈ 4.3 × 109\n",
      "94,572\n",
      "6\n",
      "≈ 1.8 × 1019\n",
      "15,028,134\n",
      "[Muroga, 1971] has shown that (for n > 1) there are no more than 2n2 linearly\n",
      "separable functions of n dimensions. (See also [Winder, 1961, Winder, 1962].)\n",
      "2.3\n",
      "Summary\n",
      "The diagram in Fig. 2.6 shows some of the set inclusions of the classes of Boolean\n",
      "functions that we have considered. We will be confronting these classes again\n",
      "in later chapters.\n",
      "DNF\n",
      "(All)\n",
      "k-DL\n",
      "k-DNF\n",
      "k-size-\n",
      "terms\n",
      "terms\n",
      "lin sep\n",
      "Figure 2.6: Classes of Boolean Functions\n",
      "The sizes of the various classes are given in the following table (adapted from\n",
      "[Dietterich, 1990, page 262]):\n",
      "2.4. BIBLIOGRAPHICAL AND HISTORICAL REMARKS\n",
      "25\n",
      "Class\n",
      "Size of Class\n",
      "terms\n",
      "3n\n",
      "clauses\n",
      "3n\n",
      "k-term DNF\n",
      "2O(kn)\n",
      "k-clause CNF\n",
      "2O(kn)\n",
      "k-DNF\n",
      "2O(nk)\n",
      "k-CNF\n",
      "2O(nk)\n",
      "k-DL\n",
      "2O[nkk log(n)]\n",
      "lin sep\n",
      "2O(n2)\n",
      "DNF\n",
      "22n\n",
      "2.4\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "26\n",
      "CHAPTER 2. BOOLEAN FUNCTIONS\n",
      "Chapter 3\n",
      "Using Version Spaces for\n",
      "Learning\n",
      "3.1\n",
      "Version Spaces and Mistake Bounds\n",
      "The ﬁrst learning methods we present are based on the concepts of version\n",
      "spaces and version graphs. These ideas are most clearly explained for the case\n",
      "of Boolean function learning. Given an initial hypothesis set H (a subset of\n",
      "all Boolean functions) and the values of f(X) for each X in a training set, Ξ,\n",
      "the version space is that subset of hypotheses, Hv, that is consistent with these\n",
      "values. A hypothesis, h, is consistent with the values of X in Ξ if and only if\n",
      "h(X) = f(X) for all X in Ξ. We say that the hypotheses in H that are not\n",
      "consistent with the values in the training set are ruled out by the training set.\n",
      "We could imagine (conceptually only!) that we have devices for implement-\n",
      "ing every function in H.\n",
      "An incremental training procedure could then be\n",
      "deﬁned which presented each pattern in Ξ to each of these functions and then\n",
      "eliminated those functions whose values for that pattern did not agree with its\n",
      "given value. At any stage of the process we would then have left some subset\n",
      "of functions that are consistent with the patterns presented so far; this subset\n",
      "is the version space for the patterns already presented. This idea is illustrated\n",
      "in Fig. 3.1.\n",
      "Consider the following procedure for classifying an arbitrary input pattern,\n",
      "X: the pattern is put in the same class (0 or 1) as are the majority of the\n",
      "outputs of the functions in the version space. During the learning procedure,\n",
      "if this majority is not equal to the value of the pattern presented, we say a\n",
      "mistake is made, and we revise the version space accordingly—eliminating all\n",
      "those (majority of the) functions voting incorrectly. Thus, whenever a mistake\n",
      "is made, we rule out at least half of the functions remaining in the version space.\n",
      "How many mistakes can such a procedure make? Obviously, we can make\n",
      "no more than log2(|H|) mistakes, where |H| is the number of hypotheses in the\n",
      "27\n",
      "28\n",
      "CHAPTER 3. USING VERSION SPACES FOR LEARNING\n",
      "h1\n",
      "h2\n",
      "hi\n",
      "hK\n",
      "X\n",
      "A Subset, H,  of all\n",
      "Boolean Functions\n",
      "Rule out hypotheses not\n",
      "consistent with training patterns\n",
      "hj\n",
      "Hypotheses not ruled out\n",
      "constitute the version space\n",
      "K = |H|\n",
      "1 or 0\n",
      "Figure 3.1: Implementing the Version Space\n",
      "original hypothesis set, H. (Note, though, that the number of training patterns\n",
      "seen before this maximum number of mistakes is made might be much greater.)\n",
      "This theoretical (and very impractical!) result (due to [Littlestone, 1988]) is an\n",
      "example of a mistake bound—an important concept in machine learning theory.\n",
      "It shows that there must exist a learning procedure that makes no more mistakes\n",
      "than this upper bound. Later, we’ll derive other mistake bounds.\n",
      "As a special case, if our bias was to limit H to terms, we would make no\n",
      "more than log2(3n) = n log2(3) = 1.585n mistakes before exhausting the version\n",
      "space. This result means that if f were a term, we would make no more than\n",
      "1.585n mistakes before learning f, and otherwise we would make no more than\n",
      "that number of mistakes before being able to decide that f is not a term.\n",
      "Even if we do not have suﬃcient training patterns to reduce the version\n",
      "space to a single function, it may be that there are enough training patterns\n",
      "to reduce the version space to a set of functions such that most of them assign\n",
      "the same values to most of the patterns we will see henceforth. We could select\n",
      "one of the remaining functions at random and be reasonably assured that it\n",
      "will generalize satisfactorily. We next discuss a computationally more feasible\n",
      "method for representing the version space.\n",
      "3.2. VERSION GRAPHS\n",
      "29\n",
      "3.2\n",
      "Version Graphs\n",
      "Boolean functions can be ordered by generality. A Boolean function, f1, is more\n",
      "general than a function, f2, (and f2 is more speciﬁc than f1), if f1 has value 1\n",
      "for all of the arguments for which f2 has value 1, and f1 ̸= f2. For example, x3\n",
      "is more general than x2x3 but is not more general than x3 + x2.\n",
      "We can form a graph with the hypotheses, {hi}, in the version space as\n",
      "nodes. A node in the graph, hi, has an arc directed to node, hj, if and only if\n",
      "hj is more general than hi. We call such a graph a version graph. In Fig. 3.2,\n",
      "we show an example of a version graph over a 3-dimensional input space for\n",
      "hypotheses restricted to terms (with none of them yet ruled out).\n",
      "0\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "x2\n",
      "x3\n",
      "1\n",
      "x1x2 x3\n",
      "x1x2\n",
      "x1\n",
      "Version Graph for Terms\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "(for simplicity, only some arcs in the graph are shown)\n",
      "(none yet ruled out)\n",
      "(k = 1)\n",
      "(k = 2)\n",
      "(k = 3)\n",
      "x1 x3\n",
      "Figure 3.2: A Version Graph for Terms\n",
      "That function, denoted here by “1,” which has value 1 for all inputs, corre-\n",
      "sponds to the node at the top of the graph. (It is more general than any other\n",
      "term.) Similarly, the function “0” is at the bottom of the graph. Just below\n",
      "“1” is a row of nodes corresponding to all terms having just one literal, and just\n",
      "below them is a row of nodes corresponding to terms having two literals, and\n",
      "30\n",
      "CHAPTER 3. USING VERSION SPACES FOR LEARNING\n",
      "so on. There are 33 = 27 functions altogether (the function “0,” included in\n",
      "the graph, is technically not a term). To make our portrayal of the graph less\n",
      "cluttered only some of the arcs are shown; each node in the actual graph has an\n",
      "arc directed to all of the nodes above it that are more general.\n",
      "We use this same example to show how the version graph changes as we\n",
      "consider a set of labeled samples in a training set, Ξ. Suppose we ﬁrst consider\n",
      "the training pattern (1, 0, 1) with value 0. Some of the functions in the version\n",
      "graph of Fig. 3.2 are inconsistent with this training pattern. These ruled out\n",
      "nodes are no longer in the version graph and are shown shaded in Fig. 3.3. We\n",
      "also show there the three-dimensional cube representation in which the vertex\n",
      "(1, 0, 1) has value 0.\n",
      "0\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "x2\n",
      "x3\n",
      "1\n",
      "x1x2 x3\n",
      "x1x2\n",
      "x1\n",
      "New Version Graph\n",
      "1, 0, 1 has\n",
      "value 0\n",
      "x1x3\n",
      "x1x2\n",
      "x2x3\n",
      "x1x2x3\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "x1x3\n",
      "(only some arcs in the graph are shown)\n",
      "ruled out nodes\n",
      "Figure 3.3: The Version Graph Upon Seeing (1, 0, 1)\n",
      "In a version graph, there are always a set of hypotheses that are maximally\n",
      "general and a set of hypotheses that are maximally speciﬁc. These are called\n",
      "the general boundary set (gbs) and the speciﬁc boundary set (sbs), respectively.\n",
      "In Fig. 3.4, we have the version graph as it exists after learning that (1,0,1) has\n",
      "value 0 and (1, 0, 0) has value 1. The gbs and sbs are shown.\n",
      "3.2. VERSION GRAPHS\n",
      "31\n",
      "0\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "x2\n",
      "x3\n",
      "1\n",
      "x1x2 x3\n",
      "x1\n",
      "x2x3\n",
      "x1x3\n",
      "general boundary set\n",
      "(gbs)\n",
      "specific boundary set (sbs)\n",
      "x1x2\n",
      "more specific than gbs,\n",
      "more general than sbs\n",
      "1, 0, 1 has\n",
      "value 0\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "1, 0, 0 has\n",
      "value 1\n",
      "Figure 3.4: The Version Graph Upon Seeing (1, 0, 1) and (1, 0, 0)\n",
      "Boundary sets are important because they provide an alternative to repre-\n",
      "senting the entire version space explicitly, which would be impractical. Given\n",
      "only the boundary sets, it is possible to determine whether or not any hypoth-\n",
      "esis (in the prescribed class of Boolean functions we are using) is a member or\n",
      "not of the version space. This determination is possible because of the fact that\n",
      "any member of the version space (that is not a member of one of the boundary\n",
      "sets) is more speciﬁc than some member of the general boundary set and is more\n",
      "general than some member of the speciﬁc boundary set.\n",
      "If we limit our Boolean functions that can be in the version space to terms,\n",
      "it is a simple matter to determine maximally general and maximally speciﬁc\n",
      "functions (assuming that there is some term that is in the version space). A\n",
      "maximally speciﬁc one corresponds to a subface of minimal dimension that\n",
      "contains all the members of the training set labelled by a 1 and no members\n",
      "labelled by a 0. A maximally general one corresponds to a subface of maximal\n",
      "dimension that contains all the members of the training set labelled by a 1 and\n",
      "no members labelled by a 0. Looking at Fig. 3.4, we see that the subface of\n",
      "minimal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is just\n",
      "the vertex (1, 0, 0) itself—corresponding to the function x1x2 x3. The subface\n",
      "32\n",
      "CHAPTER 3. USING VERSION SPACES FOR LEARNING\n",
      "of maximal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is\n",
      "the bottom face of the cube—corresponding to the function x3. In Figs. 3.2\n",
      "through 3.4 the sbs is always singular. Version spaces for terms always have\n",
      "singular speciﬁc boundary sets.\n",
      "As seen in Fig.\n",
      "3.3, however, the gbs of a\n",
      "version space for terms need not be singular.\n",
      "3.3\n",
      "Learning as Search of a Version Space\n",
      "[To be written.\n",
      "Relate to term learning algorithm presented in Chapter\n",
      "Two. Also discuss best-ﬁrst search methods. See Pat Langley’s example us-\n",
      "ing “pseudo-cells” of how to generate and eliminate hypotheses.]\n",
      "Selecting a hypothesis from the version space can be thought of as a search\n",
      "problem. One can start with a very general function and specialize it through\n",
      "various specialization operators until one ﬁnds a function that is consistent (or\n",
      "adequately so) with a set of training patterns.\n",
      "Such procedures are usually\n",
      "called top-down methods. Or, one can start with a very special function and\n",
      "generalize it—resulting in bottom-up methods. We shall see instances of both\n",
      "styles of learning in this book.\n",
      "Compare this view of top-down\n",
      "versus bottom-up with the\n",
      "divide-and-conquer and the\n",
      "covering (or AQ) methods of\n",
      "decision-tree induction.\n",
      "3.4\n",
      "The Candidate Elimination Method\n",
      "The candidate elimination method, is an incremental method for computing the\n",
      "boundary sets. Quoting from [Hirsh, 1994, page 6]:\n",
      "“The candidate-elimination algorithm manipulates the boundary-set\n",
      "representation of a version space to create boundary sets that rep-\n",
      "resent a new version space consistent with all the previous instances\n",
      "plus the new one. For a positive exmple the algorithm generalizes\n",
      "the elements of the [sbs] as little as possible so that they cover the\n",
      "new instance yet remain consistent with past data, and removes\n",
      "those elements of the [gbs] that do not cover the new instance. For\n",
      "a negative instance the algorithm specializes elements of the [gbs]\n",
      "so that they no longer cover the new instance yet remain consis-\n",
      "tent with past data, and removes from the [sbs] those elements that\n",
      "mistakenly cover the new, negative instance.”\n",
      "The\n",
      "method\n",
      "uses\n",
      "the\n",
      "following\n",
      "deﬁnitions\n",
      "(adapted\n",
      "from\n",
      "[Genesereth & Nilsson, 1987]):\n",
      "• a hypothesis is called suﬃcient if and only if it has value 1 for all training\n",
      "samples labeled by a 1,\n",
      "• a hypothesis is called necessary if and only if it has value 0 for all training\n",
      "samples labeled by a 0.\n",
      "3.4. THE CANDIDATE ELIMINATION METHOD\n",
      "33\n",
      "Here is how to think about these deﬁnitions: A hypothesis implements a suﬃ-\n",
      "cient condition that a training sample has value 1 if the hypothesis has value 1\n",
      "for all of the positive instances; a hypothesis implements a necessary condition\n",
      "that a training sample has value 1 if the hypothesis has value 0 for all of the\n",
      "negative instances. A hypothesis is consistent with the training set (and thus is\n",
      "in the version space) if and only if it is both suﬃcient and necessary.\n",
      "We start (before receiving any members of the training set) with the function\n",
      "“0” as the singleton element of the speciﬁc boundary set and with the function\n",
      "“1” as the singleton element of the general boundary set. Upon receiving a new\n",
      "labeled input vector, the boundary sets are changed as follows:\n",
      "a. If the new vector is labelled with a 1:\n",
      "The new general boundary set is obtained from the previous one by ex-\n",
      "cluding any elements in it that are not suﬃcient. (That is, we exclude any\n",
      "elements that have value 0 for the new vector.)\n",
      "The new speciﬁc boundary set is obtained from the previous one by re-\n",
      "placing each element, hi, in it by all of its least generalizations.\n",
      "The hypothesis hg is a least generalization\n",
      "of h if and only if: a) h is\n",
      "more speciﬁc than hg, b) hg is suﬃcient, c) no function (including h) that\n",
      "is more speciﬁc than hg is suﬃcient, and d) hg is more speciﬁc than some\n",
      "member of the new general boundary set. It might be that hg = h. Also,\n",
      "least generalizations of two diﬀerent functions in the speciﬁc boundary set\n",
      "may be identical.\n",
      "b. If the new vector is labelled with a 0:\n",
      "The new speciﬁc boundary set is obtained from the previous one by ex-\n",
      "cluding any elements in it that are not necessary. (That is, we exclude\n",
      "any elements that have value 1 for the new vector.)\n",
      "The new general boundary set is obtained from the previous one by re-\n",
      "placing each element, hi, in it by all of its least specializations.\n",
      "The hypothesis hs is a least specialization of h if and only if: a) h is more\n",
      "general than hs, b) hs is necessary, c) no function (including h) that is\n",
      "more general than hs is necessary, and d) hs is more general than some\n",
      "member of the new speciﬁc boundary set. Again, it might be that hs = h,\n",
      "and least specializations of two diﬀerent functions in the general boundary\n",
      "set may be identical.\n",
      "As an example, suppose we present the vectors in the following order:\n",
      "vector\n",
      "label\n",
      "(1, 0, 1)\n",
      "0\n",
      "(1, 0, 0)\n",
      "1\n",
      "(1, 1, 1)\n",
      "0\n",
      "(0, 0, 1)\n",
      "0\n",
      "34\n",
      "CHAPTER 3. USING VERSION SPACES FOR LEARNING\n",
      "We start with general boundary set, “1”, and speciﬁc boundary set, “0.”\n",
      "After seeing the ﬁrst sample, (1, 0, 1), labeled with a 0, the speciﬁc boundary\n",
      "set stays at “0” (it is necessary), and we change the general boundary set to\n",
      "{x1, x2, x3}. Each of the functions, x1, x2, and x3, are least specializations of\n",
      "“1” (they are necessary, “1” is not, they are more general than “0”, and there\n",
      "are no functions that are more general than they and also necessary).\n",
      "Then, after seeing (1, 0, 0), labeled with a 1, the general boundary set\n",
      "changes to {x3} (because x1 and x2 are not suﬃcient), and the speciﬁc boundary\n",
      "set is changed to {x1x2 x3}. This single function is a least generalization of “0”\n",
      "(it is suﬃcient, “0” is more speciﬁc than it, no function (including “0”) that is\n",
      "more speciﬁc than it is suﬃcient, and it is more speciﬁc than some member of\n",
      "the general boundary set.\n",
      "When we see (1, 1, 1), labeled with a 0, we do not change the speciﬁc\n",
      "boundary set because its function is still necessary.\n",
      "We do not change the\n",
      "general boundary set either because x3 is still necessary.\n",
      "Finally, when we see (0, 0, 1), labeled with a 0, we do not change the speciﬁc\n",
      "boundary set because its function is still necessary. We do not change the general\n",
      "boundary set either because x3 is still necessary.\n",
      "Maybe I’ll put in an example of a\n",
      "version graph for non-Boolean\n",
      "functions.\n",
      "3.5\n",
      "Bibliographical and Historical Remarks\n",
      "The concept of version spaces and their role in learning was ﬁrst investigated\n",
      "by Tom Mitchell [Mitchell, 1982]. Although these ideas are not used in prac-\n",
      "tical machine learning procedures, they do provide insight into the nature of\n",
      "hypothesis selection. In order to accomodate noisy data, version spaces have\n",
      "been generalized by [Hirsh, 1994] to allow hypotheses that are not necessarily\n",
      "consistent with the training set.\n",
      "More to be added.\n",
      "Chapter 4\n",
      "Neural Networks\n",
      "In chapter two we deﬁned several important subsets of Boolean functions. Sup-\n",
      "pose we decide to use one of these subsets as a hypothesis set for supervised\n",
      "function learning. We next have the question of how best to implement the\n",
      "function as a device that gives the outputs prescribed by the function for arbi-\n",
      "trary inputs. In this chapter we describe how networks of non-linear elements\n",
      "can be used to implement various input-output functions and how they can be\n",
      "trained using supervised learning methods.\n",
      "Networks of non-linear elements, interconnected through adjustable weights,\n",
      "play a prominent role in machine learning. They are called neural networks be-\n",
      "cause the non-linear elements have as their inputs a weighted sum of the outputs\n",
      "of other elements—much like networks of biological neurons do. These networks\n",
      "commonly use the threshold element which we encountered in chapter two in\n",
      "our study of linearly separable Boolean functions. We begin our treatment of\n",
      "neural nets by studying this threshold element and how it can be used in the\n",
      "simplest of all networks, namely ones composed of a single threshold element.\n",
      "4.1\n",
      "Threshold Logic Units\n",
      "4.1.1\n",
      "Deﬁnitions and Geometry\n",
      "Linearly separable (threshold) functions are implemented in a straightforward\n",
      "way by summing the weighted inputs and comparing this sum to a threshold\n",
      "value as shown in Fig. 4.1. This structure we call a threshold logic unit (TLU).\n",
      "Its output is 1 or 0 depending on whether or not the weighted sum of its inputs is\n",
      "greater than or equal to a threshold value, θ. It has also been called an Adaline\n",
      "(for adaptive linear element) [Widrow, 1962, Widrow & Lehr, 1990], an LTU\n",
      "(linear threshold unit), a perceptron, and a neuron. (Although the word “per-\n",
      "ceptron” is often used nowadays to refer to a single TLU, Rosenblatt originally\n",
      "deﬁned it as a class of networks of threshold elements [Rosenblatt, 1958].)\n",
      "35\n",
      "36\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "!\n",
      "x1\n",
      "x2\n",
      "xn+1 = 1\n",
      "xi\n",
      "w1\n",
      "w2\n",
      "wn+1\n",
      "wi\n",
      "wn\n",
      "X\n",
      "threshold weight\n",
      "xn\n",
      "W\n",
      "threshold  \"  = 0\n",
      "f\n",
      "f = thresh( ! wi xi,  0)\n",
      "i = 1\n",
      "n+1\n",
      "Figure 4.1: A Threshold Logic Unit (TLU)\n",
      "The n-dimensional feature or input vector is denoted by X = (x1, . . . , xn).\n",
      "When we want to distinguish among diﬀerent feature vectors, we will attach\n",
      "subscripts, such as Xi. The components of X can be any real-valued numbers,\n",
      "but we often specialize to the binary numbers 0 and 1. The weights of a TLU\n",
      "are represented by an n-dimensional weight vector, W = (w1, . . . , wn).\n",
      "Its\n",
      "components are real-valued numbers (but we sometimes specialize to integers).\n",
      "The TLU has output 1 if �n\n",
      "i=1 xiwi ≥ θ; otherwise it has output 0.\n",
      "The\n",
      "weighted sum that is calculated by the TLU can be simply represented as a\n",
      "vector dot product, X•W. (If the pattern and weight vectors are thought of as\n",
      "“column” vectors, this dot product is then sometimes written as XtW, where\n",
      "the “row” vector Xt is the transpose of X.) Often, the threshold, θ, of the TLU\n",
      "is ﬁxed at 0; in that case, arbitrary thresholds are achieved by using (n + 1)-\n",
      "dimensional “augmented” vectors, Y, and V, whose ﬁrst n components are the\n",
      "same as those of X and W, respectively. The (n + 1)-st component, xn+1, of\n",
      "the augmented feature vector, Y, always has value 1; the (n + 1)-st component,\n",
      "wn+1, of the augmented weight vector, V, is set equal to the negative of the\n",
      "desired threshold value. (When we want to emphasize the use of augmented\n",
      "vectors, we’ll use the Y,V notation; however when the context of the discussion\n",
      "makes it clear about what sort of vectors we are talking about, we’ll lapse back\n",
      "into the more familiar X,W notation.) In the Y,V notation, the TLU has an\n",
      "output of 1 if Y•V ≥ 0. Otherwise, the output is 0.\n",
      "We can give an intuitively useful geometric description of a TLU. A TLU\n",
      "divides the input space by a hyperplane as sketched in Fig. 4.2. The hyperplane\n",
      "is the boundary between patterns for which X•W + wn+1 > 0 and patterns\n",
      "for which X•W + wn+1 < 0. Thus, the equation of the hyperplane itself is\n",
      "X•W+wn+1 = 0. The unit vector that is normal to the hyperplane is n =\n",
      "W\n",
      "|W|,\n",
      "where |W| =\n",
      "�\n",
      "(w2\n",
      "1 + . . . + w2n) is the length of the vector W. (The normal\n",
      "4.1. THRESHOLD LOGIC UNITS\n",
      "37\n",
      "form of the hyperplane equation is X•n +\n",
      "W\n",
      "|W| = 0.) The distance from the\n",
      "hyperplane to the origin is wn+1\n",
      "|W| , and the distance from an arbitrary point, X,\n",
      "to the hyperplane is X•W+wn+1\n",
      "|W|\n",
      ". When the distance from the hyperplane to the\n",
      "origin is negative (that is, when wn+1 < 0), then the origin is on the negative\n",
      "side of the hyperplane (that is, the side for which X•W + wn+1 < 0).\n",
      "X.W + wn+1 > 0\n",
      "on this side\n",
      "W\n",
      "X\n",
      "W\n",
      "n =\n",
      "W\n",
      "|W|\n",
      "Origin\n",
      "Unit vector normal\n",
      "to hyperplane\n",
      "W + wn+1 = 0\n",
      "X\n",
      "n +           = 0\n",
      "X\n",
      "Equations of hyperplane:\n",
      "wn+1\n",
      "|W|\n",
      "wn+1\n",
      "W + wn+1\n",
      "X\n",
      "X.W + wn+1 < 0\n",
      "on this side\n",
      "Figure 4.2: TLU Geometry\n",
      "Adjusting the weight vector, W, changes the orientation of the hyperplane;\n",
      "adjusting wn+1 changes the position of the hyperplane (relative to the origin).\n",
      "Thus, training of a TLU can be achieved by adjusting the values of the weights.\n",
      "In this way the hyperplane can be moved so that the TLU implements diﬀerent\n",
      "(linearly separable) functions of the input.\n",
      "4.1.2\n",
      "Special Cases of Linearly Separable Functions\n",
      "Terms\n",
      "Any term of size k can be implemented by a TLU with a weight from each of\n",
      "those inputs corresponding to variables occurring in the term. A weight of +1 is\n",
      "used from an input corresponding to a positive literal, and a weight of −1 is used\n",
      "from an input corresponding to a negative literal. (Literals not mentioned in\n",
      "the term have weights of zero—that is, no connection at all—from their inputs.)\n",
      "The threshold, θ, is set equal to kp − 1/2, where kp is the number of positive\n",
      "literals in the term. Such a TLU implements a hyperplane boundary that is\n",
      "38\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "parallel to a subface of dimension (n − k) of the unit hypercube. We show a\n",
      "three-dimensional example in Fig. 4.3. Thus, linearly separable functions are a\n",
      "superset of terms.\n",
      "(1,1,1)\n",
      "(1,1,0)\n",
      "x2\n",
      "x1\n",
      "x3\n",
      "f = x1x2\n",
      "x1 + x2 - 3/2 = 0\n",
      "Equation of plane is:\n",
      "Figure 4.3: Implementing a Term\n",
      "Clauses\n",
      "The negation of a clause is a term. For example, the negation of the clause\n",
      "f = x1 + x2 + x3 is the term f = x1 x2 x3. A hyperplane can be used to\n",
      "implement this term.\n",
      "If we “invert” the hyperplane, it will implement the\n",
      "clause instead. Inverting a hyperplane is done by multiplying all of the TLU\n",
      "weights—even wn+1—by −1. This process simply changes the orientation of the\n",
      "hyperplane—ﬂipping it around by 180 degrees and thus changing its “positive\n",
      "side.” Therefore, linearly separable functions are also a superset of clauses. We\n",
      "show an example in Fig. 4.4.\n",
      "4.1.3\n",
      "Error-Correction Training of a TLU\n",
      "There are several procedures that have been proposed for adjusting the weights\n",
      "of a TLU. We present next a family of incremental training procedures with\n",
      "parameter c. These methods make adjustments to the weight vector only when\n",
      "the TLU being trained makes an error on a training pattern; they are called\n",
      "error-correction procedures. We use augmented feature and weight vectors in\n",
      "describing them.\n",
      "a. We start with a ﬁnite training set, Ξ, of vectors, Yi , and their binary\n",
      "labels.\n",
      "4.1. THRESHOLD LOGIC UNITS\n",
      "39\n",
      "f = x1 + x2 + x3\n",
      "x1\n",
      "x1 + x2 + x3 � 1/2 = 0\n",
      "f = x1x2x3\n",
      "Equation of plane is:\n",
      "x2\n",
      "x3\n",
      "Figure 4.4: Implementing a Clause\n",
      "b. Compose an inﬁnite training sequence, Σ, of vectors from Ξ and their\n",
      "labels such that each member of Ξ occurs inﬁnitely often in Σ. Set the\n",
      "initial weight values of an TLU to arbitrary values.\n",
      "c. Repeat forever:\n",
      "Present the next vector, Yi, in Σ to the TLU and note its response.\n",
      "(a) If the TLU responds correctly, make no change in the weight vector.\n",
      "(b) If Yi is supposed to produce an output of 0 and produces an output\n",
      "of 1 instead, modify the weight vector as follows:\n",
      "V ←− V − ciYi\n",
      "where ci is a positive real number called the learning rate parame-\n",
      "ter (whose value is diﬀererent in diﬀerent instances of this family of\n",
      "procedures and may depend on i).\n",
      "Note that after this adjustment the new dot product will be (V −\n",
      "ciYi)•Yi = V•Yi −ciYi•Yi, which is smaller than it was before the\n",
      "weight adjustment.\n",
      "(c) If Yi is supposed to produce an output of 1 and produces an output\n",
      "of 0 instead, modify the weight vector as follows:\n",
      "V ←− V + ciYi\n",
      "In this case, the new dot product will be (V + ciYi)•Yi = V•Yi +\n",
      "ciYi•Yi, which is larger than it was before the weight adjustment.\n",
      "Note that all three of these cases can be combined in the following rule:\n",
      "40\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "V ←− V + ci(di − fi)Yi\n",
      "where di is the desired response (1 or 0) for Yi , and fi is the actual\n",
      "response (1 or 0) for Yi.]\n",
      "Note also that because the weight vector V now includes the wn+1 thresh-\n",
      "old component, the threshold of the TLU is also changed by these adjust-\n",
      "ments.\n",
      "We identify two versions of this procedure:\n",
      "1) In the ﬁxed-increment procedure, the learning rate parameter, ci, is the\n",
      "same ﬁxed, positive constant for all i. Depending on the value of this constant,\n",
      "the weight adjustment may or may not correct the response to an erroneously\n",
      "classiﬁed feature vector.\n",
      "2) In the fractional-correction procedure, the parameter ci is set to λ Yi•V\n",
      "Yi•Yi ,\n",
      "where V is the weight vector before it is changed.\n",
      "Note that if λ = 0, no\n",
      "correction takes place at all. If λ = 1, the correction is just suﬃcient to make\n",
      "Yi•V = 0. If λ > 1, the error will be corrected.\n",
      "It can be proved that if there is some weight vector, V, that produces a\n",
      "correct output for all of the feature vectors in Ξ, then after a ﬁnite number\n",
      "of feature vector presentations, the ﬁxed-increment procedure will ﬁnd such a\n",
      "weight vector and thus make no more weight changes. The same result holds\n",
      "for the fractional-correction procedure if 1 < λ ≤ 2.\n",
      "For additional background, proofs, and examples of error-correction proce-\n",
      "dures, see [Nilsson, 1990].\n",
      "See [Maass & Tur´an, 1994] for a\n",
      "hyperplane-ﬁnding procedure that\n",
      "makes no more than O(n2 log n)\n",
      "mistakes.\n",
      "4.1.4\n",
      "Weight Space\n",
      "We can give an intuitive idea about how these procedures work by considering\n",
      "what happens to the augmented weight vector in “weight space” as corrections\n",
      "are made. We use augmented vectors in our discussion here so that the threshold\n",
      "function compares the dot product, Yi•V, against a threshold of 0. A particular\n",
      "weight vector, V, then corresponds to a point in (n + 1)-dimensional weight\n",
      "space.\n",
      "Now, for any pattern vector, Yi, consider the locus of all points in\n",
      "weight space corresponding to weight vectors yielding Yi•V = 0. This locus is\n",
      "a hyperplane passing through the origin of the (n + 1)-dimensional space. Each\n",
      "pattern vector will have such a hyperplane corresponding to it. Weight points\n",
      "in one of the half-spaces deﬁned by this hyperplane will cause the corresponding\n",
      "pattern to yield a dot product less than 0, and weight points in the other half-\n",
      "space will cause the corresponding pattern to yield a dot product greater than\n",
      "0.\n",
      "We show a schematic representation of such a weight space in Fig.\n",
      "4.5.\n",
      "There are four pattern hyperplanes, 1, 2, 3, 4 , corresponding to patterns Y1,\n",
      "4.1. THRESHOLD LOGIC UNITS\n",
      "41\n",
      "Y2, Y3, Y4, respectively, and we indicate by an arrow the half-space for each\n",
      "in which weight vectors give dot products greater than 0. Suppose we wanted\n",
      "weight values that would give positive responses for patterns Y1, Y3, and Y4,\n",
      "and a negative response for pattern Y2. The weight point, V, indicated in the\n",
      "ﬁgure is one such set of weight values.\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "V\n",
      "Figure 4.5: Weight Space\n",
      "The question of whether or not there exists a weight vector that gives desired\n",
      "responses for a given set of patterns can be given a geometric interpretation. To\n",
      "do so involves reversing the “polarity” of those hyperplanes corresponding to\n",
      "patterns for which a negative response is desired. If we do that for our example\n",
      "above, we get the weight space diagram shown in Fig. 4.6.\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "V\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "Figure 4.6: Solution Region in Weight Space\n",
      "42\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "If a weight vector exists that correctly classiﬁes a set of patterns, then the\n",
      "half-spaces deﬁned by the correct responses for these patterns will have a non-\n",
      "empty intersection, called the solution region. The solution region will be a\n",
      "“hyper-wedge” region whose vertex is at the origin of weight space and whose\n",
      "cross-section increases with increasing distance from the origin.\n",
      "This region\n",
      "is shown shaded in Fig. 4.6. (The boxed numbers show, for later purposes,\n",
      "the number of errors made by weight vectors in each of the regions.)\n",
      "The\n",
      "ﬁxed-increment error-correction procedure changes a weight vector by moving it\n",
      "normal to any pattern hyperplane for which that weight vector gives an incorrect\n",
      "response. Suppose in our example that we present the patterns in the sequence\n",
      "Y1, Y2, Y3, Y4, and start the process with a weight point V1, as shown in Fig.\n",
      "4.7. Starting at V1, we see that it gives an incorrect response for pattern Y1, so\n",
      "we move V1 to V2 in a direction normal to plane 1. (That is what adding Y1 to\n",
      "V1 does.) Y2 gives an incorrect response for pattern Y2, and so on. Ultimately,\n",
      "the responses are only incorrect for planes bounding the solution region. Some\n",
      "of the subsequent corrections may overshoot the solution region, but eventually\n",
      "we work our way out far enough in the solution region that corrections (for\n",
      "a ﬁxed increment size) take us within it. The proofs for convergence of the\n",
      "ﬁxed-increment rule make this intuitive argument precise.\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "V\n",
      "V1\n",
      "V2\n",
      "V3\n",
      "V4\n",
      "V5\n",
      "V6\n",
      "Figure 4.7: Moving Into the Solution Region\n",
      "4.1.5\n",
      "The Widrow-Hoﬀ Procedure\n",
      "The Widrow-Hoﬀ procedure (also called the LMS or the delta procedure) at-\n",
      "tempts to ﬁnd weights that minimize a squared-error function between the pat-\n",
      "tern labels and the dot product computed by a TLU. For this purpose, the\n",
      "pattern labels are assumed to be either +1 or −1 (instead of 1 or 0).\n",
      "The\n",
      "4.1. THRESHOLD LOGIC UNITS\n",
      "43\n",
      "squared error for a pattern, Xi, with label di (for desired output) is:\n",
      "εi = (di −\n",
      "n+1\n",
      "�\n",
      "j=1\n",
      "xijwj)2\n",
      "where xij is the j-th component of Xi. The total squared error (over all patterns\n",
      "in a training set, Ξ, containing m patterns) is then:\n",
      "ε =\n",
      "m\n",
      "�\n",
      "i=1\n",
      "(di −\n",
      "n+1\n",
      "�\n",
      "j=1\n",
      "xijwj)2\n",
      "We want to choose the weights wj to minimize this squared error. One way to\n",
      "ﬁnd such a set of weights is to start with an arbitrary weight vector and move it\n",
      "along the negative gradient of ε as a function of the weights. Since ε is quadratic\n",
      "in the wj, we know that it has a global minimum, and thus this steepest descent\n",
      "procedure is guaranteed to ﬁnd the minimum. Each component of the gradient\n",
      "is the partial derivative of ε with respect to one of the weights. One problem\n",
      "with taking the partial derivative of ε is that ε depends on all the input vectors\n",
      "in Ξ. Often, it is preferable to use an incremental procedure in which we try the\n",
      "TLU on just one element, Xi, of Ξ at a time, compute the gradient of the single-\n",
      "pattern squared error, εi, make the appropriate adjustment to the weights, and\n",
      "then try another member of Ξ. Of course, the results of the incremental version\n",
      "can only approximate those of the batch one, but the approximation is usually\n",
      "quite eﬀective. We will be describing the incremental version here.\n",
      "The j-th component of the gradient of the single-pattern error is:\n",
      "∂εi\n",
      "∂wj\n",
      "= −2(di −\n",
      "n+1\n",
      "�\n",
      "j=1\n",
      "xijwj)xij\n",
      "An adjustment in the direction of the negative gradient would then change each\n",
      "weight as follows:\n",
      "wj ←− wj + ci(di − fi)xij\n",
      "where fi = �n+1\n",
      "j=1 xijwj, and ci governs the size of the adjustment. The entire\n",
      "weight vector (in augmented, or V, notation) is thus adjusted according to the\n",
      "following rule:\n",
      "V ←− V + ci(di − fi)Yi\n",
      "where, as before, Yi is the i-th augmented pattern vector.\n",
      "The Widrow-Hoﬀ procedure makes adjustments to the weight vector when-\n",
      "ever the dot product itself, Yi•V, does not equal the speciﬁed desired target\n",
      "44\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "value, di (which is either 1 or −1).\n",
      "The learning-rate factor, ci, might de-\n",
      "crease with time toward 0 to achieve asymptotic convergence. The Widrow-\n",
      "Hoﬀ formula for changing the weight vector has the same form as the standard\n",
      "ﬁxed-increment error-correction formula. The only diﬀerence is that fi is the\n",
      "thresholded response of the TLU in the error-correction case while it is the dot\n",
      "product itself for the Widrow-Hoﬀ procedure.\n",
      "Finding weight values that give the desired dot products corresponds to solv-\n",
      "ing a set of linear equalities, and the Widrow-Hoﬀ procedure can be interpreted\n",
      "as a descent procedure that attempts to minimize the mean-squared-error be-\n",
      "tween the actual and desired values of the dot product. (For more on Widrow-\n",
      "Hoﬀ and other related procedures, see [Duda & Hart, 1973, pp. 151ﬀ].)\n",
      "Examples of training curves for\n",
      "TLU’s; performance on training\n",
      "set; performance on test set;\n",
      "cumulative number of corrections.\n",
      "4.1.6\n",
      "Training a TLU on Non-Linearly-Separable Training\n",
      "Sets\n",
      "When the training set is not linearly separable (perhaps because of noise or\n",
      "perhaps inherently), it may still be desired to ﬁnd a “best” separating hy-\n",
      "perplane. Typically, the error-correction procedures will not do well on non-\n",
      "linearly-separable training sets because they will continue to attempt to correct\n",
      "inevitable errors, and the hyperplane will never settle into an acceptable place.\n",
      "Several methods have been proposed to deal with this case. First, we might\n",
      "use the Widrow-Hoﬀ procedure, which (although it will not converge to zero\n",
      "error on non-linearly separable problems) will give us a weight vector that min-\n",
      "imizes the mean-squared-error. A mean-squared-error criterion often gives un-\n",
      "satisfactory results, however, because it prefers many small errors to a few large\n",
      "ones. As an alternative, error correction with a continuous decrease toward zero\n",
      "of the value of the learning rate constant, c, will result in ever decreasing changes\n",
      "to the hyperplane. Duda [Duda, 1966] has suggested keeping track of the average\n",
      "value of the weight vector during error correction and using this average to give a\n",
      "separating hyperplane that performs reasonably well on non-linearly-separable\n",
      "problems. Gallant [Gallant, 1986] proposed what he called the “pocket algo-\n",
      "rithm.” As described in [Hertz, Krogh, & Palmer, 1991, p. 160]:\n",
      ". . . the pocket algorithm . . . consists simply in storing (or “putting\n",
      "in your pocket”) the set of weights which has had the longest un-\n",
      "modiﬁed run of successes so far. The algorithm is stopped after some\n",
      "chosen time t . . .\n",
      "After stopping, the weights in the pocket are used as a set that should give a\n",
      "small number of errors on the training set. Error-correction proceeds as usual\n",
      "with the ordinary set of weights.\n",
      "Also see methods proposed by\n",
      "[John, 1995] and by\n",
      "[Marchand & Golea, 1993]. The\n",
      "latter is claimed to outperform the\n",
      "pocket algorithm.\n",
      "4.2\n",
      "Linear Machines\n",
      "The natural generalization of a (two-category) TLU to an R-category classiﬁer\n",
      "is the structure, shown in Fig. 4.8, called a linear machine. Here, to use more\n",
      "4.2. LINEAR MACHINES\n",
      "45\n",
      "familiar notation, the Ws and X are meant to be augmented vectors (with an\n",
      "(n+1)-st component). Such a structure is also sometimes called a “competitive”\n",
      "net or a “winner-take-all” net.\n",
      "The output of the linear machine is one of\n",
      "the numbers, {1, . . . , R}, corresponding to which dot product is largest. Note\n",
      "that when R = 2, the linear machine reduces to a TLU with weight vector\n",
      "W = (W1 − W2).\n",
      "X\n",
      "W1\n",
      "WR\n",
      ". . .\n",
      "�\n",
      "�\n",
      "ARGMAX\n",
      "W1.X\n",
      "WR.X\n",
      "Figure 4.8: A Linear Machine\n",
      "The diagram in Fig. 4.9 shows the character of the regions in a 2-dimensional\n",
      "space created by a linear machine for R = 5. In n dimensions, every pair of\n",
      "regions is either separated by a section of a hyperplane or is non-adjacent.\n",
      "R1\n",
      "R3\n",
      "R4\n",
      "R5\n",
      "X.W4 � X.Wi for i � 4\n",
      "R2\n",
      "In this region:\n",
      "Figure 4.9: Regions For a Linear Machine\n",
      "To train a linear machine, there is a straightforward generalization of the\n",
      "2-category error-correction rule. Assemble the patterns in the training set into\n",
      "a sequence as before.\n",
      "a. If the machine classiﬁes a pattern correctly, no change is made to any of\n",
      "46\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "the weight vectors.\n",
      "b. If the machine mistakenly classiﬁes a category u pattern, Xi, in category\n",
      "v (u ̸= v), then:\n",
      "Wu ←− Wu + ciXi\n",
      "and\n",
      "Wv ←− Wv − ciXi\n",
      "and all other weight vectors are not changed.\n",
      "This correction increases the value of the u-th dot product and decreases the\n",
      "value of the v-th dot product. Just as in the 2-category ﬁxed increment proce-\n",
      "dure, this procedure is guaranteed to terminate, for constant ci, if there exists\n",
      "weight vectors that make correct separations of the training set. Note that when\n",
      "R = 2, this procedure reduces to the ordinary TLU error-correction procedure.\n",
      "A proof that this procedure terminates is given in [Nilsson, 1990, pp. 88-90]\n",
      "and in [Duda & Hart, 1973, pp. 174-177].\n",
      "4.3\n",
      "Networks of TLUs\n",
      "4.3.1\n",
      "Motivation and Examples\n",
      "Layered Networks\n",
      "To classify correctly all of the patterns in non-linearly-separable training sets re-\n",
      "quires separating surfaces more complex than hyperplanes. One way to achieve\n",
      "more complex surfaces is with networks of TLUs. Consider, for example, the 2-\n",
      "dimensional, even parity function, f = x1x2 + x1 x2. No single line through the\n",
      "2-dimensional square can separate the vertices (1,1) and (0,0) from the vertices\n",
      "(1,0) and (0,1)—the function is not linearly separable and thus cannot be im-\n",
      "plemented by a single TLU. But, the network of three TLUs shown in Fig. 4.10\n",
      "does implement this function. In the ﬁgure, we show the weight values along\n",
      "input lines to each TLU and the threshold value inside the circle representing\n",
      "the TLU.\n",
      "The function implemented by a network of TLUs depends on its topology\n",
      "as well as on the weights of the individual TLUs. Feedforward networks have\n",
      "no cycles; in a feedforward network no TLU’s input depends (through zero\n",
      "or more intermediate TLUs) on that TLU’s output. (Networks that are not\n",
      "feedforward are called recurrent networks). If the TLUs of a feedforward network\n",
      "are arranged in layers, with the elements of layer j receiving inputs only from\n",
      "TLUs in layer j − 1, then we say that the network is a layered, feedforward\n",
      "4.3. NETWORKS OF TLUS\n",
      "47\n",
      "f\n",
      "x1\n",
      "x2\n",
      "1.5\n",
      "-0.5\n",
      "0.5\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "Figure 4.10: A Network for the Even Parity Function\n",
      "network. The network shown in Fig. 4.10 is a layered, feedforward network\n",
      "having two layers (of weights). (Some people count the layers of TLUs and\n",
      "include the inputs as a layer also; they would call this network a three-layer\n",
      "network.) In general, a feedforward, layered network has the structure shown\n",
      "in Fig. 4.11. All of the TLUs except the “output” units are called hidden units\n",
      "(they are “hidden” from the output).\n",
      "X\n",
      "hidden units\n",
      "output units\n",
      "Figure 4.11: A Layered, Feedforward Network\n",
      "Implementing DNF Functions by Two-Layer Networks\n",
      "We have already deﬁned k-term DNF functions—they are DNF functions having\n",
      "k terms. A k-term DNF function can be implemented by a two-layer network\n",
      "with k units in the hidden layer—to implement the k terms—and one output\n",
      "unit to implement the disjunction of these terms. Since any Boolean function\n",
      "has a DNF form, any Boolean function can be implemented by some two-layer\n",
      "network of TLUs. As an example, consider the function f = x1x2 + x2x3 +\n",
      "x1x3. The form of the network that implements this function is shown in Fig.\n",
      "4.12. (We leave it to the reader to calculate appropriate values of weights and\n",
      "48\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "thresholds.) The 3-cube representation of the function is shown in Fig. 4.13.\n",
      "The network of Fig. 4.12 can be designed so that each hidden unit implements\n",
      "one of the planar boundaries shown in Fig. 4.13.\n",
      "x\n",
      "conjuncts\n",
      "disjunct\n",
      "A Feedforward, 2-layer Network\n",
      "TLUs\n",
      "disjunction\n",
      "of terms\n",
      "conjunctions\n",
      "of literals\n",
      "(terms)\n",
      "Figure 4.12: A Two-Layer Network\n",
      "x2\n",
      "x1\n",
      "x3\n",
      "f = x1x2 + x2x3 + x1x3\n",
      "Figure 4.13: Three Planes Implemented by the Hidden Units\n",
      "To train a two-layer network that implements a k-term DNF function, we\n",
      "ﬁrst note that the output unit implements a disjunction, so the weights in the\n",
      "ﬁnal layer are ﬁxed. The weights in the ﬁrst layer (except for the “threshold\n",
      "weights”) can all have values of 1, −1, or 0. Later, we will present a training\n",
      "procedure for this ﬁrst layer of weights.\n",
      "Discuss half-space intersections,\n",
      "half-space unions, NP-hardness of\n",
      "optimal versions,\n",
      "single-side-error-hypeplane\n",
      "methods, relation to “AQ”\n",
      "methods.\n",
      "4.3. NETWORKS OF TLUS\n",
      "49\n",
      "Important Comment About Layered Networks\n",
      "Adding additional layers cannot compensate for an inadequate ﬁrst layer of\n",
      "TLUs. The ﬁrst layer of TLUs partitions the feature space so that no two dif-\n",
      "ferently labeled vectors are in the same region (that is, so that no two such\n",
      "vectors yield the same set of outputs of the ﬁrst-layer units). If the ﬁrst layer\n",
      "does not partition the feature space in this way, then regardless of what subse-\n",
      "quent layers do, the ﬁnal outputs will not be consistent with the labeled training\n",
      "set.\n",
      "Add diagrams showing the\n",
      "non-linear transformation\n",
      "performed by a layered network.\n",
      "4.3.2\n",
      "Madalines\n",
      "Two-Category Networks\n",
      "An interesting example of a layered, feedforward network is the two-layer one\n",
      "which has an odd number of hidden units, and a “vote-taking” TLU as the\n",
      "output unit. Such a network was called a “Madaline” (for many adalines by\n",
      "Widrow. Typically, the response of the vote taking unit is deﬁned to be the\n",
      "response of the majority of the hidden units, although other output logics are\n",
      "possible. Ridgway [Ridgway, 1962] proposed the following error-correction rule\n",
      "for adjusting the weights of the hidden units of a Madaline:\n",
      "• If the Madaline correctly classiﬁes a pattern, Xi, no corrections are made\n",
      "to any of the hidden units’ weight vectors,\n",
      "• If the Madaline incorrectly classiﬁes a pattern, Xi, then determine the\n",
      "minimum number of hidden units whose responses need to be changed\n",
      "(from 0 to 1 or from 1 to 0—depending on the type of error) in order that\n",
      "the Madaline would correctly classify Xi. Suppose that minimum number\n",
      "is ki. Of those hidden units voting incorrectly, change the weight vectors\n",
      "of those ki of them whose dot products are closest to 0 by using the error\n",
      "correction rule:\n",
      "W ←− W + ci(di − fi)Xi\n",
      "where di is the desired response of the hidden unit (0 or 1) and fi is the\n",
      "actual response (0 or 1). (We assume augmented vectors here even though\n",
      "we are using X, W notation.)\n",
      "That is, we perform error-correction on just enough hidden units to correct\n",
      "the vote to a majority voting correctly, and we change those that are easiest to\n",
      "change. There are example problems in which even though a set of weight values\n",
      "exists for a given Madaline structure such that it could classify all members of\n",
      "a training set correctly, this procedure will fail to ﬁnd them. Nevertheless, the\n",
      "procedure works eﬀectively in most experiments with it.\n",
      "We leave it to the reader to think about how this training procedure could\n",
      "be modiﬁed if the output TLU implemented an or function (or an and function).\n",
      "50\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "R-Category Madalines and Error-Correcting Output Codes\n",
      "If there are k hidden units (k > 1) in a two-layer network, their responses\n",
      "correspond to vertices of a k-dimensional hypercube. The ordinary two-category\n",
      "Madaline identiﬁes two special points in this space, namely the vertex consisting\n",
      "of k 1’s and the vertex consisting of k 0’s. The Madaline’s response is 1 if the\n",
      "point in “hidden-unit-space” is closer to the all 1’s vertex than it is to the all\n",
      "0’s vertex. We could design an R-category Madaline by identifying R vertices\n",
      "in hidden-unit space and then classifying a pattern according to which of these\n",
      "vertices the hidden-unit response is closest to. A machine using that idea was\n",
      "implemented in the early 1960s at SRI [Brain, et al., 1962]. It used the fact\n",
      "that the 2p so-called maximal-length shift-register sequences [Peterson, 1961, pp.\n",
      "147ﬀ] in a (2p −1)-dimensional Boolean space are mutually equidistant (for any\n",
      "integer p). For similar, more recent work see [Dietterich & Bakiri, 1991].\n",
      "4.3.3\n",
      "Piecewise Linear Machines\n",
      "A two-category training set is linearly separable if there exists a threshold func-\n",
      "tion that correctly classiﬁes all members of the training set. Similarly, we can\n",
      "say that an R-category training set is linearly separable if there exists a linear\n",
      "machine that correctly classiﬁes all members of the training set. When an R-\n",
      "category problem is not linearly separable, we need a more powerful classiﬁer.\n",
      "A candidate is a structure called a piecewise linear (PWL) machine illustrated\n",
      "in Fig. 4.14.\n",
      "X\n",
      "W1\n",
      "W1\n",
      ". . .\n",
      "�\n",
      "�\n",
      "MAX\n",
      ". . .\n",
      "�\n",
      "�\n",
      "MAX\n",
      ". . .\n",
      "WR\n",
      "WR\n",
      "ARG\n",
      "MAX\n",
      "1\n",
      "R\n",
      "1\n",
      "N1\n",
      "1\n",
      "NR\n",
      "Figure 4.14: A Piecewise Linear Machine\n",
      "4.3. NETWORKS OF TLUS\n",
      "51\n",
      "The PWL machine groups its weighted summing units into R banks corre-\n",
      "sponding to the R categories. An input vector X is assigned to that category\n",
      "corresponding to the bank with the largest weighted sum. We can use an error-\n",
      "correction training algorithm similar to that used for a linear machine. If a\n",
      "pattern is classiﬁed incorrectly, we subtract (a constant times) the pattern vec-\n",
      "tor from the weight vector producing the largest dot product (it was incorrectly\n",
      "the largest) and add (a constant times) the pattern vector to that weight vector\n",
      "in the correct bank of weight vectors whose dot product is locally largest in\n",
      "that bank. (Again, we use augmented vectors here.) Unfortunately, there are\n",
      "example training sets that are separable by a given PWL machine structure\n",
      "but for which this error-correction training method fails to ﬁnd a solution. The\n",
      "method does appear to work well in some situations [Duda & Fossum, 1966], al-\n",
      "though [Nilsson, 1965, page 89] observed that “it is probably not a very eﬀective\n",
      "method for training PWL machines having more than three [weight vectors] in\n",
      "each bank.”\n",
      "4.3.4\n",
      "Cascade Networks\n",
      "Another interesting class of feedforward networks is that in which all of the TLUs\n",
      "are ordered and each TLU receives inputs from all of the pattern components\n",
      "and from all TLUs lower in the ordering. Such a network is called a cascade\n",
      "network. An example is shown in Fig. 4.15 in which the TLUs are labeled by\n",
      "the linearly separable functions (of their inputs) that they implement. Each\n",
      "TLU in the network implements a set of 2k parallel hyperplanes, where k is\n",
      "the number of TLUs from which it receives inputs. (Each of the k preceding\n",
      "TLUs can have an output of 1 or 0; that’s 2k diﬀerent combinations—resulting\n",
      "in 2k diﬀerent positions for the parallel hyperplanes.) We show a 3-dimensional\n",
      "sketch for a network of two TLUs in Fig. 4.16. The reader might consider how\n",
      "the n-dimensional parity function might be implemented by a cascade network\n",
      "having log2 n TLUs.\n",
      "x\n",
      "L1\n",
      "L2\n",
      "output\n",
      "L3\n",
      "Figure 4.15: A Cascade Network\n",
      "52\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "L1\n",
      "L2\n",
      "L2\n",
      "Figure 4.16: Planes Implemented by a Cascade Network with Two TLUs\n",
      "Cascade networks might be trained by ﬁrst training L1 to do as good a job\n",
      "as possible at separating all the training patterns (perhaps by using the pocket\n",
      "algorithm, for example), then training L2 (including the weight from L1 to L2)\n",
      "also to do as good a job as possible at separating all the training patterns,\n",
      "and so on until the resulting network classiﬁes the patterns in the training set\n",
      "satisfactorily.\n",
      "Also mention the\n",
      "“cascade-correlation” method of\n",
      "[Fahlman & Lebiere, 1990].\n",
      "4.4\n",
      "Training Feedforward Networks by Back-\n",
      "propagation\n",
      "4.4.1\n",
      "Notation\n",
      "The general problem of training a network of TLUs is diﬃcult. Consider, for\n",
      "example, the layered, feedforward network of Fig. 4.11. If such a network makes\n",
      "an error on a pattern, there are usually several diﬀerent ways in which the error\n",
      "can be corrected. It is diﬃcult to assign “blame” for the error to any particular\n",
      "TLU in the network. Intuitively, one looks for weight-adjusting procedures that\n",
      "move the network in the correct direction (relative to the error) by making\n",
      "minimal changes. In this spirit, the Widrow-Hoﬀ method of gradient descent\n",
      "has been generalized to deal with multilayer networks.\n",
      "In explaining this generalization, we use Fig. 4.17 to introduce some nota-\n",
      "tion. This network has only one output unit, but, of course, it is possible to have\n",
      "several TLUs in the output layer—each implementing a diﬀerent function. Each\n",
      "of the layers of TLUs will have outputs that we take to be the components of\n",
      "vectors, just as the input features are components of an input vector. The j-th\n",
      "layer of TLUs (1 ≤ j < k) will have as their outputs the vector X(j). The input\n",
      "feature vector is denoted by X(0), and the ﬁnal output (of the k-th layer TLU)\n",
      "is f. Each TLU in each layer has a weight vector (connecting it to its inputs)\n",
      "and a threshold; the i-th TLU in the j-th layer has a weight vector denoted by\n",
      "W(j)\n",
      "i . (We will assume that the “threshold weight” is the last component of\n",
      "the associated weight vector; we might have used V notation instead to include\n",
      "4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION53\n",
      "this threshold component, but we have chosen here to use the familiar X,W\n",
      "notation, assuming that these vectors are “augmented” as appropriate.) We\n",
      "denote the weighted sum input to the i-th threshold unit in the j-th layer by\n",
      "s(j)\n",
      "i . (That is, s(j)\n",
      "i\n",
      "= X(j−1)•W(j)\n",
      "i .) The number of TLUs in the j-th layer is\n",
      "given by mj. The vector W(j)\n",
      "i\n",
      "has components w(j)\n",
      "l,i for l = 1, . . . , m(j−1) + 1.\n",
      "X(0)\n",
      ". . .\n",
      ". . .\n",
      ". . .\n",
      ". . .\n",
      "Wi(1)\n",
      "W(k)\n",
      "X(1)\n",
      "m1 TLUs\n",
      ". . .\n",
      "Wi(j)\n",
      ". . .\n",
      "X(j)\n",
      ". . .\n",
      "Wi(k-1)\n",
      "X(k-1)\n",
      "mj TLUs\n",
      "m(k-1) TLUs\n",
      "wli(j)\n",
      "wl(k)\n",
      "First Layer\n",
      "j-th Layer\n",
      "(k-1)-th Layer\n",
      "k-th Layer\n",
      ". . .\n",
      "f\n",
      "si(1)\n",
      "si(j)\n",
      "si(k-1)\n",
      "s(k)\n",
      "Figure 4.17: A k-layer Network\n",
      "4.4.2\n",
      "The Backpropagation Method\n",
      "A gradient descent method, similar to that used in the Widrow Hoﬀ method,\n",
      "has been proposed by various authors for training a multi-layer, feedforward\n",
      "network.\n",
      "As before, we deﬁne an error function on the ﬁnal output of the\n",
      "network and we adjust each weight in the network so as to minimize the error.\n",
      "If we have a desired response, di, for the i-th input vector, Xi, in the training\n",
      "set, Ξ, we can compute the squared error over the entire training set to be:\n",
      "ε =\n",
      "�\n",
      "Xi ϵ Ξ\n",
      "(di − fi)2\n",
      "where fi is the actual response of the network for input Xi. To do gradient\n",
      "descent on this squared error, we adjust each weight in the network by an\n",
      "amount proportional to the negative of the partial derivative of ε with respect\n",
      "to that weight. Again, we use a single-pattern error function so that we can\n",
      "use an incremental weight adjustment procedure. The squared error for a single\n",
      "input vector, X, evoking an output of f when the desired output is d is:\n",
      "54\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "ε = (d − f)2\n",
      "It is convenient to take the partial derivatives of ε with respect to the various\n",
      "weights in groups corresponding to the weight vectors.\n",
      "We deﬁne a partial\n",
      "derivative of a quantity φ, say, with respect to a weight vector, W(j)\n",
      "i , thus:\n",
      "∂φ\n",
      "∂W(j)\n",
      "i\n",
      "def\n",
      "=\n",
      "�\n",
      "∂φ\n",
      "∂w(j)\n",
      "1i\n",
      ", . . . ,\n",
      "∂φ\n",
      "∂w(j)\n",
      "li\n",
      ", . . . ,\n",
      "∂φ\n",
      "∂w(j)\n",
      "mj−1+1,i\n",
      "�\n",
      "where w(j)\n",
      "li\n",
      "is the l-th component of W(j)\n",
      "i . This vector partial derivative of φ is\n",
      "called the gradient of φ with respect to W and is sometimes denoted by ∇Wφ.\n",
      "Since ε’s dependence on W(j)\n",
      "i\n",
      "is entirely through s(j)\n",
      "i , we can use the chain\n",
      "rule to write:\n",
      "∂ε\n",
      "∂W(j)\n",
      "i\n",
      "=\n",
      "∂ε\n",
      "∂s(j)\n",
      "i\n",
      "∂s(j)\n",
      "i\n",
      "∂W(j)\n",
      "i\n",
      "Because s(j)\n",
      "i\n",
      "= X(j−1)•W(j)\n",
      "i ,\n",
      "∂s(j)\n",
      "i\n",
      "∂W(j)\n",
      "i\n",
      "= X(j−1). Substituting yields:\n",
      "∂ε\n",
      "∂W(j)\n",
      "i\n",
      "=\n",
      "∂ε\n",
      "∂s(j)\n",
      "i\n",
      "X(j−1)\n",
      "Note that\n",
      "∂ε\n",
      "∂s(j)\n",
      "i\n",
      "= −2(d − f) ∂f\n",
      "∂s(j)\n",
      "i\n",
      ". Thus,\n",
      "∂ε\n",
      "∂W(j)\n",
      "i\n",
      "= −2(d − f) ∂f\n",
      "∂s(j)\n",
      "i\n",
      "X(j−1)\n",
      "The quantity (d−f) ∂f\n",
      "∂s(j)\n",
      "i\n",
      "plays an important role in our calculations; we shall\n",
      "denote it by δ(j)\n",
      "i\n",
      ". Each of the δ(j)\n",
      "i\n",
      "’s tells us how sensitive the squared error of\n",
      "the network output is to changes in the input to each threshold function. Since\n",
      "we will be changing weight vectors in directions along their negative gradient,\n",
      "our fundamental rule for weight changes throughout the network will be:\n",
      "W(j)\n",
      "i\n",
      "← W(j)\n",
      "i\n",
      "+ c(j)\n",
      "i δ(j)\n",
      "i\n",
      "X(j−1)\n",
      "where c(j)\n",
      "i\n",
      "is the learning rate constant for this weight vector. (Usually, the\n",
      "learning rate constants for all weight vectors in the network are the same.) We\n",
      "see that this rule is quite similar to that used in the error correction procedure\n",
      "4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION55\n",
      "for a single TLU. A weight vector is changed by the addition of a constant times\n",
      "its vector of (unweighted) inputs.\n",
      "Now, we must turn our attention to the calculation of the δ(j)\n",
      "i\n",
      "’s. Using the\n",
      "deﬁnition, we have:\n",
      "δ(j)\n",
      "i\n",
      "= (d − f) ∂f\n",
      "∂s(j)\n",
      "i\n",
      "We have a problem, however, in attempting to carry out the partial deriva-\n",
      "tives of f with respect to the s’s. The network output, f, is not continuously\n",
      "diﬀerentiable with respect to the s’s because of the presence of the threshold\n",
      "functions. Most small changes in these sums do not change f at all, and when\n",
      "f does change, it changes abruptly from 1 to 0 or vice versa.\n",
      "A way around this diﬃculty was proposed by Werbos [Werbos, 1974] and\n",
      "(perhaps independently) pursued by several other researchers, for example\n",
      "[Rumelhart, Hinton, & Williams, 1986].\n",
      "The trick involves replacing all the\n",
      "threshold functions by diﬀerentiable functions called sigmoids.1\n",
      "The output\n",
      "of a sigmoid function, superimposed on that of a threshold function, is shown\n",
      "in Fig. 4.18. Usually, the sigmoid function used is f(s) =\n",
      "1\n",
      "1+e−s , where s is\n",
      "the input and f is the output.\n",
      "sigmoid\n",
      "threshold function\n",
      "f (s)\n",
      "s\n",
      "f (s) = 1/[1 + e�s]\n",
      "Figure 4.18: A Sigmoid Function\n",
      "1[Russell & Norvig 1995, page 595] attributes the use of this idea to [Bryson & Ho 1969].\n",
      "56\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "We show the network containing sigmoid units in place of TLUs in Fig. 4.19.\n",
      "The output of the i-th sigmoid unit in the j-th layer is denoted by f (j)\n",
      "i\n",
      ". (That\n",
      "is, f (j)\n",
      "i\n",
      "=\n",
      "1\n",
      "1+e−s(j)\n",
      "i\n",
      ".)\n",
      "X(0)\n",
      ". . .\n",
      ". . .\n",
      ". . .\n",
      ". . .\n",
      "Wi(1)\n",
      "si(1)\n",
      "W(k)\n",
      "X(1)\n",
      "fi(1)\n",
      "m1 sigmoids\n",
      ". . .\n",
      "Wi(j) fi(j)\n",
      "si(j)\n",
      ". . .\n",
      "X(j)\n",
      ". . .\n",
      "Wi(k-1)\n",
      "fi(k-1)\n",
      "si(k-1)\n",
      "f(k)\n",
      "s(k)\n",
      "X(k-1)\n",
      "mj sigmoids\n",
      "m(k-1) sigmoids\n",
      "wli(j)\n",
      "wl(k)\n",
      "�i(j)\n",
      "�i(1)\n",
      "�i(k-1)\n",
      "�(k)\n",
      "First Layer\n",
      "j-th Layer\n",
      "(k-1)-th Layer\n",
      "k-th Layer\n",
      ". . .\n",
      "Figure 4.19: A Network with Sigmoid Units\n",
      "4.4.3\n",
      "Computing Weight Changes in the Final Layer\n",
      "We ﬁrst calculate δ(k) in order to compute the weight change for the ﬁnal sigmoid\n",
      "unit:\n",
      "4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION57\n",
      "δ(k) = (d − f (k))∂f (k)\n",
      "∂s(k)\n",
      "Given the sigmoid function that we are using, namely f(s) =\n",
      "1\n",
      "1+e−s , we have\n",
      "that ∂f\n",
      "∂s = f(1 − f). Substituting gives us:\n",
      "δ(k) = (d − f (k))f (k)(1 − f (k))\n",
      "Rewriting our general rule for weight vector changes, the weight vector in\n",
      "the ﬁnal layer is changed according to the rule:\n",
      "W(k) ← W(k) + c(k)δ(k)X(k−1)\n",
      "where δ(k) = (d − f (k))f (k)(1 − f (k))\n",
      "It is interesting to compare backpropagation to the error-correction rule and\n",
      "to the Widrow-Hoﬀ rule. The backpropagation weight adjustment for the single\n",
      "element in the ﬁnal layer can be written as:\n",
      "W ←− W + c(d − f)f(1 − f)X\n",
      "Written in the same format, the error-correction rule is:\n",
      "W ←− W + c(d − f)X\n",
      "and the Widrow-Hoﬀ rule is:\n",
      "W ←− W + c(d − f)X\n",
      "The only diﬀerence (except for the fact that f is not thresholded in Widrow-\n",
      "Hoﬀ) is the f(1 − f) term due to the presence of the sigmoid function. With\n",
      "the sigmoid function, f(1 − f) can vary in value from 0 to 1. When f is 0,\n",
      "f(1 − f) is also 0; when f is 1, f(1 − f) is 0; f(1 − f) obtains its maximum\n",
      "value of 1/4 when f is 1/2 (that is, when the input to the sigmoid is 0). The\n",
      "sigmoid function can be thought of as implementing a “fuzzy” hyperplane. For\n",
      "a pattern far away from this fuzzy hyperplane, f(1 − f) has value close to 0,\n",
      "and the backpropagation rule makes little or no change to the weight values\n",
      "regardless of the desired output. (Small changes in the weights will have little\n",
      "eﬀect on the output for inputs far from the hyperplane.) Weight changes are\n",
      "only made within the region of “fuzz” surrounding the hyperplane, and these\n",
      "changes are in the direction of correcting the error, just as in the error-correction\n",
      "and Widrow-Hoﬀ rules.\n",
      "58\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "4.4.4\n",
      "Computing Changes to the Weights in Intermediate\n",
      "Layers\n",
      "Using our expression for the δ’s, we can similarly compute how to change each\n",
      "of the weight vectors in the network. Recall:\n",
      "δ(j)\n",
      "i\n",
      "= (d − f) ∂f\n",
      "∂s(j)\n",
      "i\n",
      "Again we use a chain rule. The ﬁnal output, f, depends on s(j)\n",
      "i\n",
      "through\n",
      "each of the summed inputs to the sigmoids in the (j + 1)-th layer. So:\n",
      "δ(j)\n",
      "i\n",
      "= (d − f) ∂f\n",
      "∂s(j)\n",
      "i\n",
      "= (d − f)\n",
      "�\n",
      "∂f\n",
      "∂s(j+1)\n",
      "1\n",
      "∂s(j+1)\n",
      "1\n",
      "∂s(j)\n",
      "i\n",
      "+ · · · +\n",
      "∂f\n",
      "∂s(j+1)\n",
      "l\n",
      "∂s(j+1)\n",
      "l\n",
      "∂s(j)\n",
      "i\n",
      "+ · · · +\n",
      "∂f\n",
      "∂s(j+1)\n",
      "mj+1\n",
      "∂s(j+1)\n",
      "mj+1\n",
      "∂s(j)\n",
      "i\n",
      "�\n",
      "=\n",
      "mj+1\n",
      "�\n",
      "l=1\n",
      "(d − f)\n",
      "∂f\n",
      "∂s(j+1)\n",
      "l\n",
      "∂s(j+1)\n",
      "l\n",
      "∂s(j)\n",
      "i\n",
      "=\n",
      "mj+1\n",
      "�\n",
      "l=1\n",
      "δ(j+1)\n",
      "l\n",
      "∂s(j+1)\n",
      "l\n",
      "∂s(j)\n",
      "i\n",
      "It remains to compute the\n",
      "∂s(j+1)\n",
      "l\n",
      "∂s(j)\n",
      "i\n",
      "’s. To do that we ﬁrst write:\n",
      "s(j+1)\n",
      "l\n",
      "= X(j)•W(j+1)\n",
      "l\n",
      "=\n",
      "mj+1\n",
      "�\n",
      "ν=1\n",
      "f (j)\n",
      "ν w(j+1)\n",
      "νl\n",
      "And then, since the weights do not depend on the s’s:\n",
      "∂s(j+1)\n",
      "l\n",
      "∂s(j)\n",
      "i\n",
      "=\n",
      "∂\n",
      "��mj+1\n",
      "ν=1\n",
      "f (j)\n",
      "ν w(j+1)\n",
      "νl\n",
      "�\n",
      "∂s(j)\n",
      "i\n",
      "=\n",
      "mj+1\n",
      "�\n",
      "ν=1\n",
      "w(j+1)\n",
      "νl\n",
      "∂f (j)\n",
      "ν\n",
      "∂s(j)\n",
      "i\n",
      "Now, we note that ∂f (j)\n",
      "ν\n",
      "∂s(j)\n",
      "i\n",
      "= 0 unless ν = i, in which case ∂f (j)\n",
      "ν\n",
      "∂s(j)\n",
      "ν\n",
      "= f (j)\n",
      "ν (1 − f (j)\n",
      "ν ).\n",
      "Therefore:\n",
      "∂s(j+1)\n",
      "l\n",
      "∂s(j)\n",
      "i\n",
      "= w(j+1)\n",
      "il\n",
      "f (j)\n",
      "i\n",
      "(1 − f (j)\n",
      "i\n",
      ")\n",
      "4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION59\n",
      "We use this result in our expression for δ(j)\n",
      "i\n",
      "to give:\n",
      "δ(j)\n",
      "i\n",
      "= f (j)\n",
      "i\n",
      "(1 − f (j)\n",
      "i\n",
      ")\n",
      "mj+1\n",
      "�\n",
      "l=1\n",
      "δ(j+1)\n",
      "l\n",
      "w(j+1)\n",
      "il\n",
      "The above equation is recursive in the δ’s. (It is interesting to note that\n",
      "this expression is independent of the error function; the error function explicitly\n",
      "aﬀects only the computation of δ(k).) Having computed the δ(j+1)\n",
      "i\n",
      "’s for layer\n",
      "j + 1, we can use this equation to compute the δ(j)\n",
      "i\n",
      "’s. The base case is δ(k),\n",
      "which we have already computed:\n",
      "δ(k) = (d − f (k))f (k)(1 − f (k))\n",
      "We use this expression for the δ’s in our generic weight changing rule, namely:\n",
      "W(j)\n",
      "i\n",
      "← W(j)\n",
      "i\n",
      "+ c(j)\n",
      "i δ(j)\n",
      "i\n",
      "X(j−1)\n",
      "Although this rule appears complex, it has an intuitively reasonable explanation.\n",
      "The quantity δ(k) = (d − f)f(1 − f) controls the overall amount and sign of all\n",
      "weight adjustments in the network. (Adjustments diminish as the ﬁnal output,\n",
      "f, approaches either 0 or 1, because they have vanishing eﬀect on f then.) As\n",
      "the recursion equation for the δ’s shows, the adjustments for the weights going\n",
      "in to a sigmoid unit in the j-th layer are proportional to the eﬀect that such\n",
      "adjustments have on that sigmoid unit’s output (its f (j)(1−f (j)) factor). They\n",
      "are also proportional to a kind of “average” eﬀect that any change in the output\n",
      "of that sigmoid unit will have on the ﬁnal output. This average eﬀect depends\n",
      "on the weights going out of the sigmoid unit in the j-th layer (small weights\n",
      "produce little downstream eﬀect) and the eﬀects that changes in the outputs of\n",
      "(j + 1)-th layer sigmoid units will have on the ﬁnal output (as measured by the\n",
      "δ(j+1)’s). These calculations can be simply implemented by “backpropagating”\n",
      "the δ’s through the weights in reverse direction (thus, the name backprop for\n",
      "this algorithm).\n",
      "4.4.5\n",
      "Variations on Backprop\n",
      "[To be written: problem of local minima, simulated annealing, momemtum\n",
      "(Plaut, et al., 1986, see [Hertz, Krogh, & Palmer, 1991]), quickprop, regulariza-\n",
      "tion methods]\n",
      "Simulated Annealing\n",
      "To apply simulated annealing, the value of the learning rate constant is gradually\n",
      "decreased with time. If we fall early into an error-function valley that is not\n",
      "very deep (a local minimum), it typically will neither be very broad, and soon\n",
      "60\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "a subsequent large correction will jostle us out of it. It is less likely that we will\n",
      "move out of deep valleys, and at the end of the process (with very small values\n",
      "of the learning rate constant), we descend to its deepest point. The process\n",
      "gets its name by analogy with annealing in metallurgy, in which a material’s\n",
      "temperature is gradually decreased allowing its crystalline structure to reach a\n",
      "minimal energy state.\n",
      "4.4.6\n",
      "An Application: Steering a Van\n",
      "A neural network system called ALVINN (Autonomous Land Vehicle in a Neural\n",
      "Network) has been trained to steer a Chevy van successfully on ordinary roads\n",
      "and highways at speeds of 55 mph [Pomerleau, 1991, Pomerleau, 1993]. The\n",
      "input to the network is derived from a low-resolution (30 x 32) television image.\n",
      "The TV camera is mounted on the van and looks at the road straight ahead.\n",
      "This image is sampled and produces a stream of 960-dimensional input vectors\n",
      "to the neural network. The network is shown in Fig. 4.20.\n",
      "960 inputs\n",
      "30 x 32 retina\n",
      ". . .\n",
      "5 hidden\n",
      "units connected\n",
      "to all 960 inputs\n",
      "30 output units\n",
      "connected to all\n",
      "hidden units\n",
      ". . .\n",
      "sharp left\n",
      "sharp right\n",
      "straight ahead\n",
      "centroid\n",
      "of outputs\n",
      "steers\n",
      "vehicle\n",
      "Figure 4.20: The ALVINN Network\n",
      "The network has ﬁve hidden units in its ﬁrst layer and 30 output units in the\n",
      "second layer; all are sigmoid units. The output units are arranged in a linear\n",
      "order and control the van’s steering angle. If a unit near the top of the array\n",
      "of output units has a higher output than most of the other units, the van is\n",
      "steered to the left; if a unit near the bottom of the array has a high output, the\n",
      "van is steered to the right. The “centroid” of the responses of all of the output\n",
      "4.5. SYNERGIES BETWEEN NEURAL NETWORK AND KNOWLEDGE-BASED METHODS61\n",
      "units is computed, and the van’s steering angle is set at a corresponding value\n",
      "between hard left and hard right.\n",
      "The system is trained by a modiﬁed on-line training regime. A driver drives\n",
      "the van, and his actual steering angles are taken as the correct labels for the\n",
      "corresponding inputs.\n",
      "The network is trained incrementally by backprop to\n",
      "produce the driver-speciﬁed steering angles in response to each visual pattern\n",
      "as it occurs in real time while driving.\n",
      "This simple procedure has been augmented to avoid two potential problems.\n",
      "First, since the driver is usually driving well, the network would never get any\n",
      "experience with far-from-center vehicle positions and/or incorrect vehicle orien-\n",
      "tations. Also, on long, straight stretches of road, the network would be trained\n",
      "for a long time only to produce straight-ahead steering angles; this training\n",
      "would swamp out earlier training to follow a curved road. We wouldn’t want\n",
      "to try to avoid these problems by instructing the driver to drive erratically\n",
      "occasionally, because the system would learn to mimic this erratic behavior.\n",
      "Instead, each original image is shifted and rotated in software to create 14\n",
      "additional images in which the vehicle appears to be situated diﬀerently relative\n",
      "to the road. Using a model that tells the system what steering angle ought to\n",
      "be used for each of these shifted images, given the driver-speciﬁed steering angle\n",
      "for the original image, the system constructs an additional 14 labeled training\n",
      "patterns to add to those encountered during ordinary driver training.\n",
      "4.5\n",
      "Synergies\n",
      "Between\n",
      "Neural\n",
      "Network\n",
      "and\n",
      "Knowledge-Based Methods\n",
      "To be written; discuss\n",
      "rule-generating procedures (such as\n",
      "[Towell & Shavlik, 1992]) and how\n",
      "expert-provided rules can aid\n",
      "neural net training and vice-versa\n",
      "[Towell, Shavlik, & Noordweier, 1990].\n",
      "4.6\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "62\n",
      "CHAPTER 4. NEURAL NETWORKS\n",
      "Chapter 5\n",
      "Statistical Learning\n",
      "5.1\n",
      "Using Statistical Decision Theory\n",
      "5.1.1\n",
      "Background and General Method\n",
      "Suppose the pattern vector, X, is a random variable whose probability distri-\n",
      "bution for category 1 is diﬀerent than it is for category 2. (The treatment given\n",
      "here can easily be generalized to R-category problems.) Speciﬁcally, suppose we\n",
      "have the two probability distributions (perhaps probability density functions),\n",
      "p(X | 1) and p(X | 2). Given a pattern, X, we want to use statistical tech-\n",
      "niques to determine its category—that is, to determine from which distribution\n",
      "it was drawn. These techniques are based on the idea of minimizing the ex-\n",
      "pected value of a quantity similar to the error function we used in deriving the\n",
      "weight-changing rules for backprop.\n",
      "In developing a decision method, it is necessary to know the relative serious-\n",
      "ness of the two kinds of mistakes that might be made. (We might decide that a\n",
      "pattern really in category 1 is in category 2, and vice versa.) We describe this\n",
      "information by a loss function, λ(i | j), for i, j = 1, 2. λ(i | j) represents the loss\n",
      "incurred when we decide a pattern is in category i when really it is in category\n",
      "j. We assume here that λ(1 | 1) and λ(2 | 2) are both 0. For any given pattern,\n",
      "X, we want to decide its category in such a way that minimizes the expected\n",
      "value of this loss.\n",
      "Given a pattern, X, if we decide category i, the expected value of the loss\n",
      "will be:\n",
      "LX(i) = λ(i | 1)p(1 | X) + λ(i | 2)p(2 | X)\n",
      "where p(j | X) is the probability that given a pattern X, its category is j. Our\n",
      "decision rule will be to decide that X belongs to category 1 if LX(1) ≤ LX(2),\n",
      "and to decide on category 2 otherwise.\n",
      "63\n",
      "64\n",
      "CHAPTER 5. STATISTICAL LEARNING\n",
      "We can use Bayes’ Rule to get expressions for p(j | X) in terms of p(X | j),\n",
      "which we assume to be known (or estimatible):\n",
      "p(j | X) = p(X | j)p(j)\n",
      "p(X)\n",
      "where p(j) is the (a priori) probability of category j (one category may be much\n",
      "more probable than the other); and p(X) is the (a priori) probability of pattern\n",
      "X being the pattern we are asked to classify. Performing the substitutions given\n",
      "by Bayes’ Rule, our decision rule becomes:\n",
      "Decide category 1 iﬀ:\n",
      "λ(1 | 1)p(X | 1)p(1)\n",
      "p(X)\n",
      "+ λ(1 | 2)p(X | 2)p(2)\n",
      "p(X)\n",
      "≤ λ(2 | 1)p(X | 1)p(1)\n",
      "p(X)\n",
      "+ λ(2 | 2)p(X | 2)p(2)\n",
      "p(X)\n",
      "Using the fact that λ(i | i) = 0, and noticing that p(X) is common to both\n",
      "expressions, we obtain,\n",
      "Decide category 1 iﬀ:\n",
      "λ(1 | 2)p(X | 2)p(2) ≤ λ(2 | 1)p(X | 1)p(1)\n",
      "If λ(1 | 2) = λ(2 | 1) and if p(1) = p(2), then the decision becomes particu-\n",
      "larly simple:\n",
      "Decide category 1 iﬀ:\n",
      "p(X | 2) ≤ p(X | 1)\n",
      "Since p(X | j) is called the likelihood of j with respect to X, this simple decision\n",
      "rule implements what is called a maximum-likelihood decision. More generally,\n",
      "if we deﬁne k(i | j) as λ(i | j)p(j), then our decision rule is simply,\n",
      "Decide category1 iﬀ:\n",
      "k(1 | 2)p(X | 2) ≤ k(2 | 1)p(X | 1)\n",
      "In any case, we need to compare the (perhaps weighted) quantities p(X | i) for\n",
      "i = 1 and 2. The exact decision rule depends on the the probability distributions\n",
      "assumed. We will treat two interesting distributions.\n",
      "5.1. USING STATISTICAL DECISION THEORY\n",
      "65\n",
      "5.1.2\n",
      "Gaussian (or Normal) Distributions\n",
      "The multivariate (n-dimensional) Gaussian distribution is given by the proba-\n",
      "bility density function:\n",
      "p(X) =\n",
      "1\n",
      "(2π)n/2|Σ|1/2 e\n",
      "−(X−M)tΣ\n",
      "−1\n",
      "(X−M)\n",
      "2\n",
      "where n is the dimension of the column vector X, the column vector M is called\n",
      "the mean vector, (X − M)t is the transpose of the vector (X − M), Σ is the\n",
      "covariance matrix of the distribution (an n × n symmetric, positive deﬁnite\n",
      "matrix), Σ−1 is the inverse of the covariance matrix, and |Σ| is the determinant\n",
      "of the covariance matrix.\n",
      "The mean vector, M, with components (m1, . . . , mn), is the expected value\n",
      "of X (using this distribution); that is, M = E[X].\n",
      "The components of the\n",
      "covariance matrix are given by:\n",
      "σ2\n",
      "ij = E[(xi − mi)(xj − mj)]\n",
      "In particular, σ2\n",
      "ii is called the variance of xi.\n",
      "Although the formula appears complex, an intuitive idea for Gaussian dis-\n",
      "tributions can be given when n = 2.\n",
      "We show a two-dimensional Gaussian\n",
      "distribution in Fig. 5.1. A three-dimensional plot of the distribution is shown\n",
      "at the top of the ﬁgure, and contours of equal probability are shown at the bot-\n",
      "tom. In this case, the covariance matrix, Σ, is such that the elliptical contours\n",
      "of equal probability are skewed. If the covariance matrix were diagonal, that is\n",
      "if all oﬀ-diagonal terms were 0, then the major axes of the elliptical contours\n",
      "would be aligned with the coordinate axes. In general the principal axes are\n",
      "given by the eigenvectors of Σ. In any case, the equi-probability contours are\n",
      "all centered on the mean vector, M, which in our ﬁgure happens to be at the\n",
      "origin. In general, the formula in the exponent in the Gaussian distribution\n",
      "is a positive deﬁnite quadratic form (that is, its value is always positive); thus\n",
      "equi-probability contours are hyper-ellipsoids in n-dimensional space.\n",
      "Suppose we now assume that the two classes of pattern vectors that we\n",
      "want to distinguish are each distributed according to a Gaussian distribution\n",
      "but with diﬀerent means and covariance matrices. That is, one class tends to\n",
      "have patterns clustered around one point in the n-dimensional space, and the\n",
      "other class tends to have patterns clustered around another point. We show a\n",
      "two-dimensional instance of this problem in Fig. 5.2. (In that ﬁgure, we have\n",
      "plotted the sum of the two distributions.) What decision rule should we use to\n",
      "separate patterns into the two appropriate categories?\n",
      "Substituting the Gaussian distributions into our maximum likelihood for-\n",
      "mula yields:\n",
      "66\n",
      "CHAPTER 5. STATISTICAL LEARNING\n",
      "-5\n",
      "0\n",
      "5\n",
      "-5\n",
      "0\n",
      "5\n",
      "0\n",
      "0.25\n",
      "0.5\n",
      "0.75\n",
      "1\n",
      "-5\n",
      "0\n",
      "5\n",
      "-5\n",
      "0\n",
      "5\n",
      "0\n",
      "25\n",
      ".5\n",
      "75\n",
      "1\n",
      "-6\n",
      "-4\n",
      "-2\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "-6\n",
      "-4\n",
      "-2\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "x1\n",
      "x2\n",
      "p(x1,x2)\n",
      "2\n",
      "4\n",
      "6\n",
      "2\n",
      "4\n",
      "6\n",
      "x1\n",
      "x2\n",
      "Figure 5.1: The Two-Dimensional Gaussian Distribution\n",
      "Decide category 1 iﬀ:\n",
      "1\n",
      "(2π)n/2|Σ2|1/2 e−1/2(X−M2)tΣ\n",
      "−1\n",
      "2\n",
      "(X−M2)\n",
      "is less than or equal to\n",
      "1\n",
      "(2π)n/2|Σ1|1/2 e−1/2(X−M1)tΣ\n",
      "−1\n",
      "1\n",
      "(X−M1)\n",
      "where the category 1 patterns are distributed with mean and covariance M1\n",
      "and Σ1, respectively, and the category 2 patterns are distributed with mean\n",
      "and covariance M2 and Σ2.\n",
      "The result of the comparison isn’t changed if we compare logarithms instead.\n",
      "After some manipulation, our decision rule is then:\n",
      "5.1. USING STATISTICAL DECISION THEORY\n",
      "67\n",
      "-5\n",
      "0\n",
      "5\n",
      "10\n",
      "-5\n",
      "0\n",
      "5\n",
      "10\n",
      "0\n",
      "0.25\n",
      "0.5\n",
      "0.75\n",
      "1\n",
      "-5\n",
      "0\n",
      "5\n",
      "10\n",
      "-5\n",
      "0\n",
      "5\n",
      "10\n",
      "0\n",
      "25\n",
      ".5\n",
      "75\n",
      "1\n",
      "x1\n",
      "x2\n",
      "p(x1,x2)\n",
      "-5\n",
      "-2.5\n",
      "0\n",
      "2.5\n",
      "5\n",
      "7.5\n",
      "10\n",
      "-5\n",
      "-2.5\n",
      "0\n",
      "2.5\n",
      "5\n",
      "7.5\n",
      "10\n",
      "Figure 5.2: The Sum of Two Gaussian Distributions\n",
      "Decide category 1 iﬀ:\n",
      "(X − M1)tΣ−1\n",
      "1 (X − M1) < (X − M2)tΣ−1\n",
      "2 (X − M2) + B\n",
      "where B, a constant bias term, incorporates the logarithms of the fractions\n",
      "preceding the exponential, etc.\n",
      "When the quadratic forms are multiplied out and represented in terms of\n",
      "the components xi, the decision rule involves a quadric surface (a hyperquadric)\n",
      "in n-dimensional space. The exact shape and position of this hyperquadric is\n",
      "determined by the means and the covariance matrices. The surface separates\n",
      "the space into two parts, one of which contains points that will be assigned to\n",
      "category 1 and the other contains points that will be assigned to category 2.\n",
      "It is interesting to look at a special case of this surface. If the covariance\n",
      "matrices for each category are identical and diagonal, with all σii equal to each\n",
      "other, then the contours of equal probability for each of the two distributions\n",
      "68\n",
      "CHAPTER 5. STATISTICAL LEARNING\n",
      "are hyperspherical. The quadric forms then become (1/|Σ|)(X−Mi)t(X−Mi),\n",
      "and the decision rule is:\n",
      "Decide category 1 iﬀ:\n",
      "(X − M1)t(X − M1) < (X − M2)t(X − M2)\n",
      "Multiplying out yields:\n",
      "X•X − 2X•M1 + M1•M1 < X•X − 2X•M2 + M2•M2\n",
      "or ﬁnally,\n",
      "Decide category 1 iﬀ:\n",
      "X•M1 ≥ X•M2 + Constant\n",
      "or\n",
      "X•(M1 − M2) ≥ Constant\n",
      "where the constant depends on the lengths of the mean vectors.\n",
      "We see that the optimal decision surface in this special case is a hyperplane.\n",
      "In fact, the hyperplane is perpendicular to the line joining the two means. The\n",
      "weights in a TLU implementation are equal to the diﬀerence in the mean vectors.\n",
      "If the parameters (Mi, Σi) of the probability distributions of the categories\n",
      "are not known, there are various techniques for estimating them, and then using\n",
      "those estimates in the decision rule. For example, if there are suﬃcient training\n",
      "patterns, one can use sample means and sample covariance matrices. (Caution:\n",
      "the sample covariance matrix will be singular if the training patterns happen to\n",
      "lie on a subspace of the whole n-dimensional space—as they certainly will, for\n",
      "example, if the number of training patterns is less than n.)\n",
      "5.1.3\n",
      "Conditionally Independent Binary Components\n",
      "Suppose the vector X is a random variable having binary (0,1) components.\n",
      "We continue to denote the two probability distributions by p(X | 1) and p(X |\n",
      "2).\n",
      "Further suppose that the components of these vectors are conditionally\n",
      "independent given the category. By conditional independence in this case, we\n",
      "mean that the formulas for the distribution can be expanded as follows:\n",
      "5.1. USING STATISTICAL DECISION THEORY\n",
      "69\n",
      "p(X | i) = p(x1 | i)p(x2 | i) · · · p(xn | i)\n",
      "for i = 1, 2\n",
      "Recall the minimum-average-loss decision rule,\n",
      "Decide category 1 iﬀ:\n",
      "λ(1 | 2)p(X | 2)p(2) ≤ λ(2 | 1)p(X | 1)p(1)\n",
      "Assuming conditional independence of the components and that λ(1 | 2) = λ(2 |\n",
      "1), we obtain,\n",
      "Decide category 1 iﬀ:\n",
      "p(1)p(x1 | 1)p(x2 | 1) · · · p(xn | 1) ≥ p(x1 | 2)p(x2 | 2) · · · p(xn | 2)p(2)\n",
      "or iﬀ:\n",
      "p(x1 | 1)p(x2 | 1) . . . p(xn | 1)\n",
      "p(x1 | 2)p(x2 | 2) . . . p(xn | 2) ≥ p(2)\n",
      "p(1)\n",
      "or iﬀ:\n",
      "log p(x1 | 1)\n",
      "p(x1 | 2) + log p(x2 | 1)\n",
      "p(x2 | 2) + · · · + log p(xn | 1)\n",
      "p(xn | 2) + log p(1)\n",
      "p(2) ≥ 0\n",
      "Let us deﬁne values of the components of the distribution for speciﬁc values of\n",
      "their arguments, xi :\n",
      "p(xi = 1 | 1) = pi\n",
      "p(xi = 0 | 1) = 1 − pi\n",
      "p(xi = 1 | 2) = qi\n",
      "p(xi = 0 | 2) = 1 − qi\n",
      "Now, we note that since xi can only assume the values of 1 or 0:\n",
      "log p(xi | 1)\n",
      "p(xi | 2) = xi log pi\n",
      "qi\n",
      "+ (1 − xi) log (1 − pi)\n",
      "(1 − qi)\n",
      "70\n",
      "CHAPTER 5. STATISTICAL LEARNING\n",
      "= xi log pi(1 − qi)\n",
      "qi(1 − pi) + log (1 − pi)\n",
      "(1 − qi)\n",
      "Substituting these expressions into our decision rule yields:\n",
      "Decide category 1 iﬀ:\n",
      "n\n",
      "�\n",
      "i=1\n",
      "xi log pi(1 − qi)\n",
      "qi(1 − pi) +\n",
      "n\n",
      "�\n",
      "i=1\n",
      "log (1 − pi)\n",
      "(1 − qi) + log p(1)\n",
      "p(2) ≥ 0\n",
      "We see that we can achieve this decision with a TLU with weight values as\n",
      "follows:\n",
      "wi = log pi(1 − qi)\n",
      "qi(1 − pi)\n",
      "for i = 1, . . . , n, and\n",
      "wn+1 = log\n",
      "p(1)\n",
      "1 − p(1) +\n",
      "n\n",
      "�\n",
      "i=1\n",
      "log (1 − pi)\n",
      "(1 − qi)\n",
      "If we do not know the pi, qi and p(1), we can use a sample of labeled training\n",
      "patterns to estimate these parameters.\n",
      "5.2\n",
      "Learning Belief Networks\n",
      "To be added.\n",
      "5.3\n",
      "Nearest-Neighbor Methods\n",
      "Another class of methods can be related to the statistical ones. These are called\n",
      "nearest-neighbor methods or, sometimes, memory-based methods. (A collection\n",
      "of papers on this subject is in [Dasarathy, 1991].) Given a training set Ξ of m\n",
      "labeled patterns, a nearest-neighbor procedure decides that some new pattern,\n",
      "X, belongs to the same category as do its closest neighbors in Ξ. More precisely,\n",
      "a k-nearest-neighbor method assigns a new pattern, X, to that category to which\n",
      "the plurality of its k closest neighbors belong. Using relatively large values of\n",
      "k decreases the chance that the decision will be unduly inﬂuenced by a noisy\n",
      "training pattern close to X. But large values of k also reduce the acuity of the\n",
      "method. The k-nearest-neighbor method can be thought of as estimating the\n",
      "values of the probabilities of the classes given X. Of course the denser are the\n",
      "points around X, and the larger the value of k, the better the estimate.\n",
      "5.3. NEAREST-NEIGHBOR METHODS\n",
      "71\n",
      "The distance metric used in nearest-neighbor methods (for numerical at-\n",
      "tributes) can be simple Euclidean distance. That is, the distance between two\n",
      "patterns (x11, x12, . . . , x1n) and (x21, x22, . . . , x2n) is\n",
      "��n\n",
      "j=1(x1j − x2j)2. This\n",
      "distance measure is often modiﬁed by scaling the features so that the spread of\n",
      "attribute values along each dimension is approximately the same. In that case,\n",
      "the distance between the two vectors would be\n",
      "��n\n",
      "j=1 a2\n",
      "j(x1j − x2j)2, where\n",
      "aj is the scale factor for dimension j.\n",
      "An example of a nearest-neighbor decision problem is shown in Fig. 5.3. In\n",
      "the ﬁgure the class of a training pattern is indicated by the number next to it.\n",
      "k = 8\n",
      "X (a pattern to be classified)\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "training pattern\n",
      "class of training pattern\n",
      "four patterns of category 1\n",
      "two patterns of category 2\n",
      "two patterns of category 3\n",
      "plurality are in category 1, so\n",
      "decide X is in category 1\n",
      "Figure 5.3: An 8-Nearest-Neighbor Decision\n",
      "See [Baum, 1994] for theoretical\n",
      "analysis of error rate as a function\n",
      "of the number of training patterns\n",
      "for the case in which points are\n",
      "randomly distributed on the surface\n",
      "of a unit sphere and underlying\n",
      "function is linearly separable.\n",
      "Nearest-neighbor methods are memory intensive because a large number of\n",
      "training patterns must be stored to achieve good generalization. Since memory\n",
      "cost is now reasonably low, the method and its derivatives have seen several\n",
      "practical applications.\n",
      "(See, for example, [Moore, 1992, Moore, et al., 1994].\n",
      "Also, the distance calculations required to ﬁnd nearest neighbors can often be\n",
      "eﬃciently computed by kd-tree methods [Friedman, et al., 1977].\n",
      "A theorem by Cover and Hart [Cover & Hart, 1967] relates the performance\n",
      "of the 1-nearest-neighbor method to the performance of a minimum-probability-\n",
      "of-error classiﬁer. As mentioned earlier, the minimum-probability-of-error clas-\n",
      "siﬁer would assign a new pattern X to that category that maximized p(i)p(X | i),\n",
      "where p(i) is the a priori probability of category i, and p(X | i) is the probability\n",
      "(or probability density function) of X given that X belongs to category i, for\n",
      "categories i = 1, . . . , R. Suppose the probability of error in classifying patterns\n",
      "of such a minimum-probability-of-error classiﬁer is ε.\n",
      "The Cover-Hart theo-\n",
      "rem states that under very mild conditions (having to do with the smoothness\n",
      "72\n",
      "CHAPTER 5. STATISTICAL LEARNING\n",
      "of probability density functions) the probability of error, εnn, of a 1-nearest-\n",
      "neighbor classiﬁer is bounded by:\n",
      "ε ≤ εnn ≤ ε\n",
      "�\n",
      "2 − ε\n",
      "R\n",
      "R − 1\n",
      "�\n",
      "≤ 2ε\n",
      "where R is the number of categories.\n",
      "Also see [Aha, 1991].\n",
      "5.4\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "Chapter 6\n",
      "Decision Trees\n",
      "6.1\n",
      "Deﬁnitions\n",
      "A decision tree (generally deﬁned) is a tree whose internal nodes are tests (on\n",
      "input patterns) and whose leaf nodes are categories (of patterns). We show an\n",
      "example in Fig. 6.1. A decision tree assigns a class number (or output) to an\n",
      "input pattern by ﬁltering the pattern down through the tests in the tree. Each\n",
      "test has mutually exclusive and exhaustive outcomes. For example, test T2 in\n",
      "the tree of Fig. 6.1 has three outcomes; the left-most one assigns the input\n",
      "pattern to class 3, the middle one sends the input pattern down to test T4, and\n",
      "the right-most one assigns the pattern to class 1. We follow the usual convention\n",
      "of depicting the leaf nodes by the class number.1 Note that in discussing decision\n",
      "trees we are not limited to implementing Boolean functions—they are useful for\n",
      "general, categorically valued functions.\n",
      "There are several dimensions along which decision trees might diﬀer:\n",
      "a. The tests might be multivariate (testing on several features of the input\n",
      "at once) or univariate (testing on only one of the features).\n",
      "b. The tests might have two outcomes or more than two. (If all of the tests\n",
      "have two outcomes, we have a binary decision tree.)\n",
      "c. The features or attributes might be categorical or numeric. (Binary-valued\n",
      "ones can be regarded as either.)\n",
      "1One of the researchers who has done a lot of work on learning decision trees is Ross\n",
      "Quinlan. Quinlan distinguishes between classes and categories. He calls the subsets of patterns\n",
      "that ﬁlter down to each tip categories and subsets of patterns having the same label classes.\n",
      "In Quinlan’s terminology, our example tree has nine categories and three classes. We will not\n",
      "make this distinction, however, but will use the words “category” and “class” interchangeably\n",
      "to refer to what Quinlan calls “class.”\n",
      "73\n",
      "74\n",
      "CHAPTER 6. DECISION TREES\n",
      "T1\n",
      "T2\n",
      "T3\n",
      "T4\n",
      "T4\n",
      "T4\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "Figure 6.1: A Decision Tree\n",
      "d. We might have two classes or more than two. If we have two classes and\n",
      "binary inputs, the tree implements a Boolean function, and is called a\n",
      "Boolean decision tree.\n",
      "It is straightforward to represent the function implemented by a univariate\n",
      "Boolean decision tree in DNF form. The DNF form implemented by such a tree\n",
      "can be obtained by tracing down each path leading to a tip node corresponding\n",
      "to an output value of 1, forming the conjunction of the tests along this path,\n",
      "and then taking the disjunction of these conjunctions. We show an example in\n",
      "Fig. 6.2. In drawing univariate decision trees, each non-leaf node is depicted by\n",
      "a single attribute. If the attribute has value 0 in the input pattern, we branch\n",
      "left; if it has value 1, we branch right.\n",
      "The k-DL class of Boolean functions can be implemented by a multivariate\n",
      "decision tree having the (highly unbalanced) form shown in Fig. 6.3. Each test,\n",
      "ci, is a term of size k or less. The vi all have values of 0 or 1.\n",
      "6.2\n",
      "Supervised Learning of Univariate Decision\n",
      "Trees\n",
      "Several systems for learning decision trees have been proposed.\n",
      "Prominent\n",
      "among these are ID3 and its new version, C4.5 [Quinlan, 1986, Quinlan, 1993],\n",
      "and CART [Breiman, et al., 1984] We discuss here only batch methods, al-\n",
      "though incremental ones have also been proposed [Utgoﬀ, 1989].\n",
      "6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES\n",
      "75\n",
      "x3\n",
      "x2\n",
      "x4\n",
      "x1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "x3x2\n",
      "x3x2\n",
      "x3x4\n",
      "x3x4x1\n",
      "x3x4x1\n",
      "f = x3x2 + x3x4x1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "Figure 6.2: A Decision Tree Implementing a DNF Function\n",
      "6.2.1\n",
      "Selecting the Type of Test\n",
      "As usual, we have n features or attributes. If the attributes are binary, the\n",
      "tests are simply whether the attribute’s value is 0 or 1. If the attributes are\n",
      "categorical, but non-binary, the tests might be formed by dividing the attribute\n",
      "values into mutually exclusive and exhaustive subsets. A decision tree with such\n",
      "tests is shown in Fig. 6.4. If the attributes are numeric, the tests might involve\n",
      "“interval tests,” for example 7 ≤ xi ≤ 13.2.\n",
      "6.2.2\n",
      "Using Uncertainty Reduction to Select Tests\n",
      "The main problem in learning decision trees for the binary-attribute case is\n",
      "selecting the order of the tests.\n",
      "For categorical and numeric attributes, we\n",
      "must also decide what the tests should be (besides selecting the order). Several\n",
      "techniques have been tried; the most popular one is at each stage to select that\n",
      "test that maximally reduces an entropy-like measure.\n",
      "We show how this technique works for the simple case of tests with binary\n",
      "outcomes. Extension to multiple-outcome tests is straightforward computation-\n",
      "ally but gives poor results because entropy is always decreased by having more\n",
      "outcomes.\n",
      "The entropy or uncertainty still remaining about the class of a pattern—\n",
      "knowing that it is in some set, Ξ, of patterns is deﬁned as:\n",
      "H(Ξ) = −\n",
      "�\n",
      "i\n",
      "p(i|Ξ) log2 p(i|Ξ)\n",
      "76\n",
      "CHAPTER 6. DECISION TREES\n",
      "cq\n",
      "cq-1\n",
      "ci\n",
      "1\n",
      "vn\n",
      "vn-1\n",
      "vi\n",
      "v1\n",
      "Figure 6.3: A Decision Tree Implementing a Decision List\n",
      "where p(i|Ξ) is the probability that a pattern drawn at random from Ξ belongs\n",
      "to class i, and the summation is over all of the classes. We want to select tests at\n",
      "each node such that as we travel down the decision tree, the uncertainty about\n",
      "the class of a pattern becomes less and less.\n",
      "Since we do not in general have the probabilities p(i|Ξ), we estimate them by\n",
      "sample statistics. Although these estimates might be errorful, they are never-\n",
      "theless useful in estimating uncertainties. Let ˆp(i|Ξ) be the number of patterns\n",
      "in Ξ belonging to class i divided by the total number of patterns in Ξ. Then an\n",
      "estimate of the uncertainty is:\n",
      "ˆH(Ξ) = −\n",
      "�\n",
      "i\n",
      "ˆp(i|Ξ) log2 ˆp(i|Ξ)\n",
      "For simplicity, from now on we’ll drop the “hats” and use sample statistics as\n",
      "if they were real probabilities.\n",
      "If we perform a test, T, having k possible outcomes on the patterns in Ξ, we\n",
      "will create k subsets, Ξ1, Ξ2, . . . , Ξk. Suppose that ni of the patterns in Ξ are in\n",
      "Ξi for i = 1, ..., k. (Some ni may be 0.) If we knew that T applied to a pattern\n",
      "in Ξ resulted in the j-th outcome (that is, we knew that the pattern was in Ξj),\n",
      "the uncertainty about its class would be:\n",
      "H(Ξj) = −\n",
      "�\n",
      "i\n",
      "p(i|Ξj) log2 p(i|Ξj)\n",
      "and the reduction in uncertainty (beyond knowing only that the pattern was in\n",
      "Ξ) would be:\n",
      "6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES\n",
      "77\n",
      "x3 = a, b, c, or d \n",
      "{a, c}\n",
      "{b}\n",
      "x1 = e, b, or d \n",
      "{e,b}\n",
      "{d}\n",
      "x4 = a, e, f, or g\n",
      "{a, g}\n",
      "{e, f}\n",
      "x2 = a, or g\n",
      "{a}\n",
      "{g}\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "{d}\n",
      "2\n",
      "Figure 6.4: A Decision Tree with Categorical Attributes\n",
      "H(Ξ) − H(Ξj)\n",
      "Of course we cannot say that the test T is guaranteed always to produce that\n",
      "amount of reduction in uncertainty because we don’t know that the result of\n",
      "the test will be the j-th outcome. But we can estimate the average uncertainty\n",
      "over all the Ξj, by:\n",
      "E[HT (Ξ)] =\n",
      "�\n",
      "j\n",
      "p(Ξj)H(Ξj)\n",
      "where by HT (Ξ) we mean the average uncertainty after performing test T on\n",
      "the patterns in Ξ, p(Ξj) is the probability that the test has outcome j, and the\n",
      "sum is taken from 1 to k. Again, we don’t know the probabilities p(Ξj), but we\n",
      "can use sample values. The estimate ˆp(Ξj) of p(Ξj) is just the number of those\n",
      "patterns in Ξ that have outcome j divided by the total number of patterns in\n",
      "Ξ. The average reduction in uncertainty achieved by test T (applied to patterns\n",
      "in Ξ) is then:\n",
      "RT (Ξ) = H(Ξ) − E[HT (Ξ)]\n",
      "An important family of decision tree learning algorithms selects for the root\n",
      "of the tree that test that gives maximum reduction of uncertainty, and then\n",
      "applies this criterion recursively until some termination condition is met (which\n",
      "we shall discuss in more detail later). The uncertainty calculations are particu-\n",
      "larly simple when the tests have binary outcomes and when the attributes have\n",
      "78\n",
      "CHAPTER 6. DECISION TREES\n",
      "binary values. We’ll give a simple example to illustrate how the test selection\n",
      "mechanism works in that case.\n",
      "Suppose we want to use the uncertainty-reduction method to build a decision\n",
      "tree to classify the following patterns:\n",
      "pattern\n",
      "class\n",
      "(0, 0, 0)\n",
      "0\n",
      "(0, 0, 1)\n",
      "0\n",
      "(0, 1, 0)\n",
      "0\n",
      "(0, 1, 1)\n",
      "0\n",
      "(1, 0, 0)\n",
      "0\n",
      "(1, 0, 1)\n",
      "1\n",
      "(1, 1, 0)\n",
      "0\n",
      "(1, 1, 1)\n",
      "1\n",
      "What single test, x1, x2, or x3, should be performed ﬁrst? The illustration in\n",
      "Fig. 6.5 gives geometric intuition about the problem.\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "The test x1\n",
      "Figure 6.5: Eight Patterns to be Classiﬁed by a Decision Tree\n",
      "The initial uncertainty for the set, Ξ, containing all eight points is:\n",
      "H(Ξ) = −(6/8) log2(6/8) − (2/8) log2(2/8) = 0.81\n",
      "Next, we calculate the uncertainty reduction if we perform x1 ﬁrst. The left-\n",
      "hand branch has only patterns belonging to class 0 (we call them the set Ξl), and\n",
      "the right-hand-branch (Ξr) has two patterns in each class. So, the uncertainty\n",
      "of the left-hand branch is:\n",
      "6.3. NETWORKS EQUIVALENT TO DECISION TREES\n",
      "79\n",
      "Hx1(Ξl) = −(4/4) log2(4/4) − (0/4) log2(0/4) = 0\n",
      "And the uncertainty of the right-hand branch is:\n",
      "Hx1(Ξr) = −(2/4) log2(2/4) − (2/4) log2(2/4) = 1\n",
      "Half of the patterns “go left” and half “go right” on test x1. Thus, the average\n",
      "uncertainty after performing the x1 test is:\n",
      "1/2Hx1(Ξl) + 1/2Hx1(Ξr) = 0.5\n",
      "Therefore the uncertainty reduction on Ξ achieved by x1 is:\n",
      "Rx1(Ξ) = 0.81 − 0.5 = 0.31\n",
      "By similar calculations, we see that the test x3 achieves exactly the same\n",
      "uncertainty reduction, but x2 achieves no reduction whatsoever.\n",
      "Thus, our\n",
      "“greedy” algorithm for selecting a ﬁrst test would select either x1 or x3. Suppose\n",
      "x1 is selected. The uncertainty-reduction procedure would select x3 as the next\n",
      "test. The decision tree that this procedure creates thus implements the Boolean\n",
      "function: f = x1x3.\n",
      "See [Quinlan, 1986, sect. 4] for\n",
      "another example.\n",
      "6.2.3\n",
      "Non-Binary Attributes\n",
      "If the attributes are non-binary, we can still use the uncertainty-reduction tech-\n",
      "nique to select tests. But now, in addition to selecting an attribute, we must\n",
      "select a test on that attribute. Suppose for example that the value of an at-\n",
      "tribute is a real number and that the test to be performed is to set a threshold\n",
      "and to test to see if the number is greater than or less than that threshold. In\n",
      "principle, given a set of labeled patterns, we can measure the uncertainty reduc-\n",
      "tion for each test that is achieved by every possible threshold (there are only\n",
      "a ﬁnite number of thresholds that give diﬀerent test results if there are only\n",
      "a ﬁnite number of training patterns). Similarly, if an attribute is categorical\n",
      "(with a ﬁnite number of categories), there are only a ﬁnite number of mutually\n",
      "exclusive and exhaustive subsets into which the values of the attribute can be\n",
      "split. We can calculate the uncertainty reduction for each split.\n",
      "6.3\n",
      "Networks Equivalent to Decision Trees\n",
      "Since univariate Boolean decision trees are implementations of DNF functions,\n",
      "they are also equivalent to two-layer, feedforward neural networks. We show\n",
      "an example in Fig. 6.6. The decision tree at the left of the ﬁgure implements\n",
      "80\n",
      "CHAPTER 6. DECISION TREES\n",
      "the same function as the network at the right of the ﬁgure. Of course, when\n",
      "implemented as a network, all of the features are evaluated in parallel for any\n",
      "input pattern, whereas when implemented as a decision tree only those features\n",
      "on the branch traveled down by the input pattern need to be evaluated. The\n",
      "decision-tree induction methods discussed in this chapter can thus be thought of\n",
      "as particular ways to establish the structure and the weight values for networks.\n",
      "X\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "x4\n",
      "terms\n",
      "-1\n",
      "+1\n",
      "disjunction\n",
      "x3x2\n",
      "x3x4x1\n",
      "+1\n",
      "-1\n",
      "+1\n",
      "f\n",
      "1.5\n",
      "0.5\n",
      "x3\n",
      "x2\n",
      "x4\n",
      "x1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "x3x2\n",
      "x3x2\n",
      "x3x4\n",
      "x3x4x1\n",
      "x3x4x1\n",
      "f = x3x2 + x3x4x1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "Figure 6.6: A Univariate Decision Tree and its Equivalent Network\n",
      "Multivariate decision trees with linearly separable functions at each node can\n",
      "also be implemented by feedforward networks—in this case three-layer ones. We\n",
      "show an example in Fig. 6.7 in which the linearly separable functions, each im-\n",
      "plemented by a TLU, are indicated by L1, L2, L3, and L4. Again, the ﬁnal layer\n",
      "has ﬁxed weights, but the weights in the ﬁrst two layers must be trained. Dif-\n",
      "ferent approaches to training procedures have been discussed by [Brent, 1990],\n",
      "by [John, 1995], and (for a special case) by [Marchand & Golea, 1993].\n",
      "6.4\n",
      "Overﬁtting and Evaluation\n",
      "6.4.1\n",
      "Overﬁtting\n",
      "In supervised learning, we must choose a function to ﬁt the training set from\n",
      "among a set of hypotheses.\n",
      "We have already showed that generalization is\n",
      "impossible without bias.\n",
      "When we know a priori that the function we are\n",
      "trying to guess belongs to a small subset of all possible functions, then, even\n",
      "with an incomplete set of training samples, it is possible to reduce the subset\n",
      "of functions that are consistent with the training set suﬃciently to make useful\n",
      "guesses about the value of the function for inputs not in the training set. And,\n",
      "6.4. OVERFITTING AND EVALUATION\n",
      "81\n",
      "L1\n",
      "L2\n",
      "L3\n",
      "L4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "X\n",
      "L1\n",
      "L2\n",
      "L3\n",
      "L4\n",
      "conjunctions\n",
      "L1L2\n",
      "L1 L3 L4\n",
      "�\n",
      "+\n",
      "+\n",
      "+\n",
      "disjunction\n",
      "�\n",
      "f\n",
      "Figure 6.7: A Multivariate Decision Tree and its Equivalent Network\n",
      "the larger the training set, the more likely it is that even a randomly selected\n",
      "consistent function will have appropriate outputs for patterns not yet seen.\n",
      "However, even with bias, if the training set is not suﬃciently large compared\n",
      "with the size of the hypothesis space, there will still be too many consistent\n",
      "functions for us to make useful guesses, and generalization performance will be\n",
      "poor. When there are too many hypotheses that are consistent with the training\n",
      "set, we say that we are overﬁtting the training data. Overﬁtting is a problem\n",
      "that we must address for all learning methods.\n",
      "Since a decision tree of suﬃcient size can implement any Boolean function\n",
      "there is a danger of overﬁtting—especially if the training set is small. That\n",
      "is, even if the decision tree is synthesized to classify all the members of the\n",
      "training set correctly, it might perform poorly on new patterns that were not\n",
      "used to build the decision tree. Several techniques have been proposed to avoid\n",
      "overﬁtting, and we shall examine some of them here. They make use of methods\n",
      "for estimating how well a given decision tree might generalize—methods we shall\n",
      "describe next.\n",
      "6.4.2\n",
      "Validation Methods\n",
      "The most straightforward way to estimate how well a hypothesized function\n",
      "(such as a decision tree) performs on a test set is to test it on the test set! But,\n",
      "if we are comparing several learning systems (for example, if we are comparing\n",
      "diﬀerent decision trees) so that we can select the one that performs the best on\n",
      "the test set, then such a comparison amounts to “training on the test data.”\n",
      "True, training on the test data enlarges the training set, with a consequent ex-\n",
      "pected improvement in generalization, but there is still the danger of overﬁtting\n",
      "if we are comparing several diﬀerent learning systems. Another technique is to\n",
      "82\n",
      "CHAPTER 6. DECISION TREES\n",
      "split the training set—using (say) two-thirds for training and the other third\n",
      "for estimating generalization performance. But splitting reduces the size of the\n",
      "training set and thereby increases the possibility of overﬁtting. We next describe\n",
      "some validation techniques that attempt to avoid these problems.\n",
      "Cross-Validation\n",
      "In cross-validation, we divide the training set Ξ into K mutually exclusive and\n",
      "exhaustive equal-sized subsets: Ξ1, . . . , ΞK. For each subset, Ξi, train on the\n",
      "union of all of the other subsets, and empirically determine the error rate, εi,\n",
      "on Ξi. (The error rate is the number of classiﬁcation errors made on Ξi divided\n",
      "by the number of patterns in Ξi.) An estimate of the error rate that can be\n",
      "expected on new patterns of a classiﬁer trained on all the patterns in Ξ is then\n",
      "the average of the εi.\n",
      "Leave-one-out Validation\n",
      "Leave-one-out validation is the same as cross validation for the special case in\n",
      "which K equals the number of patterns in Ξ, and each Ξi consists of a single\n",
      "pattern. When testing on each Ξi, we simply note whether or not a mistake\n",
      "was made.\n",
      "We count the total number of mistakes and divide by K to get\n",
      "the estimated error rate. This type of validation is, of course, more expensive\n",
      "computationally, but useful when a more accurate estimate of the error rate for\n",
      "a classiﬁer is needed.\n",
      "Describe “bootstrapping” also\n",
      "[Efron, 1982].\n",
      "6.4.3\n",
      "Avoiding Overﬁtting in Decision Trees\n",
      "Near the tips of a decision tree there may be only a few patterns per node.\n",
      "For these nodes, we are selecting a test based on a very small sample, and thus\n",
      "we are likely to be overﬁtting. This problem can be dealt with by terminating\n",
      "the test-generating procedure before all patterns are perfectly split into their\n",
      "separate categories. That is, a leaf node may contain patterns of more than one\n",
      "class, but we can decide in favor of the most numerous class. This procedure\n",
      "will result in a few errors but often accepting a small number of errors on the\n",
      "training set results in fewer errors on a testing set.\n",
      "This behavior is illustrated in Fig. 6.8.\n",
      "One can use cross-validation techniques to determine when to stop splitting\n",
      "nodes. If the cross validation error increases as a consequence of a node split,\n",
      "then don’t split. One has to be careful about when to stop, though, because\n",
      "underﬁtting usually leads to more errors on test sets than does overﬁtting. There\n",
      "is a general rule that the lowest error-rate attainable by a sub-tree of a fully\n",
      "expanded tree can be no less than 1/2 of the error rate of the fully expanded\n",
      "tree [Weiss & Kulikowski, 1991, page 126].\n",
      "6.4. OVERFITTING AND EVALUATION\n",
      "83\n",
      "(From Weiss, S., and Kulikowski, C., Computer Systems that Learn,\n",
      "Morgan Kaufmann, 1991)\n",
      "training errors\n",
      "validation errors\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "0\n",
      "0\n",
      "Error Rate\n",
      "Number of Terminal\n",
      "Nodes\n",
      "Iris Data Decision Tree\n",
      "Figure 6.8: Determining When Overﬁtting Begins\n",
      "Rather than stopping the growth of a decision tree, one might grow it to\n",
      "its full size and then prune away leaf nodes and their ancestors until cross-\n",
      "validation accuracy no longer increases. This technique is called post-pruning.\n",
      "Various techniques for pruning are discussed in [Weiss & Kulikowski, 1991].\n",
      "6.4.4\n",
      "Minimum-Description Length Methods\n",
      "An important tree-growing and pruning technique is based on the minimum-\n",
      "description-length (MDL) principle. (MDL is an important idea that extends\n",
      "beyond decision-tree methods [Rissanen, 1978].) The idea is that the simplest\n",
      "decision tree that can predict the classes of the training patterns is the best\n",
      "one. Consider the problem of transmitting just the labels of a training set of\n",
      "patterns, assuming that the receiver of this information already has the ordered\n",
      "set of patterns.\n",
      "If there are m patterns, each labeled by one of R classes,\n",
      "one could transmit a list of m R-valued numbers. Assuming equally probable\n",
      "classes, this transmission would require m log2 R bits. Or, one could transmit a\n",
      "decision tree that correctly labelled all of the patterns. The number of bits that\n",
      "this transmission would require depends on the technique for encoding decision\n",
      "trees and on the size of the tree. If the tree is small and accurately classiﬁes\n",
      "all of the patterns, it might be more economical to transmit the tree than to\n",
      "transmit the labels directly. In between these extremes, we might transmit a\n",
      "tree plus a list of labels of all the patterns that the tree misclassiﬁes.\n",
      "In general, the number of bits (or description length of the binary encoded\n",
      "message) is t + d, where t is the length of the message required to transmit\n",
      "the tree, and d is the length of the message required to transmit the labels of\n",
      "84\n",
      "CHAPTER 6. DECISION TREES\n",
      "the patterns misclassiﬁed by the tree. In a sense, that tree associated with the\n",
      "smallest value of t + d is the best or most economical tree. The MDL method\n",
      "is one way of adhering to the Occam’s razor principle.\n",
      "Quinlan and Rivest [Quinlan & Rivest, 1989] have proposed techniques for\n",
      "encoding decision trees and lists of exception labels and for calculating the\n",
      "description length (t+d) of these trees and labels. They then use the description\n",
      "length as a measure of quality of a tree in two ways:\n",
      "a. In growing a tree, they use the reduction in description length to select\n",
      "tests (instead of reduction in uncertainty).\n",
      "b. In pruning a tree after it has been grown to zero error, they prune away\n",
      "those nodes (starting at the tips) that achieve a decrease in the description\n",
      "length.\n",
      "These techniques compare favorably with the uncertainty-reduction method,\n",
      "although they are quite sensitive to the coding schemes used.\n",
      "6.4.5\n",
      "Noise in Data\n",
      "Noise in the data means that one must inevitably accept some number of\n",
      "errors—depending on the noise level. Refusal to tolerate errors on the training\n",
      "set when there is noise leads to the problem of “ﬁtting the noise.” Dealing with\n",
      "noise, then, requires accepting some errors at the leaf nodes just as does the\n",
      "fact that there are a small number of patterns at leaf nodes.\n",
      "6.5\n",
      "The Problem of Replicated Subtrees\n",
      "Decision trees are not the most economical means of implementing some Boolean\n",
      "functions. Consider, for example, the function f = x1x2 +x3x4. A decision tree\n",
      "for this function is shown in Fig. 6.9. Notice the replicated subtrees shown\n",
      "circled. The DNF-form equivalent to the function implemented by this decision\n",
      "tree is f = x1x2 + x1x2x3x4 + x1x3x4. This DNF form is non-minimal (in the\n",
      "number of disjunctions) and is equivalent to f = x1x2 + x3x4.\n",
      "The need for replication means that it takes longer to learn the tree and\n",
      "that subtrees replicated further down the tree must be learned using a smaller\n",
      "training subset. This problem is sometimes called the fragmentation problem.\n",
      "Several approaches might be suggested for dealing with fragmenta-\n",
      "tion.\n",
      "One is to attempt to build a decision graph instead of a tree\n",
      "[Oliver, Dowe, & Wallace, 1992, Kohavi, 1994]. A decision graph that imple-\n",
      "ments the same decisions as that of the decision tree of Fig. 6.9 is shown in Fig.\n",
      "6.10.\n",
      "Another approach is to use multivariate (rather than univariate tests at each\n",
      "node). In our example of learning f = x1x2 + x3x4, if we had a test for x1x2\n",
      "6.6. THE PROBLEM OF MISSING ATTRIBUTES\n",
      "85\n",
      "x1\n",
      "x3\n",
      "x2\n",
      "1\n",
      "0\n",
      "x4\n",
      "0\n",
      "1\n",
      "x3\n",
      "0\n",
      "x4\n",
      "0\n",
      "1\n",
      "Figure 6.9: A Decision Tree with Subtree Replication\n",
      "and a test for x3x4, the decision tree could be much simpliﬁed, as shown in Fig.\n",
      "6.11. Several researchers have proposed techniques for learning decision trees in\n",
      "which the tests at each node are linearly separable functions. [John, 1995] gives\n",
      "a nice overview (with several citations) of learning such linear discriminant trees\n",
      "and presents a method based on “soft entropy.”\n",
      "A third method for dealing with the replicated subtree problem involves ex-\n",
      "tracting propositional “rules” from the decision tree. The rules will have as an-\n",
      "tecedents the conjunctions that lead down to the leaf nodes, and as consequents\n",
      "the name of the class at the corresponding leaf node. An example rule from the\n",
      "tree with the repeating subtree of our example would be: x1 ∧¬x2 ∧x3 ∧x4 ⊃ 1.\n",
      "Quinlan [Quinlan, 1987] discusses methods for reducing a set of rules to a sim-\n",
      "pler set by 1) eliminating from the antecedent of each rule any “unnecessary”\n",
      "conjuncts, and then 2) eliminating “unnecessary” rules. A conjunct or rule is\n",
      "determined to be unnecessary if its elimination has little eﬀect on classiﬁcation\n",
      "accuracy—as determined by a chi-square test, for example. After a rule set is\n",
      "processed, it might be the case that more than one rule is “active” for any given\n",
      "pattern, and care must be taken that the active rules do not conﬂict in their\n",
      "decision about the class of a pattern.\n",
      "86\n",
      "CHAPTER 6. DECISION TREES\n",
      "x1\n",
      "x3\n",
      "x2\n",
      "1\n",
      "0\n",
      "x4\n",
      "0\n",
      "1\n",
      "Figure 6.10: A Decision Graph\n",
      "6.6\n",
      "The Problem of Missing Attributes\n",
      "To be added.\n",
      "6.7\n",
      "Comparisons\n",
      "Several experimenters have compared decision-tree, neural-net, and nearest-\n",
      "neighbor classiﬁers on a wide variety of problems.\n",
      "For a comparison of\n",
      "neural nets versus decision trees, for example, see [Dietterich, et al., 1990,\n",
      "Shavlik, Mooney, & Towell, 1991, Quinlan, 1994].\n",
      "In their StatLog project,\n",
      "[Taylor, Michie, & Spiegalhalter, 1994] give thorough comparisons of several\n",
      "machine learning algorithms on several diﬀerent types of problems. There seems\n",
      "x1x2\n",
      "1\n",
      "0\n",
      "x3x4\n",
      "1\n",
      "Figure 6.11: A Multivariate Decision Tree\n",
      "6.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS\n",
      "87\n",
      "to be no single type of classiﬁer that is best for all problems. And, there do\n",
      "not seem to be any general conclusions that would enable one to say which\n",
      "classiﬁer method is best for which sorts of classiﬁcation problems, although\n",
      "[Quinlan, 1994] does provide some intuition about properties of problems that\n",
      "might render them ill suited for decision trees, on the one hand, or backpropa-\n",
      "gation, on the other.\n",
      "6.8\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "88\n",
      "CHAPTER 6. DECISION TREES\n",
      "Chapter 7\n",
      "Inductive Logic\n",
      "Programming\n",
      "There are many diﬀerent representational forms for functions of input vari-\n",
      "ables. So far, we have seen (Boolean) algebraic expressions, decision trees, and\n",
      "neural networks, plus other computational mechanisms such as techniques for\n",
      "computing nearest neighbors.\n",
      "Of course, the representation most important\n",
      "in computer science is a computer program. For example, a Lisp predicate of\n",
      "binary-valued inputs computes a Boolean function of those inputs. Similarly, a\n",
      "logic program (whose ordinary application is to compute bindings for variables)\n",
      "can also be used simply to decide whether or not a predicate has value True\n",
      "(T) or False (F). For example, the Boolean exclusive-or (odd parity) function\n",
      "of two variables can be computed by the following logic program:\n",
      "Parity(x,y) :- True(x), ¬ True(y)\n",
      ":- True(y), ¬ True(x)\n",
      "We follow Prolog syntax (see, for example, [Mueller & Page, 1988]), except that\n",
      "our convention is to write variables as strings beginning with lower-case letters\n",
      "and predicates as strings beginning with upper-case letters. The unary function\n",
      "“True” returns T if and only if the value of its argument is T. (We now think\n",
      "of Boolean functions and arguments as having values of T and F instead of 0\n",
      "and 1.) Programs will be written in “typewriter” font.\n",
      "In this chapter, we consider the matter of learning logic programs given\n",
      "a set of variable values for which the logic program should return T (the\n",
      "positive instances) and a set of variable values for which it should return\n",
      "F (the negative instances). The subspecialty of machine learning that deals\n",
      "with learning logic programs is called inductive logic programming (ILP)\n",
      "[Lavraˇc & Dˇzeroski, 1994]. As with any learning problem, this one can be quite\n",
      "complex and intractably diﬃcult unless we constrain it with biases of some sort.\n",
      "89\n",
      "90\n",
      "CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "In ILP, there are a variety of possible biases (called language biases). One might\n",
      "restrict the program to Horn clauses, not allow recursion, not allow functions,\n",
      "and so on.\n",
      "As an example of an ILP problem, suppose we are trying to induce a func-\n",
      "tion Nonstop(x,y), that is to have value T for pairs of cities connected by a\n",
      "non-stop air ﬂight and F for all other pairs of cities. We are given a training set\n",
      "consisting of positive and negative examples. As positive examples, we might\n",
      "have (A,B), (A, A1), and some other pairs; as negative examples, we might\n",
      "have (A1, A2), and some other pairs. In ILP, we usually have additional infor-\n",
      "mation about the examples, called “background knowledge.” In our air-ﬂight\n",
      "problem, the background information might be such ground facts as Hub(A),\n",
      "Hub(B), Satellite(A1,A), plus others. (Hub(A) is intended to mean that the\n",
      "city denoted by A is a hub city, and Satellite(A1,A) is intended to mean that\n",
      "the city denoted by A1 is a satellite of the city denoted by A.) From these train-\n",
      "ing facts, we want to induce a program Nonstop(x,y), written in terms of the\n",
      "background relations Hub and Satellite, that has value T for all the positive\n",
      "instances and has value F for all the negative instances. Depending on the exact\n",
      "set of examples, we might induce the program:\n",
      "Nonstop(x,y) :- Hub(x), Hub(y)\n",
      ":- Satellite(x,y)\n",
      ":- Satellite(y,x)\n",
      "which would have value T if both of the two cities were hub cities or if one were\n",
      "a satellite of the other. As with other learning problems, we want the induced\n",
      "program to generalize well; that is, if presented with arguments not represented\n",
      "in the training set (but for which we have the needed background knowledge),\n",
      "we would like the function to guess well.\n",
      "7.1\n",
      "Notation and Deﬁnitions\n",
      "In evaluating logic programs in ILP, we implicitly append the background facts\n",
      "to the program and adopt the usual convention that a program has value T for\n",
      "a set of inputs if and only if the program interpreter returns T when actually\n",
      "running the program (with background facts appended) on those inputs; oth-\n",
      "erwise it has value F. Using the given background facts, the program above\n",
      "would return T for input (A, A1), for example. If a logic program, π, returns\n",
      "T for a set of arguments X, we say that the program covers the arguments and\n",
      "write covers(π, X). Following our terminology introduced in connection with\n",
      "version spaces, we will say that a program is suﬃcient if it covers all of the\n",
      "positive instances and that it is necessary if it does not cover any of the neg-\n",
      "ative instances. (That is, a program implements a suﬃcient condition that a\n",
      "training instance is positive if it covers all of the positive training instances; it\n",
      "7.2. A GENERIC ILP ALGORITHM\n",
      "91\n",
      "implements a necessary condition if it covers none of the negative instances.) In\n",
      "the noiseless case, we want to induce a program that is both suﬃcient and nec-\n",
      "essary, in which case we will call it consistent. With imperfect (noisy) training\n",
      "sets, we might relax this criterion and settle for a program that covers all but\n",
      "some fraction of the positive instances while allowing it to cover some fraction\n",
      "of the negative instances. We illustrate these deﬁnitions schematically in Fig.\n",
      "7.1.\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�1 is a necessary program\n",
      "�2 is a sufficient program\n",
      "�3 is a consistent program\n",
      "+\n",
      "+\n",
      "+\n",
      "+\n",
      "+\n",
      "+\n",
      "+\n",
      "+\n",
      "+\n",
      "+\n",
      "�\n",
      "�\n",
      "A positive instance\n",
      " covered by �2 and �3\n",
      "Figure 7.1: Suﬃcient, Necessary, and Consistent Programs\n",
      "As in version spaces, if a program is suﬃcient but not necessary it can be\n",
      "made to cover fewer examples by specializing it. Conversely, if it is necessary\n",
      "but not suﬃcient, it can be made to cover more examples by generalizing it.\n",
      "Suppose we are attempting to induce a logic program to compute the relation\n",
      "ρ. The most general logic program, which is certainly suﬃcient, is the one that\n",
      "has value T for all inputs, namely a single clause with an empty body, [ρ :-\n",
      "], which is called a fact in Prolog. The most special logic program, which is\n",
      "certainly necessary, is the one that has value F for all inputs, namely [ρ :-\n",
      "F\n",
      "]. Two of the many diﬀerent ways to search for a consistent logic program\n",
      "are: 1) start with [ρ :-\n",
      "] and specialize until the program is consistent, or 2)\n",
      "start with [ρ :- F\n",
      "] and generalize until the program is consistent. We will\n",
      "be discussing a method that starts with [ρ :-\n",
      "], specializes until the program\n",
      "is necessary (but might no longer be suﬃcient), then reachieves suﬃciency in\n",
      "stages by generalizing—ensuring within each stage that the program remains\n",
      "necessary (by specializing).\n",
      "7.2\n",
      "A Generic ILP Algorithm\n",
      "Since the primary operators in our search for a consistent program are special-\n",
      "ization and generalization, we must next discuss those operations. There are\n",
      "92\n",
      "CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "three major ways in which a logic program might be generalized:\n",
      "a. Replace some terms in a program clause by variables. (Readers familiar\n",
      "with substitutions in the predicate calculus will note that this process is\n",
      "the inverse of substitution.)\n",
      "b. Remove literals from the body of a clause.\n",
      "c. Add a clause to the program\n",
      "Analogously, there are three ways in which a logic program might be specialized:\n",
      "a. Replace some variables in a program clause by terms (a substitution).\n",
      "b. Add literals to the body of a clause.\n",
      "c. Remove a clause from the program\n",
      "We will be presenting an ILP learning method that adds clauses to a program\n",
      "when generalizing and that adds literals to the body of a clause when special-\n",
      "izing. When we add a clause, we will always add the clause [ρ :- ] and then\n",
      "specialize it by adding literals to the body. Thus, we need only describe the\n",
      "process for adding literals.\n",
      "Clauses can be partially ordered by the specialization relation. In general,\n",
      "clause c1 is more special than clause c2 if c2 |= c1. A special case, which is what\n",
      "we use here, is that a clause c1 is more special than a clause c2 if the set of\n",
      "literals in the body of c2 is a subset of those in c1. This ordering relation can\n",
      "be used in a structure of partially ordered clauses, called the reﬁnement graph,\n",
      "that is similar to a version space. Clause c1 is an immediate successor of clause\n",
      "c2 in this graph if and only if clause c1 can be obtained from clause c2 by adding\n",
      "a literal to the body of c2. A reﬁnement graph then tells us the ways in which\n",
      "we can specialize a clause by adding a literal to it.\n",
      "Of course there are unlimited possible literals we might add to the body of\n",
      "a clause. Practical ILP systems restrict the literals in various ways. Typical\n",
      "allowed additions are:\n",
      "a. Literals used in the background knowledge.\n",
      "b. Literals whose arguments are a subset of those in the head of the clause.\n",
      "c. Literals that introduce a new distinct variable diﬀerent from those in the\n",
      "head of the clause.\n",
      "d. A literal that equates a variable in the head of the clause with another\n",
      "such variable or with a term mentioned in the background knowledge.\n",
      "(This possibility is equivalent to forming a specialization by making a\n",
      "substitution.)\n",
      "7.2. A GENERIC ILP ALGORITHM\n",
      "93\n",
      "e. A literal that is the same (except for its arguments) as that in the head\n",
      "of the clause. (This possibility admits recursive programs, which are dis-\n",
      "allowed in some systems.)\n",
      "We can illustrate these possibilities using our air-ﬂight example. We start\n",
      "with the program [Nonstop(x,y) :-\n",
      "]. The literals used in the background\n",
      "knowledge are Hub and Satellite. Thus the literals that we might consider\n",
      "adding are:\n",
      "Hub(x)\n",
      "Hub(y)\n",
      "Hub(z)\n",
      "Satellite(x,y)\n",
      "Satellite(y,x)\n",
      "Satellite(x,z)\n",
      "Satellite(z,y)\n",
      "(x = y)\n",
      "(If recursive programs are allowed, we could also add the literals Nonstop(x,z)\n",
      "and Nonstop(z,y).) These possibilities are among those illustrated in the re-\n",
      "ﬁnement graph shown in Fig. 7.2. Whatever restrictions on additional literals\n",
      "are imposed, they are all syntactic ones from which the successors in the reﬁne-\n",
      "ment graph are easily computed. ILP programs that follow the approach we\n",
      "are discussing (of specializing clauses by adding a literal) thus have well deﬁned\n",
      "methods of computing the possible literals to add to a clause.\n",
      "Now we are ready to write down a simple generic algorithm for inducing a\n",
      "logic program, π for inducing a relation ρ. We are given a training set, Ξ of\n",
      "argument sets some known to be in the relation ρ and some not in ρ; Ξ+ are\n",
      "the positive instances, and Ξ− are the negative instances. The algorithm has\n",
      "an outer loop in which it successively adds clauses to make π more and more\n",
      "suﬃcient. It has an inner loop for constructing a clause, c, that is more and\n",
      "more necessary and in which it refers only to a subset, Ξcur, of the training\n",
      "instances. (The positive instances in Ξcur will be denoted by Ξ+\n",
      "cur, and the\n",
      "negative ones by Ξ−\n",
      "cur.) The algorithm is also given background relations and\n",
      "the means for adding literals to a clause. It uses a logic program interpreter to\n",
      "compute whether or not the program it is inducing covers training instances.\n",
      "The algorithm can be written as follows:\n",
      "Generic ILP Algorithm\n",
      "(Adapted from [Lavraˇc & Dˇzeroski, 1994, p. 60].)\n",
      "94\n",
      "CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "Nonstop(x,y) :-\n",
      "Nonstop(x,y) :-\n",
      "   Hub(x)\n",
      "Nonstop(x,y) :-\n",
      "   Satellite(x,y)\n",
      "Nonstop(x,y) :-\n",
      "   (x = y)\n",
      ". . .\n",
      ". . .\n",
      ". . .\n",
      ". . .\n",
      "Nonstop(x,y) :- Hub(x), Hub(y)\n",
      ". . .\n",
      ". . .\n",
      ". . .\n",
      "Figure 7.2: Part of a Reﬁnement Graph\n",
      "Initialize Ξcur := Ξ.\n",
      "Initialize π := empty set of clauses.\n",
      "repeat [The outer loop works to make π suﬃcient.]\n",
      "Initialize c := ρ : − .\n",
      "repeat [The inner loop makes c necessary.]\n",
      "Select a literal l to add to c. [This is a nondeterministic choice point.]\n",
      "Assign c := c, l.\n",
      "until c is necessary. [That is, until c covers no negative instances in Ξcur.]\n",
      "Assign π := π, c. [We add the clause c to the program.]\n",
      "Assign Ξcur := Ξcur − (the positive instances in Ξcur covered by π).\n",
      "until π is suﬃcient.\n",
      "(The termination tests for the inner and outer loops can be relaxed as appro-\n",
      "priate for the case of noisy instances.)\n",
      "7.3\n",
      "An Example\n",
      "We illustrate how the algorithm works by returning to our example of airline\n",
      "ﬂights. Consider the portion of an airline route map, shown in Fig. 7.3. Cities\n",
      "A, B, and C are “hub” cities, and we know that there are nonstop ﬂights between\n",
      "all hub cities (even those not shown on this portion of the route map). The other\n",
      "7.3. AN EXAMPLE\n",
      "95\n",
      "cities are “satellites” of one of the hubs, and we know that there are nonstop\n",
      "ﬂights between each satellite city and its hub. The learning program is given a\n",
      "set of positive instances, Ξ+, of pairs of cities between which there are nonstop\n",
      "ﬂights and a set of negative instances, Ξ−, of pairs of cities between which there\n",
      "are not nonstop ﬂights. Ξ+ contains just the pairs:\n",
      "{< A, B >, < A, C >, < B, C >, < B, A >, < C, A >, < C, B >,\n",
      "< A, A1 >, < A, A2 >, < A1, A >, < A2, A >, < B, B1 >, < B, B2 >,\n",
      "< B1, B >, < B2, B >, < C, C1 >, < C, C2 >, < C1, C >, < C2, C >}\n",
      "For our example, we will assume that Ξ− contains all those pairs of cities shown\n",
      "in Fig. 7.3 that are not in Ξ+ (a type of closed-world assumption). These are:\n",
      "{< A, B1 >, < A, B2 >, < A, C1 >, < A, C2 >, < B, C1 >, < B, C2 >,\n",
      "< B, A1 >, < B, A2 >, < C, A1 >, < C, A2 >, < C, B1 >, < C, B2 >,\n",
      "< B1, A >, < B2, A >, < C1, A >, < C2, A >, < C1, B >, < C2, B >,\n",
      "< A1, B >, < A2, B >, < A1, C >, < A2, C >, < B1, C >, < B2, C >}\n",
      "There may be other cities not shown on this map, so the training set does not\n",
      "necessarily exhaust all the cities.\n",
      "A\n",
      "B\n",
      "C\n",
      "C1\n",
      "C2\n",
      "B1\n",
      "B2\n",
      "A1\n",
      "A2\n",
      "Figure 7.3: Part of an Airline Route Map\n",
      "We want the learning program to induce a program for computing the value\n",
      "of the relation Nonstop. The training set, Ξ, can be thought of as a partial\n",
      "96\n",
      "CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "description of this relation in extensional form—it explicitly names some pairs\n",
      "in the relation and some pairs not in the relation.\n",
      "We desire to learn the\n",
      "Nonstop relation as a logic program in terms of the background relations, Hub\n",
      "and Satellite, which are also given in extensional form. Doing so will give us\n",
      "a more compact, intensional, description of the relation, and this description\n",
      "could well generalize usefully to other cities not mentioned in the map.\n",
      "We assume the learning program has the following extensional deﬁnitions of\n",
      "the relations Hub and Satellite:\n",
      "Hub\n",
      "{< A >, < B >, < C >}\n",
      "All other cities mentioned in the map are assumed not in the relation Hub. We\n",
      "will use the notation Hub(x) to express that the city named x is in the relation\n",
      "Hub.\n",
      "Satellite\n",
      "{< A1, A, >, < A2, A >, < B1, B >, < B2, B >, < C1, C >, < C2, C >}\n",
      "All other pairs of cities mentioned in the map are not in the relation Satellite.\n",
      "We will use the notation Satellite(x,y) to express that the pair < x, y > is\n",
      "in the relation Satellite.\n",
      "Knowing that the predicate Nonstop is a two-place predicate, the inner loop\n",
      "of our algorithm initializes the ﬁrst clause to Nonstop(x,y) :-\n",
      ". This clause\n",
      "is not necessary because it covers all the negative examples (since it covers all\n",
      "examples). So we must add a literal to its (empty) body. Suppose (selecting\n",
      "a literal from the reﬁnement graph) the algorithm adds Hub(x). The following\n",
      "positive instances in Ξ are covered by Nonstop(x,y) :- Hub(x):\n",
      "{< A, B >, < A, C >, < B, C >, < B, A >, < C, A >, < C, B >,\n",
      "< A, A1 >, < A, A2 >, < B, B1 >, < B, B2 >, < C, C1 >, < C, C2 >}\n",
      "To compute this covering, we interpret the logic program Nonstop(x,y) :-\n",
      "Hub(x) for all pairs of cities in Ξ, using the pairs given in the background\n",
      "relation Hub as ground facts. The following negative instances are also covered:\n",
      "7.3. AN EXAMPLE\n",
      "97\n",
      "{< A, B1 >, < A, B2 >, < A, C1 >, < A, C2 >, < C, A1 >, < C, A2 >,\n",
      "< C, B1 >, < C, B2 >, < B, A1 >, < B, A2 >, < B, C1 >, < B, C2 >}\n",
      "Thus, the clause is not yet necessary and another literal must be added. Sup-\n",
      "pose we next add Hub(y).\n",
      "The following positive instances are covered by\n",
      "Nonstop(x,y) :- Hub(x), Hub(y):\n",
      "{< A, B >, < A, C >, < B, C >, < B, A >, < C, A >, < C, B >}\n",
      "There are no longer any negative instances in Ξ covered so the clause\n",
      "Nonstop(x,y) :- Hub(x), Hub(y) is necessary, and we can terminate the ﬁrst\n",
      "pass through the inner loop.\n",
      "But the program, π, consisting of just this clause is not suﬃcient. These\n",
      "positive instances are not covered by the clause:\n",
      "{< A, A1 >, < A, A2 >, < A1, A >, < A2, A >, < B, B1 >, < B, B2 >,\n",
      "< B1, B >, < B2, B >, < C, C1 >, < C, C2 >, < C1, C >, < C2, C >}\n",
      "The positive instances that were covered by Nonstop(x,y) :- Hub(x), Hub(y)\n",
      "are removed from Ξ to form the Ξcur to be used in the next pass through the\n",
      "inner loop. Ξcur consists of all the negative instances in Ξ plus the positive\n",
      "instances (listed above) that are not yet covered. In order to attempt to cover\n",
      "them, the inner loop creates another clause c, initially set to Nonstop(x,y)\n",
      ":- . This clause covers all the negative instances, and so we must add liter-\n",
      "als to make it necessary. Suppose we add the literal Satellite(x,y). The\n",
      "clause Nonstop(x,y) :- Satellite(x,y) covers no negative instances, so it is\n",
      "necessary. It does cover the following positive instances in Ξcur:\n",
      "{< A1, A >, < A2, A >, < B1, B >, < B2, B >, < C1, C >, < C2, C >}\n",
      "These instances are removed from Ξcur for the next pass through the inner loop.\n",
      "The program now contains two clauses:\n",
      "Nonstop(x,y) :- Hub(x), Hub(y)\n",
      ":- Satellite(x,y)\n",
      "This program is not yet suﬃcient since it does not cover the following positive\n",
      "instances:\n",
      "{< A, A1 >, < A, A2 >, < B, B1 >, < B, B2 >, < C, C1 >, < C, C2 >}\n",
      "98\n",
      "CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "During the next pass through the inner loop, we add the clause Nonstop(x,y)\n",
      ":- Satellite(y,x). This clause is necessary, and since the program containing\n",
      "all three clauses is now suﬃcient, the procedure terminates with:\n",
      "Nonstop(x,y) :- Hub(x), Hub(y)\n",
      ":- Satellite(x,y)\n",
      ":- Satellite(y,x)\n",
      "Since each clause is necessary, and the whole program is suﬃcient, the pro-\n",
      "gram is also consistent with all instances of the training set. Note that this\n",
      "program can be applied (perhaps with good generalization) to other cities be-\n",
      "sides those in our partial map—so long as we can evaluate the relations Hub and\n",
      "Satellite for these other cities. In the next section, we show how the technique\n",
      "can be extended to use recursion on the relation we are inducing. With that\n",
      "extension, the method can be used to induce more general logic programs.\n",
      "7.4\n",
      "Inducing Recursive Programs\n",
      "To induce a recursive program, we allow the addition of a literal having the\n",
      "same predicate letter as that in the head of the clause. Various mechanisms\n",
      "must be used to ensure that such a program will terminate; one such is to make\n",
      "sure that the new literal has diﬀerent variables than those in the head literal.\n",
      "The process is best illustrated with another example. Our example continues\n",
      "the one using the airline map, but we make the map somewhat simpler in order\n",
      "to reduce the size of the extensional relations used. Consider the map shown\n",
      "in Fig. 7.4. Again, B and C are hub cities, B1 and B2 are satellites of B, C1\n",
      "and C2 are satellites of C. We have introduced two new cities, B3 and C3. No\n",
      "ﬂights exist between these cities and any other cities—perhaps there are only\n",
      "bus routes as shown by the grey lines in the map.\n",
      "We now seek to learn a program for Canfly(x,y) that covers only those\n",
      "pairs of cities that can be reached by one or more nonstop ﬂights. The relation\n",
      "Canfly is satisﬁed by the following pairs of postive instances:\n",
      "{< B1, B >, < B1, B2 >, < B1, C >, < B1, C1 >, < B1, C2 >,\n",
      "< B, B1 >, < B2, B1 >, < C, B1 >, < C1, B1 >, < C2, B1 >,\n",
      "< B2, B >, < B2, C >, < B2, C1 >, < B2, C2 >, < B, B2 >,\n",
      "< C, B2 >, < C1, B2 >, < C2, B2 >, < B, C >, < B, C1 >,\n",
      "< B, C2 >, < C, B >, < C1, B >, < C2, B >, < C, C1 >,\n",
      "< C, C2 >, < C1, C >, < C2, C >, < C1, C2 >, < C2, C1 >}\n",
      "7.4. INDUCING RECURSIVE PROGRAMS\n",
      "99\n",
      "B\n",
      "C\n",
      "C1\n",
      "C2\n",
      "B1\n",
      "B2\n",
      "B3\n",
      "C3\n",
      "Figure 7.4: Another Airline Route Map\n",
      "Using a closed-world assumption on our map, we take the negative instances of\n",
      "Canfly to be:\n",
      "{< B3, B2 >, < B3, B >, < B3, B1 >, < B3, C >, < B3, C1 >,\n",
      "< B3, C2 >, < B3, C3 >, < B2, B3 >, < B, B3 >, < B1, B3 >,\n",
      "< C, B3 >, < C1, B3 >, < C2, B3 >, < C3, B3 >, < C3, B2 >,\n",
      "< C3, B >, < C3, B1 >, < C3, C >, < C3, C1 >, < C3, C2 >,\n",
      "< B2, C3 >, < B, C3 >, < B1, C3 >, < C, C3 >, < C1, C3 >,\n",
      "< C2, C3 >}\n",
      "We will induce Canfly(x,y) using the extensionally deﬁned background\n",
      "relation Nonstop given earlier (modiﬁed as required for our reduced airline map)\n",
      "and Canfly itself (recursively).\n",
      "As before, we start with the empty program and proceed to the inner loop\n",
      "to construct a clause that is necessary. Suppose that the inner loop adds the\n",
      "background literal Nonstop(x,y). The clause Canfly(x,y) :- Nonstop(x,y)\n",
      "is necessary; it covers no negative instances. But it is not suﬃcient because it\n",
      "does not cover the following positive instances:\n",
      "{< B1, B2 >, < B1, C >, < B1, C1 >, < B1, C2 >, < B2, B1 >,\n",
      "< C, B1 >, < C1, B1 >, < C2, B1 >, < B2, C >, < B2, C1 >,\n",
      "< B2, C2 >, < C, B2 >, < C1, B2 >, < C2, B2 >, < B, C1 >,\n",
      "100\n",
      "CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "< B, C2 >, < C1, B >, < C2, B >, < C1, C2 >, < C2, C1 >}\n",
      "Thus, we must add another clause to the program. In the inner loop, we ﬁrst\n",
      "create the clause Canfly(x,y) :- Nonstop(x,z) which introduces the new\n",
      "variable z. We digress brieﬂy to describe how a program containing a clause\n",
      "with unbound variables in its body is interpreted.\n",
      "Suppose we try to inter-\n",
      "pret it for the positive instance Canfly(B1,B2). The interpreter attempts to\n",
      "establish Nonstop(B1,z) for some z. Since Nonstop(B1, B), for example, is\n",
      "a background fact, the interpreter returns T—which means that the instance\n",
      "< B1, B2 > is covered.\n",
      "Suppose now, we attempt to interpret the clause\n",
      "for the negative instance Canfly(B3,B). The interpreter attempts to estab-\n",
      "lish Nonstop(B3,z) for some z. There are no background facts that match, so\n",
      "the clause does not cover < B3, B >. Using the interpreter, we see that the\n",
      "clause Canfly(x,y) :- Nonstop(x,z) covers all of the positive instances not\n",
      "already covered by the ﬁrst clause, but it also covers many negative instances\n",
      "such as < B2, B3 >, and < B, B3 >. So the inner loop must add another literal.\n",
      "This time, suppose it adds Canfly(z,y) to yield the clause Canfly(x,y) :-\n",
      "Nonstop(x,z), Canfly(z,y). This clause is necessary; no negative instances\n",
      "are covered. The program is now suﬃcient and consistent; it is:\n",
      "Canfly(x,y) :- Nonstop(x,y)\n",
      ":- Nonstop(x,z), Canfly(z,y)\n",
      "7.5\n",
      "Choosing Literals to Add\n",
      "One of the ﬁrst practical ILP systems was Quinlan’s FOIL [Quinlan, 1990]. A\n",
      "major problem involves deciding how to select a literal to add in the inner loop\n",
      "(from among the literals that are allowed). In FOIL, Quinlan suggested that\n",
      "candidate literals can be compared using an information-like measure—similar\n",
      "to the measures used in inducing decision trees. A measure that gives the same\n",
      "comparison as does Quinlan’s is based on the amount by which adding a literal\n",
      "increases the odds that an instance drawn at random from those covered by the\n",
      "new clause is a positive instance beyond what these odds were before adding\n",
      "the literal.\n",
      "Let p be an estimate of the probability that an instance drawn at random\n",
      "from those covered by a clause before adding the literal is a positive instance.\n",
      "That is, p =(number of positive instances covered by the clause)/(total number\n",
      "of instances covered by the clause). It is convenient to express this probability\n",
      "in “odds form.” The odds, o, that a covered instance is positive is deﬁned to\n",
      "be o = p/(1 − p). Expressing the probability in terms of the odds, we obtain\n",
      "p = o/(1 + o).\n",
      "7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION101\n",
      "After selecting a literal, l, to add to a clause, some of the instances previously\n",
      "covered are still covered; some of these are positive and some are negative. Let\n",
      "pl denote the probability that an instance drawn at random from the instances\n",
      "covered by the new clause (with l added) is positive. The odds will be denoted\n",
      "by ol.\n",
      "We want to select a literal, l, that gives maximal increase in these\n",
      "odds.\n",
      "That is, if we deﬁne λl = ol/o, we want a literal that gives a high\n",
      "value of λl. Specializing the clause in such a way that it fails to cover many of\n",
      "the negative instances previously covered but still covers most of the positive\n",
      "instances previously covered will result in a high value of λl. (It turns out that\n",
      "the value of Quinlan’s information theoretic measure increases monotonically\n",
      "with λl, so we could just as well use the latter instead.)\n",
      "Besides ﬁnding a literal with a high value of λl, Quinlan’s FOIL system also\n",
      "restricts the choice to literals that:\n",
      "a) contain at least one variable that has already been used,\n",
      "b) place further restrictions on the variables if the literal selected has the\n",
      "same predicate letter as the literal being induced (in order to prevent inﬁnite\n",
      "recursion), and\n",
      "c) survive a pruning test based on the values of λl for those literals selected\n",
      "so far.\n",
      "We refer the reader to Quinlan’s paper for further discussion of these points.\n",
      "Quinlan also discusses post-processing pruning methods and presents experi-\n",
      "mental results of the method applied to learning recursive relations on lists, on\n",
      "learning rules for chess endgames and for the card game Eleusis, and for some\n",
      "other standard tasks mentioned in the machine learning literature.\n",
      "The\n",
      "reader\n",
      "should\n",
      "also\n",
      "refer\n",
      "to\n",
      "[Pazzani & Kibler, 1992,\n",
      "Lavraˇc & Dˇzeroski, 1994, Muggleton, 1991, Muggleton, 1992].\n",
      "Discuss preprocessing,\n",
      "postprocessing, bottom-up\n",
      "methods, and LINUS.\n",
      "7.6\n",
      "Relationships Between ILP and Decision\n",
      "Tree Induction\n",
      "The generic ILP algorithm can also be understood as a type of decision tree\n",
      "induction.\n",
      "Recall the problem of inducing decision trees when the values of\n",
      "attributes are categorical.\n",
      "When splitting on a single variable, the split at\n",
      "each node involves asking to which of several mutually exclusive and exhaustive\n",
      "subsets the value of a variable belongs. For example, if a node tested the variable\n",
      "xi, and if xi could have values drawn from {A, B, C, D, E, F}, then one possible\n",
      "split (among many) might be according to whether the value of xi had as value\n",
      "one of {A, B, C} or one of {D, E, F}.\n",
      "It is also possible to make a multi-variate split—testing the values of two or\n",
      "more variables at a time. With categorical variables, an n-variable split would\n",
      "be based on which of several n-ary relations the values of the variables satisﬁed.\n",
      "For example, if a node tested the variables xi and xj, and if xi and xj both\n",
      "could have values drawn from {A, B, C, D, E, F}, then one possible binary split\n",
      "102\n",
      "CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "(among many) might be according to whether or not < xi, xj > satisﬁed the\n",
      "relation {< A, C >, < C, D >}. (Note that our subset method of forming single-\n",
      "variable splits could equivalently have been framed using 1-ary relations—which\n",
      "are usually called properties.)\n",
      "In this framework, the ILP problem is as follows: We are given a training set,\n",
      "Ξ, of positively and negatively labeled patterns whose components are drawn\n",
      "from a set of variables {x, y, z, . . .}. The positively labeled patterns in Ξ form an\n",
      "extensional deﬁnition of a relation, R. We are also given background relations,\n",
      "R1, . . . , Rk, on various subsets of these variables. (That is, we are given sets\n",
      "of tuples that are in these relations.)\n",
      "We desire to construct an intensional\n",
      "deﬁnition of R in terms of the R1, . . . , Rk, such that all of the positively labeled\n",
      "patterns in Ξ are satisﬁed by R and none of the negatively labeled patterns\n",
      "are. The intensional deﬁnition will be in terms of a logic program in which the\n",
      "relation R is the head of a set of clauses whose bodies involve the background\n",
      "relations.\n",
      "The generic ILP algorithm can be understood as decision tree induction,\n",
      "where each node of the decision tree is itself a sub-decision tree, and each sub-\n",
      "decision tree consists of nodes that make binary splits on several variables using\n",
      "the background relations, Ri. Thus we will speak of a top-level decision tree\n",
      "and various sub-decision trees. (Actually, our decision trees will be decision\n",
      "lists—a special case of decision trees, but we will refer to them as trees in our\n",
      "discussions.)\n",
      "In broad outline, the method for inducing an intensional version of the rela-\n",
      "tion R is illustrated by considering the decision tree shown in Fig. 7.5. In this\n",
      "diagram, the patterns in Ξ are ﬁrst ﬁltered through the decision tree in top-\n",
      "level node 1. The background relation R1 is satisﬁed by some of these patterns;\n",
      "these are ﬁltered to the right (to relation R2), and the rest are ﬁltered to the\n",
      "left (more on what happens to these later). Right-going patterns are ﬁltered\n",
      "through a sequence of relational tests until only positively labeled patterns sat-\n",
      "isfy the last relation—in this case R3. That is, the subset of patterns satisfying\n",
      "all the relations, R1, R2, and R3 contains only positive instances from Ξ. (We\n",
      "might say that this combination of tests is necessary. They correspond to the\n",
      "clause created in the ﬁrst pass through the inner loop of the generic ILP algo-\n",
      "rithm.) Let us call the subset of patterns satisfying these relations, Ξ1; these\n",
      "satisfy Node 1 at the top level. All other patterns, that is {Ξ − Ξ1} = Ξ2 are\n",
      "ﬁltered to the left by Node 1.\n",
      "Ξ2 is then ﬁltered by top-level Node 2 in much the same manner, so that\n",
      "Node 2 is satisﬁed only by the positively labeled samples in Ξ2. We continue\n",
      "ﬁltering through top-level nodes until only the negatively labeled patterns fail to\n",
      "satisfy a top node. In our example, Ξ4 contains only negatively labeled patterns\n",
      "and the union of Ξ1 and Ξ3 contains all the positively labeled patterns. The\n",
      "relation, R, that distinguishes positive from negative patterns in Ξ is then given\n",
      "in terms of the following logic program:\n",
      "R :- R1, R2, R3\n",
      "7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION103\n",
      "R1\n",
      "R2\n",
      "R3\n",
      "T\n",
      "T\n",
      "T\n",
      "F\n",
      "F\n",
      "F\n",
      "T\n",
      "F\n",
      "R4\n",
      "R5\n",
      "T\n",
      "T\n",
      "F\n",
      "F\n",
      "T\n",
      "F\n",
      "�\n",
      "�1\n",
      "�2 = � � �1\n",
      "�3\n",
      "�4= �2 � �3\n",
      "Node 1\n",
      "Node 2\n",
      "(only positive\n",
      "instances\n",
      "satisfy all three\n",
      "tests)\n",
      "(only positivel\n",
      "instances satisfy\n",
      "these two tests)\n",
      "(only negative\n",
      "instances)\n",
      "Figure 7.5: A Decision Tree for ILP\n",
      ":- R4, R5\n",
      "If we apply this sort of decision-tree induction procedure to the problem\n",
      "of generating a logic program for the relation Nonstop (refer to Fig. 7.3), we\n",
      "obtain the decision tree shown in Fig. 7.6. The logic program resulting from\n",
      "this decision tree is the same as that produced by the generic ILP algorithm.\n",
      "In setting up the problem, the training set, Ξ can be expressed as a set of 2-\n",
      "dimensional vectors with components x and y. The values of these components\n",
      "range over the cities {A, B, C, A1, A2, B1, B2, C1, C2} except (for simplicity)\n",
      "we do not allow patterns in which x and y have the same value. As before, the\n",
      "relation, Nonstop, contains the following pairs of cities, which are the positive\n",
      "instances:\n",
      "{< A, B >, < A, C >, < B, C >, < B, A >, < C, A >, < C, B >,\n",
      "< A, A1 >, < A, A2 >, < A1, A >, < A2, A >, < B, B1 >, < B, B2 >,\n",
      "< B1, B >, < B2, B >, < C, C1 >, < C, C2 >, < C1, C >, < C2, C >}\n",
      "All other pairs of cities named in the map of Fig. 7.3 (using the closed world\n",
      "assumption) are not in the relation Nonstop and thus are negative instances.\n",
      "Because the values of x and y are categorical, decision-tree induction would\n",
      "be a very diﬃcult task—involving as it does the need to invent relations on\n",
      "104\n",
      "CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "x and y to be used as tests. But with the background relations, Ri (in this\n",
      "case Hub and Satellite), the problem is made much easier. We select these\n",
      "relations in the same way that we select literals; from among the available tests,\n",
      "we make a selection based on which leads to the largest value of λRi.\n",
      "7.7\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "7.7. BIBLIOGRAPHICAL AND HISTORICAL REMARKS\n",
      "105\n",
      "Hub(x)\n",
      "T\n",
      "F\n",
      "�\n",
      "Node 1\n",
      "(top level)\n",
      "{<A,B>, <A,C>,\n",
      "<B,C>, <B,A>,\n",
      "<C,A>, <C,B>}\n",
      "Hub(y)\n",
      "T\n",
      "T\n",
      "F\n",
      "Node 2\n",
      "(top level)\n",
      "Satellite(x,y)\n",
      "F\n",
      "T\n",
      "T\n",
      "{<A1,A>, <A2,A>, <B1,B>,\n",
      "<B2,B>, <C1,C>, <C2,C>}\n",
      "F\n",
      "{<A,A1>, <A,A2>,<B,B1>,\n",
      "<B,B2>,  <C,C1>, <C,C2>}\n",
      "Satellite(y,x)\n",
      "F\n",
      "F\n",
      "T\n",
      "Node 3\n",
      "(top level)\n",
      "T\n",
      "{Only negative instances}\n",
      "(Only positive instances)\n",
      "(Only positive instances)\n",
      "(Only positive instances)\n",
      "F\n",
      "Figure 7.6: A Decision Tree for the Airline Route Problem\n",
      "106\n",
      "CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n",
      "Chapter 8\n",
      "Computational Learning\n",
      "Theory\n",
      "In chapter one we posed the problem of guessing a function given a set of\n",
      "sample inputs and their values. We gave some intuitive arguments to support\n",
      "the claim that after seeing only a small fraction of the possible inputs (and\n",
      "their values) that we could guess almost correctly the values of most subsequent\n",
      "inputs—if we knew that the function we were trying to guess belonged to an\n",
      "appropriately restricted subset of functions. That is, a given training set of\n",
      "sample patterns might be adequate to allow us to select a function, consistent\n",
      "with the labeled samples, from among a restricted set of hypotheses such that\n",
      "with high probability the function we select will be approximately correct (small\n",
      "probability of error) on subsequent samples drawn at random according to the\n",
      "same distribution from which the labeled samples were drawn.\n",
      "This insight\n",
      "led to the theory of probably approximately correct (PAC) learning—initially\n",
      "developed by Leslie Valiant [Valiant, 1984]. We present here a brief description\n",
      "of the theory for the case of Boolean functions. [Dietterich, 1990, Haussler, 1988,\n",
      "Haussler, 1990] give nice surveys of the important results.\n",
      "Other overviews?\n",
      "8.1\n",
      "Notation and Assumptions for PAC Learn-\n",
      "ing Theory\n",
      "We assume a training set Ξ of n-dimensional vectors, Xi, i = 1, . . . , m, each\n",
      "labeled (by 1 or 0) according to a target function, f, which is unknown to\n",
      "the learner. The probability of any given vector X being in Ξ, or later being\n",
      "presented to the learner, is P(X).\n",
      "The probability distribution, P, can be\n",
      "arbitrary. (In the literature of PAC learning theory, the target function is usually\n",
      "called the target concept and is denoted by c, but to be consistent with our\n",
      "previous notation we will continue to denote it by f.) Our problem is to guess\n",
      "107\n",
      "108\n",
      "CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "a function, h(X), based on the labeled samples in Ξ. In PAC theory such a\n",
      "guessed function is called the hypothesis. We assume that the target function\n",
      "is some element of a set of functions, C. We also assume that the hypothesis,\n",
      "h, is an element of a set, H, of hypotheses, which includes the set, C, of target\n",
      "functions. H is called the hypothesis space.\n",
      "In general, h won’t be identical to f, but we can strive to have the value of\n",
      "h(X) = the value of f(X) for most X’s. That is, we want h to be approximately\n",
      "correct. To quantify this notion, we deﬁne the error of h, εh, as the probability\n",
      "that an X drawn randomly according to P will be misclassiﬁed:\n",
      "εh =\n",
      "�\n",
      "[X:h(X)̸=f(X)]\n",
      "P(X)\n",
      "Boldface symbols need to be\n",
      "smaller when they are subscripts in\n",
      "math environments.\n",
      "We say that h is approximately (except for ε ) correct if εh ≤ ε, where ε is the\n",
      "accuracy parameter.\n",
      "Suppose we are able to ﬁnd an h that classiﬁes all m randomly drawn training\n",
      "samples correctly; that is, h is consistent with this randomly selected training\n",
      "set, Ξ.\n",
      "If m is large enough, will such an h be approximately correct (and\n",
      "for what value of ε)? On some training occasions, using m randomly drawn\n",
      "training samples, such an h might turn out to be approximately correct (for a\n",
      "given value of ε), and on others it might not. We say that h is probably (except\n",
      "for δ) approximately correct (PAC) if the probability that it is approximately\n",
      "correct is greater than 1−δ, where δ is the conﬁdence parameter. We shall show\n",
      "that if m is greater than some bound whose value depends on ε and δ, such an\n",
      "h is guaranteed to be probably approximately correct.\n",
      "In general, we say that a learning algorithm PAC-learns functions from C in\n",
      "terms of H iﬀ for every function fϵ C, it outputs a hypothesis hϵ H, such that\n",
      "with probability at least (1 − δ), εh ≤ ε. Such a hypothesis is called probably\n",
      "(except for δ) approximately (except for ε) correct.\n",
      "We want learning algorithms that are tractable, so we want an algorithm\n",
      "that PAC-learns functions in polynomial time. This can only be done for certain\n",
      "classes of functions. If there are a ﬁnite number of hypotheses in a hypothesis\n",
      "set (as there are for many of the hypothesis sets we have considered), we could\n",
      "always produce a consistent hypothesis from this set by testing all of them\n",
      "against the training data. But if there are an exponential number of hypotheses,\n",
      "that would take exponential time.\n",
      "We seek training methods that produce\n",
      "consistent hypotheses in less time. The time complexities for various hypothesis\n",
      "sets have been determined, and these are summarized in a table to be presented\n",
      "later.\n",
      "A class, C, is polynomially PAC learnable in terms of H provided there exists\n",
      "a polynomial-time learning algorithm (polynomial in the number of samples\n",
      "needed, m, in the dimension, n, in 1/ε, and in 1/δ) that PAC-learns functions\n",
      "in C in terms of H.\n",
      "Initial work on PAC assumed H = C, but it was later shown that some func-\n",
      "tions cannot be polynomially PAC-learned under such an assumption (assuming\n",
      "8.2. PAC LEARNING\n",
      "109\n",
      "P ̸= NP)—but can be polynomially PAC-learned if H is a strict superset of C!\n",
      "Also our deﬁnition does not specify the distribution, P, from which patterns\n",
      "are drawn nor does it say anything about the properties of the learning algo-\n",
      "rithm. Since C and H do not have to be identical, we have the further restrictive\n",
      "deﬁnition:\n",
      "A properly PAC-learnable class is a class C for which there exists an algorithm\n",
      "that polynomially PAC-learns functions from C in terms of C.\n",
      "8.2\n",
      "PAC Learning\n",
      "8.2.1\n",
      "The Fundamental Theorem\n",
      "Suppose our learning algorithm selects some h randomly from among those that\n",
      "are consistent with the values of f on the m training patterns. The probability\n",
      "that the error of this randomly selected h is greater than some ε, with h consis-\n",
      "tent with the values of f(X) for m instances of X (drawn according to arbitrary\n",
      "P), is less than or equal to |H|e−εm, where |H| is the number of hypotheses in\n",
      "H. We state this result as a theorem [Blumer, et al., 1987]:\n",
      "Theorem 8.1 (Blumer, et al.) Let H be any set of hypotheses, Ξ be a set of\n",
      "m ≥ 1 training examples drawn independently according to some distribution\n",
      "P, f be any classiﬁcation function in H, and ε > 0. Then, the probability that\n",
      "there exists a hypothesis h consistent with f for the members of Ξ but with error\n",
      "greater than ε is at most |H|e−εm.\n",
      "Proof:\n",
      "Consider the set of all hypotheses, {h1, h2, . . . , hi, . . . , hS}, in H, where S =\n",
      "|H|. The error for hi is εhi= the probability that hi will classify a pattern in\n",
      "error (that is, diﬀerently than f would classify it). The probability that hi will\n",
      "classify a pattern correctly is (1−εhi). A subset, HB, of H will have error greater\n",
      "than ε. We will call the hypotheses in this subset bad. The probability that any\n",
      "particular one of these bad hypotheses, say hb, would classify a pattern correctly\n",
      "is (1−εhb). Since εhb > ε, the probability that hb (or any other bad hypothesis)\n",
      "would classify a pattern correctly is less than (1 − ε). The probability that it\n",
      "would classify all m independently drawn patterns correctly is then less than\n",
      "(1 − ε)m.\n",
      "That is,\n",
      "prob[hb classiﬁes all m patterns correctly |hb ϵ HB] ≤ (1 − ε)m.\n",
      "prob[some h ϵ HB classiﬁes all m patterns correctly]\n",
      "= �\n",
      "hb ϵ HB prob[hb classiﬁes all m patterns correctly |hb ϵ HB]\n",
      "≤ K(1 − ε)m, where K = |HB|.\n",
      "110\n",
      "CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "That is,\n",
      "prob[there is a bad hypothesis that classiﬁes all m patterns correctly]\n",
      "≤ K(1 − ε)m.\n",
      "Since K ≤ |H| and (1 − ε)m ≤ e−εm, we have:\n",
      "prob[there is a bad hypothesis that classiﬁes all m patterns correctly]\n",
      "= prob[there is a hypothesis with error > ε and that classiﬁes all m patterns\n",
      "correctly] ≤ |H|e−εm.\n",
      "QED\n",
      "A corollary of this theorem is:\n",
      "Corollary 8.2 Given m ≥ (1/ε)(ln |H| + ln(1/δ)) independent samples, the\n",
      "probability that there exists a hypothesis in H that is consistent with f on these\n",
      "samples and has error greater than ε is at most δ.\n",
      "Proof: We are to ﬁnd a bound on m that guarantees that\n",
      "prob[there is a hypothesis with error > ε and that classiﬁes all m patterns\n",
      "correctly] ≤ δ.\n",
      "Thus, using the result of the theorem, we must show that\n",
      "|H|e−εm ≤ δ. Taking the natural logarithm of both sides yields:\n",
      "ln |H| − εm ≤ ln δ\n",
      "or\n",
      "m ≥ (1/ε)(ln |H| + ln(1/δ))\n",
      "QED\n",
      "This corollary is important for two reasons. First it clearly states that we\n",
      "can select any hypothesis consistent with the m samples and be assured that\n",
      "with probability (1 − δ) its error will be less than ε. Also, it shows that in\n",
      "order for m to increase no more than polynomially with n, |H| can be no larger\n",
      "than 2O(nk). No class larger than that can be guaranteed to be properly PAC\n",
      "learnable.\n",
      "Here is a possible point of confusion: The bound given in the corollary is\n",
      "an upper bound on the value of m needed to guarantee polynomial probably ap-\n",
      "proximately correct learning. Values of m greater than that bound are suﬃcient\n",
      "(but might not be necessary). We will present a lower (necessary) bound later\n",
      "in the chapter.\n",
      "8.2. PAC LEARNING\n",
      "111\n",
      "8.2.2\n",
      "Examples\n",
      "Terms\n",
      "Let H be the set of terms (conjunctions of literals). Then, |H| = 3n, and\n",
      "m ≥ (1/ε)(ln(3n) + ln(1/δ))\n",
      "≥ (1/ε)(1.1n + ln(1/δ))\n",
      "Note that the bound on m increases only polynomially with n, 1/ε, and 1/δ.\n",
      "For n = 50, ε = 0.01 and δ = 0.01, m ≥ 5, 961 guarantees PAC learnability.\n",
      "In order to show that terms are properly PAC learnable, we additionally\n",
      "have to show that one can ﬁnd in time polynomial in m and n a hypothesis\n",
      "h consistent with a set of m patterns labeled by the value of a term.\n",
      "The\n",
      "following procedure for ﬁnding such a consistent hypothesis requires O(nm)\n",
      "steps (adapted from [Dietterich, 1990, page 268]):\n",
      "We are given a training sequence, Ξ, of m examples. Find the ﬁrst pattern,\n",
      "say X1, in that list that is labeled with a 1.\n",
      "Initialize a Boolean function,\n",
      "h, to the conjunction of the n literals corresponding to the values of the n\n",
      "components of X1. (Components with value 1 will have corresponding positive\n",
      "literals; components with value 0 will have corresponding negative literals.) If\n",
      "there are no patterns labeled by a 1, we exit with the null concept (h ≡ 0 for\n",
      "all patterns). Then, for each additional pattern, Xi, that is labeled with a 1,\n",
      "we delete from h any Boolean variables appearing in Xi with a sign diﬀerent\n",
      "from their sign in h. After processing all the patterns labeled with a 1, we check\n",
      "all of the patterns labeled with a 0 to make sure that none of them is assigned\n",
      "value 1 by h. If, at any stage of the algorithm, any patterns labeled with a 0\n",
      "are assigned a 1 by h, then there exists no term that consistently classiﬁes the\n",
      "patterns in Ξ, and we exit with failure. Otherwise, we exit with h.\n",
      "Change this paragraph if this\n",
      "algorithm was presented in Chapter\n",
      "Three.\n",
      "As an example, consider the following patterns, all labeled with a 1 (from\n",
      "[Dietterich, 1990]):\n",
      "(0, 1, 1, 0)\n",
      "(1, 1, 1, 0)\n",
      "(1, 1, 0, 0)\n",
      "After processing the ﬁrst pattern, we have h = x1x2x3x4; after processing the\n",
      "second pattern, we have h = x2x3x4; ﬁnally, after the third pattern, we have\n",
      "h = x2x4.\n",
      "Linearly Separable Functions\n",
      "Let H be the set of all linearly separable functions. Then, |H| ≤ 2n2, and\n",
      "112\n",
      "CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "m ≥ (1/ε)\n",
      "�\n",
      "n2 ln 2 + ln(1/δ)\n",
      "�\n",
      "Again, note that the bound on m increases only polynomially with n, 1/ε, and\n",
      "1/δ.\n",
      "For n = 50, ε = 0.01 and δ = 0.01, m ≥ 173, 748 guarantees PAC learnabil-\n",
      "ity.\n",
      "To show that linearly separable functions are properly PAC learnable, we\n",
      "would have additionally to show that one can ﬁnd in time polynomial in m and\n",
      "n a hypothesis h consistent with a set of m labeled linearly separable patterns.\n",
      "Linear programming is polynomial.\n",
      "8.2.3\n",
      "Some Properly PAC-Learnable Classes\n",
      "Some properly PAC-learnable classes of functions are given in the following\n",
      "table. (Adapted from [Dietterich, 1990,\n",
      "pages 262 and 268] which also gives\n",
      "references to proofs of some of the time complexities.)\n",
      "H\n",
      "|H|\n",
      "Time Complexity\n",
      "P. Learnable?\n",
      "terms\n",
      "3n\n",
      "polynomial\n",
      "yes\n",
      "k-term DNF\n",
      "2O(kn)\n",
      "NP-hard\n",
      "no\n",
      "(k disjunctive terms)\n",
      "k-DNF\n",
      "2O(nk)\n",
      "polynomial\n",
      "yes\n",
      "(a disjunction of k-sized terms)\n",
      "k-CNF\n",
      "2O(nk)\n",
      "polynomial\n",
      "yes\n",
      "(a conjunction of k-sized clauses)\n",
      "k-DL\n",
      "2O(nkk lg n)\n",
      "polynomial\n",
      "yes\n",
      "(decision lists with k-sized terms)\n",
      "lin. sep.\n",
      "2O(n2)\n",
      "polynomial\n",
      "yes\n",
      "lin. sep. with (0,1) weights\n",
      "?\n",
      "NP-hard\n",
      "no\n",
      "k-2NN\n",
      "?\n",
      "NP-hard\n",
      "no\n",
      "DNF\n",
      "22n\n",
      "polynomial\n",
      "no\n",
      "(all Boolean functions)\n",
      "(Members of the class k-2NN are two-layer, feedforward neural networks with\n",
      "exactly k hidden units and one output unit.)\n",
      "Summary:\n",
      "In order to show that a class of functions is Properly PAC-\n",
      "Learnable :\n",
      "a. Show that there is an algorithm that produces a consistent hypothesis on\n",
      "m n-dimensional samples in time polynomial in m and n.\n",
      "b. Show that the sample size, m, needed to ensure PAC learnability is polyno-\n",
      "mial (or better) in (1/ε), (1/δ), and n by showing that ln |H| is polynomial\n",
      "or better in the number of dimensions.\n",
      "8.3. THE VAPNIK-CHERVONENKIS DIMENSION\n",
      "113\n",
      "As hinted earlier, sometimes enlarging the class of hypotheses makes learning\n",
      "easier. For example, the table above shows that k-CNF is PAC learnable, but\n",
      "k-term-DNF is not. And yet, k-term-DNF is a subclass of k-CNF! So, even if\n",
      "the target function were in k-term-DNF, one would be able to ﬁnd a hypothesis\n",
      "in k-CNF that is probably approximately correct for the target function. Sim-\n",
      "ilarly, linearly separable functions implemented by TLUs whose weight values\n",
      "are restricted to 0 and 1 are not properly PAC learnable, whereas unrestricted\n",
      "linearly separable functions are. It is possible that enlarging the space of hy-\n",
      "potheses makes ﬁnding one that is consistent with the training examples easier.\n",
      "An interesting question is whether or not the class of functions in k-2NN is poly-\n",
      "nomially PAC learnable if the hypotheses are drawn from k′-2NN with k′ > k.\n",
      "(At the time of writing, this matter is still undecided.)\n",
      "Although PAC learning theory is a powerful analytic tool, it (like complexity\n",
      "theory) deals mainly with worst-case results. The fact that the class of two-\n",
      "layer, feedforward neural networks is not polynomially PAC learnable is more an\n",
      "attack on the theory than it is on the networks, which have had many successful\n",
      "applications. As [Baum, 1994, page 416-17] says: “ . . . humans are capable of\n",
      "learning in the natural world. Therefore, a proof within some model of learning\n",
      "that learning is not feasible is an indictment of the model. We should examine\n",
      "the model to see what constraints can be relaxed and made more realistic.”\n",
      "8.3\n",
      "The Vapnik-Chervonenkis Dimension\n",
      "8.3.1\n",
      "Linear Dichotomies\n",
      "Consider a set, H, of functions, and a set, Ξ, of (unlabeled) patterns.\n",
      "One\n",
      "measure of the expressive power of a set of hypotheses, relative to Ξ, is its\n",
      "ability to make arbitrary classiﬁcations of the patterns in Ξ.1 If there are m\n",
      "patterns in Ξ, there are 2m diﬀerent ways to divide these patterns into two\n",
      "disjoint and exhaustive subsets. We say there are 2m diﬀerent dichotomies of\n",
      "Ξ. If Ξ were to include all of the 2n Boolean patterns, for example, there are\n",
      "22n ways to dichotomize them, and (of course) the set of all possible Boolean\n",
      "functions dichotomizes them in all of these ways. But a subset, H, of the Boolean\n",
      "functions might not be able to dichotomize an arbitrary set, Ξ, of m Boolean\n",
      "patterns in all 2m ways. In general (that is, even in the non-Boolean case), we\n",
      "say that if a subset, H, of functions can dichotomize a set, Ξ, of m patterns in\n",
      "all 2m ways, then H shatters Ξ.\n",
      "As an example, consider a set Ξ of m patterns in the n-dimensional space,\n",
      "Rn. (That is, the n components of these patterns are real numbers.) We deﬁne\n",
      "a linear dichotomy as one implemented by an (n−1)-dimensional hyperplane in\n",
      "the n-dimensional space. How many linear dichotomies of m patterns in n di-\n",
      "mensions are there? For example, as shown in Fig. 8.1, there are 14 dichotomies\n",
      "1And, of course, if a hypothesis drawn from a set that could make arbitrary classiﬁcations\n",
      "of a set of training patterns, there is little likelihood that such a hypothesis will generalize\n",
      "well beyond the training set.\n",
      "114\n",
      "CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "of four points in two dimensions (each separating line yields two dichotomies\n",
      "depending on whether the points on one side of the line are classiﬁed as 1 or 0).\n",
      "(Note that even though there are an inﬁnite number of hyperplanes, there are,\n",
      "nevertheless, only a ﬁnite number of ways in which hyperplanes can dichotomize\n",
      "a ﬁnite number of patterns. Small movements of a hyperplane typically do not\n",
      "change the classiﬁcations of any patterns.)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "14 dichotomies of 4 points in 2 dimensions\n",
      "5\n",
      "6\n",
      "7\n",
      "Figure 8.1: Dichotomizing Points in Two Dimensions\n",
      "The number of dichotomies achievable by hyperplanes depends on how the\n",
      "patterns are disposed.\n",
      "For the maximum number of linear dichotomies, the\n",
      "points must be in what is called general position. For m > n, we say that a set\n",
      "of m points is in general position in an n-dimensional space if and only if no\n",
      "subset of (n+1) points lies on an (n−1)-dimensional hyperplane. When m ≤ n,\n",
      "a set of m points is in general position if no (m − 2)-dimensional hyperplane\n",
      "contains the set. Thus, for example, a set of m ≥ 4 points is in general position\n",
      "in a three-dimensional space if no four of them lie on a (two-dimensional) plane.\n",
      "We will denote the number of linear dichotomies of m points in general position\n",
      "in an n-dimensional space by the expression ΠL(m, n).\n",
      "It is not too diﬃcult to verify that:\n",
      "Include the derivation.\n",
      "ΠL(m, n) = 2\n",
      "n\n",
      "�\n",
      "i=0\n",
      "C(m − 1, i)\n",
      "for m > n, and\n",
      "= 2m\n",
      "for m ≤ n\n",
      "8.3. THE VAPNIK-CHERVONENKIS DIMENSION\n",
      "115\n",
      "where C(m − 1, i) is the binomial coeﬃcient\n",
      "(m−1)!\n",
      "(m−1−i)!i!.\n",
      "The table below shows some values for ΠL(m, n).\n",
      "m\n",
      "n\n",
      "(no. of patterns)\n",
      "(dimension)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "4\n",
      "8\n",
      "14\n",
      "16\n",
      "16\n",
      "16\n",
      "5\n",
      "10\n",
      "22\n",
      "30\n",
      "32\n",
      "32\n",
      "6\n",
      "12\n",
      "32\n",
      "52\n",
      "62\n",
      "64\n",
      "7\n",
      "14\n",
      "44\n",
      "84\n",
      "114\n",
      "126\n",
      "8\n",
      "16\n",
      "58\n",
      "128\n",
      "198\n",
      "240\n",
      "Note that the class of linear dichotomies shatters the m patterns if m ≤ n + 1.\n",
      "The bold-face entries in the table correspond to the highest values of m for\n",
      "which linear dichotomies shatter m patterns in n dimensions.\n",
      "8.3.2\n",
      "Capacity\n",
      "Let Pm,n = ΠL(m,n)\n",
      "2m\n",
      "= the probability that a randomly selected dichotomy (out\n",
      "of the 2m possible dichotomies of m patterns in n dimensions) will be linearly\n",
      "separable. In Fig. 8.2 we plot Pλ(n+1),n versus λ and n, where λ = m/(n + 1).\n",
      "Note that for large n (say n > 30) how quickly Pm,n falls from 1 to 0 as\n",
      "m goes above 2(n + 1). For m < 2(n + 1), any dichotomy of the m points is\n",
      "almost certainly linearly separable. But for m > 2(n + 1), a randomly selected\n",
      "dichotomy of the m points is almost certainly not linearly separable. For this\n",
      "reason m = 2(n + 1) is called the capacity of a TLU [Cover, 1965]. Unless the\n",
      "number of training patterns exceeds the capacity, the fact that a TLU separates\n",
      "those training patterns according to their labels means nothing in terms of how\n",
      "well that TLU will generalize to new patterns. There is nothing special about\n",
      "a separation found for m < 2(n + 1) patterns—almost any dichotomy of those\n",
      "patterns would have been linearly separable. To make sure that the separation\n",
      "found is forced by the training set and thus generalizes well, it has to be the\n",
      "case that there are very few linearly separable functions that would separate\n",
      "the m training patterns.\n",
      "Analogous results about the generalizing abilities of neural networks have\n",
      "been developed by [Baum & Haussler, 1989] and given intuitive and experimen-\n",
      "tal justiﬁcation in [Baum, 1994, page 438]:\n",
      "“The results seemed to indicate the following heuristic rule holds. If\n",
      "M examples [can be correctly classiﬁed by] a net with W weights (for\n",
      "M >> W), the net will make a fraction ε of errors on new examples\n",
      "chosen from the same [uniform] distribution where ε = W/M.”\n",
      "116\n",
      "CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0\n",
      "0.25\n",
      "0.5\n",
      "0.75\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "0\n",
      "25\n",
      ".5\n",
      "75\n",
      "1\n",
      "P�(n + 1), n\n",
      "�\n",
      "n\n",
      "Figure 8.2: Probability that a Random Dichotomy is Linearly Separable\n",
      "8.3.3\n",
      "A More General Capacity Result\n",
      "Corollary 7.2 gave us an expression for the number of training patterns suﬃcient\n",
      "to guarantee a required level of generalization—assuming that the function we\n",
      "were guessing was a function belonging to a class of known and ﬁnite cardinality.\n",
      "The capacity result just presented applies to linearly separable functions for non-\n",
      "binary patterns. We can extend these ideas to general dichotomies of non-binary\n",
      "patterns.\n",
      "In general, let us denote the maximum number of dichotomies of any set\n",
      "of m n-dimensional patterns by hypotheses in H as ΠH(m, n). The number of\n",
      "dichotomies will, of course, depend on the disposition of the m points in the\n",
      "n-dimensional space; we take ΠH(m, n) to be the maximum over all possible\n",
      "arrangements of the m points. (In the case of the class of linearly separable\n",
      "functions, the maximum number is achieved when the m points are in general\n",
      "position.) For each class, H, there will be some maximum value of m for which\n",
      "ΠH(m, n) = 2m, that is, for which H shatters the m patterns. This maximum\n",
      "number is called the Vapnik-Chervonenkis (VC) dimension and is denoted by\n",
      "VCdim(H) [Vapnik & Chervonenkis, 1971].\n",
      "We saw that for the class of linear dichotomies, VCdim(Linear) = (n + 1).\n",
      "As another example, let us calculate the VC dimension of the hypothesis space\n",
      "of single intervals on the real line—used to classify points on the real line. We\n",
      "show an example of how points on the line might be dichotomized by a single\n",
      "interval in Fig. 8.3. The set Ξ could be, for example, {0.5, 2.5, - 2.3, 3.14}, and\n",
      "one of the hypotheses in our set would be [1, 4.5]. This hypothesis would label\n",
      "the points 2.5 and 3.14 with a 1 and the points - 2.3 and 0.5 with a 0. This\n",
      "8.3. THE VAPNIK-CHERVONENKIS DIMENSION\n",
      "117\n",
      "set of hypotheses (single intervals on the real line) can arbitrarily classify any\n",
      "two points. But no single interval can classify three points such that the outer\n",
      "two are classiﬁed as 1 and the inner one as 0. Therefore the VC dimension of\n",
      "single intervals on the real line is 2. As soon as we have many more than 2\n",
      "training patterns on the real line and provided we know that the classiﬁcation\n",
      "function we are trying to guess is a single interval, then we begin to have good\n",
      "generalization.\n",
      "Figure 8.3: Dichotomizing Points by an Interval\n",
      "The VC dimension is a useful measure of the expressive power of a hypothesis\n",
      "set. Since any dichotomy of VCdim(H) or fewer patterns in general position in n\n",
      "dimensions can be achieved by some hypothesis in H, we must have many more\n",
      "than VCdim(H) patterns in the training set in order that a hypothesis consistent\n",
      "with the training set is suﬃciently constrained to imply good generalization.\n",
      "Our examples have shown that the concept of VC dimension is not restricted\n",
      "to Boolean functions.\n",
      "8.3.4\n",
      "Some Facts and Speculations About the VC Dimen-\n",
      "sion\n",
      "• If there are a ﬁnite number, |H|, of hypotheses in H, then:\n",
      "VCdim(H) ≤ log(|H|)\n",
      "• The VC dimension of terms in n dimensions is n.\n",
      "• Suppose we generalize our example that used a hypothesis set of single\n",
      "intervals on the real line. Now let us consider an n-dimensional feature\n",
      "space and tests of the form Li ≤ xi ≤ Hi. We allow only one such test per\n",
      "dimension. A hypothesis space consisting of conjunctions of these tests\n",
      "(called axis-parallel hyper-rectangles) has VC dimension bounded by:\n",
      "n ≤ VCdim ≤ 2n\n",
      "• As we have already seen, TLUs with n inputs have a VC dimension of\n",
      "n + 1.\n",
      "• [Baum, 1994, page 438] gives experimental evidence for the proposition\n",
      "that “ . . . multilayer [neural] nets have a VC dimension roughly equal to\n",
      "their total number of [adjustable] weights.”\n",
      "118\n",
      "CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n",
      "8.4\n",
      "VC Dimension and PAC Learning\n",
      "There are two theorems that connect the idea of VC dimension with PAC learn-\n",
      "ing [Blumer, et al., 1990]. We state these here without proof.\n",
      "Theorem 8.3 (Blumer, et al.) A hypothesis space H is PAC learnable iﬀ it\n",
      "has ﬁnite VC dimension.\n",
      "Theorem 8.4 A set of hypotheses, H, is properly PAC learnable if:\n",
      "a. m ≥ (1/ε) max [4 lg(2/δ), 8 VCdim lg(13/ε)], and\n",
      "b. if there is an algorithm that outputs a hypothesis h ϵ H consistent with the\n",
      "training set in polynomial (in m and n) time.\n",
      "The second of these two theorems improves the bound on the number of\n",
      "training patterns needed for linearly separable functions to one that is linear\n",
      "in n. In our previous example of how many training patterns were needed to\n",
      "ensure PAC learnability of a linearly separable function if n = 50, ε = 0.01, and\n",
      "δ = 0.01, we obtained m ≥ 173, 748. Using the Blumer, et al. result we would\n",
      "get m ≥ 52, 756.\n",
      "As another example of the second theorem, let us take H to be the set of\n",
      "closed intervals on the real line. The VC dimension is 2 (as shown previously).\n",
      "With n = 50, ε = 0.01, and δ = 0.01, m ≥ 16, 551 ensures PAC learnability.\n",
      "There is also a theorem that gives a lower (necessary) bound on the number\n",
      "of training patterns required for PAC learning [Ehrenfeucht, et al., 1988]:\n",
      "Theorem 8.5 Any\n",
      "PAC\n",
      "learning\n",
      "algorithm\n",
      "must\n",
      "examine\n",
      "at\n",
      "least\n",
      "Ω(1/ε lg(1/δ) + VCdim(H)) training patterns.\n",
      "The\n",
      "diﬀerence\n",
      "between\n",
      "the\n",
      "lower\n",
      "and\n",
      "upper\n",
      "bounds\n",
      "is\n",
      "O(log(1/ε)VCdim(H)/ε).\n",
      "8.5\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "Chapter 9\n",
      "Unsupervised Learning\n",
      "9.1\n",
      "What is Unsupervised Learning?\n",
      "Consider the various sets of points in a two-dimensional space illustrated in Fig.\n",
      "9.1. The ﬁrst set (a) seems naturally partitionable into two classes, while the\n",
      "second (b) seems diﬃcult to partition at all, and the third (c) is problematic.\n",
      "Unsupervised learning uses procedures that attempt to ﬁnd natural partitions\n",
      "of patterns. There are two stages:\n",
      "• Form an R-way partition of a set Ξ of unlabeled training patterns (where\n",
      "the value of R, itself, may need to be induced from the patterns). The\n",
      "partition separates Ξ into R mutually exclusive and exhaustive subsets,\n",
      "Ξ1, . . . , ΞR, called clusters.\n",
      "• Design a classiﬁer based on the labels assigned to the training patterns by\n",
      "the partition.\n",
      "We will explain shortly various methods for deciding how many clusters there\n",
      "should be and for separating a set of patterns into that many clusters. We can\n",
      "base some of these methods, and their motivation, on minimum-description-\n",
      "length (MDL) principles. In that setting, we assume that we want to encode\n",
      "a description of a set of points, Ξ, into a message of minimal length.\n",
      "One\n",
      "encoding involves a description of each point separately; other, perhaps shorter,\n",
      "encodings might involve a description of clusters of points together with how\n",
      "each point in a cluster can be described given the cluster it belongs to. The\n",
      "speciﬁc techniques described in this chapter do not explicitly make use of MDL\n",
      "principles, but the MDL method has been applied with success. One of the\n",
      "MDL-based methods, Autoclass II [Cheeseman, et al., 1988] discovered a new\n",
      "classiﬁcation of stars based on the properties of infrared sources.\n",
      "Another type of unsupervised learning involves ﬁnding hierarchies of par-\n",
      "titionings or clusters of clusters. A hierarchical partition is one in which Ξ is\n",
      "119\n",
      "120\n",
      "CHAPTER 9. UNSUPERVISED LEARNING\n",
      "a)  two clusters\n",
      "b) one cluster\n",
      "c) ?\n",
      "Figure 9.1: Unlabeled Patterns\n",
      "divided into mutually exclusive and exhaustive subsets, Ξ1, . . . , ΞR; each set,\n",
      "Ξi, (i = 1, . . . , R) is divided into mutually exclusive and exhaustive subsets,\n",
      "and so on. We show an example of such a hierarchical partition in Fig. 9.2.\n",
      "The hierarchical form is best displayed as a tree, as shown in Fig. 9.3. The tip\n",
      "nodes of the tree can further be expanded into their individual pattern elements.\n",
      "One application of such hierarchical partitions is in organizing individuals into\n",
      "taxonomic hierarchies such as those used in botany and zoology.\n",
      "9.2\n",
      "Clustering Methods\n",
      "9.2.1\n",
      "A Method Based on Euclidean Distance\n",
      "Most of the unsupervised learning methods use a measure of similarity between\n",
      "patterns in order to group them into clusters. The simplest of these involves\n",
      "deﬁning a distance between patterns. For patterns whose features are numeric,\n",
      "the distance measure can be ordinary Euclidean distance between two points in\n",
      "an n-dimensional space.\n",
      "There is a simple, iterative clustering method based on distance.\n",
      "It can\n",
      "be described as follows. Suppose we have R randomly chosen cluster seekers,\n",
      "C1, . . . , CR. These are points in an n-dimensional space that we want to adjust\n",
      "so that they each move toward the center of one of the clusters of patterns.\n",
      "We present the (unlabeled) patterns in the training set, Ξ, to the algorithm\n",
      "9.2. CLUSTERING METHODS\n",
      "121\n",
      "�11\n",
      "�12\n",
      "�21\n",
      "�22\n",
      "�23\n",
      "�31\n",
      "�32\n",
      "�11 � �12 = �1\n",
      "�21 � �22 � �23 = �2\n",
      "�31 � �32 = �3\n",
      "�1 � �2 � �3 = �\n",
      "Figure 9.2: A Hierarchy of Clusters\n",
      "one-by-one. For each pattern, Xi, presented, we ﬁnd that cluster seeker, Cj,\n",
      "that is closest to Xi and move it closer to Xi:\n",
      "Cj ←− (1 − αj)Cj + αjXi\n",
      "where αj is a learning rate parameter for the j-th cluster seeker; it determines\n",
      "how far Cj is moved toward Xi.\n",
      "Reﬁnements on this procedure make the cluster seekers move less far as\n",
      "training proceeds. Suppose each cluster seeker, Cj, has a mass, mj, equal to\n",
      "the number of times that it has moved. As a cluster seeker’s mass increases it\n",
      "moves less far towards a pattern. For example, we might set αj = 1/(1 + mj)\n",
      "and use the above rule together with mj ←− mj +1. With this adjustment rule,\n",
      "a cluster seeker is always at the center of gravity (sample mean) of the set of\n",
      "patterns toward which it has so far moved. Intuitively, if a cluster seeker ever\n",
      "gets within some reasonably well clustered set of patterns (and if that cluster\n",
      "seeker is the only one so located), it will converge to the center of gravity of\n",
      "that cluster.\n",
      "122\n",
      "CHAPTER 9. UNSUPERVISED LEARNING\n",
      "�\n",
      "�2\n",
      "�11\n",
      "�12\n",
      "�31\n",
      "�32\n",
      "�21\n",
      "�22\n",
      "�23\n",
      "�1\n",
      "�3\n",
      "Figure 9.3: Displaying a Hierarchy as a Tree\n",
      "Once the cluster seekers have converged, the classiﬁer implied by the now-\n",
      "labeled patterns in Ξ can be based on a Voronoi partitioning of the space (based\n",
      "on distances to the various cluster seekers). This kind of classiﬁcation, an ex-\n",
      "ample of which is shown in Fig. 9.4, can be implemented by a linear machine.\n",
      "Georgy Fedoseevich Voronoi, was a\n",
      "Russian mathematician who lived\n",
      "from 1868 to 1909.\n",
      "When basing partitioning on distance, we seek clusters whose patterns are\n",
      "as close together as possible. We can measure the badness, V , of a cluster of\n",
      "patterns, {Xi}, by computing its sample variance deﬁned by:\n",
      "V = (1/K)\n",
      "�\n",
      "i\n",
      "(Xi − M)2\n",
      "where M is the sample mean of the cluster, which is deﬁned to be:\n",
      "M = (1/K)\n",
      "�\n",
      "i\n",
      "Xi\n",
      "and K is the number of points in the cluster.\n",
      "We would like to partition a set of patterns into clusters such that the sum of\n",
      "the sample variances (badnesses) of these clusters is small. Of course if we have\n",
      "one cluster for each pattern, the sample variances will all be zero, so we must\n",
      "arrange that our measure of the badness of a partition must increase with the\n",
      "number of clusters. In this way, we can seek a trade-oﬀ between the variances of\n",
      "9.2. CLUSTERING METHODS\n",
      "123\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "Separating boundaries\n",
      "Figure 9.4: Minimum-Distance Classiﬁcation\n",
      "the clusters and the number of them in a way somewhat similar to the principle\n",
      "of minimal description length discussed earlier.\n",
      "Elaborations of our basic cluster-seeking procedure allow the number of clus-\n",
      "ter seekers to vary depending on the distances between them and depending on\n",
      "the sample variances of the clusters. For example, if the distance, dij, between\n",
      "two cluster seekers, Ci and Cj, ever falls below some threshold ε, then we can\n",
      "replace them both by a single cluster seeker placed at their center of gravity\n",
      "(taking into account their respective masses). In this way we can decrease the\n",
      "overall badness of a partition by reducing the number of clusters for compara-\n",
      "tively little penalty in increased variance.\n",
      "On the other hand, if any of the cluster seekers, say Ci, deﬁnes a cluster\n",
      "whose sample variance is larger than some amount δ, then we can place a new\n",
      "cluster seeker, Cj, at some random location somewhat adjacent to Ci and reset\n",
      "the masses of both Ci and Cj to zero. In this way the badness of the par-\n",
      "tition might ultimately decrease by decreasing the total sample variance with\n",
      "comparatively little penalty for the additional cluster seeker. The values of the\n",
      "parameters ε and δ are set depending on the relative weights given to sample\n",
      "variances and numbers of clusters.\n",
      "In distance-based methods, it is important to scale the components of the\n",
      "pattern vectors. The variation of values along some dimensions of the pattern\n",
      "vector may be much diﬀerent than that of other dimensions. One commonly\n",
      "used technique is to compute the standard deviation (i.e., the square root of the\n",
      "variance) of each of the components over the entire training set and normalize\n",
      "the values of the components so that their adjusted standard deviations are\n",
      "equal.\n",
      "124\n",
      "CHAPTER 9. UNSUPERVISED LEARNING\n",
      "9.2.2\n",
      "A Method Based on Probabilities\n",
      "Suppose we have a partition of the training set, Ξ, into R mutually exclusive\n",
      "and exhaustive clusters, C1, . . . , CR. We can decide to which of these clusters\n",
      "some arbitrary pattern, X, should be assigned by selecting the Ci for which\n",
      "the probability, p(Ci|X), is largest, providing p(Ci|X) is larger than some ﬁxed\n",
      "threshold, δ. As we saw earlier, we can use Bayes rule and base our decision on\n",
      "maximizing p(X|Ci)p(Ci). Assuming conditional independence of the pattern\n",
      "components, xi, the quantity to be maximized is:\n",
      "S(X, Ci) = p(x1|Ci)p(x2|Ci) · · · p(xn|Ci)p(Ci)\n",
      "The p(xj|Ci) can be estimated from the sample statistics of the patterns in the\n",
      "clusters and then used in the above expression. (Recall the linear form that this\n",
      "formula took in the case of binary-valued components.)\n",
      "We call S(X, Ci) the similarity of X to a cluster, Ci, of patterns. Thus, we\n",
      "assign X to the cluster to which it is most similar, providing the similarity is\n",
      "larger than δ.\n",
      "Just as before, we can deﬁne the sample mean of a cluster, Ci, to be:\n",
      "Mi = (1/Ki)\n",
      "�\n",
      "Xjϵ Ci\n",
      "Xj\n",
      "where Ki is the number of patterns in Ci.\n",
      "We can base an iterative clustering algorithm on this measure of similarity\n",
      "[Mahadevan & Connell, 1992]. It can be described as follows:\n",
      "a. Begin with a set of unlabeled patterns Ξ and an empty list, L, of clusters.\n",
      "b. For the next pattern, X, in Ξ, compute S(X, Ci) for each cluster, Ci.\n",
      "(Initially, these similarities are all zero.)\n",
      "Suppose the largest of these\n",
      "similarities is S(X, Cmax).\n",
      "(a) If S(X, Cmax) > δ, assign X to Cmax. That is,\n",
      "Cmax ←− Cmax ∪ {X}\n",
      "Update the sample statistics p(x1|Cmax), p(x2|Cmax), . . . , p(xn|Cmax),\n",
      "and p(Cmax) to take the new pattern into account. Go to 3.\n",
      "(b) If S(X, Cmax) ≤ δ, create a new cluster, Cnew = {X} and add Cnew\n",
      "to L. Go to 3.\n",
      "c. Merge any existing clusters, Ci and Cj if (Mi − Mj)2 < ε. Compute\n",
      "new sample statistics p(x1|Cmerge), p(x2|Cmerge), . . . , p(xn|Cmerge), and\n",
      "p(Cmerge) for the merged cluster, Cmerge = Ci ∪ Cj.\n",
      "9.3. HIERARCHICAL CLUSTERING METHODS\n",
      "125\n",
      "d. If the sample statistics of the clusters have not changed during an entire\n",
      "iteration through Ξ, then terminate with the clusters in L; otherwise go\n",
      "to 2.\n",
      "The value of the parameter δ controls the number of clusters. If δ is high,\n",
      "there will be a large number of clusters with few patterns in each cluster. For\n",
      "small values of δ, there will be a small number of clusters with many patterns in\n",
      "each cluster. Similarly, the larger the value of ε, the smaller the number clusters\n",
      "that will be found.\n",
      "Designing a classiﬁer based on the patterns labeled by the partitioning is\n",
      "straightforward. We assign any pattern, X, to that category that maximizes\n",
      "S(X, Ci).\n",
      "Mention “k-means and “EM”\n",
      "methods.\n",
      "9.3\n",
      "Hierarchical Clustering Methods\n",
      "9.3.1\n",
      "A Method Based on Euclidean Distance\n",
      "Suppose we have a set, Ξ, of unlabeled training patterns. We can form a hi-\n",
      "erarchical classiﬁcation of the patterns in Ξ by a simple agglomerative method.\n",
      "(The description of this algorithm is based on an unpublished manuscript by\n",
      "Pat Langley.) Our description here gives the general idea; we leave it to the\n",
      "reader to generate a precise algorithm.\n",
      "We ﬁrst compute the Euclidean distance between all pairs of patterns in Ξ.\n",
      "(Again, appropriate scaling of the dimensions is assumed.) Suppose the smallest\n",
      "distance is between patterns Xi and Xj. We collect Xi and Xj into a cluster,\n",
      "C, eliminate Xi and Xj from Ξ and replace them by a cluster vector, C, equal\n",
      "to the average of Xi and Xj. Next we compute the Euclidean distance again\n",
      "between all pairs of points in Ξ. If the smallest distance is between pairs of\n",
      "patterns, we form a new cluster, C, as before and replace the pair of patterns\n",
      "in Ξ by their average. If the shortest distance is between a pattern, Xi, and\n",
      "a cluster vector, Cj (representing a cluster, Cj), we form a new cluster, C,\n",
      "consisting of the union of Cj and {Xi}. In this case, we replace Cj and Xi\n",
      "in Ξ by their (appropriately weighted) average and continue. If the shortest\n",
      "distance is between two cluster vectors, Ci and Cj, we form a new cluster, C,\n",
      "consisting of the union of Ci and Cj. In this case, we replace Ci and Cj by their\n",
      "(appropriately weighted) average and continue. Since we reduce the number of\n",
      "points in Ξ by one each time, we ultimately terminate with a tree of clusters\n",
      "rooted in the cluster containing all of the points in the original training set.\n",
      "An example of how this method aggregates a set of two dimensional patterns\n",
      "is shown in Fig. 9.5. The numbers associated with each cluster indicate the order\n",
      "in which they were formed. These clusters can be organized hierarchically in a\n",
      "binary tree with cluster 9 as root, clusters 7 and 8 as the two descendants of the\n",
      "root, and so on. A ternary tree could be formed instead if one searches for the\n",
      "three points in Ξ whose triangle deﬁned by those patterns has minimal area.\n",
      "126\n",
      "CHAPTER 9. UNSUPERVISED LEARNING\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Figure 9.5: Agglommerative Clustering\n",
      "9.3.2\n",
      "A Method Based on Probabilities\n",
      "A probabilistic quality measure for partitions\n",
      "We can develop a measure of the goodness of a partitioning based on how\n",
      "accurately we can guess a pattern given only what partition it is in. Suppose\n",
      "we are given a partitioning of Ξ into R classes, C1, . . . , CR. As before, we can\n",
      "compute the sample statistics p(xi|Ck) which give probability values for each\n",
      "component given the class assigned to it by the partitioning.\n",
      "Suppose each\n",
      "component xi of X can take on the values vij, where the index j steps over the\n",
      "domain of that component. We use the notation pi(vij|Ck) = probability(xi =\n",
      "vij|Ck).\n",
      "Suppose we use the following probabilistic guessing rule about the values\n",
      "of the components of a vector X given only that it is in class k. Guess that\n",
      "xi = vij with probability pi(vij|Ck). Then, the probability that we guess the\n",
      "i-th component correctly is:\n",
      "�\n",
      "j\n",
      "probability(guess is vij)pi(vij|Ck) =\n",
      "�\n",
      "j\n",
      "[pi(vij|Ck)]2\n",
      "The average number of (the n) components whose values are guessed correctly\n",
      "by this method is then given by the sum of these probabilities over all of the\n",
      "components of X:\n",
      "�\n",
      "i\n",
      "�\n",
      "j\n",
      "[pi(vij|Ck)]2\n",
      "9.3. HIERARCHICAL CLUSTERING METHODS\n",
      "127\n",
      "Given our partitioning into R classes, the goodness measure, G, of this parti-\n",
      "tioning is the average of the above expression over all classes:\n",
      "G =\n",
      "�\n",
      "k\n",
      "p(Ck)\n",
      "�\n",
      "i\n",
      "�\n",
      "j\n",
      "[pi(vij|Ck)]2\n",
      "where p(Ck) is the probability that a pattern is in class Ck. In order to penalize\n",
      "this measure for having a large number of classes, we divide it by R to get an\n",
      "overall “quality” measure of a partitioning:\n",
      "Z = (1/R)\n",
      "�\n",
      "k\n",
      "p(Ck)\n",
      "�\n",
      "i\n",
      "�\n",
      "j\n",
      "[pi(vij|Ck)]2\n",
      "We give an example of the use of this measure for a trivially simple\n",
      "clustering of the four three-dimensional patterns shown in Fig.\n",
      "9.6.\n",
      "There\n",
      "are several diﬀerent partitionings.\n",
      "Let’s evaluate Z values for the follow-\n",
      "ing ones: P1 = {a, b, c, d}, P2 = {{a, b}, {c, d}}, P3 = {{a, c}, {b, d}}, and\n",
      "P4 = {{a}, {b}, {c}, {d}}. The ﬁrst, P1, puts all of the patterns into a single\n",
      "cluster. The sample probabilities pi(vi1 = 1) and pi(vi0 = 0) are all equal to 1/2\n",
      "for each of the three components. Summing over the values of the components\n",
      "(0 and 1) gives (1/2)2 + (1/2)2 = 1/2. Summing over the three components\n",
      "gives 3/2. Averaging over all of the clusters (there is just one) also gives 3/2.\n",
      "Finally, dividing by the number of clusters produces the ﬁnal Z value of this\n",
      "partition, Z(P1) = 3/2.\n",
      "The second partition, P2, gives the following sample probabilities:\n",
      "p1(v11 = 1|C1) = 1\n",
      "p2(v21 = 1|C1) = 1/2\n",
      "p3(v31 = 1|C1) = 1\n",
      "Summing over the values of the components (0 and 1) gives (1)2 + (0)2 = 1 for\n",
      "component 1, (1/2)2 + (1/2)2 = 1/2 for component 2, and (1)2 + (0)2 = 1 for\n",
      "component 3. Summing over the three components gives 2 1/2 for class 1. A\n",
      "similar calculation also gives 2 1/2 for class 2. Averaging over the two clusters\n",
      "also gives 2 1/2. Finally, dividing by the number of clusters produces the ﬁnal\n",
      "Z value of this partition, Z(P2) = 1 1/4, not quite as high as Z(P1).\n",
      "Similar calculations yield Z(P3) = 1 and Z(P4) = 3/4, so this method of\n",
      "evaluating partitions would favor placing all patterns in a single cluster.\n",
      "128\n",
      "CHAPTER 9. UNSUPERVISED LEARNING\n",
      "x2\n",
      "x3\n",
      "x1\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "Figure 9.6: Patterns in 3-Dimensional Space\n",
      "An iterative method for hierarchical clustering\n",
      "Evaluating all partitionings of m patterns and then selecting the best would be\n",
      "computationally intractable. The following iterative method is based on a hi-\n",
      "erarchical clustering procedure called COBWEB [Fisher, 1987]. The procedure\n",
      "grows a tree each node of which is labeled by a set of patterns. At the end\n",
      "of the process, the root node contains all of the patterns in Ξ. The successors\n",
      "of the root node will contain mutually exclusive and exhaustive subsets of Ξ.\n",
      "In general, the successors of a node, η, are labeled by mutually exclusive and\n",
      "exhaustive subsets of the pattern set labelling node η. The tips of the tree will\n",
      "contain singleton sets. The method uses Z values to place patterns at the vari-\n",
      "ous nodes; sample statistics are used to update the Z values whenever a pattern\n",
      "is placed at a node. The algorithm is as follows:\n",
      "a. We start with a tree whose root node contains all of the patterns in Ξ\n",
      "and a single empty successor node. We arrange that at all times dur-\n",
      "ing the process every non-empty node in the tree has (besides any other\n",
      "successors) exactly one empty successor.\n",
      "b. Select a pattern Xi in Ξ (if there are no more patterns to select, terminate).\n",
      "c. Set µ to the root node.\n",
      "d. For each of the successors of µ (including the empty successor!), calculate\n",
      "the best host for Xi. A best host is determined by tentatively placing\n",
      "Xi in one of the successors and calculating the resulting Z value for each\n",
      "9.3. HIERARCHICAL CLUSTERING METHODS\n",
      "129\n",
      "one of these ways of accomodating Xi. The best host corresponds to the\n",
      "assignment with the highest Z value.\n",
      "e. If the best host is an empty node, η, we place Xi in η, generate an empty\n",
      "successor node of η, generate an empty sibling node of η, and go to 2.\n",
      "f. If the best host is a non-empty, singleton (tip) node, η, we place Xi in η,\n",
      "create one successor node of η containing the singleton pattern that was\n",
      "in η, create another successor node of η containing Xi, create an empty\n",
      "successor node of η, create empty successor nodes of the new non-empty\n",
      "successors of η, and go to 2.\n",
      "g. If the best host is a non-empty, non-singleton node, η, we place Xi in η,\n",
      "set µ to η, and go to 4.\n",
      "This process is rather sensitive to the order in which patterns are presented.\n",
      "To make the ﬁnal classiﬁcation tree less order dependent, the COBWEB proce-\n",
      "dure incorporates node merging and splitting.\n",
      "Node merging:\n",
      "It may happen that two nodes having the same parent could be merged with\n",
      "an overall increase in the quality of the resulting classiﬁcation performed by the\n",
      "successors of that parent. Rather than try all pairs to merge, a good heuristic\n",
      "is to attempt to merge the two best hosts. When such a merging improves the\n",
      "Z value, a new node containing the union of the patterns in the merged nodes\n",
      "replaces the merged nodes, and the two nodes that were merged are installed\n",
      "as successors of the new node.\n",
      "Node splitting:\n",
      "A heuristic for node splitting is to consider replacing the best host among a\n",
      "group of siblings by that host’s successors. This operation is performed only if\n",
      "it increases the Z value of the classiﬁcation performed by a group of siblings.\n",
      "Example results from COBWEB\n",
      "We mention two experiments with COBWEB. In the ﬁrst, the program at-\n",
      "tempted to ﬁnd two categories (we will call them Class 1 and Class 2) of United\n",
      "States Senators based on their votes (yes or no) on six issues. After the clus-\n",
      "ters were established, the majority vote in each class was computed. These are\n",
      "shown in the table below.\n",
      "Issue\n",
      "Class 1\n",
      "Class 2\n",
      "Toxic Waste\n",
      "yes\n",
      "no\n",
      "Budget Cuts\n",
      "yes\n",
      "no\n",
      "SDI Reduction\n",
      "no\n",
      "yes\n",
      "Contra Aid\n",
      "yes\n",
      "no\n",
      "Line-Item Veto\n",
      "yes\n",
      "no\n",
      "MX Production\n",
      "yes\n",
      "no\n",
      "130\n",
      "CHAPTER 9. UNSUPERVISED LEARNING\n",
      "In the second experiment, the program attempted to classify soybean dis-\n",
      "eases based on various characteristics. COBWEB grouped the diseases in the\n",
      "taxonomy shown in Fig. 9.7.\n",
      "N0\n",
      "soybean\n",
      "diseases\n",
      "N1\n",
      "  Diaporthe\n",
      "Stem Canker\n",
      "N2\n",
      "Charcoal\n",
      "     Rot\n",
      "N3\n",
      "N31\n",
      "Rhizoctonia\n",
      "       Rot\n",
      "N32\n",
      "Phytophthora\n",
      "       Rot\n",
      "Figure 9.7: Taxonomy Induced for Soybean Diseases\n",
      "9.4\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "Chapter 10\n",
      "Temporal-Diﬀerence\n",
      "Learning\n",
      "10.1\n",
      "Temporal Patterns and Prediction Prob-\n",
      "lems\n",
      "In this chapter, we consider problems in which we wish to learn to predict the\n",
      "future value of some quantity, say z, from an n-dimensional input pattern, X.\n",
      "In many of these problems, the patterns occur in temporal sequence, X1, X2,\n",
      ".\n",
      ".\n",
      "., Xi, Xi+1, . . ., Xm, and are generated by a dynamical process.\n",
      "The\n",
      "components of Xi are features whose values are available at time, t = i. We\n",
      "distinguish two kinds of prediction problems. In one, we desire to predict the\n",
      "value of z at time t = i + 1 based on input Xi for every i. For example, we\n",
      "might wish to predict some aspects of tomorrow’s weather based on a set of\n",
      "measurements made today. In the other kind of prediction problem, we desire\n",
      "to make a sequence of predictions about the value of z at some ﬁxed time, say\n",
      "t = m + 1, based on each of the Xi, i = 1, . . . , m. For example, we might wish\n",
      "to make a series of predictions about some aspect of the weather on next New\n",
      "Year’s Day, based on measurements taken every day before New Year’s. Sutton\n",
      "[Sutton, 1988] has called this latter problem, multi-step prediction, and that is\n",
      "the problem we consider here. In multi-step prediction, we might expect that\n",
      "the prediction accuracy should get better and better as i increases toward m.\n",
      "10.2\n",
      "Supervised and Temporal-Diﬀerence Meth-\n",
      "ods\n",
      "A training method that naturally suggests itself is to use the actual value of\n",
      "z at time m + 1 (once it is known) in a supervised learning procedure using a\n",
      "131\n",
      "132\n",
      "CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "sequence of training patterns, {X1, X2, . . ., Xi, Xi+1, . . ., Xm}. That is, we\n",
      "seek to learn a function, f, such that f(Xi) is as close as possible to z for each i.\n",
      "Typically, we would need a training set, Ξ, consisting of several such sequences.\n",
      "We will show that a method that is better than supervised learning for some\n",
      "important problems is to base learning on the diﬀerence between f(Xi+1) and\n",
      "f(Xi) rather than on the diﬀerence between z and f(Xi). Such methods involve\n",
      "what is called temporal-diﬀerence (TD) learning.\n",
      "We assume that our prediction, f(X), depends on a vector of modiﬁable\n",
      "weights, W. To make that dependence explicit, we write f(X, W).\n",
      "For su-\n",
      "pervised learning, we consider procedures of the following type: For each Xi,\n",
      "the prediction f(Xi, W) is computed and compared to z, and the learning rule\n",
      "(whatever it is) computes the change, (∆Wi), to be made to W. Then, taking\n",
      "into account the weight changes for each pattern in a sequence all at once after\n",
      "having made all of the predictions with the old weight vector, we change W as\n",
      "follows:\n",
      "W ←− W +\n",
      "m\n",
      "�\n",
      "i=1\n",
      "(∆W)i\n",
      "Whenever we are attempting to minimize the squared error between z and\n",
      "f(Xi, W) by gradient descent, the weight-changing rule for each pattern is:\n",
      "(∆W)i = c(z − fi) ∂fi\n",
      "∂W\n",
      "where c is a learning rate parameter, fi is our prediction of z, f(Xi, W),\n",
      "at time t = i, and\n",
      "∂fi\n",
      "∂W is, by deﬁnition, the vector of partial derivatives\n",
      "( ∂fi\n",
      "∂w1 , . . . , ∂fi\n",
      "∂wi , . . . , ∂fi\n",
      "∂wn ) in which the wi are the individual components of W.\n",
      "(The expression\n",
      "∂fi\n",
      "∂W is sometimes written ∇Wfi.) The reader will recall that\n",
      "we used an equivalent expression for (∆W)i in deriving the backpropagation\n",
      "formulas used in training multi-layer neural networks.\n",
      "The Widrow-Hoﬀ rule results when f(X, W) = X • W. Then:\n",
      "(∆W)i = c(z − fi)Xi\n",
      "An interesting form for (∆W)i can be developed if we note that\n",
      "(z − fi) =\n",
      "m\n",
      "�\n",
      "k=i\n",
      "(fk+1 − fk)\n",
      "where we deﬁne fm+1 = z. Substituting in our formula for (∆W)i yields:\n",
      "(∆W)i = c(z − fi) ∂fi\n",
      "∂W\n",
      "10.2. SUPERVISED AND TEMPORAL-DIFFERENCE METHODS\n",
      "133\n",
      "= c ∂fi\n",
      "∂W\n",
      "m\n",
      "�\n",
      "k=i\n",
      "(fk+1 − fk)\n",
      "In this form, instead of using the diﬀerence between a prediction and the value\n",
      "of z, we use the diﬀerences between successive predictions—thus the phrase\n",
      "temporal-diﬀerence (TD) learning.\n",
      "In the case when f(X, W) = X • W, the temporal diﬀerence form of the\n",
      "Widrow-Hoﬀ rule is:\n",
      "(∆W)i = cXi\n",
      "m\n",
      "�\n",
      "k=i\n",
      "(fk+1 − fk)\n",
      "One reason for writing (∆W)i in temporal-diﬀerence form is to permit an\n",
      "interesting generalization as follows:\n",
      "(∆W)i = c ∂fi\n",
      "∂W\n",
      "m\n",
      "�\n",
      "k=i\n",
      "λ(k−i)(fk+1 − fk)\n",
      "where 0 < λ ≤ 1. Here, the λ term gives exponentially decreasing weight to\n",
      "diﬀerences later in time than t = i. When λ = 1, we have the same rule with\n",
      "which we began—weighting all diﬀerences equally, but as λ → 0, we weight only\n",
      "the (fi+1 − fi) diﬀerence. With the λ term, the method is called TD(λ).\n",
      "It is interesting to compare the two extreme cases:\n",
      "For TD(0):\n",
      "(∆W)i = c(fi+1 − fi) ∂fi\n",
      "∂W\n",
      "For TD(1):\n",
      "(∆W)i = c(z − fi) ∂fi\n",
      "∂W\n",
      "Both extremes can be handled by the same learning mechanism; only the error\n",
      "term is diﬀerent. In TD(0), the error is the diﬀerence between successive predic-\n",
      "tions, and in TD(1), the error is the diﬀerence between the ﬁnally revealed value\n",
      "of z and the prediction. Intermediate values of λ take into account diﬀerently\n",
      "weighted diﬀerences between future pairs of successive predictions.\n",
      "Only TD(1) can be considered a pure supervised learning procedure, sensitive\n",
      "to the ﬁnal value of z provided by the teacher. For λ < 1, we have various degrees\n",
      "of unsupervised learning, in which the prediction function strives to make each\n",
      "prediction more like successive ones (whatever they might be). We shall soon\n",
      "see that these unsupervised procedures result in better learning than do the\n",
      "supervised ones for an important class of problems.\n",
      "134\n",
      "CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "10.3\n",
      "Incremental Computation of the (∆W)i\n",
      "We can rewrite our formula for (∆W)i, namely\n",
      "(∆W)i = c ∂fi\n",
      "∂W\n",
      "m\n",
      "�\n",
      "k=i\n",
      "λ(k−i)(fk+1 − fk)\n",
      "to allow a type of incremental computation. First we write the expression for\n",
      "the weight change rule that takes into account all of the (∆W)i:\n",
      "W ←− W +\n",
      "m\n",
      "�\n",
      "i=1\n",
      "c ∂fi\n",
      "∂W\n",
      "m\n",
      "�\n",
      "k=i\n",
      "λ(k−i)(fk+1 − fk)\n",
      "Interchanging the order of the summations yields:\n",
      "W ←− W +\n",
      "m\n",
      "�\n",
      "k=1\n",
      "c\n",
      "k\n",
      "�\n",
      "i=1\n",
      "λ(k−i)(fk+1 − fk) ∂fi\n",
      "∂W\n",
      "= W +\n",
      "m\n",
      "�\n",
      "k=1\n",
      "c(fk+1 − fk)\n",
      "k\n",
      "�\n",
      "i=1\n",
      "λ(k−i) ∂fi\n",
      "∂W\n",
      "Interchanging the indices k and i ﬁnally yields:\n",
      "W ←− W +\n",
      "m\n",
      "�\n",
      "i=1\n",
      "c(fi+1 − fi)\n",
      "i\n",
      "�\n",
      "k=1\n",
      "λ(i−k) ∂fk\n",
      "∂W\n",
      "If, as earlier, we want to use an expression of the form W ←− W+�m\n",
      "i=1(∆W)i,\n",
      "we see that we can write:\n",
      "(∆W)i = c(fi+1 − fi)\n",
      "i\n",
      "�\n",
      "k=1\n",
      "λ(i−k) ∂fk\n",
      "∂W\n",
      "Now, if we let ei = �i\n",
      "k=1 λ(i−k) ∂fk\n",
      "∂W, we can develop a computationally eﬃcient\n",
      "recurrence equation for ei+1 as follows:\n",
      "ei+1 =\n",
      "i+1\n",
      "�\n",
      "k=1\n",
      "λ(i+1−k) ∂fk\n",
      "∂W\n",
      "= ∂fi+1\n",
      "∂W +\n",
      "i\n",
      "�\n",
      "k=1\n",
      "λ(i+1−k) ∂fk\n",
      "∂W\n",
      "10.4. AN EXPERIMENT WITH TD METHODS\n",
      "135\n",
      "= ∂fi+1\n",
      "∂W + λei\n",
      "Rewriting (∆W)i in these terms, we obtain:\n",
      "(∆W)i = c(fi+1 − fi)ei\n",
      "where:\n",
      "e1 = ∂f1\n",
      "∂W\n",
      "e2 = ∂f2\n",
      "∂W + λe1\n",
      "etc.\n",
      "Quoting Sutton [Sutton, 1988, page 15] (about a diﬀerent equation, but the\n",
      "quote applies equally well to this one):\n",
      "“. . . this equation can be computed incrementally, because each\n",
      "(∆W)i depends only on a pair of successive predictions and on the\n",
      "[weighted] sum of all past values for ∂fi\n",
      "∂W. This saves substantially on\n",
      "memory, because it is no longer necessary to individually remember\n",
      "all past values of\n",
      "∂fi\n",
      "∂W.”\n",
      "10.4\n",
      "An Experiment with TD Methods\n",
      "TD prediction methods [especially TD(0)] are well suited to situations in which\n",
      "the patterns are generated by a dynamic process. In that case, sequences of\n",
      "temporally presented patterns contain important information that is ignored\n",
      "by a conventional supervised method such as the Widrow-Hoﬀ rule.\n",
      "Sutton\n",
      "[Sutton, 1988, page 19] gives an interesting example involving a random walk,\n",
      "which we repeat here. In Fig. 10.1, sequences of vectors, X, are generated as\n",
      "follows: We start with vector XD; the next vector in the sequence is equally\n",
      "likely to be one of the adjacent vectors in the diagram. If the next vector is\n",
      "XC (or XE), the next one after that is equally likely to be one of the vectors\n",
      "adjacent to XC (or XE). When XB is in the sequence, it is equally likely that\n",
      "the sequence terminates with z = 0 or that the next vector is XC. Similarly,\n",
      "when XF is in the sequence, it is equally likely that the sequence terminates\n",
      "with z = 1 or that the next vector is XE. Thus the sequences are random, but\n",
      "they always start with XD. Some sample sequences are shown in the ﬁgure.\n",
      "136\n",
      "CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "z = 0\n",
      "z = 1\n",
      "XB\n",
      "XC\n",
      "XD\n",
      "XE\n",
      "XF\n",
      "Typical Sequences:\n",
      "XDXCXDXEXF  1\n",
      "XDXCXBXCXDXEXDXEXF  1\n",
      "XDXEXDXCXB  0\n",
      "Figure 10.1: A Markov Process\n",
      "This random walk is an example of a Markov process; transitions from state i\n",
      "to state j occur with probabilities that depend only on i and j.\n",
      "Given a set of sequences generated by this process as a training set, we want\n",
      "to be able to predict the value of z for each X in a test sequence. We assume\n",
      "that the learning system does not know the transition probabilities.\n",
      "For his experiments with this process, Sutton used a linear predictor, that\n",
      "is f(X, W) = X • W. The learning problem is to ﬁnd a weight vector, W, that\n",
      "minimizes the mean-squared error between z and the predicted value of z. Given\n",
      "the ﬁve diﬀerent values that X can take on, we have the following predictions:\n",
      "f(XB) = w1, f(XC) = w2, f(XD) = w3, f(XE) = w4, f(XF ) = w5, where\n",
      "wi is the i-th component of the weight vector. (Note that the values of the\n",
      "predictions are not limited to 1 or 0—even though z can only have one of\n",
      "those values—because we are minimizing mean-squared error.) After training,\n",
      "these predictions will be compared with the optimal ones—given the transition\n",
      "probabilities.\n",
      "The experimental setup was as follows: ten random sequences were generated\n",
      "using the transition probabilities. Each of these sequences was presented in turn\n",
      "to a TD(λ) method for various values of λ. Weight vector increments, (∆W)i,\n",
      "were computed after each pattern presentation but no weight changes were\n",
      "made until all ten sequences were presented. The weight vector increments were\n",
      "summed after all ten sequences were presented, and this sum was used to change\n",
      "the weight vector to be used for the next pass through the ten sequences. This\n",
      "process was repeated over and over (using the same training sequences) until\n",
      "(quoting Sutton) “the procedure no longer produced any signiﬁcant changes in\n",
      "the weight vector. For small c, the weight vector always converged in this way,\n",
      "10.4. AN EXPERIMENT WITH TD METHODS\n",
      "137\n",
      "and always to the same ﬁnal value [for 100 diﬀerent training sets of ten random\n",
      "sequences], independent of its initial value.” (Even though, for ﬁxed, small c,\n",
      "the weight vector always converged to the same vector, it might converge to a\n",
      "somewhat diﬀerent vector for diﬀerent values of c.)\n",
      "After convergence, the predictions made by the ﬁnal weight vector are com-\n",
      "pared with the optimal predictions made using the transition probabilities.\n",
      "These optimal predictions are simply p(z = 1|X). We can compute these proba-\n",
      "bilities to be 1/6, 1/3, 1/2, 2/3, and 5/6 for XB, XC, XD, XE, XF , respectively.\n",
      "The root-mean-squared diﬀerences between the best learned predictions (over\n",
      "all c) and these optimal ones are plotted in Fig. 10.2 for seven diﬀerent values\n",
      "of λ. (For each data point, the standard error is approximately σ = 0.01.)\n",
      "0.10\n",
      "0.12\n",
      "0.14\n",
      "0.16\n",
      "0.18\n",
      "0.20\n",
      "0.0 0.1\n",
      "0.3\n",
      "0.5\n",
      "0.7\n",
      "0.9 1.0\n",
      "�\n",
      "Error using\n",
      "best c\n",
      "Widrow-Hoff\n",
      "TD(1)\n",
      "TD(0)\n",
      "(Adapted from Sutton, p. 20, 1988)\n",
      "Figure 10.2: Prediction Errors for TD(λ)\n",
      "Notice that the Widrow-Hoﬀ procedure does not perform as well as other\n",
      "versions of TD(λ) for λ < 1! Quoting [Sutton, 1988, page 21]:\n",
      "“This result contradicts conventional wisdom. It is well known that,\n",
      "under repeated presentations, the Widrow-Hoﬀ procedure minimizes\n",
      "the RMS error between its predictions and the actual outcomes in\n",
      "the training set ([Widrow & Stearns, 1985]). How can it be that this\n",
      "optimal method peformed worse than all the TD methods for λ <\n",
      "1? The answer is that the Widrow-Hoﬀ procedure only minimizes\n",
      "error on the training set; it does not necessarily minimize error for\n",
      "future experience. [Later] we prove that in fact it is linear TD(0)\n",
      "that converges to what can be considered the optimal estimates for\n",
      "138\n",
      "CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "matching future experience—those consistent with the maximum-\n",
      "likelihood estimate of the underlying Markov process.”\n",
      "10.5\n",
      "Theoretical Results\n",
      "It is possible to analyze the performance of the linear-prediction TD(λ) methods\n",
      "on Markov processes. We state some theorems here without proof.\n",
      "Theorem 10.1 (Sutton, page 24, 1988) For any absorbing Markov chain,\n",
      "and for any linearly independent set of observation vectors {Xi} for the non-\n",
      "terminal states, there exists an ε > 0 such that for all positive c < ε and for any\n",
      "initial weight vector, the predictions of linear TD(0) (with weight updates after\n",
      "each sequence) converge in expected value to the optimal (maximum likelihood)\n",
      "predictions of the true process.\n",
      "Even though the expected values of the predictions converge, the predictions\n",
      "themselves do not converge but vary around their expected values depending on\n",
      "their most recent experience. Sutton conjectures that if c is made to approach\n",
      "0 as training progresses, the variance of the predictions will approach 0 also.\n",
      "Dayan [Dayan, 1992] has extended the result of Theorem 9.1 to TD(λ) for\n",
      "arbitrary λ between 0 and 1. (Also see [Dayan & Sejnowski, 1994].)\n",
      "10.6\n",
      "Intra-Sequence Weight Updating\n",
      "Our standard weight updating rule for TD(λ) methods is:\n",
      "W ←− W +\n",
      "m\n",
      "�\n",
      "i=1\n",
      "c(fi+1 − fi)\n",
      "i\n",
      "�\n",
      "k=1\n",
      "λ(i−k) ∂fk\n",
      "∂W\n",
      "where the weight update occurs after an entire sequence is observed. To make\n",
      "the method truly incremental (in analogy with weight updating rules for neural\n",
      "nets), it would be desirable to change the weight vector after every pattern\n",
      "presentation. The obvious extension is:\n",
      "Wi+1 ←− Wi + c(fi+1 − fi)\n",
      "i\n",
      "�\n",
      "k=1\n",
      "λ(i−k) ∂fk\n",
      "∂W\n",
      "where fi+1 is computed before making the weight change; that is, fi+1 =\n",
      "f(Xi+1, Wi). But that would make fi = f(Xi, Wi−1), and such a rule would\n",
      "make the prediction diﬀerence, namely (fi+1 − fi), sensitive both to changes in\n",
      "X and changes in W and could lead to instabilities. Instead, we modify the rule\n",
      "so that, for every pair of predictions, fi+1 = f(Xi+1, Wi) and fi = f(Xi, Wi).\n",
      "This version of the rule has been used in practice with excellent results.\n",
      "10.6. INTRA-SEQUENCE WEIGHT UPDATING\n",
      "139\n",
      "For TD(0) and linear predictors, the rule is:\n",
      "Wi+1 = Wi + c(fi+1 − fi)Xi\n",
      "The rule is implemented as follows:\n",
      "a. Initialize the weight vector, W, arbitrarily.\n",
      "b. For i = 1, ..., m, do:\n",
      "(a) fi ←− Xi • W\n",
      "(We compute fi anew each time through rather than use the value\n",
      "of fi+1 the previous time through.)\n",
      "(b) fi+1 ←− Xi+1 • W\n",
      "(c) di+1 ←− fi+1 − fi\n",
      "(d) W ←− W + c di+1Xi\n",
      "(If fi were computed again with this changed weight vector, its value\n",
      "would be closer to fi+1 as desired.)\n",
      "The linear TD(0) method can be regarded as a technique for training a\n",
      "very simple network consisting of a single dot product unit (and no threshold\n",
      "or sigmoid function). TD methods can also be used in combination with back-\n",
      "propagation to train neural networks. For TD(0) we change the network weights\n",
      "according to the expression:\n",
      "Wi+1 = Wi + c(fi+1 − fi) ∂fi\n",
      "∂W\n",
      "The only change that must be made to the standard backpropagation weight-\n",
      "changing rule is that the diﬀerence term between the desired output and the\n",
      "output of the unit in the ﬁnal (k-th) layer, namely (d − f (k)), must be replaced\n",
      "by a diﬀerence term between successive outputs, (fi+1 − fi). This change has a\n",
      "direct eﬀect only on the expression for δ(k) which becomes:\n",
      "δ(k) = 2(f ′(k) − f (k))f (k)(1 − f (k))\n",
      "where f ′(k) and f (k) are two successive outputs of the network.\n",
      "The weight changing rule for the i-th weight vector in the j-th layer of weights\n",
      "has the same form as before, namely:\n",
      "W(j)\n",
      "i\n",
      "←− W(j)\n",
      "i\n",
      "+ cδ(j)\n",
      "i\n",
      "X(j−1)\n",
      "where the δ(j)\n",
      "i\n",
      "are given recursively by:\n",
      "δ(j)\n",
      "i\n",
      "= f (j)\n",
      "i\n",
      "(1 − f (j)\n",
      "i\n",
      ")\n",
      "mj+1\n",
      "�\n",
      "l=1\n",
      "δ(j+1)\n",
      "l\n",
      "w(j+1)\n",
      "il\n",
      "and w(j+1)\n",
      "il\n",
      "is the l-th component of the i-th weight vector in the (j +1)-th layer\n",
      "of weights. Of course, here also it is assumed that f ′(k) and f (k) are computed\n",
      "using the same weights and then the weights are changed. In the next section\n",
      "we shall see an interesting example of this application of TD learning.\n",
      "140\n",
      "CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "10.7\n",
      "An Example Application: TD-gammon\n",
      "A program called TD-gammon [Tesauro, 1992] learns to play backgammon by\n",
      "training a neural network via temporal-diﬀerence methods. The structure of\n",
      "the neural net, and its coding is as shown in Fig. 10.3. The network is trained\n",
      "to minimize the error between actual payoﬀ and estimated payoﬀ, where the\n",
      "actual payoﬀ is deﬁned to be df = p1 + 2p2 − p3 − 2p4, and the pi are the actual\n",
      "probabilities of the various outcomes as deﬁned in the ﬁgure.\n",
      ". . .\n",
      "p3 = pr(black wins)\n",
      "p4 = pr(black gammons)\n",
      "p1 = pr(white wins)\n",
      "p2 = pr(white gammons)\n",
      "estimated payoff:\n",
      "d = p1 + 2p2 � p3 � 2p4\n",
      "no. of white\n",
      "on cell 1\n",
      "no. on bar,\n",
      "off board,\n",
      "and who\n",
      "moves\n",
      "198 inputs\n",
      "1\n",
      "2\n",
      "3\n",
      "# > 3\n",
      ". . .\n",
      "up to 40 hidden units\n",
      "2 x 24\n",
      "cells\n",
      "4 output units\n",
      "hidden and output units are sigmoids\n",
      "learning rate:  c = 0.1; initial weights chosen\n",
      "randomly between �0.5 and +0.5.\n",
      "estimated probabilities:\n",
      "Figure 10.3: The TD-gammon Network\n",
      "TD-gammon learned by using the network to select that move that results\n",
      "in the best predicted payoﬀ. That is, at any stage of the game some ﬁnite set of\n",
      "moves is possible and these lead to the set, {X}, of new board positions. Each\n",
      "member of this set is evaluated by the network, and the one with the largest\n",
      "10.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS\n",
      "141\n",
      "predicted payoﬀ is selected if it is white’s move (and the smallest if it is black’s).\n",
      "The move is made, and the network weights are adjusted to make the predicted\n",
      "payoﬀ from the original position closer to that of the resulting position.\n",
      "The weight adjustment procedure combines temporal-diﬀerence (TD(λ))\n",
      "learning with backpropagation.\n",
      "If dt is the network’s estimate of the payoﬀ\n",
      "at time t (before a move is made), and dt+1 is the estimate at time t + 1 (after\n",
      "a move is made), the weight adjustment rule is:\n",
      "∆Wt = c(dt+1 − dt)\n",
      "t\n",
      "�\n",
      "k=1\n",
      "λt−k ∂dk\n",
      "∂W\n",
      "where Wt is a vector of all weights in the network at time t, and\n",
      "∂dk\n",
      "∂W is the\n",
      "gradient of dk in this weight space. (For a layered, feedforward network, such\n",
      "as that of TD-gammon, the weight changes for the weight vectors in each layer\n",
      "can be expressed in the usual manner.)\n",
      "To make the special cases clear, recall that for TD(0), the network would be\n",
      "trained so that, for all t, its output, dt, for input Xt tended toward its expected\n",
      "output, dt+1, for input Xt+1. For TD(1), the network would be trained so that,\n",
      "for all t, its output, dt, for input Xt tended toward the expected ﬁnal payoﬀ,\n",
      "df, given that input. The latter case is the same as the Widrow-Hoﬀ rule.\n",
      "After about 200,000 games the following results were obtained. TD-gammon\n",
      "(with 40 hidden units, λ = 0.7, and c = 0.1) won 66.2% of 10,000 games against\n",
      "SUN Microsystems Gammontool and 55% of 10,000 games against a neural\n",
      "network trained using expert moves. Commenting on a later version of TD-\n",
      "gammon, incorporating special features as inputs, Tesauro said: “It appears to\n",
      "be the strongest program ever seen by this author.”\n",
      "10.8\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "142\n",
      "CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n",
      "Chapter 11\n",
      "Delayed-Reinforcement\n",
      "Learning\n",
      "11.1\n",
      "The General Problem\n",
      "Imagine a robot that exists in an environment in which it can sense and act.\n",
      "Suppose (as an extreme case) that it has no idea about the eﬀects of its actions.\n",
      "That is, it doesn’t know how acting will change its sensory inputs. Along with\n",
      "its sensory inputs are “rewards,” which it occasionally receives. How should it\n",
      "choose its actions so as to maximize its rewards over the long run? To maximize\n",
      "rewards, it will need to be able to predict how actions change inputs, and in\n",
      "particular, how actions lead to rewards.\n",
      "We formalize the problem in the following way: The robot exists in an\n",
      "environment consisting of a set, S, of states. We assume that the robot’s sensory\n",
      "apparatus constructs an input vector, X, from the environment, which informs\n",
      "the robot about which state the environment is in. For the moment, we will\n",
      "assume that the mapping from states to vectors is one-to-one, and, in fact, will\n",
      "use the notation X to refer to the state of the environment as well as to the\n",
      "input vector. When presented with an input vector, the robot decides which\n",
      "action from a set, A, of actions to perform. Performing the action produces an\n",
      "eﬀect on the environment—moving it to a new state. The new state results in\n",
      "the robot perceiving a new input vector, and the cycle repeats. We assume a\n",
      "discrete time model; the input vector at time t = i is Xi, the action taken at\n",
      "that time is ai, and the expected reward, ri, received at t = i depends on the\n",
      "action taken and on the state, that is ri = r(Xi, ai). The learner’s goal is to ﬁnd\n",
      "a policy, π(X), that maps input vectors to actions in such a way that maximizes\n",
      "rewards accumulated over time. This type of learning is called reinforcement\n",
      "learning. The learner must ﬁnd the policy by trial and error; it has no initial\n",
      "knowledge of the eﬀects of its actions. The situation is as shown in Fig. 11.1.\n",
      "143\n",
      "144\n",
      "CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Xi\n",
      "ri\n",
      "Learner\n",
      "Environment\n",
      "(reward)\n",
      "(state)\n",
      "(action)\n",
      "ai\n",
      "Figure 11.1: Reinforcement Learning\n",
      "11.2\n",
      "An Example\n",
      "A “grid world,” such as the one shown in Fig. 11.2 is often used to illustrate\n",
      "reinforcement learning. Imagine a robot initially in cell (2,3). The robot receives\n",
      "input vector (x1, x2) telling it what cell it is in; it is capable of four actions,\n",
      "n, e, s, w moving the robot one cell up, right, down, or left, respectively. It is\n",
      "rewarded one negative unit whenever it bumps into the wall or into the blocked\n",
      "cells. For example, if the input to the robot is (1,3), and the robot chooses\n",
      "action w, the next input to the robot is still (1,3) and it receives a reward of\n",
      "−1. If the robot lands in the cell marked G (for goal), it receives a reward of\n",
      "+10. Let’s suppose that whenever the robot lands in the goal cell and gets its\n",
      "reward, it is immediately transported out to some random cell, and the quest\n",
      "for reward continues.\n",
      "A policy for our robot is a speciﬁcation of what action to take for every one\n",
      "of its inputs, that is, for every one of the cells in the grid. For example, a com-\n",
      "ponent of such a policy would be “when in cell (3,1), move right.” An optimal\n",
      "policy is a policy that maximizes long-term reward. One way of displaying a\n",
      "policy for our grid-world robot is by an arrow in each cell indicating the direc-\n",
      "tion the robot should move when in that cell. In Fig. 11.3, we show an optimal\n",
      "policy displayed in this manner. In this chapter we will describe methods for\n",
      "learning optimal policies based on reward values received by the learner.\n",
      "11.3. TEMPORAL DISCOUNTING AND OPTIMAL POLICIES\n",
      "145\n",
      "R\n",
      "G\n",
      "1 2 3 4\n",
      "5 6 7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Figure 11.2: A Grid World\n",
      "11.3\n",
      "Temporal Discounting and Optimal Poli-\n",
      "cies\n",
      "In delayed reinforcement learning, one often assumes that rewards in the distant\n",
      "future are not as valuable as are more immediate rewards. This preference can\n",
      "be accomodated by a temporal discount factor, 0 ≤ γ < 1. The present value of\n",
      "a reward, ri, occuring i time units in the future, is taken to be γiri. Suppose\n",
      "we have a policy π(X) that maps input vectors into actions, and let rπ(X)\n",
      "i\n",
      "be\n",
      "the reward that will be received on the i-th time step after one begins executing\n",
      "policy π starting in state X. Then the total reward accumulated over all time\n",
      "steps by policy π beginning in state X is:\n",
      "V π(X) =\n",
      "∞\n",
      "�\n",
      "i=0\n",
      "γirπ(X)\n",
      "i\n",
      "One reason for using a temporal discount factor is so that the above sum will\n",
      "be ﬁnite. An optimal policy is one that maximizes V π(X) for all inputs, X.\n",
      "In general, we want to consider the case in which the rewards, ri, are random\n",
      "variables and in which the eﬀects of actions on environmental states are random.\n",
      "In Markovian environments, for example, the probability that action a in state\n",
      "Xi will lead to state Xj is given by a transition probability p[Xj|Xi, a]. Then,\n",
      "we will want to maximize expected future reward and would deﬁne V π(X) as:\n",
      "V π(X) = E\n",
      "� ∞\n",
      "�\n",
      "i=0\n",
      "γirπ(X)\n",
      "i\n",
      "�\n",
      "In either case, we call V π(X) the value of policy π for input X.\n",
      "146\n",
      "CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "R\n",
      "G\n",
      "1 2 3 4\n",
      "5 6 7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Figure 11.3: An Optimal Policy in the Grid World\n",
      "If the action prescribed by π taken in state X leads to state X′ (randomly\n",
      "according to the transition probabilities), then we can write V π(X) in terms of\n",
      "V π(X′) as follows:\n",
      "V π(X) = r[X, π(X)] + γ\n",
      "�\n",
      "X′\n",
      "p[X′|X, π(X)]V π(X′)\n",
      "where (in summary):\n",
      "γ = the discount factor,\n",
      "V π(X) = the value of state X under policy π,\n",
      "r[X, π(X)] = the expected immediate reward received when we execute the\n",
      "action prescribed by π in state X, and\n",
      "p[X′|X, π(X)] = the probability that the environment transitions to state\n",
      "X′ when we execute the action prescribed by π in state X.\n",
      "In other words, the value of state X under policy π is the expected value of\n",
      "the immediate reward received when executing the action recommended by π\n",
      "plus the average value (under π) of all of the states accessible from X.\n",
      "For an optimal policy, π∗ (and no others!), we have the famous “optimality\n",
      "equation:”\n",
      "V π∗(X) = max\n",
      "a\n",
      "�\n",
      "r(X, a) + γ\n",
      "�\n",
      "X′\n",
      "p[X′|X, a]V π∗(X′)\n",
      "�\n",
      "The theory of dynamic programming (DP) [Bellman, 1957, Ross, 1983] assures\n",
      "us that there is at least one optimal policy, π∗, that satisﬁes this equation. DP\n",
      "11.4. Q-LEARNING\n",
      "147\n",
      "also provides methods for calculating V π∗(X) and at least one π∗, assuming\n",
      "that we know the average rewards and the transition probabilities. If we knew\n",
      "the transition probabilities, the average rewards, and V π∗(X) for all X and a,\n",
      "then it would be easy to implement an optimal policy. We would simply select\n",
      "that a that maximizes r(X, a) + γ �\n",
      "X′ p[X′|X, a]V π∗(X′). That is,\n",
      "π∗(X) = arg max\n",
      "a\n",
      "�\n",
      "r(X, a) + γ\n",
      "�\n",
      "X′\n",
      "p[X′|X, a]V π∗(X′)\n",
      "�\n",
      "But, of course, we are assuming that we do not know these average rewards nor\n",
      "the transition probabilities, so we have to ﬁnd a method that eﬀectively learns\n",
      "them.\n",
      "If we had a model of actions, that is, if we knew for every state, X, and\n",
      "action a, which state, X′ resulted, then we could use a method called value\n",
      "iteration to ﬁnd an optimal policy. Value iteration works as follows: We begin\n",
      "by assigning, randomly, an estimated value ˆV (X) to every state, X. On the i-th\n",
      "step of the process, suppose we are at state Xi (that is, our input on the i-th\n",
      "step is Xi), and that the estimated value of state Xi on the i-th step is ˆVi(Xi).\n",
      "We then select that action a that maximizes the estimated value of the predicted\n",
      "subsequent state. Suppose this subsequent state having the highest estimated\n",
      "value is X′\n",
      "i. Then we update the estimated value, ˆVi(Xi), of state Xi as follows:\n",
      "ˆVi(X) = (1 − ci) ˆVi−1(X) + ci\n",
      "�\n",
      "ri + γ ˆVi−1(X′\n",
      "i)\n",
      "�\n",
      "if X = Xi,\n",
      "= ˆVi−1(X)\n",
      "otherwise.\n",
      "We see that this adjustment moves the value of ˆVi(Xi) an increment (depend-\n",
      "ing on ci) closer to\n",
      "�\n",
      "ri + γ ˆVi(X′\n",
      "i)\n",
      "�\n",
      ". Assuming that ˆVi(X′\n",
      "i) is a good estimate for\n",
      "Vi(X′\n",
      "i), then this adjustment helps to make the two estimates more consistent.\n",
      "Providing that 0 < ci < 1 and that we visit each state inﬁnitely often, this\n",
      "process of value iteration will converge to the optimal values.\n",
      "Discuss synchronous dynamic\n",
      "programming, asynchronous\n",
      "dynamic programming, and policy\n",
      "iteration.\n",
      "11.4\n",
      "Q-Learning\n",
      "Watkins [Watkins, 1989] has proposed a technique that he calls incremental\n",
      "dynamic programming. Let a; π stand for the policy that chooses action a once,\n",
      "and thereafter chooses actions according to policy π. We deﬁne:\n",
      "Qπ(X, a) = V a;π(X)\n",
      "148\n",
      "CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Then the optimal value from state X is given by:\n",
      "V π∗(X) = max\n",
      "a\n",
      "Qπ∗(X, a)\n",
      "This equation holds only for an optimal policy, π∗. The optimal policy is given\n",
      "by:\n",
      "π∗(X) = arg max\n",
      "a\n",
      "Qπ∗(X, a)\n",
      "Note that if an action a makes Qπ(X, a) larger than V π(X), then we can improve\n",
      "π by changing it so that π(X) = a. Making such a change is the basis for a\n",
      "powerful learning rule that we shall describe shortly.\n",
      "Suppose action a in state X leads to state X′. Then using the deﬁnitions of\n",
      "Q and V , it is easy to show that:\n",
      "Qπ(X, a) = r(X, a) + γE[V π(X′)]\n",
      "where r(X, a) is the average value of the immediate reward received when we\n",
      "execute action a in state X. For an optimal policy (and no others), we have\n",
      "another version of the optimality equation in terms of Q values:\n",
      "Qπ∗(X, a) = max\n",
      "a\n",
      "�\n",
      "r(X, a) + γE\n",
      "�\n",
      "Qπ∗(X′, a)\n",
      "��\n",
      "for all actions, a, and states, X. Now, if we had the optimal Q values (for all\n",
      "a and X), then we could implement an optimal policy simply by selecting that\n",
      "action that maximized r(X, a) + γE\n",
      "�\n",
      "Qπ∗(X′, a)\n",
      "�\n",
      ".\n",
      "That is,\n",
      "π∗(X) = arg max\n",
      "a\n",
      "�\n",
      "r(X, a) + γE\n",
      "�\n",
      "Qπ∗(X′, a)\n",
      "��\n",
      "Watkins’ proposal amounts to a TD(0) method of learning the Q values.\n",
      "We quote (with minor notational changes) from [Watkins & Dayan, 1992, page\n",
      "281]:\n",
      "“In Q-Learning, the agent’s experience consists of a sequence of dis-\n",
      "tinct stages or episodes. In the i-th episode, the agent:\n",
      "• observes its current state Xi,\n",
      "• selects [using the method described below] and performs an\n",
      "action ai,\n",
      "• observes the subsequent state X′\n",
      "i,\n",
      "• receives an immediate reward ri, and\n",
      "11.4. Q-LEARNING\n",
      "149\n",
      "• adjusts its Qi−1 values using a learning factor ci, according to:\n",
      "Qi(X, a) = (1 − ci)Qi−1(X, a) + ci[ri + γVi−1(X′\n",
      "i)]\n",
      "if X = Xi and a = ai,\n",
      "= Qi−1(X, a)\n",
      "otherwise,\n",
      "where\n",
      "Vi−1(X′) = max\n",
      "b\n",
      "[Qi−1(X′, b)]\n",
      "is the best the agent thinks it can do from state X′. . . . The\n",
      "initial Q values, Q0(X, a), for all states and actions are assumed\n",
      "given.”\n",
      "Using the current Q values, Qi(X, a), the agent always selects that action\n",
      "that maximizes Qi(X, a).\n",
      "Note that only the Q value corresponding to the\n",
      "state just exited and the action just taken is adjusted. And that Q value is\n",
      "adjusted so that it is closer (by an amount determined by ci) to the sum of\n",
      "the immediate reward plus the discounted maximum (over all actions) of the Q\n",
      "values of the state just entered. If we imagine the Q values to be predictions of\n",
      "ultimate (inﬁnite horizon) total reward, then the learning procedure described\n",
      "above is exactly a TD(0) method of learning how to predict these Q values.\n",
      "Q learning strengthens the usual TD methods, however, because TD (applied\n",
      "to reinforcement problems using value iteration) requires a one-step lookahead,\n",
      "using a model of the eﬀects of actions, whereas Q learning does not.\n",
      "A convenient notation (proposed by [Schwartz, 1993]) for representing the\n",
      "change in Q value is:\n",
      "Q(X, a)\n",
      "β\n",
      "←− r + γV (X′)\n",
      "where Q(X, a) is the new Q value for input X and action a, r is the immediate\n",
      "reward when action a is taken in response to input X, V (X′) is the maximum\n",
      "(over all actions) of the Q value of the state next reached when action a is taken\n",
      "from state X, and β is the fraction of the way toward which the new Q value,\n",
      "Q(X, a), is adjusted to equal r + γV (X′).\n",
      "Watkins and Dayan [Watkins & Dayan, 1992] prove that, under certain con-\n",
      "ditions, the Q values computed by this learning procedure converge to optimal\n",
      "ones (that is, to ones on which an optimal policy can be based).\n",
      "We deﬁne ni(X, a) as the index (episode number) of the i-th time that action\n",
      "a is tried in state X. Then, we have:\n",
      "150\n",
      "CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Theorem 11.1 (Watkins and Dayan) For Markov problems with states {X}\n",
      "and actions {a}, and given bounded rewards |rn| ≤ R, learning rates 0 ≤ cn < 1,\n",
      "and\n",
      "∞\n",
      "�\n",
      "i=0\n",
      "cni(X,a) = ∞,\n",
      "∞\n",
      "�\n",
      "i=0\n",
      "�\n",
      "cni(X,a)\n",
      "�2 < ∞\n",
      "for all X and a, then\n",
      "Qn(X, a) → Q∗\n",
      "n(X, a) as n → ∞, for all X and a, with probability 1, where\n",
      "Q∗\n",
      "n(X, a) corresponds to the Q values of an optimal policy.\n",
      "Again, we quote from [Watkins & Dayan, 1992, page 281]:\n",
      "“The most important condition implicit in the convergence theorem\n",
      ". . . is that the sequence of episodes that forms the basis of learning\n",
      "must include an inﬁnite number of episodes for each starting state\n",
      "and action. This may be considered a strong condition on the way\n",
      "states and actions are selected—however, under the stochastic con-\n",
      "ditions of the theorem, no method could be guaranteed to ﬁnd an\n",
      "optimal policy under weaker conditions. Note, however, that the\n",
      "episodes need not form a continuous sequence—that is the X′ of one\n",
      "episode need not be the X of the next episode.”\n",
      "The relationships among Q learning, dynamic programming, and control\n",
      "are very well described in [Barto, Bradtke, & Singh, 1994]. Q learning is best\n",
      "thought of as a stochastic approximation method for calculating the Q values.\n",
      "Although the deﬁnition of the optimal Q values for any state depends recursively\n",
      "on expected values of the Q values for subsequent states (and on the expected\n",
      "values of rewards), no expected values are explicitly computed by the procedure.\n",
      "Instead, these values are approximated by iterative sampling using the actual\n",
      "stochastic mechanism that produces successor states.\n",
      "11.5\n",
      "Discussion, Limitations, and Extensions of\n",
      "Q-Learning\n",
      "11.5.1\n",
      "An Illustrative Example\n",
      "The Q-learning procedure requires that we maintain a table of Q(X, a) values\n",
      "for all state-action pairs. In the grid world that we described earlier, such a\n",
      "table would not be excessively large. We might start with random entries in the\n",
      "table; a portion of such an intial table might be as follows:\n",
      "11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING151\n",
      "X\n",
      "a\n",
      "Q(X, a)\n",
      "r(X, a)\n",
      "(2,3)\n",
      "w\n",
      "7\n",
      "0\n",
      "(2,3)\n",
      "n\n",
      "4\n",
      "0\n",
      "(2,3)\n",
      "e\n",
      "3\n",
      "0\n",
      "(2,3)\n",
      "s\n",
      "6\n",
      "0\n",
      "(1,3)\n",
      "w\n",
      "4\n",
      "-1\n",
      "(1,3)\n",
      "n\n",
      "5\n",
      "0\n",
      "(1,3)\n",
      "e\n",
      "2\n",
      "0\n",
      "(1,3)\n",
      "s\n",
      "4\n",
      "0\n",
      "Suppose the robot is in cell (2,3). The maximum Q value occurs for a = w, so the\n",
      "robot moves west to cell (1,3)—receiving no immediate reward. The maximum\n",
      "Q value in cell (1,3) is 5, and the learning mechanism attempts to make the\n",
      "value of Q((2, 3), w) closer to the discounted value of 5 plus the immediate\n",
      "reward (which was 0 in this case). With a learning rate parameter c = 0.5\n",
      "and γ = 0.9, the Q value of Q((2, 3), w) is adjusted from 7 to 5.75. No other\n",
      "changes are made to the table at this episode. The reader might try this learning\n",
      "procedure on the grid world with a simple computer program. Notice that an\n",
      "optimal policy might not be discovered if some cells are not visited nor some\n",
      "actions not tried frequently enough.\n",
      "The learning problem faced by the agent is to associate speciﬁc actions with\n",
      "speciﬁc input patterns. Q learning gradually reinforces those actions that con-\n",
      "tribute to positive rewards by increasing the associated Q values. Typically, as\n",
      "in this example, rewards occur somewhat after the actions that lead to them—\n",
      "hence the phrase delayed-reinforcement learning. One can imagine that better\n",
      "and better approximations to the optimal Q values gradually propagate back\n",
      "from states producing rewards toward all of the other states that the agent fre-\n",
      "quently visits. With random Q values to begin, the agent’s actions amount to a\n",
      "random walk through its space of states. Only when this random walk happens\n",
      "to stumble into rewarding states does Q learning begin to produce Q values\n",
      "that are useful, and, even then, the Q values have to work their way outward\n",
      "from these rewarding states. The general problem of associating rewards with\n",
      "state-action pairs is called the temporal credit assignment problem—how should\n",
      "credit for a reward be apportioned to the actions leading up to it? Q learning is,\n",
      "to date, the most successful technique for temporal credit assignment, although\n",
      "a related method, called the bucket brigade algorithm, has been proposed by\n",
      "[Holland, 1986].\n",
      "Learning problems similar to that faced by the agent in our grid world have\n",
      "been thoroughly studied by Sutton who has proposed an architecture, called\n",
      "DYNA, for solving them [Sutton, 1990]. DYNA combines reinforcement learning\n",
      "with planning. Sutton characterizes planning as learning in a simulated world\n",
      "that models the world that the agent inhabits. The agent’s model of the world\n",
      "is obtained by Q learning in its actual world, and planning is accomplished by\n",
      "Q learning in its model of the world.\n",
      "We should note that the learning problem faced by our grid-world robot\n",
      "152\n",
      "CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "could be modiﬁed to have several places in the grid that give positive rewards.\n",
      "This possibility presents an interesting way to generalize the classical notion of\n",
      "a “goal” in AI planning systems—even in those that do no learning. Instead of\n",
      "representing a goal as a condition to be achieved, we represent a “goal struc-\n",
      "ture” as a set of rewards to be given for achieving various conditions. Then,\n",
      "the generalized “goal” becomes maximizing discounted future reward instead of\n",
      "simply achieving some particular condition. This generalization can be made to\n",
      "encompass so-called goals of maintenance and goals of avoidance. The exam-\n",
      "ple presented above included avoiding bumping into the grid-world boundary.\n",
      "A goal of maintenance, of a particular state, could be expressed in terms of a\n",
      "reward that was earned whenever the agent was in that state and performed an\n",
      "action that transitioned back to that state in one step.\n",
      "11.5.2\n",
      "Using Random Actions\n",
      "When the next pattern presentation in a sequence of patterns is the one caused\n",
      "by the agent’s own action in response to the last pattern, we have what is called\n",
      "an on-line learning method. In Watkins and Dayan’s terminology, in on-line\n",
      "learning the episodes form a continous sequence. As already mentioned, the\n",
      "convergence theorem for Q learning does not require on-line learning; indeed,\n",
      "special precautions must be taken to ensure that on-line learning meets the\n",
      "conditions of the theorem.\n",
      "If on-line learning discovers some good paths to\n",
      "rewards, the agent may ﬁxate on these and never discover a policy that leads\n",
      "to a possibly greater long-term reward. In reinforcement learning phraseology,\n",
      "this problem is referred to as the problem of exploitation (of already learned\n",
      "behavior) versus exploration (of possibly better behavior).\n",
      "One way to force exploration is to perform occasional random actions (in-\n",
      "stead of that single action prescribed by the current Q values). For example,\n",
      "in the grid-world problem, one could imagine selecting an action randomly ac-\n",
      "cording to a probability distribution over the actions (n, e, s, and w).\n",
      "This\n",
      "distribution, in turn, could depend on the Q values. For example, we might\n",
      "ﬁrst ﬁnd that action prescribed by the Q values and then choose that action\n",
      "with probability 1/2, choose the two orthogonal actions with probability 3/16\n",
      "each, and choose the opposite action with probability 1/8. This policy might be\n",
      "modiﬁed by “simulated annealing” which would gradually increase the probabil-\n",
      "ity of the action prescribed by the Q values more and more as time goes on. This\n",
      "strategy would favor exploration at the beginning of learning and exploitation\n",
      "later.\n",
      "Other methods, also, have been proposed for dealing with exploration, in-\n",
      "cluding making unvisited states intrinsically rewarding and using an “interval\n",
      "estimate,” which is related to the uncertainty in the estimate of a state’s value\n",
      "[Kaelbling, 1993].\n",
      "11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING153\n",
      "11.5.3\n",
      "Generalizing Over Inputs\n",
      "For large problems it would be impractical to maintain a table like that used\n",
      "in our grid-world example. Various researchers have suggested mechanisms for\n",
      "computing Q values, given pattern inputs and actions. One method that sug-\n",
      "gests itself is to use a neural network. For example, consider the simple linear\n",
      "machine shown in Fig. 11.4.\n",
      "X\n",
      ". . .\n",
      ". . .\n",
      "�\n",
      "�\n",
      "�\n",
      "trainable weights\n",
      "�\n",
      "Wi\n",
      "R dot product units\n",
      "Q(ai, X) = X . Wi\n",
      "Q(a1, X)\n",
      "Q(a2, X)\n",
      "Q(aR, X)\n",
      "Figure 11.4: A Net that Computes Q Values\n",
      "Such a neural net could be used by an agent that has R actions to select\n",
      "from. The Q values (as a function of the input pattern X and the action ai) are\n",
      "computed as dot products of weight vectors (one for each action) and the input\n",
      "vector. Weight adjustments are made according to a TD(0) procedure to bring\n",
      "the Q value for the action last selected closer to the sum of the immediate reward\n",
      "(if any) and the (discounted) maximum Q value for the next input pattern.\n",
      "If the optimum Q values for the problem (whatever they might be) are more\n",
      "complex than those that can be computed by a linear machine, a layered neural\n",
      "network might be used. Sigmoid units in the ﬁnal layer would compute Q values\n",
      "in the range 0 to 1. The TD(0) method for updating Q values would then have to\n",
      "be combined with a multi-layer weight-changing rule, such as backpropagation.\n",
      "Networks of this sort are able to aggregate diﬀerent input vectors into regions\n",
      "for which the same action should be performed. This kind of aggregation is an\n",
      "example of what has been called structural credit assignment. Combining TD(λ)\n",
      "and backpropagation is a method for dealing with both the temporal and the\n",
      "structural credit assignment problems.\n",
      "154\n",
      "CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Interesting examples of delayed-reinforcement training of simulated and\n",
      "actual robots requiring structural credit assignment have been reported by\n",
      "[Lin, 1992, Mahadevan & Connell, 1992].\n",
      "11.5.4\n",
      "Partially Observable States\n",
      "So far, we have identiﬁed the input vector, X, with the actual state of the envi-\n",
      "ronment. When the input vector results from an agent’s perceptual apparatus\n",
      "(as we assume it does), there is no reason to suppose that it uniquely identiﬁes\n",
      "the environmental state. Because of inevitable perceptual limitations, several\n",
      "diﬀerent environmental states might give rise to the same input vector. This\n",
      "phenomenon has been referred to as perceptual aliasing. With perceptual alias-\n",
      "ing, we can no longer guarantee that Q learning will result in even useful action\n",
      "policies, let alone optimal ones. Several researchers have attempted to deal with\n",
      "this problem using a variety of methods including attempting to model “hid-\n",
      "den” states by using internal memory [Lin, 1993]. That is, if some aspect of\n",
      "the environment cannot be sensed currently, perhaps it was sensed once and\n",
      "can be remembered by the agent. When such is the case, we no longer have a\n",
      "Markov problem; that is, the next X vector, given any action, may depend on\n",
      "a sequence of previous ones rather than just the immediately preceding one. It\n",
      "might be possible to reinstate a Markov framework (over the X’s) if X includes\n",
      "not only current sensory precepts but information from the agent’s memory.\n",
      "11.5.5\n",
      "Scaling Problems\n",
      "Several diﬃculties have so far prohibited wide application of reinforcement learn-\n",
      "ing to large problems. (The TD-gammon program, mentioned in the last chap-\n",
      "ter, is probably unique in terms of success on a high-dimensional problem.)\n",
      "We have already touched on some diﬃculties; these and others are summarized\n",
      "below with references to attempts to overcome them.\n",
      "a. Exploration versus exploitation.\n",
      "• use random actions\n",
      "• favor states not visited recently\n",
      "• separate the learning phase from the use phase\n",
      "• employ a teacher to guide exploration\n",
      "b. Slow time to convergence\n",
      "• combine learning with prior knowledge; use estimates of Q values\n",
      "(rather than random values) initially\n",
      "• use a hierarchy of actions; learn primitive actions ﬁrst and freeze the\n",
      "useful sequences into macros and then learn how to use the macros\n",
      "11.6. BIBLIOGRAPHICAL AND HISTORICAL REMARKS\n",
      "155\n",
      "• employ a teacher; use graded “lessons”—starting near the rewards\n",
      "and then backing away, and use examples of good behavior [Lin, 1992]\n",
      "• use more eﬃcient computations; e.g. do several updates per episode\n",
      "[Moore & Atkeson, 1993]\n",
      "c. Large state spaces\n",
      "• use hand-coded features\n",
      "• use neural networks\n",
      "• use nearest-neighbor methods [Moore, 1990]\n",
      "d. Temporal discounting problems. Using small γ can make the learner too\n",
      "greedy for present rewards and indiﬀerent to the future; but using large γ\n",
      "slows down learning.\n",
      "• use a learning method based on average rewards [Schwartz, 1993]\n",
      "e. No “transfer” of learning . What is learned depends on the reward struc-\n",
      "ture; if the rewards change, learning has to start over.\n",
      "• Separate the learning into two parts: learn an “action model” which\n",
      "predicts how actions change states (and is constant over all prob-\n",
      "lems), and then learn the “values” of states by reinforcement learn-\n",
      "ing for each diﬀerent set of rewards. Sometimes the reinforcement\n",
      "learning part can be replaced by a “planner” that uses the action\n",
      "model to produce plans to achieve goals.\n",
      "Also see other articles in the special issue on reinforcement learning: Machine\n",
      "Learning, 8, May, 1992.\n",
      "11.6\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "156\n",
      "CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\n",
      "Chapter 12\n",
      "Explanation-Based\n",
      "Learning\n",
      "12.1\n",
      "Deductive Learning\n",
      "In the learning methods studied so far, typically the training set does not ex-\n",
      "haust the version space. Using logical terminology, we could say that the classi-\n",
      "ﬁer’s output does not logically follow from the training set. In this sense, these\n",
      "methods are inductive. In logic, a deductive system is one whose conclusions\n",
      "logically follow from a set of input facts, if the system is sound.1\n",
      "To contrast inductive with deductive systems in a logical setting, suppose\n",
      "we have a set of facts (the training set) that includes the following formulas:\n",
      "{Round(Obj1), Round(Obj2), Round(Obj3), Round(Obj4),\n",
      "Ball(Obj1), Ball(Obj2), Ball(Obj3), Ball(Obj4)}\n",
      "A learning system that forms the conclusion (∀x)[Ball(x) ⊃ Round(x)] is in-\n",
      "ductive.\n",
      "This conclusion may be useful (if there are no facts of the form\n",
      "Ball(σ) ∧ ¬Round(σ)), but it does not logically follow from the facts. On the\n",
      "other hand, if we had the facts Green(Obj5) and Green(Obj5) ⊃ Round(Obj5),\n",
      "then we could logically conclude Round(Obj5). Making this conclusion and sav-\n",
      "ing it is an instance of deductive learning—a topic we study in this chapter.\n",
      "Suppose that some logical proposition, φ, logically follows from some set of\n",
      "facts, ∆. Under what circumstances might we say that the process of deducing\n",
      "φ from ∆ results in our learning φ? In a sense, we implicitly knew φ all along,\n",
      "since it was inherent in knowing ∆. Yet, φ might not be obvious given ∆, and\n",
      "1Logical reasoning systems that are not sound, for example those using non-monotonic\n",
      "reasoning, themselves might produce inductive conclusions that do not logically follow from\n",
      "the input facts.\n",
      "157\n",
      "158\n",
      "CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "the deduction process to establish φ might have been arduous. Rather than have\n",
      "to deduce φ again, we might want to save it, perhaps along with its deduction,\n",
      "in case it is needed later. Shouldn’t that process count as learning? Dietterich\n",
      "[Dietterich, 1990] has called this type of learning speed-up learning.\n",
      "Strictly speaking, speed-up learning does not result in a system being able to\n",
      "make decisions that, in principle, could not have been made before the learning\n",
      "took place. Speed-up learning simply makes it possible to make those decisions\n",
      "more eﬃciently.\n",
      "But, in practice, this type of learning might make possible\n",
      "certain decisions that might otherwise have been infeasible.\n",
      "To take an extreme case, a chess player can be said to learn chess even though\n",
      "optimal play is inherent in the rules of chess. On the surface, there seems to be\n",
      "no real diﬀerence between the experience-based hypotheses that a chess player\n",
      "makes about what constitutes good play and the kind of learning we have been\n",
      "studying so far.\n",
      "As another example, suppose we are given some theorems about geometry\n",
      "and are asked to prove that the sum of the angles of a right triangle is 180\n",
      "degrees. Let us further suppose that the proof we constructed did not depend\n",
      "on the given triangle being a right triangle; in that case we can learn a more\n",
      "general fact. The learning technique that we are going to study next is related\n",
      "to this example.\n",
      "It is called explanation-based learning (EBL). EBL can be\n",
      "thought of as a process in which implicit knowledge is converted into explicit\n",
      "knowledge.\n",
      "In EBL, we specialize parts of a domain theory to explain a particular ex-\n",
      "ample, then we generalize the explanation to produce another element of the\n",
      "domain theory that will be useful on similar examples. This process is illustrated\n",
      "in Fig. 12.1.\n",
      "12.2\n",
      "Domain Theories\n",
      "Two types of information were present in the inductive methods we have studied:\n",
      "the information inherent in the training samples and the information about the\n",
      "domain that is implied by the “bias” (for example, the hypothesis set from which\n",
      "we choose functions). The learning methods are successful only if the hypothesis\n",
      "set is appropriate for the problem. Typically, the smaller the hypothesis set (that\n",
      "is, the more a priori information we have about the function being sought), the\n",
      "less dependent we are on information being supplied by a training set (that\n",
      "is, fewer samples). A priori information about a problem can be expressed in\n",
      "several ways. The methods we have studied so far restrict the hypotheses in a\n",
      "rather direct way. A less direct method involves making assertions in a logical\n",
      "language about the property we are trying to learn. A set of such assertions is\n",
      "usually called a “domain theory.”\n",
      "Suppose, for example, that we wanted to classify people according to whether\n",
      "or not they were good credit risks. We might represent a person by a set of\n",
      "properties (income, marital status, type of employment, etc.), assemble such\n",
      "12.3. AN EXAMPLE\n",
      "159\n",
      "Domain\n",
      "Theory\n",
      "Example\n",
      "(X is P)\n",
      "Prove: X is P\n",
      "specialize\n",
      "Explanation\n",
      "(Proof)\n",
      "generalize\n",
      "A New Domain Rule:\n",
      "Things \"like\" X are P\n",
      "Y is like X\n",
      "Complex Proof\n",
      "Process\n",
      "Trivial  Proof\n",
      "Y is P\n",
      "Figure 12.1: The EBL Process\n",
      "data about people who are known to be good and bad credit risks and train a\n",
      "classiﬁer to make decisions. Or, we might go to a loan oﬃcer of a bank, ask him\n",
      "or her what sorts of things s/he looks for in making a decision about a loan,\n",
      "encode this knowledge into a set of rules for an expert system, and then use\n",
      "the expert system to make decisions. The knowledge used by the loan oﬃcer\n",
      "might have originated as a set of “policies” (the domain theory), but perhaps the\n",
      "application of these policies were specialized and made more eﬃcient through\n",
      "experience with the special cases of loans made in his or her district.\n",
      "12.3\n",
      "An Example\n",
      "To make our discussion more concrete, let’s consider the following fanciful exam-\n",
      "ple. We want to ﬁnd a way to classify robots as “robust” or not. The attributes\n",
      "that we use to represent a robot might include some that are relevant to this\n",
      "decision and some that are not.\n",
      "160\n",
      "CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "Suppose we have a domain theory of logical sentences that taken together,\n",
      "help to deﬁne whether or not a robot can be classiﬁed as robust. (The same\n",
      "domain theory may be useful for several other purposes also, but among other\n",
      "things, it describes the concept “robust.”)\n",
      "In this example, let’s suppose that our domain theory includes the sentences:\n",
      "Fixes(u, u) ⊃ Robust(u)\n",
      "(An individual that can ﬁx itself is robust.)\n",
      "Sees(x, y) ∧ Habile(x) ⊃ Fixes(x, y)\n",
      "(A habile individual that can see another entity can ﬁx that entity.)\n",
      "Robot(w) ⊃ Sees(w, w)\n",
      "(All robots can see themselves.)\n",
      "R2D2(x) ⊃ Habile(x)\n",
      "(R2D2-class individuals are habile.)\n",
      "C3PO(x) ⊃ Habile(x)\n",
      "(C3PO-class individuals are habile.)\n",
      ". . .\n",
      "(By convention, variables are assumed to be universally quantiﬁed.) We could\n",
      "use theorem-proving methods operating on this domain theory to conclude\n",
      "whether certain robots are robust. These methods might be computationally\n",
      "quite expensive because extensive search may have to be performed to derive a\n",
      "conclusion. But after having found a proof for some particular robot, we might\n",
      "be able to derive some new sentence whose use allows a much faster conclusion.\n",
      "We next show how such a new rule might be derived in this example. Suppose\n",
      "we are given a number of facts about Num5, such as:\n",
      "Robot(Num5)\n",
      "R2D2(Num5)\n",
      "Age(Num5, 5)\n",
      "Manufacturer(Num5, GR)\n",
      ". . .\n",
      "12.3. AN EXAMPLE\n",
      "161\n",
      "Fixes(u, u) => Robust(u)\n",
      "Robust(Num5)\n",
      "Fixes(Num5, Num5)\n",
      "Sees(Num5,Num5)\n",
      "Habile(Num5)\n",
      "Sees(x,y) & Habile(x)\n",
      "              => Fixes(x,y)\n",
      "Robot(w)\n",
      "     => Sees(w,w)\n",
      "Robot(Num5)\n",
      "R2D2(x)\n",
      "         => Habile(x)\n",
      "R2D2(Num5)\n",
      "Figure 12.2: A Proof Tree\n",
      "We are also told that Robust(Num5) is true, but we nevertheless attempt to\n",
      "ﬁnd a proof of that assertion using these facts about Num5 and the domain\n",
      "theory. The facts about Num5 correspond to the features that we might use\n",
      "to represent Num5. In this example, not all of them are relevant to a decision\n",
      "about Robust(Num5). The relevant ones are those used or needed in proving\n",
      "Robust(Num5) using the domain theory. The proof tree in Fig. 12.2 is one that\n",
      "a typical theorem-proving system might produce.\n",
      "In the language of EBL, this proof is an explanation for the fact\n",
      "Robust(Num5). We see from this explanation that the only facts about Num5\n",
      "that were used were Robot(Num5) and R2D2(Num5). In fact, we could con-\n",
      "struct the following rule from this explanation:\n",
      "Robot(Num5) ∧ R2D2(Num5) ⊃ Robust(Num5)\n",
      "The explanation has allowed us to prune some attributes about Num5 that are\n",
      "irrelevant (at least for deciding Robust(Num5)). This type of pruning is the ﬁrst\n",
      "sense in which an explanation is used to generalize the classiﬁcation problem.\n",
      "([DeJong & Mooney, 1986] call this aspect of explanation-based learning feature\n",
      "elimination.) But the rule we extracted from the explanation applies only to\n",
      "Num5. There might be little value in learning that rule since it is so speciﬁc.\n",
      "Can it be generalized so that it can be applied to other individuals as well?\n",
      "162\n",
      "CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "Examination of the proof shows that the same proof structure, using the\n",
      "same sentences from the domain theory, could be used independently of whether\n",
      "we are talking about Num5 or some other individual. We can generalize the\n",
      "proof by a process that replaces constants in the tip nodes of the proof tree\n",
      "with variables and works upward—using uniﬁcation to constrain the values of\n",
      "variables as needed to obtain a proof.\n",
      "In this example, we replace Robot(Num5) by Robot(r) and R2D2(Num5)\n",
      "by R2D2(s) and redo the proof—using the explanation proof as a template.\n",
      "Note that we use diﬀerent values for the two diﬀerent occurrences of Num5 at\n",
      "the tip nodes. Doing so sometimes results in more general, but nevertheless\n",
      "valid rules. We now apply the rules used in the proof in the forward direction,\n",
      "keeping track of the substitutions imposed by the most general uniﬁers used in\n",
      "the proof. (Note that we always substitute terms that are already in the tree for\n",
      "variables in rules.) This process results in the generalized proof tree shown in\n",
      "Fig. 12.3. Note that the occurrence of Sees(r, r) as a node in the tree forces the\n",
      "uniﬁcation of x with y in the domain rule, Sees(x, y)∧Habile(y) ⊃ Fixes(x, y).\n",
      "The substitutions are then applied to the variables in the tip nodes and the root\n",
      "node to yield the general rule: Robot(r) ∧ R2D2(r) ⊃ Robust(r).\n",
      "This rule is the end result of EBL for this example.\n",
      "The process\n",
      "by which Num5 in this example was generalized to a variable is what\n",
      "[DeJong & Mooney, 1986] call identity elimination (the precise identity of Num5\n",
      "turned out to be irrelevant). (The generalization process described in this ex-\n",
      "ample is based on that of [DeJong & Mooney, 1986] and diﬀers from that of\n",
      "[Mitchell, et al., 1986]. It is also similar to that used in [Fikes, et al., 1972].)\n",
      "Clearly, under certain assumptions, this general rule is more easily used to con-\n",
      "clude Robust about an individual than the original proof process was.\n",
      "It is important to note that we could have derived the general rule from the\n",
      "domain theory without using the example. (In the literature, doing so is called\n",
      "static analysis [Etzioni, 1991].) In fact, the example told us nothing new other\n",
      "than what it told us about Num5. The sole role of the example in this instance\n",
      "of EBL was to provide a template for a proof to help guide the generalization\n",
      "process. Basing the generalization process on examples helps to insure that we\n",
      "learn rules matched to the distribution of problems that occur.\n",
      "There are a number of qualiﬁcations and elaborations about EBL that need\n",
      "to be mentioned.\n",
      "12.4\n",
      "Evaluable Predicates\n",
      "The domain theory includes a number of predicates other than the one occuring\n",
      "in the formula we are trying to prove and other than those that might custom-\n",
      "arily be used to describe an individual. One might note, for example, that if we\n",
      "used Habile(Num5) to describe Num5, the proof would have been shorter. Why\n",
      "didn’t we? The situation is analogous to that of using a data base augmented\n",
      "by logical rules. In the latter application, the formulas in the actual data base\n",
      "12.4. EVALUABLE PREDICATES\n",
      "163\n",
      "Robust(r)\n",
      "Fixes(r, r)\n",
      "Sees(r,r)\n",
      "Habile(s)\n",
      "Robot(r)\n",
      "R2D2(s)\n",
      "{r/w}\n",
      "{s/x}\n",
      "{r/x, r/y, r/s}\n",
      "{r/u}\n",
      "Robot(w)\n",
      "     => Sees(w,w)\n",
      "R2D2(x)\n",
      "         => Habile(x)\n",
      "Sees(x,y) & Habile(x)\n",
      "              => Fixes(x,y)\n",
      "Fixes(u, u) => Robust(u)\n",
      "becomes R2D2(r) after\n",
      "applying {r/s}\n",
      "Figure 12.3: A Generalized Proof Tree\n",
      "are “extensional,” and those in the logical rules are “intensional.” This usage\n",
      "reﬂects the fact that the predicates in the data base part are deﬁned by their\n",
      "extension—we explicitly list all the tuples sastisfying a relation.\n",
      "The logical\n",
      "rules serve to connect the data base predicates with higher level abstractions\n",
      "that are described (if not deﬁned) by the rules. We typically cannot look up\n",
      "the truth values of formulas containing these intensional predicates; they have\n",
      "to be derived using the rules and the database.\n",
      "The EBL process assumes something similar. The domain theory is useful\n",
      "for connecting formulas that we might want to prove with those whose truth\n",
      "values can be “looked up” or otherwise evaluated. In the EBL literature, such\n",
      "formulas satisfy what is called the operationality criterion.\n",
      "Perhaps another\n",
      "analogy might be to neural networks. The evaluable predicates correspond to\n",
      "the components of the input pattern vector; the predicates in the domain theory\n",
      "correspond to the hidden units. Finding the new rule corresponds to ﬁnding a\n",
      "simpler expression for the formula to be proved in terms only of the evaluable\n",
      "predicates.\n",
      "164\n",
      "CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "12.5\n",
      "More General Proofs\n",
      "Examining the domain theory for our example reveals that an alternative rule\n",
      "might have been:\n",
      "Robot(u) ∧ C3PO(u) ⊃ Robust(u).\n",
      "Such a rule might\n",
      "have resulted if we were given {C3PO(Num6), Robot(Num6), . . .} and proved\n",
      "Robust(Num6).\n",
      "After considering these two examples (Num5 and Num6),\n",
      "the question arises, do we want to generalize the two rules to something like:\n",
      "Robot(u)∧[C3PO(u)∨R2D2(u)] ⊃ Robust(u)? Doing so is an example of what\n",
      "[DeJong & Mooney, 1986] call structural generalization (via disjunctive augmen-\n",
      "tation ).\n",
      "Adding disjunctions for every alternative proof can soon become cumbersome\n",
      "and destroy any eﬃciency advantage of EBL. In our example, the eﬃciency\n",
      "might be retrieved if there were another evaluable predicate, say, Bionic(u) such\n",
      "that the domain theory also contained R2D2(x) ⊃ Bionic(x) and C3PO(x) ⊃\n",
      "Bionic(x). After seeing a number of similar examples, we might be willing to\n",
      "induce the formula Bionic(u) ⊃ [C3PO(u) ∨ R2D2(u)] in which case the rule\n",
      "with the disjunction could be replaced with Robot(u) ∧ Bionic(u) ⊃ Robust(u).\n",
      "12.6\n",
      "Utility of EBL\n",
      "It is well known in theorem proving that the complexity of ﬁnding a proof\n",
      "depends both on the number of formulas in the domain theory and on the depth\n",
      "of the shortest proof. Adding a new rule decreases the depth of the shortest\n",
      "proof but it also increases the number of formulas in the domain theory. In\n",
      "realistic applications, the added rules will be relevant for some tasks and not for\n",
      "others. Thus, it is unclear whether the overall utility of the new rules will turn\n",
      "out to be positive. EBL methods have been applied in several settings, usually\n",
      "with positive utility. (See [Minton, 1990] for an analysis).\n",
      "12.7\n",
      "Applications\n",
      "There have been several applications of EBL methods. We mention two here,\n",
      "namely the formation of macro-operators in automatic plan generation and\n",
      "learning how to control search.\n",
      "12.7.1\n",
      "Macro-Operators in Planning\n",
      "In automatic planning systems, eﬃciency can sometimes be enhanced by chain-\n",
      "ing together a sequence of operators into macro-operators. We show an exam-\n",
      "ple of a process for creating macro-operators based on techniques explored by\n",
      "[Fikes, et al., 1972].\n",
      "Referring to Fig. 12.4, consider the problem of ﬁnding a plan for a robot in\n",
      "room R1 to fetch a box, B1, by going to an adjacent room, R2, and pushing it\n",
      "12.7. APPLICATIONS\n",
      "165\n",
      "back to R1. The goal for the robot is INROOM(B1, R1), and the facts that\n",
      "are true in the initial state are listed in the ﬁgure.\n",
      "R1\n",
      "R2\n",
      "R3\n",
      "D1\n",
      "D2\n",
      "B1\n",
      "Initial State:\n",
      "INROOM(ROBOT, R1)\n",
      "INROOM(B1,R2)\n",
      "CONNECTS(D1,R1,R2)\n",
      "CONNECTS(D1,R2,R1)\n",
      ". . .\n",
      "Figure 12.4: Initial State of a Robot Problem\n",
      "We will construct the plan from a set of STRIPS operators that include:\n",
      "GOTHRU(d, r1, r2)\n",
      "Preconditions: INROOM(ROBOT, r1), CONNECTS(d, r1, r2)\n",
      "Delete list: INROOM(ROBOT, r1)\n",
      "Add list: INROOM(ROBOT, r2)\n",
      "PUSHTHRU(b, d, r1, r2)\n",
      "Preconditions: INROOM(ROBOT, r1), CONNECTS(d, r1, r2), INROOM(b, r1)\n",
      "Delete list: INROOM(ROBOT, r1), INROOM(b, r1)\n",
      "Add list: INROOM(ROBOT, r2), INROOM(b, r2)\n",
      "A backward-reasoning STRIPS system might produce the plan shown in\n",
      "Fig. 12.5. We show there the main goal and the subgoals along a solution path.\n",
      "(The conditions in each subgoal that are true in the initial state are shown\n",
      "underlined.) The preconditions for this plan, true in the initial state, are:\n",
      "INROOM(ROBOT, R1)\n",
      "166\n",
      "CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "CONNECTS(D1, R1, R2)\n",
      "CONNECTS(D1, R2, R1)\n",
      "INROOM(B1, R2)\n",
      "Saving this speciﬁc plan, valid only for the speciﬁc constants it mentions, would\n",
      "not be as useful as would be saving a more general one. We ﬁrst generalize\n",
      "these preconditions by substituting variables for constants. We then follow the\n",
      "structure of the speciﬁc plan to produce the generalized plan shown in Fig. 12.6\n",
      "that achieves INROOM(b1, r4). Note that the generalized plan does not require\n",
      "pushing the box back to the place where the robot started. The preconditions\n",
      "for the generalized plan are:\n",
      "INROOM(ROBOT, r1)\n",
      "CONNECTS(d1, r1, r2)\n",
      "CONNECTS(d2, r2, r4)\n",
      "INROOM(b, r4)\n",
      "INROOM(B1,R1)\n",
      "PUSHTHRU(B1,d,r1,R1)\n",
      "INROOM(ROBOT, r1),\n",
      "CONNECTS(d, r1, R1),\n",
      "INROOM(B1, r1)\n",
      "INROOM(ROBOT, R2),\n",
      "CONNECTS(D1, R2, R1),\n",
      "INROOM(B1, R2)\n",
      "{R2/r1,\n",
      "D1/d}\n",
      "GOTHRU(d2, r3, R2)\n",
      "INROOM(ROBOT, r3),\n",
      "CONNECTS(d2, r3, R2),\n",
      "CONNECTS(D1, R2, R1),\n",
      "INROOM(B1, R2)\n",
      "{R1/r3, D1/d2}\n",
      "INROOM(ROBOT, R1),\n",
      "CONNECTS(D1, R1, R2),\n",
      "CONNECTS(D1, R2, R1),\n",
      "INROOM(B1, R2)\n",
      "R1\n",
      "R2\n",
      "R3\n",
      "D1\n",
      "D2\n",
      "GOTHRU(D1,R1,R2)\n",
      "PUSHTHRU(B1,D1,R2,R1)\n",
      "B1\n",
      "PLAN:\n",
      "Figure 12.5: A Plan for the Robot Problem\n",
      "Another related technique that chains together sequences of operators to\n",
      "form more general ones is the chunking mechanism in Soar [Laird, et al., 1986].\n",
      "12.7. APPLICATIONS\n",
      "167\n",
      "INROOM(b1,r4)\n",
      "PUSHTHRU(b1,d2,r2,r4)\n",
      "INROOM(ROBOT, r2),\n",
      "CONNECTS(d1, r1, r2),\n",
      "CONNECTS(d2, r2, r4),\n",
      "INROOM(b1, r4)\n",
      "GOTHRU(d1, r1, r2)\n",
      "INROOM(ROBOT, r1),\n",
      "CONNECTS(d1, r1, r2),\n",
      "CONNECTS(d2, r2, r4),\n",
      "INROOM(b1, r4)\n",
      "Figure 12.6: A Generalized Plan\n",
      "12.7.2\n",
      "Learning Search Control Knowledge\n",
      "Besides their use in creating macro-operators, EBL methods can be used to\n",
      "improve the eﬃciency of planning in another way also. In his system called\n",
      "PRODIGY, Minton proposed using EBL to learn eﬀective ways to control\n",
      "search [Minton, 1988]. PRODIGY is a STRIPS-like system that solves planning\n",
      "problems in the blocks-world, in a simple mobile robot world, and in job-shop\n",
      "scheduling. PRODIGY has a domain theory involving both the domain of the\n",
      "problem and a simple (meta) theory about planning. Its meta theory includes\n",
      "statements about whether a control choice about a subgoal to work on, an oper-\n",
      "ator to apply, etc. either succeeds or fails. After producing a plan, it analyzes its\n",
      "successful and its unsuccessful choices and attempts to explain them in terms\n",
      "of its domain theory. Using an EBL-like process, it is able to produce useful\n",
      "control rules such as:\n",
      "168\n",
      "CHAPTER 12. EXPLANATION-BASED LEARNING\n",
      "IF (AND (CURRENT − NODE node)\n",
      "(CANDIDATE − GOAL node (ON x y))\n",
      "(CANDIDATE − GOAL node (ON y z)))\n",
      "THEN (PREFER GOAL (ON y z) TO (ON x y))\n",
      "PRODIGY keeps statistics on how often these learned rules are used, their\n",
      "savings (in time to ﬁnd plans), and their cost of application. It saves only the\n",
      "rules whose utility, thus measured, is judged to be high. Minton [Minton, 1990]\n",
      "has shown that there is an overall advantage of using these rules (as against not\n",
      "having any rules and as against hand-coded search control rules).\n",
      "12.8\n",
      "Bibliographical and Historical Remarks\n",
      "To be added.\n",
      "Bibliography\n",
      "[Acorn & Walden, 1992] Acorn, T., and Walden, S., “SMART: Support Man-\n",
      "agement Automated Reasoning Technology for COMPAQ Customer Ser-\n",
      "vice,” Proc. Fourth Annual Conf. on Innovative Applications of Artiﬁcial\n",
      "Intelligence, Menlo Park, CA: AAAI Press, 1992.\n",
      "[Aha, 1991] Aha, D., Kibler, D., and Albert, M., “Instance-Based Learning\n",
      "Algorithms,” Machine Learning, 6, 37-66, 1991.\n",
      "[Anderson & Bower, 1973] Anderson, J. R., and Bower, G. H., Human Asso-\n",
      "ciative Memory, Hillsdale, NJ: Erlbaum, 1973.\n",
      "[Anderson, 1958] Anderson, T. W., An Introduction to Multivariate Statistical\n",
      "Analysis, New York: John Wiley, 1958.\n",
      "[Barto, Bradtke, & Singh, 1994] Barto, A., Bradtke, S., and Singh, S., “Learn-\n",
      "ing to Act Using Real-Time Dynamic Programming,” to appear in Ar-\n",
      "tiﬁcial Intelligence, 1994.\n",
      "[Baum & Haussler, 1989] Baum, E, and Haussler, D., “What Size Net Gives\n",
      "Valid Generalization?” Neural Computation, 1, pp. 151-160, 1989.\n",
      "[Baum, 1994] Baum, E., “When Are k-Nearest Neighbor and Backpropagation\n",
      "Accurate for Feasible-Sized Sets of Examples?” in Hanson, S., Drastal,\n",
      "G., and Rivest, R., (eds.), Computational Learning Theory and Natural\n",
      "Learning Systems, Volume 1: Constraints and Prospects, pp. 415-442,\n",
      "Cambridge, MA: MIT Press, 1994.\n",
      "[Bellman, 1957] Bellman, R. E., Dynamic Programming, Princeton: Princeton\n",
      "University Press, 1957.\n",
      "[Blumer, et al., 1987] Blumer, A., et al., “Occam’s Razor,” Info. Process. Lett.,\n",
      "vol 24, pp. 377-80, 1987.\n",
      "[Blumer, et al., 1990] Blumer,\n",
      "A.,\n",
      "et al.,\n",
      "“Learnability and the Vapnik-\n",
      "Chervonenkis Dimension,” JACM, 1990.\n",
      "[Bollinger & Duﬃe, 1988] Bollinger, J., and Duﬃe, N., Computer Control of\n",
      "Machines and Processes, Reading, MA: Addison-Wesley, 1988.\n",
      "169\n",
      "170\n",
      "BIBLIOGRAPHY\n",
      "[Brain, et al., 1962] Brain, A. E., et al., “Graphical Data Processing Research\n",
      "Study and Experimental Investigation,” Report No. 8 (pp. 9-13) and No.\n",
      "9 (pp. 3-10), Contract DA 36-039 SC-78343, SRI International, Menlo\n",
      "Park, CA, June 1962 and September 1962.\n",
      "[Breiman, et al., 1984] Breiman, L., Friedman, J., Olshen, R., and Stone, C.,\n",
      "Classiﬁcation and Regression Trees, Monterey, CA: Wadsworth, 1984.\n",
      "[Brent, 1990] Brent, R. P., “Fast Training Algorithms for Multi-Layer Neural\n",
      "Nets,” Numerical Analysis Project Manuscript NA-90-03, Computer Sci-\n",
      "ence Department, Stanford University, Stanford, CA 94305, March 1990.\n",
      "[Bryson & Ho 1969] Bryson, A., and Ho, Y.-C., Applied Optimal Control, New\n",
      "York: Blaisdell.\n",
      "[Buchanan & Wilkins, 1993] Buchanan, B. and Wilkins, D., (eds.), Readings in\n",
      "Knowledge Acquisition and Learning, San Francisco: Morgan Kaufmann,\n",
      "1993.\n",
      "[Carbonell, 1983] Carbonell, J., “Learning by Analogy,” in Machine Learning:\n",
      "An Artiﬁcial Intelligence Approach, Michalski, R., Carbonell, J., and\n",
      "Mitchell, T., (eds.), San Francisco: Morgan Kaufmann, 1983.\n",
      "[Cheeseman, et al., 1988] Cheeseman, P., et al., “AutoClass: A Bayesian Clas-\n",
      "siﬁcation System,” Proc. Fifth Intl. Workshop on Machine Learning,\n",
      "Morgan Kaufmann, San Mateo, CA, 1988. Reprinted in Shavlik, J. and\n",
      "Dietterich, T., Readings in Machine Learning, Morgan Kaufmann, San\n",
      "Francisco, pp. 296-306, 1990.\n",
      "[Cover & Hart, 1967] Cover, T., and Hart, P., “Nearest Neighbor Pattern Clas-\n",
      "siﬁcation,” IEEE Trans. on Information Theory, 13, 21-27, 1967.\n",
      "[Cover, 1965] Cover, T., “Geometrical and Statistical Properties of Systems\n",
      "of Linear Inequalities with Applications in Pattern Recognition,” IEEE\n",
      "Trans. Elec. Comp., EC-14, 326-334, June, 1965.\n",
      "[Dasarathy, 1991] Dasarathy, B. V., Nearest Neighbor Pattern Classiﬁcation\n",
      "Techniques, IEEE Computer Society Press, 1991.\n",
      "[Dayan & Sejnowski, 1994] Dayan, P., and Sejnowski, T., “TD(λ) Converges\n",
      "with Probability 1,” Machine Learning, 14, pp. 295-301, 1994.\n",
      "[Dayan, 1992] Dayan, P., “The Convergence of TD(λ) for General λ,” Machine\n",
      "Learning, 8, 341-362, 1992.\n",
      "[DeJong & Mooney, 1986] DeJong, G., and Mooney, R., “Explanation-Based\n",
      "Learning: An Alternative View,” Machine Learning, 1:145-176, 1986.\n",
      "Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\n",
      "ing, San Francisco: Morgan Kaufmann, 1990, pp 452-467.\n",
      "BIBLIOGRAPHY\n",
      "171\n",
      "[Dietterich & Bakiri, 1991] Dietterich, T. G., and Bakiri, G., “Error-Correcting\n",
      "Output Codes:\n",
      "A General Method for Improving Multiclass Induc-\n",
      "tive Learning Programs,” Proc. Ninth Nat. Conf. on A.I., pp. 572-577,\n",
      "AAAI-91, MIT Press, 1991.\n",
      "[Dietterich, et al., 1990] Dietterich, T., Hild, H., and Bakiri, G., “A Compara-\n",
      "tive Study of ID3 and Backpropagation for English Text-to-Speech Map-\n",
      "ping,” Proc. Seventh Intl. Conf. Mach. Learning, Porter, B. and Mooney,\n",
      "R. (eds.), pp. 24-31, San Francisco: Morgan Kaufmann, 1990.\n",
      "[Dietterich, 1990] Dietterich, T., “Machine Learning,” Annu. Rev. Comput.\n",
      "Sci., 4:255-306, Palo Alto: Annual Reviews Inc., 1990.\n",
      "[Duda & Fossum, 1966] Duda, R. O., and Fossum, H., “Pattern Classiﬁcation\n",
      "by Iteratively Determined Linear and Piecewise Linear Discriminant\n",
      "Functions,” IEEE Trans. on Elect. Computers, vol. EC-15, pp. 220-232,\n",
      "April, 1966.\n",
      "[Duda & Hart, 1973] Duda, R. O., and Hart, P.E., Pattern Classiﬁcation and\n",
      "Scene Analysis, New York: Wiley, 1973.\n",
      "[Duda, 1966] Duda, R. O., “Training a Linear Machine on Mislabeled Patterns,”\n",
      "SRI Tech. Report prepared for ONR under Contract 3438(00), SRI In-\n",
      "ternational, Menlo Park, CA, April 1966.\n",
      "[Efron, 1982] Efron, B., The Jackknife, the Bootstrap and Other Resampling\n",
      "Plans, Philadelphia: SIAM, 1982.\n",
      "[Ehrenfeucht, et al., 1988] Ehrenfeucht, A., et al., “A General Lower Bound on\n",
      "the Number of Examples Needed for Learning,” in Proc. 1988 Workshop\n",
      "on Computational Learning Theory, pp. 110-120, San Francisco: Morgan\n",
      "Kaufmann, 1988.\n",
      "[Etzioni, 1991] Etzioni,\n",
      "O.,\n",
      "“STATIC:\n",
      "A\n",
      "Problem-Space\n",
      "Compiler\n",
      "for\n",
      "PRODIGY,” Proc. of Ninth National Conf. on Artiﬁcial Intelligence,\n",
      "pp. 533-540, Menlo Park: AAAI Press, 1991.\n",
      "[Etzioni, 1993] Etzioni, O., “A Structural Theory of Explanation-Based Learn-\n",
      "ing,” Artiﬁcial Intelligence, 60:1, pp. 93-139, March, 1993.\n",
      "[Evans & Fisher, 1992] Evans, B., and Fisher, D., Process Delay Analyses Using\n",
      "Decision-Tree Induction, Tech. Report CS92-06, Department of Com-\n",
      "puter Science, Vanderbilt University, TN, 1992.\n",
      "[Fahlman & Lebiere, 1990] Fahlman,\n",
      "S.,\n",
      "and Lebiere,\n",
      "C.,\n",
      "“The Cascade-\n",
      "Correlation Learning Architecture,” in Touretzky, D., (ed.), Advances in\n",
      "Neural Information Processing Systems, 2, pp. 524-532, San Francisco:\n",
      "Morgan Kaufmann, 1990.\n",
      "172\n",
      "BIBLIOGRAPHY\n",
      "[Fayyad, et al., 1993] Fayyad, U. M., Weir, N., and Djorgovski, S., “SKICAT:\n",
      "A Machine Learning System for Automated Cataloging of Large Scale\n",
      "Sky Surveys,” in Proc. Tenth Intl. Conf. on Machine Learning, pp. 112-\n",
      "119, San Francisco: Morgan Kaufmann, 1993. (For a longer version of\n",
      "this paper see: Fayyad, U. Djorgovski, G., and Weir, N., “Automating\n",
      "the Analysis and Cataloging of Sky Surveys,” in Fayyad, U., et al.(eds.),\n",
      "Advances in Knowledge Discovery and Data Mining, Chapter 19, pp.\n",
      "471ﬀ., Cambridge: The MIT Press, March, 1996.)\n",
      "[Feigenbaum, 1961] Feigenbaum, E. A., “The Simulation of Verbal Learning Be-\n",
      "havior,” Proceedings of the Western Joint Computer Conference, 19:121-\n",
      "132, 1961.\n",
      "[Fikes, et al., 1972] Fikes, R., Hart, P., and Nilsson, N., “Learning and Execut-\n",
      "ing Generalized Robot Plans,” Artiﬁcial Intelligence, pp 251-288, 1972.\n",
      "Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\n",
      "ing, San Francisco: Morgan Kaufmann, 1990, pp 468-486.\n",
      "[Fisher, 1987] Fisher, D., “Knowledge Acquisition via Incremental Conceptual\n",
      "Clustering,” Machine Learning, 2:139-172, 1987. Reprinted in Shavlik,\n",
      "J. and Dietterich, T., Readings in Machine Learning, San Francisco:\n",
      "Morgan Kaufmann, 1990, pp. 267–283.\n",
      "[Friedman, et al., 1977] Friedman, J. H., Bentley, J. L., and Finkel, R. A., “An\n",
      "Algorithm for Finding Best Matches in Logarithmic Expected Time,”\n",
      "ACM Trans. on Math. Software, 3(3):209-226, September 1977.\n",
      "[Fu, 1994] Fu,\n",
      "L.,\n",
      "Neural Networks in Artiﬁcial Intelligence,\n",
      "New York:\n",
      "McGraw-Hill, 1994.\n",
      "[Gallant, 1986] Gallant, S. I., “Optimal Linear Discriminants,” in Eighth Inter-\n",
      "national Conf. on Pattern Recognition, pp. 849-852, New York: IEEE,\n",
      "1986.\n",
      "[Genesereth & Nilsson, 1987] Genesereth, M., and Nilsson, N., Logical Founda-\n",
      "tions of Artiﬁcial Intelligence, San Francisco: Morgan Kaufmann, 1987.\n",
      "[Gluck & Rumelhart, 1989] Gluck, M. and Rumelhart, D., Neuroscience and\n",
      "Connectionist Theory, The Developments in Connectionist Theory, Hills-\n",
      "dale, NJ: Erlbaum Associates, 1989.\n",
      "[Hammerstrom, 1993] Hammerstrom, D., “Neural Networks at Work,” IEEE\n",
      "Spectrum, pp. 26-32, June 1993.\n",
      "[Haussler, 1988] Haussler, D., “Quantifying Inductive Bias: AI Learning Al-\n",
      "gorithms and Valiant’s Learning Framework,” Artiﬁcial Intelligence,\n",
      "36:177-221, 1988. Reprinted in Shavlik, J. and Dietterich, T., Readings in\n",
      "Machine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96-107.\n",
      "BIBLIOGRAPHY\n",
      "173\n",
      "[Haussler, 1990] Haussler, D., “Probably Approximately Correct Learning,”\n",
      "Proc. Eighth Nat. Conf. on AI, pp. 1101-1108. Cambridge, MA: MIT\n",
      "Press, 1990.\n",
      "[Hebb, 1949] Hebb, D. O., The Organization of Behaviour, New York: John\n",
      "Wiley, 1949.\n",
      "[Hertz, Krogh, & Palmer, 1991] Hertz, J., Krogh, A, and Palmer, R., Introduc-\n",
      "tion to the Theory of Neural Computation, Lecture Notes, vol. 1, Santa\n",
      "Fe Inst. Studies in the Sciences of Complexity, New York: Addison-\n",
      "Wesley, 1991.\n",
      "[Hirsh, 1994] Hirsh, H., “Generalizing Version Spaces,” Machine Learning, 17,\n",
      "5-45, 1994.\n",
      "[Holland, 1975] Holland, J., Adaptation in Natural and Artiﬁcial Systems, Ann\n",
      "Arbor: The University of Michigan Press, 1975. (Second edition printed\n",
      "in 1992 by MIT Press, Cambridge, MA.)\n",
      "[Holland, 1986] Holland, J. H., “Escaping Brittleness; The Possibilities of\n",
      "General-Purpose Learning Algorithms Applied to Parallel Rule-Based\n",
      "Systems.” In Michalski, R., Carbonell, J., and Mitchell, T. (eds.) , Ma-\n",
      "chine Learning: An Artiﬁcial Intelligence Approach, Volume 2, chapter\n",
      "20, San Francisco: Morgan Kaufmann, 1986.\n",
      "[Hunt, Marin, & Stone, 1966] Hunt, E., Marin, J., and Stone, P., Experiments\n",
      "in Induction, New York: Academic Press, 1966.\n",
      "[Jabbour, K., et al., 1987] Jabbour, K., et al., “ALFA: Automated Load Fore-\n",
      "casting Assistant,” Proc. of the IEEE Pwer Engineering Society Summer\n",
      "Meeting, San Francisco, CA, 1987.\n",
      "[John, 1995] John, G., “Robust Linear Discriminant Trees,” Proc. of the Conf.\n",
      "on Artiﬁcial Intelligence and Statistics, Ft. Lauderdale, FL, January,\n",
      "1995.\n",
      "[Kaelbling, 1993] Kaelbling, L. P., Learning in Embedded Systems, Cambridge,\n",
      "MA: MIT Press, 1993.\n",
      "[Kohavi, 1994] Kohavi, R., “Bottom-Up Induction of Oblivious Read-Once De-\n",
      "cision Graphs,” Proc. of European Conference on Machine Learning\n",
      "(ECML-94), 1994.\n",
      "[Kolodner, 1993] Kolodner, J., Case-Based Reasoning, San Francisco: Morgan\n",
      "Kaufmann, 1993.\n",
      "[Koza, 1992] Koza, J., Genetic Programming: On the Programming of Comput-\n",
      "ers by Means of Natural Selection, Cambridge, MA: MIT Press, 1992.\n",
      "[Koza, 1994] Koza,\n",
      "J.,\n",
      "Genetic Programming II: Automatic Discovery of\n",
      "Reusable Programs, Cambridge, MA: MIT Press, 1994.\n",
      "174\n",
      "BIBLIOGRAPHY\n",
      "[Laird, et al., 1986] Laird, J., Rosenbloom, P., and Newell, A., “Chunking in\n",
      "Soar: The Anatomy of a General Learning Mechanism,” Machine Learn-\n",
      "ing, 1, pp. 11-46, 1986. Reprinted in Buchanan, B. and Wilkins, D.,\n",
      "(eds.), Readings in Knowledge Acquisition and Learning, pp. 518-535,\n",
      "Morgan Kaufmann, San Francisco, CA, 1993.\n",
      "[Langley, 1992] Langley, P., “Areas of Application for Machine Learning,” Proc.\n",
      "of Fifth Int’l. Symp. on Knowledge Engineering, Sevilla, 1992.\n",
      "[Langley, 1996] Langley, P., Elements of Machine Learning, San Francisco:\n",
      "Morgan Kaufmann, 1996.\n",
      "[Lavraˇc & Dˇzeroski, 1994] Lavraˇc, N., and Dˇzeroski, S., Inductive Logic Pro-\n",
      "gramming, Chichester, England: Ellis Horwood, 1994.\n",
      "[Lin, 1992] Lin, L., “Self-Improving Reactive Agents Based on Reinforcement\n",
      "Learning, Planning, and Teaching,” Machine Learning, 8, 293-321, 1992.\n",
      "[Lin, 1993] Lin, L., “Scaling Up Reinforcement Learning for Robot Control,”\n",
      "Proc. Tenth Intl. Conf. on Machine Learning, pp. 182-189, San Francisco:\n",
      "Morgan Kaufmann, 1993.\n",
      "[Littlestone, 1988] Littlestone, N., “Learning Quickly When Irrelevant At-\n",
      "tributes Abound: A New Linear-Threshold Algorithm,” Machine Learn-\n",
      "ing 2: 285-318, 1988.\n",
      "[Maass & Tur´an, 1994] Maass, W., and Tur´an, G., “How Fast Can a Thresh-\n",
      "old Gate Learn?,” in Hanson, S., Drastal, G., and Rivest, R., (eds.),\n",
      "Computational Learning Theory and Natural Learning Systems, Volume\n",
      "1: Constraints and Prospects, pp. 381-414, Cambridge, MA: MIT Press,\n",
      "1994.\n",
      "[Mahadevan & Connell, 1992] Mahadevan, S., and Connell, J., “Automatic\n",
      "Programming of Behavior-Based Robots Using Reinforcement Learn-\n",
      "ing,” Artiﬁcial Intelligence, 55, pp. 311-365, 1992.\n",
      "[Marchand & Golea, 1993] Marchand, M., and Golea, M., “On Learning Sim-\n",
      "ple Neural Concepts: From Halfspace Intersections to Neural Decision\n",
      "Lists,” Network, 4:67-85, 1993.\n",
      "[McCulloch & Pitts, 1943] McCulloch, W. S., and Pitts, W. H., “A Logical Cal-\n",
      "culus of the Ideas Immanent in Nervous Activity,” Bulletin of Mathe-\n",
      "matical Biophysics, Vol. 5, pp. 115-133, Chicago: University of Chicago\n",
      "Press, 1943.\n",
      "[Michie, 1992] Michie, D., “Some Directions in Machine Intelligence,” unpub-\n",
      "lished manuscript, The Turing Institute, Glasgow, Scotland, 1992.\n",
      "[Minton, 1988] Minton,\n",
      "S.,\n",
      "Learning\n",
      "Search\n",
      "Control\n",
      "Knowledge:\n",
      "An\n",
      "Explanation-Based Approach, Kluwer Academic Publishers, Boston,\n",
      "MA, 1988.\n",
      "BIBLIOGRAPHY\n",
      "175\n",
      "[Minton, 1990] Minton, S., “Quantitative Results Concerning the Utility of\n",
      "Explanation-Based Learning,” Artiﬁcial Intelligence, 42, pp. 363-392,\n",
      "1990. Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine\n",
      "Learning, San Francisco: Morgan Kaufmann, 1990, pp. 573-587.\n",
      "[Mitchell, et al., 1986] Mitchell, T., et al., “Explanation-Based Generalization:\n",
      "A Unifying View,” Machine Learning, 1:1, 1986. Reprinted in Shavlik,\n",
      "J. and Dietterich, T., Readings in Machine Learning, San Francisco:\n",
      "Morgan Kaufmann, 1990, pp. 435-451.\n",
      "[Mitchell, 1982] Mitchell, T., “Generalization as Search,” Artiﬁcial Intelligence,\n",
      "18:203-226, 1982. Reprinted in Shavlik, J. and Dietterich, T., Readings in\n",
      "Machine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96–107.\n",
      "[Moore & Atkeson, 1993] Moore, A., and Atkeson, C., “Prioritized Sweeping:\n",
      "Reinforcement Learning with Less Data and Less Time,” Machine Learn-\n",
      "ing, 13, pp. 103-130, 1993.\n",
      "[Moore, et al., 1994] Moore, A. W., Hill, D. J., and Johnson, M. P., “An Em-\n",
      "pirical Investigation of Brute Force to Choose Features, Smoothers, and\n",
      "Function Approximators,” in Hanson, S., Judd, S., and Petsche, T.,\n",
      "(eds.), Computational Learning Theory and Natural Learning Systems,\n",
      "Vol. 3, Cambridge: MIT Press, 1994.\n",
      "[Moore, 1990] Moore, A., Eﬃcient Memory-based Learning for Robot Control,\n",
      "PhD. Thesis; Technical Report No. 209, Computer Laboratory, Univer-\n",
      "sity of Cambridge, October, 1990.\n",
      "[Moore, 1992] Moore, A., “Fast, Robust Adaptive Control by Learning Only\n",
      "Forward Models,” in Moody, J., Hanson, S., and Lippman, R., (eds.),\n",
      "Advances in Neural Information Processing Systems 4, San Francisco:\n",
      "Morgan Kaufmann, 1992.\n",
      "[Mueller & Page, 1988] Mueller, R. and Page, R., Symbolic Computing with\n",
      "Lisp and Prolog, New York: John Wiley & Sons, 1988.\n",
      "[Muggleton, 1991] Muggleton, S., “Inductive Logic Programming,” New Gen-\n",
      "eration Computing, 8, pp. 295-318, 1991.\n",
      "[Muggleton, 1992] Muggleton, S., Inductive Logic Programming, London: Aca-\n",
      "demic Press, 1992.\n",
      "[Muroga, 1971] Muroga, S., Threshold Logic and its Applications, New York:\n",
      "Wiley, 1971.\n",
      "[Natarjan, 1991] Natarajan, B., Machine Learning: A Theoretical Approach,\n",
      "San Francisco: Morgan Kaufmann, 1991.\n",
      "176\n",
      "BIBLIOGRAPHY\n",
      "[Nilsson, 1965] Nilsson, N. J., “Theoretical and Experimental Investigations in\n",
      "Trainable Pattern-Classifying Systems,” Tech. Report No. RADC-TR-\n",
      "65-257, Final Report on Contract AF30(602)-3448, Rome Air Develop-\n",
      "ment Center (Now Rome Laboratories), Griﬃss Air Force Base, New\n",
      "York, September, 1965.\n",
      "[Nilsson, 1990] Nilsson, N. J., The Mathematical Foundations of Learning Ma-\n",
      "chines, San Francisco: Morgan Kaufmann, 1990. (This book is a reprint\n",
      "of Learning Machines:\n",
      "Foundations of Trainable Pattern-Classifying\n",
      "Systems, New York: McGraw-Hill, 1965.)\n",
      "[Oliver, Dowe, & Wallace, 1992] Oliver, J., Dowe, D., and Wallace, C., “Infer-\n",
      "ring Decision Graphs using the Minimum Message Length Principle,”\n",
      "Proc. 1992 Australian Artiﬁcial Intelligence Conference, 1992.\n",
      "[Pagallo & Haussler, 1990] Pagallo, G. and Haussler, D., “Boolean Feature Dis-\n",
      "covery in Empirical Learning,” Machine Learning, vol.5, no.1, pp. 71-99,\n",
      "March 1990.\n",
      "[Pazzani & Kibler, 1992] Pazzani, M., and Kibler, D., “The Utility of Knowl-\n",
      "edge in Inductive Learning,” Machine Learning, 9, 57-94, 1992.\n",
      "[Peterson, 1961] Peterson, W., Error Correcting Codes, New York: John Wiley,\n",
      "1961.\n",
      "[Pomerleau, 1991] Pomerleau, D., “Rapidly Adapting Artiﬁcial Neural Net-\n",
      "works for Autonomous Navigation,” in Lippmann, P., et al. (eds.), Ad-\n",
      "vances in Neural Information Processing Systems, 3, pp. 429-435, San\n",
      "Francisco: Morgan Kaufmann, 1991.\n",
      "[Pomerleau, 1993] Pomerleau, D, Neural Network Perception for Mobile Robot\n",
      "Guidance, Boston: Kluwer Academic Publishers, 1993.\n",
      "[Quinlan & Rivest, 1989] Quinlan, J. Ross, and Rivest, Ron, “Inferring Deci-\n",
      "sion Trees Using the Minimum Description Length Principle,” Informa-\n",
      "tion and Computation, 80:227–248, March, 1989.\n",
      "[Quinlan, 1986] Quinlan, J. Ross, “Induction of Decision Trees,” Machine\n",
      "Learning, 1:81–106, 1986. Reprinted in Shavlik, J. and Dietterich, T.,\n",
      "Readings in Machine Learning, San Francisco: Morgan Kaufmann, 1990,\n",
      "pp. 57–69.\n",
      "[Quinlan, 1987] Quinlan, J. R., “Generating Production Rules from Decision\n",
      "Trees,” In IJCAI-87: Proceedings of the Tenth Intl. Joint Conf. on Ar-\n",
      "tiﬁcial Intelligence, pp. 304-7, San Francisco: Morgan-Kaufmann, 1987.\n",
      "[Quinlan, 1990] Quinlan, J. R., “Learning Logical Deﬁnitions from Relations,”\n",
      "Machine Learning, 5, 239-266, 1990.\n",
      "BIBLIOGRAPHY\n",
      "177\n",
      "[Quinlan, 1993] Quinlan, J. Ross, C4.5: Programs for Machine Learning, San\n",
      "Francisco: Morgan Kaufmann, 1993.\n",
      "[Quinlan, 1994] Quinlan, J. R., “Comparing Connectionist and Symbolic Learn-\n",
      "ing Methods,” in Hanson, S., Drastal, G., and Rivest, R., (eds.), Com-\n",
      "putational Learning Theory and Natural Learning Systems, Volume 1:\n",
      "Constraints and Prospects, pp. 445-456,, Cambridge, MA: MIT Press,\n",
      "1994.\n",
      "[Ridgway, 1962] Ridgway, W. C., An Adaptive Logic System with Generalizing\n",
      "Properties, PhD thesis, Tech. Rep. 1556-1, Stanford Electronics Labs.,\n",
      "Stanford, CA, April 1962.\n",
      "[Rissanen, 1978] Rissanen, J., “Modeling by Shortest Data Description,” Auto-\n",
      "matica, 14:465-471, 1978.\n",
      "[Rivest, 1987] Rivest, R. L., “Learning Decision Lists,” Machine Learning, 2,\n",
      "229-246, 1987.\n",
      "[Rosenblatt, 1958] Rosenblatt, F., Principles of Neurodynamics, Washington:\n",
      "Spartan Books, 1961.\n",
      "[Ross, 1983] Ross, S., Introduction to Stochastic Dynamic Programming, New\n",
      "York: Academic Press, 1983.\n",
      "[Rumelhart, Hinton, & Williams, 1986] Rumelhart, D. E., Hinton, G. E., and\n",
      "Williams, R. J., “Learning Internal Representations by Error Propa-\n",
      "gation,” In Rumelhart, D. E., and McClelland, J. L., (eds.) Parallel\n",
      "Distributed Processing, Vol 1, 318–362, 1986.\n",
      "[Russell & Norvig 1995] Russell, S., and Norvig, P., Artiﬁcial Intelligence: A\n",
      "Modern Approach, Englewood Cliﬀs, NJ: Prentice Hall, 1995.\n",
      "[Samuel, 1959] Samuel, A., “Some Studies in Machine Learning Using the Game\n",
      "of Checkers,” IBM Journal of Research and Development, 3:211-229, July\n",
      "1959.\n",
      "[Schwartz, 1993] Schwartz, A., “A Reinforcement Learning Method for Max-\n",
      "imizing Undiscounted Rewards,” Proc. Tenth Intl. Conf. on Machine\n",
      "Learning, pp. 298-305, San Francisco: Morgan Kaufmann, 1993.\n",
      "[Sejnowski, Koch, & Churchland, 1988] Sejnowski, T., Koch, C., and Church-\n",
      "land, P., “Computational Neuroscience,” Science, 241: 1299-1306, 1988.\n",
      "[Shavlik, Mooney, & Towell, 1991] Shavlik, J., Mooney, R., and Towell, G.,\n",
      "“Symbolic and Neural Learning Algorithms: An Experimental Compar-\n",
      "ison,” Machine Learning, 6, pp. 111-143, 1991.\n",
      "[Shavlik & Dietterich, 1990] Shavlik, J. and Dietterich, T., Readings in Ma-\n",
      "chine Learning, San Francisco: Morgan Kaufmann, 1990.\n",
      "178\n",
      "BIBLIOGRAPHY\n",
      "[Sutton & Barto, 1987] Sutton,\n",
      "R. S.,\n",
      "and Barto,\n",
      "A. G.,\n",
      "“A Temporal-\n",
      "Diﬀerence Model of Classical Conditioning,” in Proceedings of the Ninth\n",
      "Annual Conference of the Cognitive Science Society, Hillsdale, NJ: Erl-\n",
      "baum, 1987.\n",
      "[Sutton, 1988] Sutton, R. S., “Learning to Predict by the Methods of Temporal\n",
      "Diﬀerences,” Machine Learning 3: 9-44, 1988.\n",
      "[Sutton, 1990] Sutton, R., “Integrated Architectures for Learning, Planning,\n",
      "and Reacting Based on Approximating Dynamic Programming,” Proc. of\n",
      "the Seventh Intl. Conf. on Machine Learning, pp. 216-224, San Francisco:\n",
      "Morgan Kaufmann, 1990.\n",
      "[Taylor, Michie, & Spiegalhalter, 1994] Taylor, C., Michie, D., and Spiegal-\n",
      "halter, D., Machine Learning, Neural and Statistical Classiﬁcation,\n",
      "Paramount Publishing International.\n",
      "[Tesauro, 1992] Tesauro, G., “Practical Issues in Temporal Diﬀerence Learn-\n",
      "ing,” Machine Learning, 8, nos. 3/4, pp. 257-277, 1992.\n",
      "[Towell & Shavlik, 1992] Towell G., and Shavlik, J., “Interpretation of Artiﬁ-\n",
      "cial Neural Networks: Mapping Knowledge-Based Neural Networks into\n",
      "Rules,” in Moody, J., Hanson, S., and Lippmann, R., (eds.), Advances in\n",
      "Neural Information Processing Systems, 4, pp. 977-984, San Francisco:\n",
      "Morgan Kaufmann, 1992.\n",
      "[Towell, Shavlik, & Noordweier, 1990] Towell, G., Shavlik, J., and Noordweier,\n",
      "M., “Reﬁnement of Approximate Domain Theories by Knowledge-Based\n",
      "Artiﬁcial Neural Networks,” Proc. Eighth Natl., Conf. on Artiﬁcial In-\n",
      "telligence, pp. 861-866, 1990.\n",
      "[Unger, 1989] Unger, S., The Essence of Logic Circuits, Englewood Cliﬀs, NJ:\n",
      "Prentice-Hall, 1989.\n",
      "[Utgoﬀ, 1989] Utgoﬀ, P., “Incremental Induction of Decision Trees,” Machine\n",
      "Learning, 4:161–186, Nov., 1989.\n",
      "[Valiant, 1984] Valiant, L., “A Theory of the Learnable,” Communications of\n",
      "the ACM, Vol. 27, pp. 1134-1142, 1984.\n",
      "[Vapnik & Chervonenkis, 1971] Vapnik, V., and Chervonenkis, A., “On the\n",
      "Uniform Convergence of Relative Frequencies, Theory of Probability and\n",
      "its Applications, Vol. 16, No. 2, pp. 264-280, 1971.\n",
      "[Various Editors, 1989-1994] Advances in Neural Information Processing Sys-\n",
      "tems, vols 1 through 6, San Francisco: Morgan Kaufmann, 1989 -1994.\n",
      "[Watkins & Dayan, 1992] Watkins, C. J. C. H., and Dayan, P., “Technical Note:\n",
      "Q-Learning,” Machine Learning, 8, 279-292, 1992.\n",
      "BIBLIOGRAPHY\n",
      "179\n",
      "[Watkins, 1989] Watkins, C. J. C. H., Learning From Delayed Rewards, PhD\n",
      "Thesis, University of Cambridge, England, 1989.\n",
      "[Weiss & Kulikowski, 1991] Weiss, S., and Kulikowski, C., Computer Systems\n",
      "that Learn, San Francisco: Morgan Kaufmann, 1991.\n",
      "[Werbos, 1974] Werbos, P., Beyond Regression: New Tools for Prediction and\n",
      "Analysis in the Behavioral Sciences, Ph.D. Thesis, Harvard University,\n",
      "1974.\n",
      "[Widrow & Lehr, 1990] Widrow, B., and Lehr, M. A., “30 Years of Adaptive\n",
      "Neural Networks: Perceptron, Madaline and Backpropagation,” Proc.\n",
      "IEEE, vol. 78, no. 9, pp. 1415-1442, September, 1990.\n",
      "[Widrow & Stearns, 1985] Widrow, B., and Stearns, S., Adaptive Signal Pro-\n",
      "cessing, Englewood Cliﬀs, NJ: Prentice-Hall.\n",
      "[Widrow, 1962] Widrow, B., “Generalization and Storage in Networks of Ada-\n",
      "line Neurons,” in Yovits, Jacobi, and Goldstein (eds.), Self-organizing\n",
      "Systems—1962, pp. 435-461, Washington, DC: Spartan Books, 1962.\n",
      "[Winder, 1961] Winder, R., “Single Stage Threshold Logic,” Proc. of the AIEE\n",
      "Symp. on Switching Circuits and Logical Design, Conf. paper CP-60-\n",
      "1261, pp. 321-332, 1961.\n",
      "[Winder, 1962] Winder, R., Threshold Logic, PhD Dissertation, Princeton Uni-\n",
      "versity, Princeton, NJ, 1962.\n",
      "[Wnek, et al., 1990] Wnek, J., et al., “Comparing Learning Paradigms via Di-\n",
      "agrammatic Visualization,” in Proc. Fifth Intl. Symp. on Methodologies\n",
      "for Intelligent Systems, pp. 428-437, 1990. (Also Tech. Report MLI90-2,\n",
      "University of Illinois at Urbana-Champaign.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz # install using: pip install PyMuPDF\n",
    "\n",
    "with fitz.open(\"MLBOOK.pdf\") as doc:\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54fd52c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTRODUCTION\n",
      "TO\n",
      "MACHINE LEARNING\n",
      "AN EARLY DRAFT OF A PROPOSED\n",
      "TEXTBOOK\n",
      "Nils J. Nilsson\n",
      "Robotics Laboratory\n",
      "Department of Computer Science\n",
      "Stanford University\n"
     ]
    }
   ],
   "source": [
    "print(text[0:157])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81cd3e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tika\n",
      "  Downloading tika-1.24.tar.gz (28 kB)\n",
      "Requirement already satisfied: setuptools in d:\\programfiles\\anaconda3\\lib\\site-packages (from tika) (60.10.0)\n",
      "Requirement already satisfied: requests in d:\\programfiles\\anaconda3\\lib\\site-packages (from tika) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programfiles\\anaconda3\\lib\\site-packages (from requests->tika) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programfiles\\anaconda3\\lib\\site-packages (from requests->tika) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programfiles\\anaconda3\\lib\\site-packages (from requests->tika) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from requests->tika) (2.0.4)\n",
      "Building wheels for collected packages: tika\n",
      "  Building wheel for tika (setup.py): started\n",
      "  Building wheel for tika (setup.py): finished with status 'done'\n",
      "  Created wheel for tika: filename=tika-1.24-py3-none-any.whl size=32891 sha256=456f8875407b5bf4b3953132c24283b643d845ca52382f6125f8dfd035764a2c\n",
      "  Stored in directory: c:\\users\\abhirockzzz\\appdata\\local\\pip\\cache\\wheels\\ec\\76\\38\\0e4b92d8a3a89cbfff5be03a40c02d15b2072b1b08ebf28d6a\n",
      "Successfully built tika\n",
      "Installing collected packages: tika\n",
      "Successfully installed tika-1.24\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de19d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ba28c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/34837707/how-to-extract-text-from-a-pdf-file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ecddb1",
   "metadata": {},
   "source": [
    "# Extract images from pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c034b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"MLBOOK.pdf\")\n",
    "for page in reader.pages:\n",
    "    for image in page.images:\n",
    "        with open(image.name, \"wb\") as fp:\n",
    "            fp.write(image.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8230d218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting minecart\n",
      "  Downloading minecart-0.3.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: six in d:\\programfiles\\anaconda3\\lib\\site-packages (from minecart) (1.16.0)\n",
      "Collecting pdfminer3k\n",
      "  Downloading pdfminer3k-1.3.4-py3-none-any.whl (100 kB)\n",
      "Collecting ply\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Installing collected packages: ply, pdfminer3k, minecart\n",
      "Successfully installed minecart-0.3.0 pdfminer3k-1.3.4 ply-3.11\n"
     ]
    }
   ],
   "source": [
    "!pip3 install minecart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e68ab1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in d:\\programfiles\\anaconda3\\lib\\site-packages (1.21.1)\n",
      "Requirement already satisfied: Pillow in d:\\programfiles\\anaconda3\\lib\\site-packages (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PyMuPDF Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f030f035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf2 in d:\\programfiles\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in d:\\programfiles\\anaconda3\\lib\\site-packages (from pypdf2) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2853c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import fitz\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee68e38",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PageObject' object has no attribute 'extractImage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Iterate over all the pages in the PDF\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pdf\u001b[38;5;241m.\u001b[39mgetNumPages()):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Extract the image from the current page\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetPage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractImage\u001b[49m()\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Save the image to a temporary file\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m image_file:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PageObject' object has no attribute 'extractImage'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "# Open the PDF file in read-binary mode\n",
    "with open('MLBOOK.pdf', 'rb') as file:\n",
    "    # Create a PDF object\n",
    "    pdf = PyPDF2.PdfFileReader(file)\n",
    "    \n",
    "    # Iterate over all the pages in the PDF\n",
    "    for page in range(pdf.getNumPages()):\n",
    "        # Extract the image from the current page\n",
    "        image = pdf.getPage(page).extractImage()\n",
    "        \n",
    "        # Save the image to a temporary file\n",
    "        with tempfile.NamedTemporaryFile(mode='wb', suffix='.jpg', delete=False) as image_file:\n",
    "            image_file.write(image)\n",
    "            \n",
    "        # Open the image file\n",
    "        with open(image_file.name, 'rb') as f:\n",
    "            # Do something with the image (e.g. display it, save it to a permanent location, etc.)\n",
    "            pass\n",
    "            \n",
    "        # Delete the temporary image file\n",
    "        os.unlink(image_file.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0ce827c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Page' object has no attribute 'getPageImageList'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pdf_file)):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# get the page itself\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     page \u001b[38;5;241m=\u001b[39m pdf_file[page_index]\n\u001b[1;32m---> 10\u001b[0m     image_list \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetPageImageList\u001b[49m()\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# printing number of images found in this page\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image_list:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Page' object has no attribute 'getPageImageList'"
     ]
    }
   ],
   "source": [
    "# file path you want to extract images from\n",
    "file = \"MLBOOK.pdf\"\n",
    "# open the file\n",
    "pdf_file = fitz.open(file)\n",
    "\n",
    "# iterate over pdf pages\n",
    "for page_index in range(len(pdf_file)):\n",
    "    # get the page itself\n",
    "    page = pdf_file[page_index]\n",
    "    image_list = page.getImageList()\n",
    "    # printing number of images found in this page\n",
    "    if image_list:\n",
    "        print(f\"[+] Found a total of {len(image_list)} images in page {page_index}\")\n",
    "    else:\n",
    "        print(\"[!] No images found on page\", page_index)\n",
    "    for image_index, img in enumerate(page.getImageList(), start=1):\n",
    "        # get the XREF of the image\n",
    "        xref = img[0]\n",
    "        # extract the image bytes\n",
    "        base_image = pdf_file.extractImage(xref)\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        # get the image extension\n",
    "        image_ext = base_image[\"ext\"]\n",
    "        # load it to PIL\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        # save it to local disk\n",
    "        image.save(open(f\"image{page_index+1}_{image_index}.{image_ext}\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e1782",
   "metadata": {},
   "source": [
    "# Automate Excel Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4097e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in d:\\programfiles\\anaconda3\\lib\\site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in d:\\programfiles\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16328175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl as xl\n",
    "from openpyxl.chart import BarChart, Reference, Series, BarChart3D,PieChart,ProjectedPieChart,PieChart3D\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font\n",
    "import string\n",
    "from openpyxl.chart.series import DataPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81827837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.chart import (\n",
    "    Reference,\n",
    "    Series,\n",
    "    BarChart3D,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a46f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.chart import (\n",
    "    PieChart,\n",
    "    ProjectedPieChart,PieChart3D,\n",
    "    Reference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f3b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.chart.series import DataPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7cac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57b47f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rape</th>\n",
       "      <th>Kidnapping and Abduction</th>\n",
       "      <th>Dowry Deaths</th>\n",
       "      <th>Assault on women with intent to outrage her modesty</th>\n",
       "      <th>Insult to modesty of Women</th>\n",
       "      <th>Cruelty by Husband or his Relatives</th>\n",
       "      <th>Importation of Girls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>ADILABAD</td>\n",
       "      <td>2001</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>149</td>\n",
       "      <td>34</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>ANANTAPUR</td>\n",
       "      <td>2001</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>CHITTOOR</td>\n",
       "      <td>2001</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>112</td>\n",
       "      <td>83</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>CUDDAPAH</td>\n",
       "      <td>2001</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>126</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>EAST GODAVARI</td>\n",
       "      <td>2001</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATE/UT       DISTRICT  Year  Rape  Kidnapping and Abduction  \\\n",
       "0  ANDHRA PRADESH       ADILABAD  2001    50                        30   \n",
       "1  ANDHRA PRADESH      ANANTAPUR  2001    23                        30   \n",
       "2  ANDHRA PRADESH       CHITTOOR  2001    27                        34   \n",
       "3  ANDHRA PRADESH       CUDDAPAH  2001    20                        20   \n",
       "4  ANDHRA PRADESH  EAST GODAVARI  2001    23                        26   \n",
       "\n",
       "   Dowry Deaths  Assault on women with intent to outrage her modesty  \\\n",
       "0            16                                                149     \n",
       "1             7                                                118     \n",
       "2            14                                                112     \n",
       "3            17                                                126     \n",
       "4            12                                                109     \n",
       "\n",
       "   Insult to modesty of Women  Cruelty by Husband or his Relatives  \\\n",
       "0                          34                                  175   \n",
       "1                          24                                  154   \n",
       "2                          83                                  186   \n",
       "3                          38                                   57   \n",
       "4                          58                                  247   \n",
       "\n",
       "   Importation of Girls  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_file = pd.read_csv('42_District_wise_crimes_committed_against_women_2001_2012.csv')\n",
    "excel_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6bc3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c0622ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = pd.pivot_table(excel_file, values ='Kidnapping and Abduction', index =['Year'],\n",
    "                          aggfunc = max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbb52df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table.to_excel('report_2021.xlsx',\n",
    "                      sheet_name='Crime_Report',\n",
    "                      startrow=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d36fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook('report_2021.xlsx')\n",
    "sheet = wb['Crime_Report']\n",
    "# cell references (original spreadsheet) \n",
    "min_column = wb.active.min_column\n",
    "max_column = wb.active.max_column\n",
    "min_row = wb.active.min_row\n",
    "max_row = wb.active.max_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0a44359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "5\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(min_column)\n",
    "print(max_column)\n",
    "print(min_row)\n",
    "print(max_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ed4c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook('report_2021.xlsx')\n",
    "sheet = wb['Crime_Report']\n",
    "# barchart\n",
    "barchart = BarChart()\n",
    "#locate data and categories\n",
    "data = Reference(sheet,\n",
    "                 min_col=min_column+1,\n",
    "                 max_col=max_column,\n",
    "                 min_row=min_row,\n",
    "                 max_row=max_row) #including headers\n",
    "categories = Reference(sheet,\n",
    "                       min_col=min_column,\n",
    "                       max_col=min_column,\n",
    "                       min_row=min_row+1,\n",
    "                       max_row=max_row) #not including headers\n",
    "# adding data and categories\n",
    "barchart.add_data(data, titles_from_data=True)\n",
    "barchart.set_categories(categories)\n",
    "#location chart\n",
    "sheet.add_chart(barchart, \"H12\")\n",
    "barchart.title = 'Crime by State and Year'\n",
    "barchart.style = 5 #choose the chart style\n",
    "wb.save('report_2021_crime.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf1fcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook('report_2021.xlsx')\n",
    "sheet = wb['Crime_Report']\n",
    "# barchart\n",
    "barchart = BarChart3D()\n",
    "#locate data and categories\n",
    "data = Reference(sheet,\n",
    "                 min_col=min_column+1,\n",
    "                 max_col=max_column,\n",
    "                 min_row=min_row,\n",
    "                 max_row=max_row) #including headers\n",
    "categories = Reference(sheet,\n",
    "                       min_col=min_column,\n",
    "                       max_col=min_column,\n",
    "                       min_row=min_row+1,\n",
    "                       max_row=max_row) #not including headers\n",
    "# adding data and categories\n",
    "barchart.add_data(data, titles_from_data=True)\n",
    "barchart.set_categories(categories)\n",
    "#location chart\n",
    "sheet.add_chart(barchart, \"H4\")\n",
    "barchart.title = 'Crime by State and Year'\n",
    "barchart.style = 5 #choose the chart style\n",
    "wb.save('report_2021_3D_Chart_crime.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17b46d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook('report_2021.xlsx')\n",
    "sheet = wb['Crime_Report']\n",
    "\n",
    "#locate data and categories\n",
    "data = Reference(sheet,\n",
    "                 min_col=min_column+1,\n",
    "                 max_col=max_column,\n",
    "                 min_row=min_row,\n",
    "                 max_row=max_row) #including headers\n",
    "categories = Reference(sheet,\n",
    "                       min_col=min_column,\n",
    "                       max_col=min_column,\n",
    "                       min_row=min_row+1,\n",
    "                       max_row=max_row) #not including headers\n",
    "\n",
    "pie = PieChart()\n",
    "pie.add_data(data, titles_from_data=True)\n",
    "pie.set_categories(categories)\n",
    "pie.title = \"Crime by States\"\n",
    "\n",
    "# Cut the first slice out of the pie\n",
    "slice1 = DataPoint(idx=0, explosion=20)\n",
    "pie.series[0].data_points = [slice1]\n",
    "\n",
    "sheet.add_chart(pie, \"H2\")\n",
    "wb.save('report_2021_Pie_Chart_crime.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e63f3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook('report_2021.xlsx')\n",
    "sheet = wb['Crime_Report']\n",
    "\n",
    "#locate data and categories\n",
    "data = Reference(sheet,\n",
    "                 min_col=min_column+1,\n",
    "                 max_col=max_column,\n",
    "                 min_row=min_row,\n",
    "                 max_row=max_row) #including headers\n",
    "categories = Reference(sheet,\n",
    "                       min_col=min_column,\n",
    "                       max_col=min_column,\n",
    "                       min_row=min_row+1,\n",
    "                       max_row=max_row) #not including headers\n",
    "\n",
    "projected_pie = ProjectedPieChart()\n",
    "projected_pie.type = \"pie\"\n",
    "projected_pie.splitType = \"val\" # split by value\n",
    "projected_pie.add_data(data, titles_from_data=True)\n",
    "projected_pie.set_categories(categories)\n",
    "\n",
    "sheet.add_chart(projected_pie, \"H2\")\n",
    "\n",
    "from copy import deepcopy\n",
    "projected_bar = deepcopy(projected_pie)\n",
    "projected_bar.type = \"bar\"\n",
    "projected_bar.splitType = 'pos' # split by position\n",
    "\n",
    "sheet.add_chart(projected_bar, \"H20\")\n",
    "\n",
    "wb.save('report_2021_Pie_Chart_Projected_Pie_crime.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1635ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook('report_2021.xlsx')\n",
    "sheet = wb['Crime_Report']\n",
    "\n",
    "#locate data and categories\n",
    "data = Reference(sheet,\n",
    "                 min_col=min_column+1,\n",
    "                 max_col=max_column,\n",
    "                 min_row=min_row,\n",
    "                 max_row=max_row) #including headers\n",
    "categories = Reference(sheet,\n",
    "                       min_col=min_column,\n",
    "                       max_col=min_column,\n",
    "                       min_row=min_row+1,\n",
    "                       max_row=max_row) #not including headers\n",
    "\n",
    "pie = PieChart3D()\n",
    "\n",
    "pie.add_data(data, titles_from_data=True)\n",
    "pie.set_categories(categories)\n",
    "pie.title = \"Crime by Year in 3D Pie Chart\"\n",
    "\n",
    "\n",
    "\n",
    "sheet.add_chart(pie, \"H2\")\n",
    "wb.save('report_2021_Pie_Chart_3D_crime.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c3bc2",
   "metadata": {},
   "source": [
    "# Create excel files using Openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65f505",
   "metadata": {},
   "source": [
    "#https://automatetheboringstuff.com/2e/chapter13/\n",
    "\n",
    "Write excel documents and fill in with cell values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/a-simple-guide-to-automate-your-excel-reporting-with-python-9d35f143ef7\n",
    "#https://openpyxl.readthedocs.io/en/latest/charts/introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6434d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3762156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new workbook\n",
    "wb = openpyxl.Workbook()\n",
    "#Get sheet name\n",
    "Sheet_name = wb.sheetnames\n",
    "#Save created workbook\n",
    "wb.save(filename='Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b058af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheet']\n"
     ]
    }
   ],
   "source": [
    "print(Sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7531f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheet name is renamed as: sheet1\n"
     ]
    }
   ],
   "source": [
    "sheet=wb.active\n",
    "# One can change the name of the title\n",
    "sheet.title = \"sheet1\"\n",
    "print(\"sheet name is renamed as: \" + sheet.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca8eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,  timedelta\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc482556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate with some data in the excel file\n",
    "sheet=wb.active\n",
    "# Note: The first row or column integer\n",
    "# is 1, not 0. Cell object is created by\n",
    "# using sheet object's cell() method.\n",
    "c1 = sheet.cell(row = 1, column = 1)\n",
    "  \n",
    "# writing values to cells\n",
    "c1.value = \"Hello\"\n",
    "  \n",
    "c2 = sheet.cell(row= 1 , column = 2)\n",
    "c2.value = \"World\"\n",
    "  \n",
    "# Once have a Worksheet object, one can\n",
    "# access a cell object by its name also.\n",
    "# A2 means column = 1 & row = 2.\n",
    "c3 = sheet['A2']\n",
    "c3.value = \"First\"\n",
    "  \n",
    "# B2 means column = 2 & row = 2.\n",
    "c4 = sheet['B2']\n",
    "c4.value = \"Word\"\n",
    "\n",
    "\n",
    "# Once have a Worksheet object, one can\n",
    "# access a cell object by its name also.\n",
    "# A3 means column = 1 & row = 3.\n",
    "c5 = sheet['A3']\n",
    "c5.value = now #Added current time\n",
    "\n",
    "# B3 means column = 2 & row = 3.\n",
    "c4 = sheet['B3']\n",
    "c4.value = now + timedelta(minutes = 50) #Added time advanced by 50 minutes ahead\n",
    "\n",
    "\n",
    "\n",
    "wb.save(\"Test.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ae05e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new sheets in the workbook\n",
    "wb.create_sheet(index = 1 , title = \"new sheet2\")\n",
    "wb.save(\"Test.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99310524",
   "metadata": {},
   "source": [
    "# A daily calendar to schedule my tasks using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aa3dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a task for Saturday: saturday\n",
      "Tasks for Saturday:\n",
      "saturday\n"
     ]
    }
   ],
   "source": [
    "# Import the calendar and datetime modules\n",
    "import calendar\n",
    "import datetime\n",
    "\n",
    "# Create a dictionary to hold the tasks for each day of the week\n",
    "tasks = {\n",
    "    'Monday': [],\n",
    "    'Tuesday': [],\n",
    "    'Wednesday': [],\n",
    "    'Thursday': [],\n",
    "    'Friday': [],\n",
    "    'Saturday': [],\n",
    "    'Sunday': []\n",
    "}\n",
    "\n",
    "# Get the current day of the week\n",
    "today = datetime.datetime.today().weekday()\n",
    "\n",
    "# Get the name of the current day of the week\n",
    "day_of_week = calendar.day_name[today]\n",
    "\n",
    "# Prompt the user to enter a task for the current day\n",
    "task = input(f'Enter a task for {day_of_week}: ')\n",
    "\n",
    "# Add the task to the dictionary\n",
    "tasks[day_of_week].append(task)\n",
    "\n",
    "# Print the tasks for the current day\n",
    "print(f'Tasks for {day_of_week}:')\n",
    "for task in tasks[day_of_week]:\n",
    "    print(task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d911b518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Monday': [],\n",
       " 'Tuesday': [],\n",
       " 'Wednesday': [],\n",
       " 'Thursday': [],\n",
       " 'Friday': [],\n",
       " 'Saturday': ['saturday'],\n",
       " 'Sunday': []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de48fd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.today().weekday()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea32e1",
   "metadata": {},
   "source": [
    "# create a daily calendar and schedule my tasks into an excel file using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "516900bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "#Create a new Workbook object\n",
    "workbook = Workbook()\n",
    "\n",
    "#Create a new worksheet and give it a name\n",
    "worksheet = workbook.active\n",
    "worksheet.title = \"Daily Calendar\"\n",
    "\n",
    "#Define the column headings for the calendar. For example\n",
    "worksheet['A1'] = 'Time'\n",
    "worksheet['B1'] = 'Task'\n",
    "\n",
    "#Define the time slots for the calendar. For example\n",
    "worksheet['A2'] = '9:00am - 10:00am'\n",
    "worksheet['A3'] = '10:00am - 11:00am'\n",
    "\n",
    "#Schedule tasks for each time slot. For example\n",
    "worksheet['B2'] = 'Meeting with Akshay'\n",
    "worksheet['B3'] = 'Write report'\n",
    "\n",
    "#Save the Excel file\n",
    "workbook.save(\"My_daily_calendar.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c841b0",
   "metadata": {},
   "source": [
    "# Automate reading and writing files using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2699e9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Read a file\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('filename.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    contents = file.read()\n",
    "    # Print the contents\n",
    "    print(contents)\n",
    "\n",
    "\n",
    "#Write a file\n",
    "\n",
    "# Open the file in write mode\n",
    "with open('filename.txt', 'w') as file:\n",
    "    # Write some text to the file\n",
    "    file.write('My name is Abhi, and I love to write articles on python and machine learning.')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#Append a file\n",
    "\n",
    "# Open the file in append mode\n",
    "with open('filename.txt', 'a') as file:\n",
    "    # Append some text to the file\n",
    "    file.write('\\nThis is some extra text to test the code')\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erase contents of the file\n",
    "\n",
    "open('filename.txt', 'w').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4e983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03e7a678",
   "metadata": {},
   "source": [
    "These examples use the with statement to automatically handle opening and closing the file. \n",
    "\n",
    "The 'r' mode is used to read the file, 'w' mode is used to write to the file \n",
    "(overwriting any existing contents), and 'a' mode is used to append to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1018208",
   "metadata": {},
   "source": [
    "# Send an email using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "\n",
    "# Create a connection to the server\n",
    "server = smtplib.SMTP('smtp.example.com', 587)\n",
    "\n",
    "# Start the server connection\n",
    "server.starttls()\n",
    "\n",
    "# Login to the email account\n",
    "server.login(\"youremail@example.com\", \"yourpassword\")\n",
    "\n",
    "# Send the email\n",
    "msg = \"Hello, this is a test email\"\n",
    "server.sendmail(\"youremail@example.com\", \"recipient@example.com\", msg)\n",
    "\n",
    "# End the server connection\n",
    "server.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yagmail\n",
    "\n",
    "yag = yagmail.SMTP('youremail@example.com', 'yourpassword')\n",
    "contents = ['This is the body of the email', 'You can use a list of strings']\n",
    "yag.send('recipient@example.com', 'subject', contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2802c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mailer import Mailer\n",
    "from mailer import Message\n",
    "\n",
    "message = Message(From=\"youremail@example.com\",\n",
    "                  To=\"recipient@example.com\",\n",
    "                  charset=\"utf-8\")\n",
    "message.Subject = \"Test Email\"\n",
    "message.Html = \"<p>Hello, this is a test email</p>\"\n",
    "message.Body = \"Hello, this is a test email\"\n",
    "\n",
    "sender = Mailer('smtp.example.com')\n",
    "sender.login(\"youremail@example.com\", \"yourpassword\")\n",
    "sender.send(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc7e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78705b47",
   "metadata": {},
   "source": [
    "# Extract tables from websites using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "164d3e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables: 6\n",
      "                                                   0  \\\n",
      "0  .mw-parser-output .legend{page-break-inside:av...   \n",
      "\n",
      "                                                   1  \\\n",
      "0  $20,000 - $30,000 $10,000 - $20,000 $5,000 - $...   \n",
      "\n",
      "                                             2  \n",
      "0  $1,000 - $2,500 $500 - $1,000 <$500 No data  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract tables from a website\n",
    "tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)_per_capita')\n",
    "\n",
    "# Print the number of tables extracted\n",
    "print(f'Number of tables: {len(tables)}')\n",
    "\n",
    "# Print the first table\n",
    "print(tables[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4946a23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: six>=1.9 in d:\\programfiles\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in d:\\programfiles\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Installing collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3127e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
